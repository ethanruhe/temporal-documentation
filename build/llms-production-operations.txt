# Temporal Production Deployment and Operations

> Build invincible applications

This file contains all documentation content in a single document following the llmstxt.org standard.

## Temporal CLI activity command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## complete

Complete an Activity, marking it as successfully finished. Specify the
Activity ID and include a JSON result for the returned value:

```
temporal activity complete \
    --activity-id YourActivityId \
    --workflow-id YourWorkflowId \
    --result '{"YourResultKey": "YourResultVal"}'
```

Use the following options to change the behavior of this command.

**Flags:**

**--activity-id** _string_

Activity ID to complete. Required.

**--result** _string_

Result `JSON` to return. Required.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## fail

Fail an Activity, marking it as having encountered an error. Specify the
Activity and Workflow IDs:

```
temporal activity fail \
    --activity-id YourActivityId \
    --workflow-id YourWorkflowId
```

Use the following options to change the behavior of this command.

**Flags:**

**--activity-id** _string_

Activity ID to fail. Required.

**--detail** _string_

Reason for failing the Activity (JSON).

**--reason** _string_

Reason for failing the Activity.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## pause

Pause an Activity.

If the Activity is not currently running (e.g. because it previously
failed), it will not be run again until it is unpaused.

However, if the Activity is currently running, it will run until the next
time it fails, completes, or times out, at which point the pause will kick in.

If the Activity is on its last retry attempt and fails, the failure will
be returned to the caller, just as if the Activity had not been paused.

Activities should be specified either by their Activity ID or Activity Type.

For example, specify the Activity and Workflow IDs like this:

```
temporal activity pause \
    --activity-id YourActivityId \
    --workflow-id YourWorkflowId
```

To later unpause the activity, see [unpause](#unpause). You may also want to
[reset](#reset) the activity to unpause it while also starting it from the beginning.

Use the following options to change the behavior of this command.

**Flags:**

**--activity-id**, **-a** _string_

The Activity ID to pause. Either `activity-id` or `activity-type` must be provided, but not both.

**--activity-type** _string_

All activities of the Activity Type will be paused. Either `activity-id` or `activity-type` must be provided, but not both.

**--identity** _string_

The identity of the user or client submitting this request.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## reset

Reset an activity. This restarts the activity as if it were first being
scheduled. That is, it will reset both the number of attempts and the
activity timeout, as well as, optionally, the
[heartbeat details](#reset-heartbeats).

If the activity may be executing (i.e. it has not yet timed out), the
reset will take effect the next time it fails, heartbeats, or times out.
If is waiting for a retry (i.e. has failed or timed out), the reset
will apply immediately.

If the activity is already paused, it will be unpaused by default.
You can specify `keep_paused` to prevent this.

If the activity is paused and the `keep_paused` flag is not provided,
it will be unpaused. If the activity is paused and `keep_paused` flag
is provided - it will stay paused.

Activities can be specified by their Activity ID or Activity Type.

### Resetting activities that heartbeat {#reset-heartbeats}

Activities that heartbeat will receive a [Canceled failure](/references/failures#cancelled-failure)
the next time they heartbeat after a reset.

If, in your Activity, you need to do any cleanup when an Activity is
reset, handle this error and then re-throw it when you've cleaned up.

If the `reset_heartbeats` flag is set, the heartbeat details will also be cleared.

Specify the Activity Type of ID and Workflow IDs:

```
temporal activity reset \
    --activity-id YourActivityId \
    --workflow-id YourWorkflowId
    --keep-paused
    --reset-heartbeats
```

Either `activity-id`, `activity-type`, or `--match-all` must be specified.

Activities can be reset in bulk with a visibility query list filter.
For example, if you want to reset activities of type Foo:

```
temporal activity reset \
    --query 'TemporalResetInfo="property:activityType=Foo"'
```

Use the following options to change the behavior of this command.

**Flags:**

**--activity-id**, **-a** _string_

The Activity ID to reset. Either `activity-id` or `activity-type` must be provided, but not both.

**--activity-type** _string_

The Activity Type to reset. Either `activity-id` or `activity-type` must be provided, but not both.

**--identity** _string_

The identity of the user or client submitting this request.

**--jitter** _duration_

The activity will reset at random a time within the specified duration. Can only be used with --query.

**--keep-paused** _bool_

If the activity was paused, it will stay paused.

**--match-all** _bool_

Every activity should be reset. Every activity should be updated. Mutually exclusive with `--activity-id` and `--activity-type`.

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for batch operation. Only use with --query. Defaults to user name.

**--reset-attempts** _bool_

Reset the activity attempts.

**--reset-heartbeats** _bool_

Clear the Activity's heartbeat details.

**--restore-original-options** _bool_

Restore the original options of the activity.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Only use with --workflow-id. Cannot use with --query.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm signaling. Only allowed when --query is present.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## unpause

Re-schedule a previously-paused Activity for execution.

If the Activity is not running and is past its retry timeout, it will be
scheduled immediately. Otherwise, it will be scheduled after its retry
timeout expires.

Use `--reset-attempts` to reset the number of previous run attempts to
zero. For example, if an Activity is near the maximum number of attempts
N specified in its retry policy, `--reset-attempts` will allow the
Activity to be retried another N times after unpausing.

Use `--reset-heartbeat` to reset the Activity's heartbeats.

Activities can be specified by their Activity ID or Activity Type.
One of those parameters must be provided.

Specify the Activity ID or Type and Workflow IDs:

```
temporal activity unpause \
    --activity-id YourActivityId \
    --workflow-id YourWorkflowId
    --reset-attempts
    --reset-heartbeats
```

Activities can be unpaused in bulk via a visibility Query list filter.
For example, if you want to unpause activities of type Foo that you
previously paused, do:

```
temporal activity unpause \
    --query 'TemporalPauseInfo="property:activityType=Foo"'
```

Use the following options to change the behavior of this command.

**Flags:**

**--activity-id**, **-a** _string_

The Activity ID to unpause. Can only be used without --query or --match-all. Either `activity-id` or `activity-type` must be provided, but not both.

**--activity-type**, **-g** _string_

Activities of this Type will unpause. Can only be used without --match-all. Either `activity-id` or `activity-type` must be provided, but not both.

**--identity** _string_

The identity of the user or client submitting this request.

**--jitter** _duration_

The activity will start at random a time within the specified duration. Can only be used with --query.

**--match-all** _bool_

Every paused activity should be unpaused. This flag is ignored if activity-type is provided.

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for batch operation. Only use with --query. Defaults to user name.

**--reset-attempts** _bool_

Reset the activity attempts.

**--reset-heartbeats** _bool_

Reset the Activity's heartbeats. Only works with --reset-attempts.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Only use with --workflow-id. Cannot use with --query.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm signaling. Only allowed when --query is present.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## update-options

Update the options of a running Activity that were passed into it from
a Workflow. Updates are incremental, only changing the specified
options.

For example:

```
temporal activity update-options \
    --activity-id YourActivityId \
    --workflow-id YourWorkflowId \
    --task-queue NewTaskQueueName \
    --schedule-to-close-timeout DURATION \
    --schedule-to-start-timeout DURATION \
    --start-to-close-timeout DURATION \
    --heartbeat-timeout DURATION \
    --retry-initial-interval DURATION \
    --retry-maximum-interval DURATION \
    --retry-backoff-coefficient NewBackoffCoefficient \
    --retry-maximum-attempts NewMaximumAttempts
```

You may follow this command with `temporal activity reset`, and the new values will apply after the reset.

Either `activity-id`, `activity-type`, or `--match-all` must be specified.

Activity options can be updated in bulk with a visibility query list filter.
For example, if you want to reset for activities of type Foo, do:

```
temporal activity update-options \
    --query 'TemporalPauseInfo="property:activityType=Foo"'
    ...
```

You may follow this command with `temporal activity reset`, and the new values will apply after the reset.

Use the following options to change the behavior of this command.

**Flags:**

**--activity-id**, **-a** _string_

The Activity ID to update options. Mutually exclusive with `--query`, `--match-all`, and `--activity-type`. Requires `--workflow-id` to be specified.

**--activity-type** _string_

Activities of this Type will be updated. Mutually exclusive with `--match-all` and `activity-id`.

**--heartbeat-timeout** _duration_

Maximum permitted time between successful worker heartbeats.

**--match-all** _bool_

Every activity should be updated. Mutually exclusive with `--activity-id` and `--activity-type`.

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for batch operation. Only use with --query. Defaults to user name.

**--restore-original-options** _bool_

Restore the original options of the activity.

**--retry-backoff-coefficient** _float_

Coefficient used to calculate the next retry interval. The next retry interval is previous interval multiplied by the backoff coefficient. Must be 1 or larger.

**--retry-initial-interval** _duration_

Interval of the first retry. If retryBackoffCoefficient is 1.0 then it is used for all retries.

**--retry-maximum-attempts** _int_

Maximum number of attempts. When exceeded the retries stop even if not expired yet. Setting this value to 1 disables retries. Setting this value to 0 means unlimited attempts(up to the timeouts).

**--retry-maximum-interval** _duration_

Maximum interval between retries. Exponential backoff leads to interval increase. This value is the cap of the increase.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Only use with --workflow-id. Cannot use with --query.

**--schedule-to-close-timeout** _duration_

Indicates how long the caller is willing to wait for an activity completion. Limits how long retries will be attempted.

**--schedule-to-start-timeout** _duration_

Limits time an activity task can stay in a task queue before a worker picks it up. This timeout is always non retryable, as all a retry would achieve is to put it back into the same queue. Defaults to the schedule-to-close timeout or workflow execution timeout if not specified.

**--start-to-close-timeout** _duration_

Maximum time an activity is allowed to execute after being picked up by a worker. This timeout is always retryable.

**--task-queue** _string_

Name of the task queue for the Activity.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm signaling. Only allowed when --query is present.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI batch command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## describe

Show the progress of an ongoing batch job. Pass a valid job ID to display its
information:

```
temporal batch describe \
    --job-id YourJobId
```

Use the following options to change the behavior of this command.

**Flags:**

**--job-id** _string_

Batch job ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## list

Return a list of batch jobs on the Service or within a single Namespace. For
example, list the batch jobs for "YourNamespace":

```
temporal batch list \
    --namespace YourNamespace
```

Use the following options to change the behavior of this command.

**Flags:**

**--limit** _int_

Maximum number of batch jobs to display.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## terminate

Terminate a batch job with the provided job ID. You must provide a reason for
the termination. The Service stores this explanation as metadata for the
termination event for later reference:

```
temporal batch terminate \
    --job-id YourJobId \
    --reason YourTerminationReason
```

Use the following options to change the behavior of this command.

**Flags:**

**--job-id** _string_

Job ID to terminate. Required.

**--reason** _string_

Reason for terminating the batch job. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI command options reference

## active-cluster

Active cluster name.

## activity-id

Identifies the Activity Execution.

## activity-jitter

If set, the Activity will start at a random time within the specified jitter duration.

## activity-type

Command is applied to the all running activities with of this type.

## address

The host and port (formatted as host:port) for the Temporal Frontend Service.

## api-key

API key for request.

## archived

List archived Workflow Executions.

:::note

Caution: `--archived` is experimental.

:::

## build-id

Identifies the build to retrieve reachability information for.
Can be specified multiple times.

## calendar

Calendar specification in JSON `({"dayOfWeek":"Fri","hour":"17","minute":"5"})` or as a Cron string `("30 2 \* \* 5" or "@daily")`.

## catchup-window

Maximum allowed catch-up time if server is down.

## cluster

Cluster name.

## codec-auth

Sets the authorization header on requests to the Codec Server.

## codec-endpoint

Endpoint for a remote Codec Server.

## color

When to use color: auto, always, never. (default: auto)

## command-timeout

The command execution timeout. 0s means no timeout.

## concurrency

Request concurrency.

## cron

The Cron schedule can be formatted like the following:

```text
┌───────────── minute (0 - 59)
│ ┌───────────── hour (0 - 23)
│ │ ┌───────────── day of the month (1 - 31)
│ │ │ ┌───────────── month (1 - 12)
│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
│ │ │ │ │
* * * * *
```

## data

Namespace data in a key=value format.

Values must be in JSON format.

## db-filename

File in which to persist Temporal state.
By default, Workflows are lost when the process dies.

## depth

The number of Child Workflows to fetch and expand.
Use `-1` to fetch Child Workflows at any depth.

## description

Namespace description or Nexus Endpoint description.
You may use Markdown formatting in the Nexus Endpoint description.

## description-file

Path to the Nexus Endpoint description file.
The contents of the description file may use Markdown formatting.

## detail

A provided reason for failing an Activity.

## dry-run

Simulate reset without resetting any Workflow Executions.

## dynamic-config-value

Dynamic config value, formatted as `KEY=JSON_VALUE`.
String values require quotation marks.

## email

Owner email.

## enable-connection

Enable cross-cluster connection.

## end-time

Backfill end time.

## env

Name of the environment to read environmental variables from.

## env-file

Path to environment settings file.
Defaults to `$HOME/.config/temporalio/temporal.yaml`.

## event-id

The Event Id for any Event after WorkflowTaskStarted you want to reset to (exclusive).
It can be WorkflowTaskCompleted, WorkflowTaskFailed or others.

## exclude-file

Input file that specifies Workflow Executions to exclude from resetting.

## execution-timeout

Timeout (in seconds) for a [Workflow Execution](/workflow-execution), including retries and `ContinueAsNew` tasks.

## existing-compatible-build-id

A Build Id that already exists in the version sets known by the Task Queue.
New Build Ids are stored in the version set containing this Id, making them compatible with the versions in that set.

## fields

Customize fields to print.
Set to 'long' to automatically print more of main fields.

## first-execution-run-id

Run update on the last execution in the chain that started with this Run Id.

## fold

Statuses for which Child Workflows will be folded in (this will reduce the number of information fetched and displayed).
Case-insensitive and ignored if `--no-fold` is supplied.

## follow

Follow the progress of a Workflow Execution.

## frontend-address

Frontend address of the remote Cluster.

## global

Flag to indicate whether a Namespace is a Global Namespace.

## grpc-meta

Contains gRPC metadata to send with requests (format: `key=value`).
Values must be in a valid JSON format.

## headless

Disable the Web UI.

## heartbeat-timeout

Maximum permitted time between successful Worker Heartbeats.

## history-archival-state

Sets the history archival state.
Valid values are "disabled" and "enabled".

## history-uri

Optionally specify history archival URI (cannot be changed after first time archival is enabled).

## id-reuse-policy

Allows the same Workflow Id to be used in a new Workflow Execution.
Options: AllowDuplicate, AllowDuplicateFailedOnly, RejectDuplicate, TerminateIfRunning.

## identity

Specify operator's identity.

## input

Use the `--input` command option to include data in the command.

This command option accepts a valid JSON string.
If the entity that the command is acting on accepts multiple parameters, pass "null" for null values within the JSON string.

The following is an example of starting a Workflow with the `--input` command option.
This Workflow expects a single string as a parameter:

```shell
temporal workflow start --input '"+1 555-555-5555"'
```

## input-file

Passes optional input for the Workflow from a JSON file.
If there are multiple JSON files, concatenate them and separate by space or newline.
Input from the command line will overwrite file input.

## input-parallelism

Number of goroutines to run in parallel.
Each goroutine processes one line for every second.

## input-separator

Separator for the input file. The default is a tab (`\t`).

## interval

Interval duration, such as 90m, or 90m/13m to include phase offset.

## ip

IPv4 address to bind the frontend service to.
(default: 127.0.0.1)

## jitter

Jitter duration.

## job-id

Batch Job Id.

## keep-paused

If this flag is provided and Activity was paused, it will stay paused after reset.

## limit

Number of items to print on a page.

## log-format

Set the log formatting.
Options: ["json", "pretty"].

## log-level

Set the log level.
Options: ["debug" "info" "warn" "error" "fatal"].

## match-all

If set, all currently running activities will be unpaused.

## max-field-length

Maximum length for each attribute field.

## max-sets

Limits how many compatible sets will be returned.
Specify 1 to return only the current default major version set.
0 returns all sets.

## memo

Set a memo on a schedule (format: key=value).
Use valid JSON formats for value.

## memo-file

Set a memo from a file.
Each line should follow the format key=value.
Use valid JSON formats for value.

## metrics-port

Port for `/metrics`.
Enabled by default with a randomly assigned port.

## name

Frontend address of the remote Cluster or the Endpoint name.

## namespace

Identifies a Namespace in the Temporal Workflow.

## namespace-id

Namespace Id.

## no-fold

Disable folding.
All Child Workflows within the set depth will be fetched and displayed.

## no-json-shorthand-payloads

Raw payload output, even if the JSON option was used.

## no-pager

Disables the interactive pager.

## non-deterministic

Reset Workflow Execution only if its last Event is `WorkflowTaskFailed` with a nondeterminism error.

## notes

Initial value of notes field.

## output

Format of output.
Options: table, json, card.

## overlap-policy

Overlap policy.
Options: Skip, BufferOne, BufferAll, CancelOther, TerminateOther, AllowAll.

## pager

Sets the pager for the Temporal CLI to use.
Options are less, more, and favoritePager.

## pause

Pauses the Schedule.

## pause-on-failure

Pause schedule after any Workflow failure.

## port

Port for the frontend gRPC service.

## promote-global

Promote local Namespace to Global Namespace.

## query

Provides a SQL-like Query of Search Attributes to return Workflow Executions to reset.
For more information, refer to the [`temporal workflow list`](/cli/workflow#list) command.

## raw

Print raw data in a JSON format.
For scripting, we recommend using this option instead of `-o json`.

## reachability-type

Specify how you'd like to filter the reachability of Build IDs.
The following are valid choices:

- `open`: reachable by one or more open Workflows.
- `closed`: reachable by one or more closed Workflows.
- `existing`: reachable by either open or closed Workflows.

Build IDs that are reachable by new Workflows are always reported.

## reapply-type

Event types to reapply after the reset point.
Options: Signal, None.

## reason

Reason for the operation.

## reject-condition

Optional flag for rejecting Queries based on Workflow state.
Valid values are "not_open" and "not_completed_cleanly".

## remaining-actions

Total number of actions allowed.

## reset-attempts

Providing this flag will reset the number of attempts.

## reset-heartbeat

Providing this flag will reset the heartbeat details.

## reset-points

Only show Workflow Events that are eligible for reset.

## result

Set the result value of Activity completion.

## retention

Workflow Execution retention.

## retry-backoff-coefficient

Coefficient used to calculate the next retry interval.
The next retry interval is previous interval multiplied by the coefficient.
Must be 1 or larger.

## retry-initial-interval

Interval of the first retry. If retryBackoffCoefficient is 1.0 then it is used for all retries.

## retry-maximum-attempts

Maximum number of attempts. When exceeded the retries stop even if not expired yet.
1 disables retries. 0 means unlimited (up to the timeouts).

## retry-maximum-interval

Maximum interval between retries. Exponential backoff leads to interval increase.
This value is the cap of the increase. Default is 100x of the initial interval.

## run-id

Identifies the current Workflow Run.

## run-timeout

Timeout (in seconds) of a single Workflow run.

## schedule-id

Schedule Id.

## schedule-to-close-timeout

Indicates how long the caller is willing to wait for an Activity completion.
Limits how long retries will be attempted.

## schedule-to-start-timeout

Limits time an Activity Task can stay in a task queue before a Worker picks it up.
This timeout is always non retryable, as all a retry would achieve is to put it back into the same queue.
Defaults to `schedule_to_close_timeout` or workflow execution timeout if not specified.

## search-attribute

Set Search Attribute on a Schedule (formatted as `key=value`).
Use valid JSON formats for value.

## set-as-default

When set, establishes the compatible set being targeted as the default for the Task Queue.

If a different set is the current default, the targeted set replaces it.

## skip-base-is-not-current

Skip a Workflow Execution if the base Workflow Run is not the current Workflow Run.

## skip-current-open

Skip a Workflow Execution if the current Run is open for the same Workflow Id as the base Run.

## sqlite-pragma

Specify sqlite pragma statements in pragma=value format.
Pragma options: ["journal_mode" "synchronous"].

## start-delay

Specify a delay before the workflow starts.

## start-time

Backfill start time.

## start-to-close-timeout

Maximum time an Activity is allowed to execute after being picked up by a Worker.
This Timeout is always retryable.

## target-namespace

Namespace in which a handler Worker will poll for Nexus tasks.

## target-task-queue

Task Queue in which a handler Worker will poll for Nexus tasks.

## target-url

An external Nexus Endpoint where Nexus requests are forwarded to.
May be used as an alternative to `--target-namespace` and `--target-task-queue`.

:::note

Caution: `--target-url` is experimental.

:::

## task-queue

Task Queue.

## task-queue-type

Task Queue type, which can be either Workflow or Activity.
The default type is Workflow.

## task-timeout

Start-to-close timeout for a Workflow Task (in seconds).

## time-format

Format time as: relative, iso, raw.

## time-zone

Time zone (IANA name).

## tls

Enable TLS encryption without additional options such as mTLS or client certificates.

## tls-ca-data

Data for server CA certificate. Can't be used with --tls-ca-path.

## tls-ca-path

Path to server CA certificate.

## tls-cert-data

Data for x509 certificate. Can't be used with --tls-cert-path.

## tls-cert-path

Path to x509 certificate.

## tls-disable-host-verification

Disables TLS host name verification.

## tls-key-data

Private certificate key data. Can't be used with --tls-key-path.

## tls-key-path

Path to private certificate key.

## tls-server-name

Overrides the target TLS server name.

## type

Search attribute type.
Options: Text, Keyword, Int, Double, Bool, Datetime, KeywordList.

## ui-asset-path

UI Custom Assets path.

## ui-codec-endpoint

UI Remote data converter HTTP endpoint.

## ui-ip

IPv4 address to bind the Web UI to.

## ui-port

Port for the Web UI.
Default: `--port` + 1000 (for example, 4000).

## unpause

Unpauses the Schedule.

## unset-description

Unset the description.

## verbose

Print applied Namespace changes.

## visibility-archival-state

Visibility Archival state.
Valid values: "disabled", "enabled".

## visibility-uri

Specify URI for Visibility Archival.
This cannot be changed after Archival is enabled.

## workflow-id

Workflow Id.

## workflow-type

Workflow type name.

## yes

Confirm all prompts.

---

## Temporal CLI config command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## delete

Remove a property within a profile.

```
temporal env delete \
    --prop tls.client_cert_path
```

Use the following options to change the behavior of this command.

**Flags:**

**--prop**, **-p** _string_

Specific property to delete. If unset, deletes entire profile. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## delete-profile

Remove a full profile entirely. The `--profile` must be set explicitly.

```
temporal env delete-profile \
    --profile my-profile
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## get

Display specific properties or the entire profile.

```
temporal config get \
    --prop address
```

or

```
temporal config get
```

Use the following options to change the behavior of this command.

**Flags:**

**--prop**, **-p** _string_

Specific property to get.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## list

List profile names in the config file.

```
temporal config list
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## set

Assign a value to a property and store it in the config file:

```
temporal config set \
    --prop address \
    --value us-west-2.aws.api.temporal.io:7233
```

Use the following options to change the behavior of this command.

**Flags:**

**--prop**, **-p** _string_

Property name. Required.

**--value**, **-v** _string_

Property value. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI env command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## delete

Remove a presets environment entirely _or_ remove a key-value pair within an
environment. If you don't specify an environment (with `--env` or by setting
the `TEMPORAL_ENV` variable), this command updates the "default" environment:

```
temporal env delete \
    --env YourEnvironment
```

or

```
temporal env delete \
    --env prod \
    --key tls-key-path
```

Use the following options to change the behavior of this command.

**Flags:**

**--key**, **-k** _string_

Property name.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## get

List the properties for a given environment:

```
temporal env get \
    --env YourEnvironment
```

Print a single property:

```
temporal env get \
    --env YourEnvironment \
    --key YourPropertyKey
```

If you don't specify an environment (with `--env` or by setting the
`TEMPORAL_ENV` variable), this command lists properties of the "default"
environment.

Use the following options to change the behavior of this command.

**Flags:**

**--key**, **-k** _string_

Property name.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## list

List the environments you have set up on your local computer. Environments are
stored in "$HOME/.config/temporalio/temporal.yaml".

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## set

Assign a value to a property key and store it to an environment:

```
temporal env set \
    --env environment \
    --key property \
    --value value
```

If you don't specify an environment (with `--env` or by setting the
`TEMPORAL_ENV` variable), this command sets properties in the "default"
environment.

Storing keys with CLI option names lets the CLI automatically set those
options for you. This reduces effort and helps avoid typos when issuing
commands.

Use the following options to change the behavior of this command.

**Flags:**

**--key**, **-k** _string_

Property name (required).

**--value**, **-v** _string_

Property value (required).

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI command reference

The Temporal CLI provides direct access to a Temporal Service via the terminal.
It's a powerful tool for managing, monitoring, and debugging Temporal Applications.
You can use it to start, stop, inspect and operate on Workflows and Activities, and perform administrative tasks such as Namespace, Schedule, and Task Queue management.

The Temporal CLI also includes an embedded Temporal Service suitable for use in development and CI/CD.
It includes the [Temporal Server](/temporal-service/temporal-server), SQLite persistence, and the [Temporal Web UI](/web-ui).

:::note

When upgrading from [tctl](/tctl-v1) to the Temporal CLI, make sure to update your environment variables and use updated commands.
For details, see [CLI release notes](https://github.com/temporalio/cli/releases/).

:::

## Install the Temporal CLI {#install}

**How to download and install the Temporal CLI**

The Temporal CLI is available on macOS, Windows, and Linux, or as a Docker image.

### How to install the Temporal CLI on macOS

Choose one of the following install methods to install the Temporal CLI on macOS:

- Install the Temporal CLI with Homebrew.

```shell
brew install temporal
```

- Install the Temporal CLI from CDN.

  1. Select the platform and architecture needed.

  - Download for Darwin amd64: https://temporal.download/cli/archive/latest?platform=darwin&arch=amd64
  - Download for Darwin arm64: https://temporal.download/cli/archive/latest?platform=darwin&arch=arm64

  2. Extract the downloaded archive.

  3. Add the Temporal CLI binary to your PATH.

### How to install the Temporal CLI on Linux

Choose one of the following install methods to install the Temporal CLI on Linux:

- Install the Temporal CLI from CDN.

  1. Select the platform and architecture needed.

  - Download for Linux amd64: https://temporal.download/cli/archive/latest?platform=linux&arch=amd64
  - Download for Linux arm64: https://temporal.download/cli/archive/latest?platform=linux&arch=arm64

  2. Extract the downloaded archive.

  3. Add the `temporal` binary to your PATH.

### How to install the Temporal CLI on Windows

Choose one of the following methods to install the Temporal CLI on Windows:

- Install the Temporal CLI from CDN.

  1. Select the platform and architecture needed and download the binary.

  - Download for Windows amd64: https://temporal.download/cli/archive/latest?platform=windows&arch=amd64
  - Download for Windows arm64: https://temporal.download/cli/archive/latest?platform=windows&arch=arm64

  2. Extract the downloaded archive.

  3. Add the `temporal.exe` binary to your PATH.

### How to run the Temporal CLI inside Docker

Temporal CLI container image is available on [DockerHub](https://hub.docker.com/r/temporalio/temporal) and can be run directly:

```shell
docker run --rm temporalio/temporal --help
```

:::note

When running the CLI inside Docker, for the development server to be accessible from the host system,
the server needs to be configured to listen on external IP and the ports need to be forwarded:

```shell
docker run --rm -p 7233:7233 -p 8233:8233 temporalio/temporal server start-dev --ip 0.0.0.0
# UI is now accessible from host at http://localhost:8233/
```

:::

## Command set

- [temporal activity](/cli/activity/)
- [temporal batch](/cli/batch/)
- [temporal env](/cli/env/)
- [temporal operator](/cli/operator/)
- [temporal schedule](/cli/schedule/)
- [temporal server](/cli/server)
- [temporal task-queue](/cli/task-queue/)
- [temporal workflow](/cli/workflow/)

## Configuration

The following information provides important configuration details.

### Namespace registration

Namespaces are pre-registered at startup for immediate use.
Customize pre-registered Namespaces with the following command:

```shell
temporal server start-dev --namespace foo --namespace bar
```

Register Namespaces with `namespace create`:

```shell
temporal operator namespace create --namespace foo
```

### Enable or disable Temporal UI

By default, the Temporal UI is enabled when running the development server using the Temporal CLI.
To disable the UI, use the `--headless` modifier:

```shell
temporal server start-dev --headless
```

### Dynamic configuration

Advanced Temporal CLI configuration requires a dynamic configuration file.

To set values on the command line, use `--dynamic-config-value KEY=JSON_VALUE`.
For example, enable the Search Attribute cache:

```bash
temporal server start-dev --dynamic-config-value system.forceSearchAttributesCacheRefreshOnRead=false
```

This setting makes created Search Attributes immediately available.

## Environment variables

The following table describes the environment variables you can set for the Temporal CLI.

<!-- This is an automatically generated file and the TEMPORAL_API_KEY correction will disappear on the next push. -->

| Variable                                 | Definition                                                                | Client Option                   |
| ---------------------------------------- | ------------------------------------------------------------------------- | ------------------------------- |
| `TEMPORAL_ADDRESS`                       | Host and port (formatted as host:port) for the Temporal Frontend Service. | --address                       |
| `TEMPORAL_CODEC_AUTH`                    | Authorization header for requests to Codec Server.                        | --codec-auth                    |
| `TEMPORAL_CODEC_ENDPOINT`                | Endpoint for remote Codec Server.                                         | --codec-endpoint                |
| `TEMPORAL_NAMESPACE`                     | Namespace in Temporal Workflow. Default: "default".                       | --namespace                     |
| `TEMPORAL_TLS_CA`                        | Path to server CA certificate.                                            | --tls-ca-path                   |
| `TEMPORAL_TLS_CERT`                      | Path to x509 certificate.                                                 | --tls-cert-path                 |
| `TEMPORAL_TLS_DISABLE_HOST_VERIFICATION` | Disables TLS host name verification. Default: false.                      | --tls-disable-host-verification |
| `TEMPORAL_TLS_KEY`                       | Path to private certificate key.                                          | --tls-key-path                  |
| `TEMPORAL_TLS_SERVER_NAME`               | Override for target TLS server name.                                      | --tls-server-name               |
| `TEMPORAL_API_KEY`                       | API key used for authentication.                                          | --api-key                       |

<!-- This is an automatically generated file and this caution will disappear on the next push. -->
<!-- issue: https://github.com/temporalio/cli/issues/776 -->

:::tip ENVIRONMENT VARIABLES

Do not confuse environment variables, set with your shell, with temporal env options.

:::

## Proxy support

The Temporal CLI provides support for users who are operating behind a proxy.
This feature ensures seamless communication even in network-restricted environments.

#### Setting up proxy support

If you are behind a proxy, you'll need to instruct the Temporal CLI to route its requests via that proxy.
You can achieve this by setting the `HTTPS_PROXY` environment variable.

```command
export HTTPS_PROXY=<host>:<port>
```

Replace `<host>` with the proxy's hostname or IP address, and `<port>` with the proxy's port number.

Once set, you can run the Temporal CLI commands as you normally would.

:::note

Temporal CLI uses the gRPC library which natively supports HTTP CONNECT proxies. The gRPC library checks for the `HTTPS_PROXY` (and its case-insensitive variants) environment variable to determine if it should route requests through a proxy.

:::

In addition to `HTTPS_PROXY`, gRPC also respects the `NO_PROXY` environment variable.
This can be useful if there are specific addresses or domains you wish to exclude from proxying.

For more information, see [Proxy](https://github.com/grpc/grpc-go/blob/master/Documentation/proxy.md) in the gRPC documentation.

## Auto-completion

Enable auto-completion using the following commands.

### zsh auto-completion

1. Add the following line to your `~/.zshrc` startup script:

   ```sh
   eval "$(temporal completion zsh)"
   ```

2. Re-launch your shell or run:

   ```sh
   source ~/.zshrc
   ```

### Bash auto-completion

1. Install [bash-completion](https://github.com/scop/bash-completion#installation) and add the software to your `~/.bashrc`.

2. Add the following line to your `~/.bashrc` startup script:

   ```sh
   eval "$(temporal completion bash)"
   ```

3. Re-launch your shell or run:

   ```sh
   source ~/.bashrc
   ```

:::note

If auto-completion fails with the error: `bash: _get_comp_words_by_ref: command not found`, you did not successfully install [bash-completion](https://github.com/scop/bash-completion#installation). This package must be loaded into your shell for `temporal` auto-completion to work.

:::

### Fish auto-completion

1. Create the Fish custom completions directory if it does not already exist:

   ```fish
   mkdir -p ~/.config/fish/completions
   ```

2. Configure the completions to load when needed. Note: the file name must be `temporal.fish` or the completions will not be found:

   ```fish
   echo 'eval "$(temporal completion fish)"' >~/.config/fish/completions/temporal.fish
   ```

3. Re-launch your shell or run:

   ```fish
   source ~/.config/fish/completions/temporal.fish
   ```

## Temporal dev server {#start-dev-server}

**How to start the Temporal development server**

To start the Temporal development server run the following command:

```bash
temporal server start-dev
```

This command automatically starts the Web UI, creates the `default` [Namespace](/namespaces), and uses an in-memory database.

The Temporal Server should be available on `localhost:7233` and the Temporal Web UI should be available at [`http://localhost:8233`](http://localhost:8233/).

The in-memory SQLite database does not persist if you stop the dev server.
Use the `--db-filename` option to specify a database file, persisting application state.
This is helpful if you plan on stopping and re-starting the dev server.

```shell
temporal server start-dev --db-filename temporal.db
```

:::note

Local databases created with `--db-filename` may not be compatible with newer versions of the Temporal CLI.
The `temporal server` command is only intended for development environments.

:::

For the full list of dev server options use the `--help` flag:

```shell
temporal server start-dev --help
```

## Common CLI operations {#common-operations}

The following are some of the more common operations you can perform with the Temporal CLI.

### Start a Workflow

In another terminal, use the following commands to interact with the Server.
The following command starts a Workflow:

```shell
$ temporal workflow start \
  --task-queue hello-world \
  --type MyWorkflow \
  --workflow-id 123 \
  --input 456

Running execution:
  WorkflowId                                   123
  RunId       357074e4-0dd8-4c44-8367-d92536dd0943
  Type        MyWorkflow
  Namespace   default
  TaskQueue   hello-world
  Args        [456]
```

Shorthand options are available:

```shell
temporal workflow start --task-queue hello-world --type MyWorkflow --workflow-id 123 --input 456
```

You can also list and describe Workflows:

```shell
$ temporal workflow list

  Status   WorkflowId     Name       StartTime
  Running         123  MyWorkflow  14 seconds ago

$ temporal workflow describe --workflow-id 123

{
  "executionConfig": {
    "taskQueue": {
      "name": "hello-world",
      "kind": "Normal"
    },
    "workflowExecutionTimeout": "0s",
    "workflowRunTimeout": "0s",
    "defaultWorkflowTaskTimeout": "10s"
  },
  "workflowExecutionInfo": {
    "execution": {
      "workflowId": "123",
      "runId": "357074e4-0dd8-4c44-8367-d92536dd0943"
    },
    "type": {
      "name": "MyWorkflow"
    },
    "startTime": "2023-04-15T06:42:31.191137Z",
    "status": "Running",
    "historyLength": "2",
    "executionTime": "2023-04-15T06:42:31.191137Z",
    "memo": {

    },
    "autoResetPoints": {

    },
    "stateTransitionCount": "1"
  },
  "pendingWorkflowTask": {
    "state": "Scheduled",
    "scheduledTime": "2023-04-15T06:42:31.191173Z",
    "originalScheduledTime": "2023-04-15T06:42:31.191173Z",
    "attempt": 1
  }
}
```

For more detailed output in JSON format, use the following command:

```shell
$ temporal workflow list --fields long --output json

[
  {
    "execution": {
      "workflow_id": "123",
      "run_id": "357074e4-0dd8-4c44-8367-d92536dd0943"
    },
    "type": {
      "name": "MyWorkflow"
    },
    "start_time": "2023-04-15T06:42:31.191137Z",
    "status": 1,
    "execution_time": "2023-04-15T06:42:31.191137Z",
    "memo": {},
    "task_queue": "hello-world"
  }
]
```

Filter out Workflows based on Workflow Type with [jq](https://stedolan.github.io/jq/):

```shell
$ temporal workflow list --fields long --output json | jq '.[].type.name'

"OtherWorkflow"
"MyWorkflow"
"MyWorkflow"
```

To count the number of Workflows, use the following command:

```shell
$ temporal workflow list --fields long --output json | jq '.[].type.name' | uniq -c

   1 "OtherWorkflow"
   2 "MyWorkflow"
```

To see the full range of Workflow-related commands, run `temporal workflow` or see the [Temporal CLI workflow command reference](/cli/workflow).

For a full list of available commands, run `temporal` without arguments or see [Available commands](#command-set).

### Customize your environment variables

To communicate with a different Server, like a production Namespace on Temporal Cloud:

1. Create an environment named `prod`.
2. Pass `--env prod` to commands, like `temporal workflow list --env prod`.

To create a new environment and set its properties:

```shell
temporal env set prod.namespace production.f45a2
temporal env set prod.address production.f45a2.tmprl.cloud:7233
temporal env set prod.tls-cert-path /temporal/certs/prod.pem
temporal env set prod.tls-key-path /temporal/certs/prod.key
```

Check your settings:

```shell
$ temporal env get prod

  address        production.f45a2.tmprl.cloud:7233
  namespace      production.f45a2
  tls-cert-path  /temporal/certs/prod.pem
  tls-key-path   /temporal/certs/prod.key
```

Run a command to test the connection:

```shell
$ temporal workflow list --env prod
```

For a full list of properties, use `temporal env set -h`.

```shell
$ temporal env set -h

OPTIONS:
   Client Options:

   --address value                          The host and port (formatted as host:port) for the Temporal Frontend Service. [$TEMPORAL_CLI_ADDRESS]
   --codec-auth value                       Sets the authorization header on requests to the Codec Server. [$TEMPORAL_CLI_CODEC_AUTH]
   --codec-endpoint value                   Endpoint for a remote Codec Server. [$TEMPORAL_CLI_CODEC_ENDPOINT]
   --command-timeout duration               Timeout for the span of a command. (default 0s)
   --env value                              Name of the environment to read environmental variables from. (default: "default")
   --grpc-meta value [ --grpc-meta value ]  Contains gRPC metadata to send with requests (format: key=value). Values must be in a valid JSON format.
   --namespace value, -n value              Identifies a Namespace in the Temporal Workflow. (default: "default") [$TEMPORAL_CLI_NAMESPACE]
   --tls-ca-path value                      Path to server CA certificate. [$TEMPORAL_CLI_TLS_CA]
   --tls-cert-path value                    Path to x509 certificate. [$TEMPORAL_CLI_TLS_CERT]
   --tls-disable-host-verification          Disables TLS host name verification if already enabled. (default: false) [$TEMPORAL_CLI_TLS_DISABLE_HOST_VERIFICATION]
   --tls-key-path value                     Path to private certificate key. [$TEMPORAL_CLI_TLS_KEY]
   --tls-server-name value                  Provides an override for the target TLS server name. [$TEMPORAL_CLI_TLS_SERVER_NAME]

   Display Options:

   --color value  when to use color: auto, always, never. (default: "auto")
```

---

## Temporal CLI operator command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## cluster

Perform operator actions on Temporal Services (also known as Clusters).

```
temporal operator cluster [subcommand] [options]
```

For example to check Service/Cluster health:

```
temporal operator cluster health
```

### describe

View information about a Temporal Cluster (Service), including Cluster Name,
persistence store, and visibility store. Add `--detail` for additional info:

```
temporal operator cluster describe [--detail]
```

Use the following options to change the behavior of this command.

**Flags:**

**--detail** _bool_

Show history shard count and Cluster/Service version information.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### health

View information about the health of a Temporal Service:

```
temporal operator cluster health
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### list

Print a list of remote Temporal Clusters (Services) registered to the local
Service. Report details include the Cluster's name, ID, address, History Shard
count, Failover version, and availability:

```
temporal operator cluster list [--limit max-count]
```

Use the following options to change the behavior of this command.

**Flags:**

**--limit** _int_

Maximum number of Clusters to display.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### remove

Remove a registered remote Temporal Cluster (Service) from the local Service.

```
temporal operator cluster remove \
    --name YourClusterName
```

Use the following options to change the behavior of this command.

**Flags:**

**--name** _string_

Cluster/Service name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### system

Show Temporal Server information for Temporal Clusters (Service): Server
version, scheduling support, and more. This information helps diagnose
problems with the Temporal Server.

The command defaults to the local Service. Otherwise, use the
`--frontend-address` option to specify a Cluster (Service) endpoint:

```
temporal operator cluster system \
    --frontend-address "YourRemoteEndpoint:YourRemotePort"
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### upsert

Add, remove, or update a registered ("remote") Temporal Cluster (Service).

```
temporal operator cluster upsert [options]
```

For example:

```
temporal operator cluster upsert \
    --frontend-address "YourRemoteEndpoint:YourRemotePort"
    --enable-connection false
```

Use the following options to change the behavior of this command.

**Flags:**

**--enable-connection** _bool_

Set the connection to "enabled".

**--frontend-address** _string_

Remote endpoint. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## namespace

Manage Temporal Cluster (Service) Namespaces:

```
temporal operator namespace [command] [command options]
```

For example:

```
temporal operator namespace create \
    --namespace YourNewNamespaceName
```

### create

Create a new Namespace on the Temporal Service:

```
temporal operator namespace create \
    --namespace YourNewNamespaceName \
    [options]
```

Create a Namespace with multi-region data replication:

```
temporal operator namespace create \
    --global \
    --namespace YourNewNamespaceName
```

Configure settings like retention and Visibility Archival State as needed.
For example, the Visibility Archive can be set on a separate URI:

```
temporal operator namespace create \
    --retention 5d \
    --visibility-archival-state enabled \
    --visibility-uri YourURI \
    --namespace YourNewNamespaceName
```

Note: URI values for archival states can't be changed once enabled.

Use the following options to change the behavior of this command.

**Flags:**

**--active-cluster** _string_

Active Cluster (Service) name.

**--cluster** _string[]_

Cluster (Service) names for Namespace creation. Can be passed multiple times.

**--data** _string[]_

Namespace data as `KEY=VALUE` pairs. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--description** _string_

Namespace description.

**--email** _string_

Owner email.

**--global** _bool_

Enable multi-region data replication.

**--history-archival-state** _string-enum_

History archival state. Accepted values: disabled, enabled. (default "disabled")

**--history-uri** _string_

Archive history to this `URI`. Once enabled, can't be changed.

**--retention** _duration_

Time to preserve closed Workflows before deletion. (default "72h")

**--visibility-archival-state** _string-enum_

Visibility archival state. Accepted values: disabled, enabled. (default "disabled")

**--visibility-uri** _string_

Archive visibility data to this `URI`. Once enabled, can't be changed.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### delete

Removes a Namespace from the Service.

```
temporal operator namespace delete [options]
```

For example:

```
temporal operator namespace delete \
    --namespace YourNamespaceName
```

Use the following options to change the behavior of this command.

**Flags:**

**--yes**, **-y** _bool_

Request confirmation before deletion.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### describe

Provide long-form information about a Namespace identified by its ID or name:

```
temporal operator namespace describe \
    --namespace-id YourNamespaceId
```

or

```
temporal operator namespace describe \
    --namespace YourNamespaceName
```

Use the following options to change the behavior of this command.

**Flags:**

**--namespace-id** _string_

Namespace ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### list

Display a detailed listing for all Namespaces on the Service:

```
temporal operator namespace list
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### update

Update a Namespace using properties you specify.

```
temporal operator namespace update [options]
```

Assign a Namespace's active Cluster (Service):

```
temporal operator namespace update \
    --namespace YourNamespaceName \
    --active-cluster NewActiveCluster
```

Promote a Namespace for multi-region data replication:

```
temporal operator namespace update \
    --namespace YourNamespaceName \
    --promote-global
```

You may update archives that were previously enabled or disabled. Note: URI
values for archival states can't be changed once enabled.

```
temporal operator namespace update \
    --namespace YourNamespaceName \
    --history-archival-state enabled \
    --visibility-archival-state disabled
```

Use the following options to change the behavior of this command.

**Flags:**

**--active-cluster** _string_

Active Cluster (Service) name.

**--cluster** _string[]_

Cluster (Service) names.

**--data** _string[]_

Namespace data as `KEY=VALUE` pairs. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--description** _string_

Namespace description.

**--email** _string_

Owner email.

**--history-archival-state** _string-enum_

History archival state. Accepted values: disabled, enabled.

**--history-uri** _string_

Archive history to this `URI`. Once enabled, can't be changed.

**--promote-global** _bool_

Enable multi-region data replication.

**--retention** _duration_

Length of time a closed Workflow is preserved before deletion.

**--visibility-archival-state** _string-enum_

Visibility archival state. Accepted values: disabled, enabled.

**--visibility-uri** _string_

Archive visibility data to this `URI`. Once enabled, can't be changed.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## nexus

These commands manage Nexus resources.

Nexus commands follow this syntax:

```
temporal operator nexus [command] [subcommand] [options]
```

### endpoint

These commands manage Nexus Endpoints.

Nexus Endpoint commands follow this syntax:

```
temporal operator nexus endpoint [command] [options]
```

#### create

Create a Nexus Endpoint on the Server.

A Nexus Endpoint name is used in Workflow code to invoke Nexus Operations.
The endpoint target may either be a Worker, in which case
`--target-namespace` and `--target-task-queue` must both be provided, or
an external URL, in which case `--target-url` must be provided.

This command will fail if an Endpoint with the same name is already
registered.

```
temporal operator nexus endpoint create \
  --name your-endpoint \
  --target-namespace your-namespace \
  --target-task-queue your-task-queue \
  --description-file DESCRIPTION.md
```

Use the following options to change the behavior of this command.

**Flags:**

**--description** _string_

Nexus Endpoint description. You may use Markdown formatting in the Nexus Endpoint description.

**--description-file** _string_

Path to the Nexus Endpoint description file. The contents of the description file may use Markdown formatting.

**--name** _string_

Endpoint name. Required.

**--target-namespace** _string_

Namespace where a handler Worker polls for Nexus tasks.

**--target-task-queue** _string_

Task Queue that a handler Worker polls for Nexus tasks.

**--target-url** _string_

An external Nexus Endpoint that receives forwarded Nexus requests. May be used as an alternative to `--target-namespace` and `--target-task-queue`.

:::note

Option is experimental.

:::

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

#### delete

Delete a Nexus Endpoint from the Server.

```
temporal operator nexus endpoint delete --name your-endpoint
```

Use the following options to change the behavior of this command.

**Flags:**

**--name** _string_

Endpoint name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

#### get

Get a Nexus Endpoint by name from the Server.

```
temporal operator nexus endpoint get --name your-endpoint
```

Use the following options to change the behavior of this command.

**Flags:**

**--name** _string_

Endpoint name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

#### list

List all Nexus Endpoints on the Server.

```
temporal operator nexus endpoint list
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

#### update

Update an existing Nexus Endpoint on the Server.

A Nexus Endpoint name is used in Workflow code to invoke Nexus Operations.
The Endpoint target may either be a Worker, in which case
`--target-namespace` and `--target-task-queue` must both be provided, or
an external URL, in which case `--target-url` must be provided.

The Endpoint is patched; existing fields for which flags are not provided
are left as they were.

Update only the target task queue:

```
temporal operator nexus endpoint update \
  --name your-endpoint \
  --target-task-queue your-other-queue
```

Update only the description:

```
temporal operator nexus endpoint update \
  --name your-endpoint \
  --description-file DESCRIPTION.md
```

Use the following options to change the behavior of this command.

**Flags:**

**--description** _string_

Nexus Endpoint description. You may use Markdown formatting in the Nexus Endpoint description.

**--description-file** _string_

Path to the Nexus Endpoint description file. The contents of the description file may use Markdown formatting.

**--name** _string_

Endpoint name. Required.

**--target-namespace** _string_

Namespace where a handler Worker polls for Nexus tasks.

**--target-task-queue** _string_

Task Queue that a handler Worker polls for Nexus tasks.

**--target-url** _string_

An external Nexus Endpoint that receives forwarded Nexus requests. May be used as an alternative to `--target-namespace` and `--target-task-queue`.

:::note

Option is experimental.

:::

**--unset-description** _bool_

Unset the description.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## search-attribute

Create, list, or remove Search Attributes fields stored in a Workflow
Execution's metadata:

```
temporal operator search-attribute create \
    --name YourAttributeName \
    --type Keyword
```

Supported types include: Text, Keyword, Int, Double, Bool, Datetime, and
KeywordList.

If you wish to delete a Search Attribute, please contact support
at https://support.temporal.io.

### create

Add one or more custom Search Attributes:

```
temporal operator search-attribute create \
    --name YourAttributeName \
    --type Keyword
```

Use the following options to change the behavior of this command.

**Flags:**

**--name** _string[]_

Search Attribute name. Required.

**--type** _string-enum[]_

Search Attribute type. Required. Accepted values: Text, Keyword, Int, Double, Bool, Datetime, KeywordList.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### list

Display a list of active Search Attributes that can be assigned or used with
Workflow Queries. You can manage this list and add attributes as needed:

```
temporal operator search-attribute list
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### remove

Remove custom Search Attributes from the options that can be assigned or used
with Workflow Queries.

```
temporal operator search-attribute remove \
    --name YourAttributeName
```

Remove attributes without confirmation:

```
temporal operator search-attribute remove \
    --name YourAttributeName \
    --yes
```

Use the following options to change the behavior of this command.

**Flags:**

**--name** _string[]_

Search Attribute name. Required.

**--yes**, **-y** _bool_

Don't prompt to confirm removal.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI schedule command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## backfill

Batch-execute actions that would have run during a specified time interval.
Use this command to fill in Workflow runs from when a Schedule was paused,
before a Schedule was created, from the future, or to re-process a previously
executed interval.

Backfills require a Schedule ID and the time period covered by the request.
It's best to use the `BufferAll` or `AllowAll` policies to avoid conflicts
and ensure no Workflow Executions are skipped.

For example:

```
temporal schedule backfill \
    --schedule-id "YourScheduleId" \
    --start-time "2022-05-01T00:00:00Z" \
    --end-time "2022-05-31T23:59:59Z" \
    --overlap-policy BufferAll
```

The policies include:

- **AllowAll**: Allow unlimited concurrent Workflow Executions. This
  significantly speeds up the backfilling process on systems that support
  concurrency. You must ensure running Workflow Executions do not interfere
  with each other.
- **BufferAll**: Buffer all incoming Workflow Executions while waiting for
  the running Workflow Execution to complete.
- **Skip**: If a previous Workflow Execution is still running, discard new
  Workflow Executions.
- **BufferOne**: Same as 'Skip' but buffer a single Workflow Execution to be
  run after the previous Execution completes. Discard other Workflow
  Executions.
- **CancelOther**: Cancel the running Workflow Execution and replace it with
  the incoming new Workflow Execution.
- **TerminateOther**: Terminate the running Workflow Execution and replace
  it with the incoming new Workflow Execution.

Use the following options to change the behavior of this command.

**Flags:**

**--end-time** _timestamp_

Backfill end time. Required.

**--overlap-policy** _string-enum_

Policy for handling overlapping Workflow Executions. Accepted values: Skip, BufferOne, BufferAll, CancelOther, TerminateOther, AllowAll. (default "Skip")

**--schedule-id**, **-s** _string_

Schedule ID. Required.

**--start-time** _timestamp_

Backfill start time. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## create

Create a new Schedule on the Temporal Service. A Schedule automatically starts
new Workflow Executions at the times you specify.

For example:

```
temporal schedule create \
  --schedule-id "YourScheduleId" \
  --calendar '{"dayOfWeek":"Fri","hour":"3","minute":"30"}' \
  --workflow-id YourBaseWorkflowIdName \
  --task-queue YourTaskQueue \
  --type YourWorkflowType
```

Schedules support any combination of `--calendar`, `--interval`, and `--cron`:

- Shorthand `--interval` strings.
  For example: 45m (every 45 minutes) or 6h/5h (every 6 hours, at the top of
  the 5th hour).
- JSON `--calendar`, as in the preceding example.
- Unix-style `--cron` strings and robfig declarations
  (@daily/@weekly/@every X/etc).
  For example, every Friday at 12:30 PM: `30 12 * * Fri`.

Use the following options to change the behavior of this command.

**Flags:**

**--calendar** _string[]_

Calendar specification in JSON. For example: `{"dayOfWeek":"Fri","hour":"17","minute":"5"}`.

**--catchup-window** _duration_

Maximum catch-up time for when the Service is unavailable.

**--cron** _string[]_

Calendar specification in cron string format. For example: `"30 12 * * Fri"`.

**--end-time** _timestamp_

Schedule end time.

**--execution-timeout** _duration_

Fail a WorkflowExecution if it lasts longer than `DURATION`. This time-out includes retries and ContinueAsNew tasks.

**--fairness-key** _string_

Fairness key (max 64 bytes) for proportional task dispatch. Tasks with same key share capacity based on their weight.

**--fairness-weight** _float_

Weight [0.001-1000] for this fairness key. Keys are dispatched proportionally to their weights.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--interval** _string[]_

Interval duration. For example, 90m, or 60m/15m to include phase offset.

**--jitter** _duration_

Max difference in time from the specification. Vary the start time randomly within this amount.

**--memo** _string[]_

Memo using 'KEY="VALUE"' pairs. Use JSON values.

**--notes** _string_

Initial notes field value.

**--overlap-policy** _string-enum_

Policy for handling overlapping Workflow Executions. Accepted values: Skip, BufferOne, BufferAll, CancelOther, TerminateOther, AllowAll. (default "Skip")

**--pause-on-failure** _bool_

Pause schedule after Workflow failures.

**--paused** _bool_

Pause the Schedule immediately on creation.

**--priority-key** _int_

Priority key (1-5, lower numbers = higher priority). Tasks in a queue should be processed in close-to-priority-order. Default is 3 when not specified.

**--remaining-actions** _int_

Total allowed actions. Default is zero (unlimited).

**--run-timeout** _duration_

Fail a Workflow Run if it lasts longer than `DURATION`.

**--schedule-id**, **-s** _string_

Schedule ID. Required.

**--schedule-memo** _string[]_

Set schedule memo using `KEY="VALUE` pairs. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--schedule-search-attribute** _string[]_

Set schedule Search Attributes using `KEY="VALUE` pairs. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--search-attribute** _string[]_

Search Attribute in `KEY=VALUE` format. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--start-time** _timestamp_

Schedule start time.

**--static-details** _string_

Static Workflow details for human consumption in UIs. Uses Temporal Markdown formatting, may be multiple lines.

:::note

Option is experimental.

:::

**--static-summary** _string_

Static Workflow summary for human consumption in UIs. Uses Temporal Markdown formatting, should be a single line.

:::note

Option is experimental.

:::

**--task-queue**, **-t** _string_

Workflow Task queue. Required.

**--task-timeout** _duration_

Fail a Workflow Task if it lasts longer than `DURATION`. This is the Start-to-close timeout for a Workflow Task. (default "10s")

**--time-zone** _string_

Interpret calendar specs with the `TZ` time zone. For a list of time zones, see: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones.

**--type** _string_

Workflow Type name. Required.

**--workflow-id**, **-w** _string_

Workflow ID. If not supplied, the Service generates a unique ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## delete

Deletes a Schedule on the front end Service:

```
temporal schedule delete \
    --schedule-id YourScheduleId
```

Removing a Schedule won't affect the Workflow Executions it started that are
still running. To cancel or terminate these Workflow Executions, use `temporal workflow delete` with the `TemporalScheduledById` Search Attribute instead.

Use the following options to change the behavior of this command.

**Flags:**

**--schedule-id**, **-s** _string_

Schedule ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## describe

Show a Schedule configuration, including information about past, current, and
future Workflow runs:

```
temporal schedule describe \
    --schedule-id YourScheduleId
```

Use the following options to change the behavior of this command.

**Flags:**

**--schedule-id**, **-s** _string_

Schedule ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## list

Lists the Schedules hosted by a Namespace:

```
temporal schedule list \
    --namespace YourNamespace
```

Use the following options to change the behavior of this command.

**Flags:**

**--long**, **-l** _bool_

Show detailed information.

**--query**, **-q** _string_

Filter results using given List Filter.

**--really-long** _bool_

Show extensive information in non-table form.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## toggle

Pause or unpause a Schedule by passing a flag with your desired state:

```
temporal schedule toggle \
    --schedule-id "YourScheduleId" \
    --pause \
    --reason "YourReason"
```

and

```
temporal schedule toggle
    --schedule-id "YourScheduleId" \
    --unpause \
    --reason "YourReason"
```

The `--reason` text updates the Schedule's `notes` field for operations
communication. It defaults to "(no reason provided)" if omitted. This field is
also visible on the Service Web UI.

Use the following options to change the behavior of this command.

**Flags:**

**--pause** _bool_

Pause the Schedule.

**--reason** _string_

Reason for pausing or unpausing the Schedule. (default "(no reason provided)")

**--schedule-id**, **-s** _string_

Schedule ID. Required.

**--unpause** _bool_

Unpause the Schedule.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## trigger

Trigger a Schedule to run immediately:

```
temporal schedule trigger \
    --schedule-id "YourScheduleId"
```

Use the following options to change the behavior of this command.

**Flags:**

**--overlap-policy** _string-enum_

Policy for handling overlapping Workflow Executions. Accepted values: Skip, BufferOne, BufferAll, CancelOther, TerminateOther, AllowAll. (default "Skip")

**--schedule-id**, **-s** _string_

Schedule ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## update

Update an existing Schedule with new configuration details, including time
specifications, action, and policies:

```
temporal schedule update \
    --schedule-id "YourScheduleId" \
    --workflow-type "NewWorkflowType"
```

Use the following options to change the behavior of this command.

**Flags:**

**--calendar** _string[]_

Calendar specification in JSON. For example: `{"dayOfWeek":"Fri","hour":"17","minute":"5"}`.

**--catchup-window** _duration_

Maximum catch-up time for when the Service is unavailable.

**--cron** _string[]_

Calendar specification in cron string format. For example: `"30 12 * * Fri"`.

**--end-time** _timestamp_

Schedule end time.

**--execution-timeout** _duration_

Fail a WorkflowExecution if it lasts longer than `DURATION`. This time-out includes retries and ContinueAsNew tasks.

**--fairness-key** _string_

Fairness key (max 64 bytes) for proportional task dispatch. Tasks with same key share capacity based on their weight.

**--fairness-weight** _float_

Weight [0.001-1000] for this fairness key. Keys are dispatched proportionally to their weights.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--interval** _string[]_

Interval duration. For example, 90m, or 60m/15m to include phase offset.

**--jitter** _duration_

Max difference in time from the specification. Vary the start time randomly within this amount.

**--memo** _string[]_

Memo using 'KEY="VALUE"' pairs. Use JSON values.

**--notes** _string_

Initial notes field value.

**--overlap-policy** _string-enum_

Policy for handling overlapping Workflow Executions. Accepted values: Skip, BufferOne, BufferAll, CancelOther, TerminateOther, AllowAll. (default "Skip")

**--pause-on-failure** _bool_

Pause schedule after Workflow failures.

**--paused** _bool_

Pause the Schedule immediately on creation.

**--priority-key** _int_

Priority key (1-5, lower numbers = higher priority). Tasks in a queue should be processed in close-to-priority-order. Default is 3 when not specified.

**--remaining-actions** _int_

Total allowed actions. Default is zero (unlimited).

**--run-timeout** _duration_

Fail a Workflow Run if it lasts longer than `DURATION`.

**--schedule-id**, **-s** _string_

Schedule ID. Required.

**--schedule-memo** _string[]_

Set schedule memo using `KEY="VALUE` pairs. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--schedule-search-attribute** _string[]_

Set schedule Search Attributes using `KEY="VALUE` pairs. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--search-attribute** _string[]_

Search Attribute in `KEY=VALUE` format. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--start-time** _timestamp_

Schedule start time.

**--static-details** _string_

Static Workflow details for human consumption in UIs. Uses Temporal Markdown formatting, may be multiple lines.

:::note

Option is experimental.

:::

**--static-summary** _string_

Static Workflow summary for human consumption in UIs. Uses Temporal Markdown formatting, should be a single line.

:::note

Option is experimental.

:::

**--task-queue**, **-t** _string_

Workflow Task queue. Required.

**--task-timeout** _duration_

Fail a Workflow Task if it lasts longer than `DURATION`. This is the Start-to-close timeout for a Workflow Task. (default "10s")

**--time-zone** _string_

Interpret calendar specs with the `TZ` time zone. For a list of time zones, see: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones.

**--type** _string_

Workflow Type name. Required.

**--workflow-id**, **-w** _string_

Workflow ID. If not supplied, the Service generates a unique ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI server command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## start-dev

Run a development Temporal Server on your local system.

+------------------------------------------------------------------------+
| WARNING: The development server is not intended for production use. |
| It skips certain HTTP security checks to make local use simpler. |
| |
| For production use, see: |
| https://docs.temporal.io/production-deployment |
+------------------------------------------------------------------------+

View the Web UI for the default configuration at: http://localhost:8233

```
temporal server start-dev
```

Add persistence for Workflow Executions across runs:

```
temporal server start-dev \
    --db-filename path-to-your-local-persistent-store
```

Set the port from the front-end gRPC Service (7233 default):

```
temporal server start-dev \
    --port 7000
```

Use a custom port for the Web UI. The default is the gRPC port (7233 default)
plus 1000 (8233):

```
temporal server start-dev \
    --ui-port 3000
```

Use the following options to change the behavior of this command.

**Flags:**

**--db-filename**, **-f** _string_

Path to file for persistent Temporal state store. By default, Workflow Executions are lost when the server process dies.

**--dynamic-config-value** _string[]_

Dynamic configuration value using `KEY=VALUE` pairs. Keys must be identifiers, and values must be JSON values. For example: 'YourKey="YourString"'. Can be passed multiple times.

**--headless** _bool_

Disable the Web UI.

**--http-port** _int_

Port for the HTTP API service. Defaults to a random free port. (default "0")

**--ip** _string_

IP address bound to the front-end Service. (default "localhost")

**--log-config** _bool_

Log the server config to stderr.

**--metrics-port** _int_

Port for '/metrics'. Default is off.

**--namespace**, **-n** _string[]_

Namespaces to be created at launch. The "default" Namespace is always created automatically.

**--port**, **-p** _int_

Port for the front-end gRPC Service. (default "7233")

**--search-attribute** _string[]_

Search attributes to register using `KEY=VALUE` pairs. Keys must be identifiers, and values must be the search attribute type, which is one of the following: Text, Keyword, Int, Double, Bool, Datetime, KeywordList.

**--sqlite-pragma** _string[]_

SQLite pragma statements in "PRAGMA=VALUE" format.

**--ui-asset-path** _string_

UI custom assets path.

**--ui-codec-endpoint** _string_

UI remote codec HTTP endpoint.

**--ui-ip** _string_

IP address bound to the Web UI. Default is same as '--ip' value.

**--ui-port** _int_

Port for the Web UI. Default is '--port' value + 1000.

**--ui-public-path** _string_

The public base path for the Web UI. Default is `/`.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Set up the Temporal CLI

The Temporal CLI is a command-line tool for interacting with the Temporal Service.
It helps you manage, monitor, and debug Temporal applications.
You can also use it to run a local development server and interact with Temporal Applications from the command line.

With the Temporal CLI, you can:

- Run a local Temporal Service for development
- Start Workflow Executions on any Temporal Service (local, self-hosted, or Temporal Cloud)
- Interact with running Workflows
- Inspect the state of Workflows and Activities
- Manage Namespaces, Schedules, and Task Queues
- Monitor and debug application behavior

## Install the CLI

The CLI is available for macOS, Linux, and Windows, or as a Docker image.

<Tabs>

<TabItem value="macosinstall" label="macOS">

Install with Homebrew:

```bash
brew install temporal
```

Or download from the CDN:

- [Darwin amd64](https://temporal.download/cli/archive/latest?platform=darwin&arch=amd64)
- [Darwin arm64](https://temporal.download/cli/archive/latest?platform=darwin&arch=arm64)

Extract the archive and add the `temporal` binary to your `PATH`.

</TabItem>

<TabItem value="linuxinstall" label="Linux">

Install with Homebrew (if available):

```bash
brew install temporal
```

Or download from the CDN:

- [Linux amd64](https://temporal.download/cli/archive/latest?platform=linux&arch=amd64)
- [Linux arm64](https://temporal.download/cli/archive/latest?platform=linux&arch=arm64)

Extract the archive and add the `temporal` binary to your `PATH`.

</TabItem>

<TabItem value="windowsinstall" label="Windows">

Download from the CDN:

- [Windows amd64](https://temporal.download/cli/archive/latest?platform=windows&arch=amd64)
- [Windows arm64](https://temporal.download/cli/archive/latest?platform=windows&arch=arm64)

Extract the archive and add the `temporal.exe` binary to your `PATH`.

</TabItem>

<TabItem value="dockerinstall" label="Docker">

Temporal CLI container image is available on [DockerHub](https://hub.docker.com/r/temporalio/temporal) and can be run directly:

```shell
docker run --rm temporalio/temporal --help
```

</TabItem>

</Tabs>

## Run the development server

The CLI includes a local Temporal development service for fast feedback while building your application.

Start the server:

```bash
temporal server start-dev \
   --db-filename path/to/local-persistent-store
```

View available options:

```bash
temporal server start-dev \
   --help
```

:::note

When running the CLI inside Docker, for the development server to be accessible from the host system,
the server needs to be configured to listen on external IP and the ports need to be forwarded:

```shell
docker run --rm \
   -p 7233:7233 -p 8233:8233 \
   temporalio/temporal server start-dev \
      --ip 0.0.0.0
# UI is now accessible from host at http://localhost:8233/
```

:::

### What the local server provides

- A local instance of the Temporal Service
- Automatic startup of the Web UI
- A default Namespace
- Optional persistence using SQLite

Omitting `--db-filename` uses an in-memory database. This speeds up testing but does not persist Workflow data between sessions.

### Access the Web UI

- Temporal Service: `localhost:7233`
- Web UI: [http://localhost:8233](http://localhost:8233)

:::tip
The CLI works with all Temporal SDKs.
Use it to develop and test your application before deploying to production.
:::

## Getting CLI help

From the command line:

```
temporal <command> <subcommand> --help
```

For example:

- `temporal --help`
- `temporal workflow --help`
- `temporal workflow delete --help`

Available commands

| Command                            | Description                                                 |
| ---------------------------------- | ----------------------------------------------------------- |
| [**activity**](/cli/activity)      | Complete, update, pause, unpause, reset or fail an Activity |
| [**batch**](/cli/batch)            | Manage running batch jobs                                   |
| [**completion**](/cli/cmd-options) | Generate the autocompletion script for the specified shell  |
| [**env**](/cli/env)                | Manage environments                                         |
| [**operator**](/cli/operator)      | Manage Temporal deployments                                 |
| [**schedule**](/cli/schedule)      | Perform operations on Schedules                             |
| [**server**](/cli/server)          | Run Temporal Server                                         |
| [**task-queue**](/cli/task-queue)  | Manage Task Queues                                          |
| [**worker**](/cli/worker)          | Read or update Worker state                                 |
| [**workflow**](/cli/workflow)      | Start, list, and operate on Workflows                       |

---

## Temporal CLI task-queue command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## describe

Display a list of active Workers that have recently polled a Task Queue. The
Temporal Server records each poll request time. A `LastAccessTime` over one
minute may indicate the Worker is at capacity or has shut down. Temporal
Workers are removed if 5 minutes have passed since the last poll request.

```
temporal task-queue describe \
  --task-queue YourTaskQueue
```

This command provides poller information for a given Task Queue.
Workflow and Activity polling use separate Task Queues:

```
temporal task-queue describe \
    --task-queue YourTaskQueue \
    --task-queue-type "activity"
```

This command provides the following task queue statistics:

- `ApproximateBacklogCount`: The approximate number of tasks backlogged in this
  task queue. May count expired tasks but eventually converges to the right
  value.
- `ApproximateBacklogAge`: Approximate age of the oldest task in the backlog,
  based on its creation time, measured in seconds.
- `TasksAddRate`: Approximate rate at which tasks are being added to the task
  queue, measured in tasks per second, averaged over the last 30 seconds.
  Includes tasks dispatched immediately without going to the backlog
  (sync-matched tasks), as well as tasks added to the backlog. (See note below.)
- `TasksDispatchRate`: Approximate rate at which tasks are being dispatched from
  the task queue, measured in tasks per second, averaged over the last 30
  seconds. Includes tasks dispatched immediately without going to the backlog
  (sync-matched tasks), as well as tasks added to the backlog. (See note below.)
- `BacklogIncreaseRate`: Approximate rate at which the backlog size is
  increasing (if positive) or decreasing (if negative), measured in tasks per
  second, averaged over the last 30 seconds. This is roughly equivalent to:
  `TasksAddRate` - `TasksDispatchRate`.

NOTE: The `TasksAddRate` and `TasksDispatchRate` metrics may differ from the
actual rate of add/dispatch, because tasks may be dispatched eagerly to an
available worker, or may apply only to specific workers (they are "sticky").
Such tasks are not counted by these metrics. Despite the inaccuracy of
these two metrics, the derived metric of `BacklogIncreaseRate` is accurate
for backlogs older than a few seconds.

Safely retire Workers assigned a Build ID by checking reachability across
all task types. Use the flag `--report-reachability`:

```
temporal task-queue describe \
    --task-queue YourTaskQueue \
    --build-id "YourBuildId" \
    --report-reachability
```

Task reachability information is returned for the requested versions and all
task types, which can be used to safely retire Workers with old code versions,
provided that they were assigned a Build ID.

Note that task reachability status is experimental and may significantly change
or be removed in a future release. Also, determining task reachability incurs a
non-trivial computing cost.

Task reachability states are reported per build ID. The state may be one of the
following:

- `Reachable`: using the current versioning rules, the Build ID may be used
  by new Workflow Executions or Activities OR there are currently open
  Workflow or backlogged Activity tasks assigned to the queue.
- `ClosedWorkflowsOnly`: the Build ID does not have open Workflow Executions
  and can't be reached by new Workflow Executions. It MAY have closed
  Workflow Executions within the Namespace retention period.
- `Unreachable`: this Build ID is not used for new Workflow Executions and
  isn't used by any existing Workflow Execution within the retention period.

Task reachability is eventually consistent. You may experience a delay until
reachability converges to the most accurate value. This is designed to act
in the most conservative way until convergence. For example, `Reachable` is
more conservative than `ClosedWorkflowsOnly`.

Use the following options to change the behavior of this command.

**Flags:**

**--disable-stats** _bool_

Disable task queue statistics.

**--legacy-mode** _bool_

Enable a legacy mode for servers that do not support rules-based worker versioning. This mode only provides pollers info.

**--partitions-legacy** _int_

Query partitions 1 through `N`. Experimental/Temporary feature. Legacy mode only. (default "1")

**--report-reachability** _bool_

Display task reachability information.

**--select-all-active** _bool_

Include all active versions. A version is active if it had new tasks or polls recently.

**--select-build-id** _string[]_

Filter the Task Queue based on Build ID.

**--select-unversioned** _bool_

Include the unversioned queue.

**--task-queue**, **-t** _string_

Task Queue name. Required.

**--task-queue-type** _string-enum[]_

Task Queue type. If not specified, all types are reported. Accepted values: workflow, activity, nexus.

**--task-queue-type-legacy** _string-enum_

Task Queue type (legacy mode only). Accepted values: workflow, activity. (default "workflow")

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## get-build-id-reachability

+-----------------------------------------------------------------------------+
| CAUTION: This command is deprecated and will be removed in a later release. |
+-----------------------------------------------------------------------------+

Show if a given Build ID can be used for new, existing, or closed Workflows
in Namespaces that support Worker versioning:

```
temporal task-queue get-build-id-reachability \
    --task-queue YourTaskQueue \
    --build-id "YourBuildId"
```

You can specify the `--build-id` and `--task-queue` flags multiple times. If
`--task-queue` is omitted, the command checks Build ID reachability against
all Task Queues.

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string[]_

One or more Build ID strings. Can be passed multiple times.

**--reachability-type** _string-enum_

Reachability filter. `open`: reachable by one or more open workflows. `closed`: reachable by one or more closed workflows. `existing`: reachable by either. New Workflow Executions reachable by a Build ID are always reported. Accepted values: open, closed, existing. (default "existing")

**--task-queue**, **-t** _string[]_

Search only the specified task queue(s). Can be passed multiple times.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## get-build-ids

+-----------------------------------------------------------------------------+
| CAUTION: This command is deprecated and will be removed in a later release. |
+-----------------------------------------------------------------------------+

Fetch sets of compatible Build IDs for specified Task Queues and display their
information:

```
temporal task-queue get-build-ids \
    --task-queue YourTaskQueue
```

This command is limited to Namespaces that support Worker versioning.

Use the following options to change the behavior of this command.

**Flags:**

**--max-sets** _int_

Max return count. Use 1 for default major version. Use 0 for all sets. (default "0")

**--task-queue**, **-t** _string_

Task Queue name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## list-partition

Display a Task Queue's partition list with assigned matching nodes:

```
temporal task-queue list-partition \
    --task-queue YourTaskQueue
```

Use the following options to change the behavior of this command.

**Flags:**

**--task-queue**, **-t** _string_

Task Queue name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## update-build-ids

+-----------------------------------------------------------------------------+
| CAUTION: This command is deprecated and will be removed in a later release. |
+-----------------------------------------------------------------------------+

Add or change a Task Queue's compatible Build IDs for Namespaces using Worker
versioning:

```
temporal task-queue update-build-ids [subcommands] [options] \
    --task-queue YourTaskQueue
```

### add-new-compatible

Add a compatible Build ID to a Task Queue's existing version set. Provide an
existing Build ID and a new Build ID:

```
temporal task-queue update-build-ids add-new-compatible \
    --task-queue YourTaskQueue \
    --existing-compatible-build-id "YourExistingBuildId" \
    --build-id "YourNewBuildId"
```

The new ID is stored in the set containing the existing ID and becomes the new
default for that set.

This command is limited to Namespaces that support Worker versioning.

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID to be added. Required.

**--existing-compatible-build-id** _string_

Pre-existing Build ID in this Task Queue. Required.

**--set-as-default** _bool_

Set the expanded Build ID set as the Task Queue default.

**--task-queue**, **-t** _string_

Task Queue name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### add-new-default

+-----------------------------------------------------------------------------+
| CAUTION: This command is deprecated and will be removed in a later release. |
+-----------------------------------------------------------------------------+

Create a new Task Queue Build ID set, add a Build ID to it, and make it the
overall Task Queue default. The new set will be incompatible with previous
sets and versions.

```
temporal task-queue update-build-ids add-new-default \
    --task-queue YourTaskQueue \
    --build-id "YourNewBuildId"
```

+------------------------------------------------------------------------+
| NOTICE: This command is limited to Namespaces that support Worker |
| versioning. Worker versioning is experimental. Versioning commands are |
| subject to change. |
+------------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID to be added. Required.

**--task-queue**, **-t** _string_

Task Queue name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### promote-id-in-set

+-----------------------------------------------------------------------------+
| CAUTION: This command is deprecated and will be removed in a later release. |
+-----------------------------------------------------------------------------+

Establish an existing Build ID as the default in its Task Queue set. New tasks
compatible with this set will now be dispatched to this ID:

```
temporal task-queue update-build-ids promote-id-in-set \
    --task-queue YourTaskQueue \
    --build-id "YourBuildId"
```

+------------------------------------------------------------------------+
| NOTICE: This command is limited to Namespaces that support Worker |
| versioning. Worker versioning is experimental. Versioning commands are |
| subject to change. |
+------------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID to set as default. Required.

**--task-queue**, **-t** _string_

Task Queue name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### promote-set

+-----------------------------------------------------------------------------+
| CAUTION: This command is deprecated and will be removed in a later release. |
+-----------------------------------------------------------------------------+

Promote a Build ID set to be the default on a Task Queue. Identify the set by
providing a Build ID within it. If the set is already the default, this
command has no effect:

```
temporal task-queue update-build-ids promote-set \
    --task-queue YourTaskQueue \
    --build-id "YourBuildId"
```

+------------------------------------------------------------------------+
| NOTICE: This command is limited to Namespaces that support Worker |
| versioning. Worker versioning is experimental. Versioning commands are |
| subject to change. |
+------------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID within the promoted set. Required.

**--task-queue**, **-t** _string_

Task Queue name. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## versioning

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Provides commands to add, list, remove, or replace Worker Build ID assignment
and redirect rules associated with Task Queues:

```
temporal task-queue versioning [subcommands] [options] \
    --task-queue YourTaskQueue
```

Task Queues support the following versioning rules and policies:

- Assignment Rules: manage how new executions are assigned to run on specific
  Worker Build IDs. Each Task Queue stores a list of ordered Assignment Rules,
  which are evaluated from first to last. Assignment Rules also allow for
  gradual rollout of new Build IDs by setting ramp percentage.
- Redirect Rules: automatically assign work for a source Build ID to a target
  Build ID. You may add at most one redirect rule for each source Build ID.
  Redirect rules require that a target Build ID is fully compatible with
  the source Build ID.

### add-redirect-rule

Add a new redirect rule for a given Task Queue. You may add at most one
redirect rule for each distinct source build ID:

```
temporal task-queue versioning add-redirect-rule \
    --task-queue YourTaskQueue \
    --source-build-id "YourSourceBuildID" \
    --target-build-id "YourTargetBuildID"
```

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--source-build-id** _string_

Source build ID. Required.

**--target-build-id** _string_

Target build ID. Required.

**--yes**, **-y** _bool_

Don't prompt to confirm.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### commit-build-id

Complete a Build ID's rollout and clean up unnecessary rules that might have
been created during a gradual rollout:

```
temporal task-queue versioning commit-build-id \
    --task-queue YourTaskQueue
    --build-id "YourBuildId"
```

This command automatically applies the following atomic changes:

- Adds an unconditional assignment rule for the target Build ID at the
  end of the list.
- Removes all previously added assignment rules to the given target
  Build ID.
- Removes any unconditional assignment rules for other Build IDs.

Rejects requests when there have been no recent pollers for this Build ID.
This prevents committing invalid Build IDs. Use the `--force` option to
override this validation.

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Target build ID. Required.

**--force** _bool_

Bypass recent-poller validation.

**--yes**, **-y** _bool_

Don't prompt to confirm.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### delete-assignment-rule

Deletes a rule identified by its index in the Task Queue's list of assignment
rules.

```
temporal task-queue versioning delete-assignment-rule \
    --task-queue YourTaskQueue \
    --rule-index YourIntegerRuleIndex
```

By default, the Task Queue must retain one unconditional rule, such as "no
hint filter" or "percentage". Otherwise, the delete operation is rejected.
Use the `--force` option to override this validation.

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--force** _bool_

Bypass one-unconditional-rule validation.

**--rule-index**, **-i** _int_

Position of the assignment rule to be replaced. Requests for invalid indices will fail. Required.

**--yes**, **-y** _bool_

Don't prompt to confirm.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### delete-redirect-rule

Deletes the routing rule for the given source Build ID.

```
temporal task-queue versioning delete-redirect-rule \
    --task-queue YourTaskQueue \
    --source-build-id "YourBuildId"
```

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--source-build-id** _string_

Source Build ID. Required.

**--yes**, **-y** _bool_

Don't prompt to confirm.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### get-rules

Retrieve all the Worker Build ID assignments and redirect rules associated
with a Task Queue:

```
temporal task-queue versioning get-rules \
    --task-queue YourTaskQueue
```

Task Queues support the following versioning rules:

- Assignment Rules: manage how new executions are assigned to run on specific
  Worker Build IDs. Each Task Queue stores a list of ordered Assignment Rules,
  which are evaluated from first to last. Assignment Rules also allow for
  gradual rollout of new Build IDs by setting ramp percentage.
- Redirect Rules: automatically assign work for a source Build ID to a target
  Build ID. You may add at most one redirect rule for each source Build ID.
  Redirect rules require that a target Build ID is fully compatible with
  the source Build ID.
  +---------------------------------------------------------------------+
  | CAUTION: This API has been deprecated by Worker Deployment. |
  +---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### insert-assignment-rule

Inserts a new assignment rule for this Task Queue. Rules are evaluated in
order, starting from index 0. The first applicable rule is applied, and the
rest ignored:

```
temporal task-queue versioning insert-assignment-rule \
    --task-queue YourTaskQueue \
    --build-id "YourBuildId"
```

If you do not specify a `--rule-index`, this command inserts at index 0.

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Target Build ID. Required.

**--percentage** _int_

Traffic percent to send to target Build ID. (default "100")

**--rule-index**, **-i** _int_

Insertion position. Ranges from 0 (insert at start) to count (append). Any number greater than the count is treated as "append". (default "0")

**--yes**, **-y** _bool_

Don't prompt to confirm.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### replace-assignment-rule

Change an assignment rule for this Task Queue. By default, this enforces one
unconditional rule (no hint filter or percentage). Otherwise, the operation
will be rejected. Set `force` to true to bypass this validation.

```
temporal task-queue versioning replace-assignment-rule \
    --task-queue YourTaskQueue \
    --rule-index AnIntegerIndex \
    --build-id "YourBuildId"
```

To assign multiple assignment rules to a single Build ID, use
'insert-assignment-rule'.

To update the percent:

```
temporal task-queue versioning replace-assignment-rule \
    --task-queue YourTaskQueue \
    --rule-index AnIntegerIndex \
    --build-id "YourBuildId" \
    --percentage AnIntegerPercent
```

Percent may vary between 0 and 100 (default).

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Target Build ID. Required.

**--force** _bool_

Bypass the validation that one unconditional rule remains.

**--percentage** _int_

Divert percent of traffic to target Build ID. (default "100")

**--rule-index**, **-i** _int_

Position of the assignment rule to be replaced. Requests for invalid indices will fail. Required.

**--yes**, **-y** _bool_

Don't prompt to confirm.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### replace-redirect-rule

Updates a Build ID's redirect rule on a Task Queue by replacing its target
Build ID:

```
temporal task-queue versioning replace-redirect-rule \
    --task-queue YourTaskQueue \
    --source-build-id YourSourceBuildId \
    --target-build-id YourNewTargetBuildId
```

+---------------------------------------------------------------------+
| CAUTION: This API has been deprecated by Worker Deployment. |
+---------------------------------------------------------------------+

Use the following options to change the behavior of this command.

**Flags:**

**--source-build-id** _string_

Source Build ID. Required.

**--target-build-id** _string_

Target Build ID. Required.

**--yes**, **-y** _bool_

Don't prompt to confirm.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI worker command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## deployment

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

Deployment commands perform operations on Worker Deployments:

```
temporal worker deployment [command] [options]
```

For example:

```
temporal worker deployment list
```

Lists the Deployments in the client's namespace.

Arguments can be Worker Deployment Versions associated with
a Deployment, specified using the Deployment name and Build ID.

For example:

```
temporal worker deployment set-current-version \
         --deployment-name YourDeploymentName --build-id YourBuildID
```

Sets the current Deployment Version for a given Deployment.

### delete

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

Remove a Worker Deployment given its Deployment Name.
A Deployment can only be deleted if it has no Version in it.

```
temporal worker deployment delete [options]
```

For example, setting the user identity that removed the deployment:

```
temporal worker deployment delete \
    --name YourDeploymentName \
    --identity YourIdentity
```

Use the following options to change the behavior of this command.

**Flags:**

**--name**, **-d** _string_

Name for a Worker Deployment. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### delete-version

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

Remove a Worker Deployment Version given its fully-qualified identifier.
This is rarely needed during normal operation
since unused Versions are eventually garbage collected.
The client can delete a Version only when all of the following conditions
are met:

- It is not the Current or Ramping Version for this Deployment.
- It has no active pollers, i.e., none of the task queues in the
  Version have pollers.
- It is not draining. This requirement can be ignored with the option
  `--skip-drainage`.

```
temporal worker deployment delete-version [options]
```

For example, skipping the drainage restriction:

```
temporal worker deployment delete-version \
    --deployment-name YourDeploymentName --build-id YourBuildID \
    --skip-drainage
```

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID of the Worker Deployment Version. Required.

**--deployment-name** _string_

Name of the Worker Deployment. Required.

**--skip-drainage** _bool_

Ignore the deletion requirement of not draining.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### describe

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

Describe properties of a Worker Deployment, such as the versions
associated with it, routing information of new or existing tasks
executed by this deployment, or its creation time.

```
temporal worker deployment describe [options]
```

For example, to describe a deployment `YourDeploymentName` in the default
namespace:

```
temporal worker deployment describe \
    --name YourDeploymentName
```

Use the following options to change the behavior of this command.

**Flags:**

**--name**, **-d** _string_

Name for a Worker Deployment. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### describe-version

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

Describe properties of a Worker Deployment Version, such as the task
queues polled by workers in this Deployment Version, or drainage
information required to safely decommission workers, or user-provided
metadata, or its creation/modification time.

```
temporal worker deployment describe-version [options]
```

For example, to describe a deployment version in a deployment
`YourDeploymentName`, with Build ID `YourBuildID`, and in the default
namespace:

```
temporal worker deployment describe-version \
    --deployment-name YourDeploymentName --build-id YourBuildID
```

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID of the Worker Deployment Version. Required.

**--deployment-name** _string_

Name of the Worker Deployment. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### list

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

List existing Worker Deployments in the client's namespace.

```
temporal worker deployment list [options]
```

For example, listing Deployments in YourDeploymentNamespace:

```
temporal worker deployment list \
    --namespace YourDeploymentNamespace
```

Use the following options to change the behavior of this command.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### set-current-version

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

Set the Current Version for a Deployment.
When a Version is current, Workers of that Deployment Version will receive
tasks from new Workflows, and from existing AutoUpgrade Workflows that
are running on this Deployment.

If not all the expected Task Queues are being polled by Workers in the
new Version the request will fail. To override this protection use
`--ignore-missing-task-queues`. Note that this would ignore task queues
in a deployment that are not yet discovered, leading to inconsistent task
queue configuration.

```
temporal worker deployment set-current-version [options]
```

For example, to set the Current Version of a deployment
`YourDeploymentName`, with a version with Build ID `YourBuildID`, and
in the default namespace:

```
temporal worker deployment set-current-version \
    --deployment-name YourDeploymentName --build-id YourBuildID
```

The target of set-current-version can also be unversioned workers:

```
temporal worker deployment set-current-version \
    --deployment-name YourDeploymentName --unversioned
```

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID of the Worker Deployment Version. Required unless --unversioned is specified.

**--deployment-name** _string_

Name of the Worker Deployment. Required.

**--ignore-missing-task-queues** _bool_

Override protection to accidentally remove task queues.

**--unversioned** _bool_

Set unversioned workers as the target version. Cannot be used with --build-id.

**--yes**, **-y** _bool_

Don't prompt to confirm set Current Version.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### set-ramping-version

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+

Set the Ramping Version and Percentage for a Deployment.

The Ramping Version can be set using deployment name and build ID,
or set to unversioned workers using the --unversioned flag.

The Ramping Percentage is a float with values in the range [0, 100].
A value of 100 does not make the Ramping Version Current, use
`set-current-version` instead.

To remove a Ramping Version use the flag `--delete`.

If not all the expected Task Queues are being polled by Workers in the
new Ramping Version the request will fail. To override this protection use
`--ignore-missing-task-queues`. Note that this would ignore task queues
in a deployment that are not yet discovered, leading to inconsistent task
queue configuration.

```
temporal worker deployment set-ramping-version [options]
```

For example, to set the Ramping Version of a deployment
`YourDeploymentName`, with a version with Build ID `YourBuildID`, with
10 percent of tasks redirected to this version, and
using the default namespace:

```
temporal worker deployment set-ramping-version \
    --deployment-name YourDeploymentName --build-id YourBuildID \
    --percentage 10.0
```

And to remove that ramping:

```
temporal worker deployment set-ramping-version \
    --deployment-name YourDeploymentName --build-id YourBuildID \
    --delete
```

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID of the Worker Deployment Version. Required unless --unversioned is specified.

**--delete** _bool_

Delete the Ramping Version.

**--deployment-name** _string_

Name of the Worker Deployment. Required.

**--ignore-missing-task-queues** _bool_

Override protection to accidentally remove task queues.

**--percentage** _float_

Percentage of tasks redirected to the Ramping Version. Valid range [0,100].

**--unversioned** _bool_

Set unversioned workers as the target version. Cannot be used with --build-id.

**--yes**, **-y** _bool_

Don't prompt to confirm set Ramping Version.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### update-metadata-version

+---------------------------------------------------------------------+
| CAUTION: Worker Deployment is experimental. Deployment commands are |
| subject to change. |
+---------------------------------------------------------------------+
Update metadata associated with a Worker Deployment Version.

For example:

```
temporal worker deployment update-metadata-version \
   --deployment-name YourDeploymentName --build-id YourBuildID \
   --metadata bar=1 \
   --metadata foo=true
```

The current metadata is also returned with `describe-version`:

```
temporal worker deployment describe-version \
   --deployment-name YourDeploymentName --build-id YourBuildID \
```

Use the following options to change the behavior of this command.

**Flags:**

**--build-id** _string_

Build ID of the Worker Deployment Version. Required.

**--deployment-name** _string_

Name of the Worker Deployment. Required.

**--metadata** _string[]_

Set deployment metadata using `KEY="VALUE"` pairs. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--remove-entries** _string[]_

Keys of entries to be deleted from metadata. Can be passed multiple times.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Temporal CLI workflow command reference

{/* NOTE: This is an auto-generated file. Any edit to this file will be overwritten.
This file is generated from https://github.com/temporalio/cli/blob/main/temporalcli/commandsgen/commands.yml */}

## cancel

Canceling a running Workflow Execution records a
`WorkflowExecutionCancelRequested` event in the Event History. The Service
schedules a new Command Task, and the Workflow Execution performs any cleanup
work supported by its implementation.

Use the Workflow ID to cancel an Execution:

```
temporal workflow cancel \
    --workflow-id YourWorkflowId
```

A visibility Query lets you send bulk cancellations to Workflow Executions
matching the results:

```
temporal workflow cancel \
    --query YourQuery
```

Visit https://docs.temporal.io/visibility to read more about Search Attributes
and Query creation. See `temporal batch --help` for a quick reference.

Use the following options to change the behavior of this command.

**Flags:**

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for batch operation. Only use with --query. Defaults to user name.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Only use with --workflow-id. Cannot use with --query.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm signaling. Only allowed when --query is present.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## count

Show a count of Workflow Executions, regardless of execution state (running,
terminated, etc). Use `--query` to select a subset of Workflow Executions:

```
temporal workflow count \
    --query YourQuery
```

Visit https://docs.temporal.io/visibility to read more about Search Attributes
and Query creation. See `temporal batch --help` for a quick reference.

Use the following options to change the behavior of this command.

**Flags:**

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## delete

Delete a Workflow Executions and its Event History:

```
temporal workflow delete \
    --workflow-id YourWorkflowId
```

The removal executes asynchronously. If the Execution is Running, the Service
terminates it before deletion.

Visit https://docs.temporal.io/visibility to read more about Search Attributes
and Query creation. See `temporal batch --help` for a quick reference.

Use the following options to change the behavior of this command.

**Flags:**

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for batch operation. Only use with --query. Defaults to user name.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Only use with --workflow-id. Cannot use with --query.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm signaling. Only allowed when --query is present.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## describe

Display information about a specific Workflow Execution:

```
temporal workflow describe \
    --workflow-id YourWorkflowId
```

Show the Workflow Execution's auto-reset points:

```
temporal workflow describe \
    --workflow-id YourWorkflowId \
    --reset-points true
```

Use the following options to change the behavior of this command.

**Flags:**

**--raw** _bool_

Print properties without changing their format.

**--reset-points** _bool_

Show auto-reset points only.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## execute

Establish a new Workflow Execution and direct its progress to stdout. The
command blocks and returns when the Workflow Execution completes. If your
Workflow requires input, pass valid JSON:

```
temporal workflow execute
    --workflow-id YourWorkflowId \
    --type YourWorkflow \
    --task-queue YourTaskQueue \
    --input '{"some-key": "some-value"}'
```

Use `--event-details` to relay updates to the command-line output in JSON
format. When using JSON output (`--output json`), this includes the entire
"history" JSON key for the run.

Use the following options to change the behavior of this command.

**Flags:**

**--cron** _string_

Cron schedule for the Workflow.

**--detailed** _bool_

Display events as sections instead of table. Does not apply to JSON output.

**--execution-timeout** _duration_

Fail a WorkflowExecution if it lasts longer than `DURATION`. This time-out includes retries and ContinueAsNew tasks.

**--fail-existing** _bool_

Fail if the Workflow already exists.

**--fairness-key** _string_

Fairness key (max 64 bytes) for proportional task dispatch. Tasks with same key share capacity based on their weight.

**--fairness-weight** _float_

Weight [0.001-1000] for this fairness key. Keys are dispatched proportionally to their weights.

**--id-conflict-policy** _string-enum_

Determines how to resolve a conflict when spawning a new Workflow Execution with a particular Workflow Id used by an existing Open Workflow Execution. Accepted values: Fail, UseExisting, TerminateExisting.

**--id-reuse-policy** _string-enum_

Re-use policy for the Workflow ID in new Workflow Executions. Accepted values: AllowDuplicate, AllowDuplicateFailedOnly, RejectDuplicate, TerminateIfRunning.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--memo** _string[]_

Memo using 'KEY="VALUE"' pairs. Use JSON values.

**--priority-key** _int_

Priority key (1-5, lower numbers = higher priority). Tasks in a queue should be processed in close-to-priority-order. Default is 3 when not specified.

**--run-timeout** _duration_

Fail a Workflow Run if it lasts longer than `DURATION`.

**--search-attribute** _string[]_

Search Attribute in `KEY=VALUE` format. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--start-delay** _duration_

Delay before starting the Workflow Execution. Can't be used with cron schedules. If the Workflow receives a signal or update prior to this time, the Workflow Execution starts immediately.

**--static-details** _string_

Static Workflow details for human consumption in UIs. Uses Temporal Markdown formatting, may be multiple lines.

:::note

Option is experimental.

:::

**--static-summary** _string_

Static Workflow summary for human consumption in UIs. Uses Temporal Markdown formatting, should be a single line.

:::note

Option is experimental.

:::

**--task-queue**, **-t** _string_

Workflow Task queue. Required.

**--task-timeout** _duration_

Fail a Workflow Task if it lasts longer than `DURATION`. This is the Start-to-close timeout for a Workflow Task. (default "10s")

**--type** _string_

Workflow Type name. Required.

**--workflow-id**, **-w** _string_

Workflow ID. If not supplied, the Service generates a unique ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## execute-update-with-start

Send a message to a Workflow Execution to invoke an Update handler, and wait for
the update to complete. If the Workflow Execution is not running, then a new workflow
execution is started and the update is sent.

Experimental.

```
temporal workflow execute-update-with-start \
  --update-name YourUpdate \
  --update-input '{"update-key": "update-value"}' \
  --workflow-id YourWorkflowId \
  --type YourWorkflowType \
  --task-queue YourTaskQueue \
  --id-conflict-policy Fail \
  --input '{"wf-key": "wf-value"}'
```

Use the following options to change the behavior of this command.

**Flags:**

**--cron** _string_

Cron schedule for the Workflow.

**--execution-timeout** _duration_

Fail a WorkflowExecution if it lasts longer than `DURATION`. This time-out includes retries and ContinueAsNew tasks.

**--fail-existing** _bool_

Fail if the Workflow already exists.

**--fairness-key** _string_

Fairness key (max 64 bytes) for proportional task dispatch. Tasks with same key share capacity based on their weight.

**--fairness-weight** _float_

Weight [0.001-1000] for this fairness key. Keys are dispatched proportionally to their weights.

**--id-conflict-policy** _string-enum_

Determines how to resolve a conflict when spawning a new Workflow Execution with a particular Workflow Id used by an existing Open Workflow Execution. Accepted values: Fail, UseExisting, TerminateExisting.

**--id-reuse-policy** _string-enum_

Re-use policy for the Workflow ID in new Workflow Executions. Accepted values: AllowDuplicate, AllowDuplicateFailedOnly, RejectDuplicate, TerminateIfRunning.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--memo** _string[]_

Memo using 'KEY="VALUE"' pairs. Use JSON values.

**--priority-key** _int_

Priority key (1-5, lower numbers = higher priority). Tasks in a queue should be processed in close-to-priority-order. Default is 3 when not specified.

**--run-id**, **-r** _string_

Run ID. If unset, looks for an Update against the currently-running Workflow Execution.

**--run-timeout** _duration_

Fail a Workflow Run if it lasts longer than `DURATION`.

**--search-attribute** _string[]_

Search Attribute in `KEY=VALUE` format. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--start-delay** _duration_

Delay before starting the Workflow Execution. Can't be used with cron schedules. If the Workflow receives a signal or update prior to this time, the Workflow Execution starts immediately.

**--static-details** _string_

Static Workflow details for human consumption in UIs. Uses Temporal Markdown formatting, may be multiple lines.

:::note

Option is experimental.

:::

**--static-summary** _string_

Static Workflow summary for human consumption in UIs. Uses Temporal Markdown formatting, should be a single line.

:::note

Option is experimental.

:::

**--task-queue**, **-t** _string_

Workflow Task queue. Required.

**--task-timeout** _duration_

Fail a Workflow Task if it lasts longer than `DURATION`. This is the Start-to-close timeout for a Workflow Task. (default "10s")

**--type** _string_

Workflow Type name. Required.

**--update-first-execution-run-id** _string_

Parent Run ID. The update is sent to the last Workflow Execution in the chain started with this Run ID.

**--update-id** _string_

Update ID. If unset, defaults to a UUID.

**--update-input** _string[]_

Update input value. Use JSON content or set --update-input-meta to override. Can't be combined with --update-input-file. Can be passed multiple times to pass multiple arguments.

**--update-input-base64** _bool_

Assume update inputs are base64-encoded and attempt to decode them.

**--update-input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --update-input-meta to override. Can't be combined with --update-input. Can be passed multiple times to pass multiple arguments.

**--update-input-meta** _string[]_

Input update payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times.

**--update-name** _string_

Update name. Required.

**--workflow-id**, **-w** _string_

Workflow ID. If not supplied, the Service generates a unique ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## fix-history-json

Reserialize an Event History JSON file:

```
temporal workflow fix-history-json \
    --source /path/to/original.json \
    --target /path/to/reserialized.json
```

Use the following options to change the behavior of this command.

**Flags:**

**--source**, **-s** _string_

Path to the original file. Required.

**--target**, **-t** _string_

Path to the results file. When omitted, output is sent to stdout.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## list

List Workflow Executions. The optional `--query` limits the output to
Workflows matching a Query:

```
temporal workflow list \
    --query YourQuery`
```

Visit https://docs.temporal.io/visibility to read more about Search Attributes
and Query creation. See `temporal batch --help` for a quick reference.

View a list of archived Workflow Executions:

```
temporal workflow list \
    --archived
```

Use the following options to change the behavior of this command.

**Flags:**

**--archived** _bool_

Limit output to archived Workflow Executions.

:::note

Option is experimental.

:::

**--limit** _int_

Maximum number of Workflow Executions to display.

**--page-size** _int_

Maximum number of Workflow Executions to fetch at a time from the server.

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## metadata

Issue a Query for and display user-set metadata like summary and
details for a specific Workflow Execution:

```
temporal workflow metadata \
    --workflow-id YourWorkflowId
```

Use the following options to change the behavior of this command.

**Flags:**

**--reject-condition** _string-enum_

Optional flag for rejecting Queries based on Workflow state. Accepted values: not_open, not_completed_cleanly.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## query

Send a Query to a Workflow Execution by Workflow ID to retrieve its state.
This synchronous operation exposes the internal state of a running Workflow
Execution, which constantly changes. You can query both running and completed
Workflow Executions:

```
temporal workflow query \
    --workflow-id YourWorkflowId
    --type YourQueryType
    --input '{"YourInputKey": "YourInputValue"}'
```

Use the following options to change the behavior of this command.

**Flags:**

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--name** _string_

Query Type/Name. Required.

**--reject-condition** _string-enum_

Optional flag for rejecting Queries based on Workflow state. Accepted values: not_open, not_completed_cleanly.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## reset

Reset a Workflow Execution so it can resume from a point in its Event History
without losing its progress up to that point:

```
temporal workflow reset \
    --workflow-id YourWorkflowId \
    --event-id YourLastEvent
```

Start from where the Workflow Execution last continued as new:

```
temporal workflow reset \
    --workflow-id YourWorkflowId \
    --type LastContinuedAsNew
```

For batch resets, limit your resets to FirstWorkflowTask, LastWorkflowTask, or
BuildId. Do not use Workflow IDs, run IDs, or event IDs with this command.

Visit https://docs.temporal.io/visibility to read more about Search
Attributes and Query creation.

### with-workflow-update-options

Run Workflow Update Options atomically after the Workflow is reset.
Workflows selected by the reset command are forwarded onto the subcommand.

Use the following options to change the behavior of this command.

**Flags:**

**--versioning-override-behavior** _string-enum_

Override the versioning behavior of a Workflow. Required. Accepted values: pinned, auto_upgrade.

**--versioning-override-build-id** _string_

When overriding to a `pinned` behavior, specifies the Build ID of the version to target.

**--versioning-override-deployment-name** _string_

When overriding to a `pinned` behavior, specifies the Deployment Name of the version to target.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## result

Wait for and print the result of a Workflow Execution:

```
temporal workflow result \
    --workflow-id YourWorkflowId
```

Use the following options to change the behavior of this command.

**Flags:**

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## show

Show a Workflow Execution's Event History.
When using JSON output (`--output json`), you may pass the results to an SDK
to perform a replay:

```
temporal workflow show \
    --workflow-id YourWorkflowId
    --output json
```

Use the following options to change the behavior of this command.

**Flags:**

**--detailed** _bool_

Display events as detailed sections instead of table. Does not apply to JSON output.

**--follow**, **-f** _bool_

Follow the Workflow Execution progress in real time. Does not apply to JSON output.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## signal

Send an asynchronous notification (Signal) to a running Workflow Execution by
its Workflow ID. The Signal is written to the History. When you include
`--input`, that data is available for the Workflow Execution to consume:

```
temporal workflow signal \
    --workflow-id YourWorkflowId \
    --name YourSignal \
    --input '{"YourInputKey": "YourInputValue"}'
```

Visit https://docs.temporal.io/visibility to read more about Search Attributes
and Query creation. See `temporal batch --help` for a quick reference.

Use the following options to change the behavior of this command.

**Flags:**

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--name** _string_

Signal name. Required.

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for batch operation. Only use with --query. Defaults to user name.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Only use with --workflow-id. Cannot use with --query.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm signaling. Only allowed when --query is present.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## signal-with-start

Send an asynchronous notification (Signal) to a Workflow Execution.
If the Workflow Execution is not running or is not found, it starts the
workflow then sends the signal.

```
temporal workflow signal-with-start \
  --signal-name YourSignal \
  --signal-input '{"some-key": "some-value"}' \
  --workflow-id YourWorkflowId \
  --type YourWorkflowType \
  --task-queue YourTaskQueue \
  --input '{"some-key": "some-value"}'
```

Use the following options to change the behavior of this command.

**Flags:**

**--cron** _string_

Cron schedule for the Workflow.

**--execution-timeout** _duration_

Fail a WorkflowExecution if it lasts longer than `DURATION`. This time-out includes retries and ContinueAsNew tasks.

**--fail-existing** _bool_

Fail if the Workflow already exists.

**--fairness-key** _string_

Fairness key (max 64 bytes) for proportional task dispatch. Tasks with same key share capacity based on their weight.

**--fairness-weight** _float_

Weight [0.001-1000] for this fairness key. Keys are dispatched proportionally to their weights.

**--id-conflict-policy** _string-enum_

Determines how to resolve a conflict when spawning a new Workflow Execution with a particular Workflow Id used by an existing Open Workflow Execution. Accepted values: Fail, UseExisting, TerminateExisting.

**--id-reuse-policy** _string-enum_

Re-use policy for the Workflow ID in new Workflow Executions. Accepted values: AllowDuplicate, AllowDuplicateFailedOnly, RejectDuplicate, TerminateIfRunning.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--memo** _string[]_

Memo using 'KEY="VALUE"' pairs. Use JSON values.

**--priority-key** _int_

Priority key (1-5, lower numbers = higher priority). Tasks in a queue should be processed in close-to-priority-order. Default is 3 when not specified.

**--run-timeout** _duration_

Fail a Workflow Run if it lasts longer than `DURATION`.

**--search-attribute** _string[]_

Search Attribute in `KEY=VALUE` format. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--signal-input** _string[]_

Signal input value. Use JSON content or set --signal-input-meta to override. Can't be combined with --signal-input-file. Can be passed multiple times to pass multiple arguments.

**--signal-input-base64** _bool_

Assume signal inputs are base64-encoded and attempt to decode them.

**--signal-input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --signal-input-meta to override. Can't be combined with --signal-input. Can be passed multiple times to pass multiple arguments.

**--signal-input-meta** _string[]_

Input signal payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times.

**--signal-name** _string_

Signal name. Required.

**--start-delay** _duration_

Delay before starting the Workflow Execution. Can't be used with cron schedules. If the Workflow receives a signal or update prior to this time, the Workflow Execution starts immediately.

**--static-details** _string_

Static Workflow details for human consumption in UIs. Uses Temporal Markdown formatting, may be multiple lines.

:::note

Option is experimental.

:::

**--static-summary** _string_

Static Workflow summary for human consumption in UIs. Uses Temporal Markdown formatting, should be a single line.

:::note

Option is experimental.

:::

**--task-queue**, **-t** _string_

Workflow Task queue. Required.

**--task-timeout** _duration_

Fail a Workflow Task if it lasts longer than `DURATION`. This is the Start-to-close timeout for a Workflow Task. (default "10s")

**--type** _string_

Workflow Type name. Required.

**--workflow-id**, **-w** _string_

Workflow ID. If not supplied, the Service generates a unique ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## stack

Perform a Query on a Workflow Execution using a `__stack_trace`-type Query.
Display a stack trace of the threads and routines currently in use by the
Workflow for troubleshooting:

```
temporal workflow stack \
    --workflow-id YourWorkflowId
```

Use the following options to change the behavior of this command.

**Flags:**

**--reject-condition** _string-enum_

Optional flag to reject Queries based on Workflow state. Accepted values: not_open, not_completed_cleanly.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## start

Start a new Workflow Execution. Returns the Workflow- and Run-IDs:

```
temporal workflow start \
    --workflow-id YourWorkflowId \
    --type YourWorkflow \
    --task-queue YourTaskQueue \
    --input '{"some-key": "some-value"}'
```

Use the following options to change the behavior of this command.

**Flags:**

**--cron** _string_

Cron schedule for the Workflow.

**--execution-timeout** _duration_

Fail a WorkflowExecution if it lasts longer than `DURATION`. This time-out includes retries and ContinueAsNew tasks.

**--fail-existing** _bool_

Fail if the Workflow already exists.

**--fairness-key** _string_

Fairness key (max 64 bytes) for proportional task dispatch. Tasks with same key share capacity based on their weight.

**--fairness-weight** _float_

Weight [0.001-1000] for this fairness key. Keys are dispatched proportionally to their weights.

**--id-conflict-policy** _string-enum_

Determines how to resolve a conflict when spawning a new Workflow Execution with a particular Workflow Id used by an existing Open Workflow Execution. Accepted values: Fail, UseExisting, TerminateExisting.

**--id-reuse-policy** _string-enum_

Re-use policy for the Workflow ID in new Workflow Executions. Accepted values: AllowDuplicate, AllowDuplicateFailedOnly, RejectDuplicate, TerminateIfRunning.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--memo** _string[]_

Memo using 'KEY="VALUE"' pairs. Use JSON values.

**--priority-key** _int_

Priority key (1-5, lower numbers = higher priority). Tasks in a queue should be processed in close-to-priority-order. Default is 3 when not specified.

**--run-timeout** _duration_

Fail a Workflow Run if it lasts longer than `DURATION`.

**--search-attribute** _string[]_

Search Attribute in `KEY=VALUE` format. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--start-delay** _duration_

Delay before starting the Workflow Execution. Can't be used with cron schedules. If the Workflow receives a signal or update prior to this time, the Workflow Execution starts immediately.

**--static-details** _string_

Static Workflow details for human consumption in UIs. Uses Temporal Markdown formatting, may be multiple lines.

:::note

Option is experimental.

:::

**--static-summary** _string_

Static Workflow summary for human consumption in UIs. Uses Temporal Markdown formatting, should be a single line.

:::note

Option is experimental.

:::

**--task-queue**, **-t** _string_

Workflow Task queue. Required.

**--task-timeout** _duration_

Fail a Workflow Task if it lasts longer than `DURATION`. This is the Start-to-close timeout for a Workflow Task. (default "10s")

**--type** _string_

Workflow Type name. Required.

**--workflow-id**, **-w** _string_

Workflow ID. If not supplied, the Service generates a unique ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## start-update-with-start

Send a message to a Workflow Execution to invoke an Update handler, and wait for
the update to be accepted or rejected. If the Workflow Execution is not running,
then a new workflow execution is started and the update is sent.

Experimental.

```
temporal workflow start-update-with-start \
  --update-name YourUpdate \
  --update-input '{"update-key": "update-value"}' \
  --update-wait-for-stage accepted \
  --workflow-id YourWorkflowId \
  --type YourWorkflowType \
  --task-queue YourTaskQueue \
  --id-conflict-policy Fail \
  --input '{"wf-key": "wf-value"}'
```

Use the following options to change the behavior of this command.

**Flags:**

**--cron** _string_

Cron schedule for the Workflow.

**--execution-timeout** _duration_

Fail a WorkflowExecution if it lasts longer than `DURATION`. This time-out includes retries and ContinueAsNew tasks.

**--fail-existing** _bool_

Fail if the Workflow already exists.

**--fairness-key** _string_

Fairness key (max 64 bytes) for proportional task dispatch. Tasks with same key share capacity based on their weight.

**--fairness-weight** _float_

Weight [0.001-1000] for this fairness key. Keys are dispatched proportionally to their weights.

**--id-conflict-policy** _string-enum_

Determines how to resolve a conflict when spawning a new Workflow Execution with a particular Workflow Id used by an existing Open Workflow Execution. Accepted values: Fail, UseExisting, TerminateExisting.

**--id-reuse-policy** _string-enum_

Re-use policy for the Workflow ID in new Workflow Executions. Accepted values: AllowDuplicate, AllowDuplicateFailedOnly, RejectDuplicate, TerminateIfRunning.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--memo** _string[]_

Memo using 'KEY="VALUE"' pairs. Use JSON values.

**--priority-key** _int_

Priority key (1-5, lower numbers = higher priority). Tasks in a queue should be processed in close-to-priority-order. Default is 3 when not specified.

**--run-id**, **-r** _string_

Run ID. If unset, looks for an Update against the currently-running Workflow Execution.

**--run-timeout** _duration_

Fail a Workflow Run if it lasts longer than `DURATION`.

**--search-attribute** _string[]_

Search Attribute in `KEY=VALUE` format. Keys must be identifiers, and values must be JSON values. For example: `'YourKey={"your": "value"}'`. Can be passed multiple times.

**--start-delay** _duration_

Delay before starting the Workflow Execution. Can't be used with cron schedules. If the Workflow receives a signal or update prior to this time, the Workflow Execution starts immediately.

**--static-details** _string_

Static Workflow details for human consumption in UIs. Uses Temporal Markdown formatting, may be multiple lines.

:::note

Option is experimental.

:::

**--static-summary** _string_

Static Workflow summary for human consumption in UIs. Uses Temporal Markdown formatting, should be a single line.

:::note

Option is experimental.

:::

**--task-queue**, **-t** _string_

Workflow Task queue. Required.

**--task-timeout** _duration_

Fail a Workflow Task if it lasts longer than `DURATION`. This is the Start-to-close timeout for a Workflow Task. (default "10s")

**--type** _string_

Workflow Type name. Required.

**--update-first-execution-run-id** _string_

Parent Run ID. The update is sent to the last Workflow Execution in the chain started with this Run ID.

**--update-id** _string_

Update ID. If unset, defaults to a UUID.

**--update-input** _string[]_

Update input value. Use JSON content or set --update-input-meta to override. Can't be combined with --update-input-file. Can be passed multiple times to pass multiple arguments.

**--update-input-base64** _bool_

Assume update inputs are base64-encoded and attempt to decode them.

**--update-input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --update-input-meta to override. Can't be combined with --update-input. Can be passed multiple times to pass multiple arguments.

**--update-input-meta** _string[]_

Input update payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times.

**--update-name** _string_

Update name. Required.

**--update-wait-for-stage** _string-enum_

Update stage to wait for. The only option is `accepted`, but this option is required. This is to allow a future version of the CLI to choose a default value. Required. Accepted values: accepted.

**--workflow-id**, **-w** _string_

Workflow ID. If not supplied, the Service generates a unique ID.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## terminate

Terminate a Workflow Execution:

```
temporal workflow terminate \
    --reason YourReasonForTermination \
    --workflow-id YourWorkflowId
```

The reason is optional and defaults to the current user's name. The reason
is stored in the Event History as part of the `WorkflowExecutionTerminated`
event. This becomes the closing Event in the Workflow Execution's history.

Executions may be terminated in bulk via a visibility Query list filter:

```
temporal workflow terminate \
    --query YourQuery \
    --reason YourReasonForTermination
```

Workflow code cannot see or respond to terminations. To perform clean-up work
in your Workflow code, use `temporal workflow cancel` instead.

Visit https://docs.temporal.io/visibility to read more about Search Attributes
and Query creation. See `temporal batch --help` for a quick reference.

Use the following options to change the behavior of this command.

**Flags:**

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for termination. Defaults to message with the current user's name.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Can only be set with --workflow-id. Do not use with --query.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm termination. Can only be used with --query.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## trace

Display the progress of a Workflow Execution and its child workflows with a
real-time trace. This view helps you understand how Workflows are proceeding:

```
temporal workflow trace \
    --workflow-id YourWorkflowId
```

Use the following options to change the behavior of this command.

**Flags:**

**--concurrency** _int_

Number of Workflow Histories to fetch at a time. (default "10")

**--depth** _int_

Set depth for your Child Workflow fetches. Pass -1 to fetch child workflows at any depth. (default "-1")

**--fold** _string[]_

Fold away Child Workflows with the specified statuses. Case-insensitive. Ignored if --no-fold supplied. Available values: running, completed, failed, canceled, terminated, timedout, continueasnew. Can be passed multiple times.

**--no-fold** _bool_

Disable folding. Fetch and display Child Workflows within the set depth.

**--run-id**, **-r** _string_

Run ID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## update

An Update is a synchronous call to a Workflow Execution that can change its
state, control its flow, and return a result.

### describe

Given a Workflow Execution and an Update ID, return information about its current status, including
a result if it has finished.

```
temporal workflow update describe \
    --workflow-id YourWorkflowId \
    --update-id YourUpdateId
```

Use the following options to change the behavior of this command.

**Flags:**

**--run-id**, **-r** _string_

Run ID. If unset, updates the currently-running Workflow Execution.

**--update-id** _string_

Update ID. Must be unique per Workflow Execution. Required.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### execute

Send a message to a Workflow Execution to invoke an Update handler, and wait for
the update to complete or fail. You can also use this to wait for an existing
update to complete, by submitting an existing update ID.

```
temporal workflow update execute \
    --workflow-id YourWorkflowId \
    --name YourUpdate \
    --input '{"some-key": "some-value"}'
```

Use the following options to change the behavior of this command.

**Flags:**

**--first-execution-run-id** _string_

Parent Run ID. The update is sent to the last Workflow Execution in the chain started with this Run ID.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--name** _string_

Handler method name. Required.

**--run-id**, **-r** _string_

Run ID. If unset, looks for an Update against the currently-running Workflow Execution.

**--update-id** _string_

Update ID. If unset, defaults to a UUID.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### result

Given a Workflow Execution and an Update ID, wait for the Update to complete or fail and
print the result.

```
temporal workflow update result \
    --workflow-id YourWorkflowId \
    --update-id YourUpdateId
```

Use the following options to change the behavior of this command.

**Flags:**

**--run-id**, **-r** _string_

Run ID. If unset, updates the currently-running Workflow Execution.

**--update-id** _string_

Update ID. Must be unique per Workflow Execution. Required.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

### start

Send a message to a Workflow Execution to invoke an Update handler, and wait for
the update to be accepted or rejected. You can subsequently wait for the update
to complete by using `temporal workflow update execute`.

```
temporal workflow update start \
    --workflow-id YourWorkflowId \
    --name YourUpdate \
    --input '{"some-key": "some-value"}'
    --wait-for-stage accepted
```

Use the following options to change the behavior of this command.

**Flags:**

**--first-execution-run-id** _string_

Parent Run ID. The update is sent to the last Workflow Execution in the chain started with this Run ID.

**--input**, **-i** _string[]_

Input value. Use JSON content or set --input-meta to override. Can't be combined with --input-file. Can be passed multiple times to pass multiple arguments.

**--input-base64** _bool_

Assume inputs are base64-encoded and attempt to decode them.

**--input-file** _string[]_

A path or paths for input file(s). Use JSON content or set --input-meta to override. Can't be combined with --input. Can be passed multiple times to pass multiple arguments.

**--input-meta** _string[]_

Input payload metadata as a `KEY=VALUE` pair. When the KEY is "encoding", this overrides the default ("json/plain"). Can be passed multiple times. Repeated metadata keys are applied to the corresponding inputs in the provided order.

**--name** _string_

Handler method name. Required.

**--run-id**, **-r** _string_

Run ID. If unset, looks for an Update against the currently-running Workflow Execution.

**--update-id** _string_

Update ID. If unset, defaults to a UUID.

**--wait-for-stage** _string-enum_

Update stage to wait for. The only option is `accepted`, but this option is required. This is to allow a future version of the CLI to choose a default value. Required. Accepted values: accepted.

**--workflow-id**, **-w** _string_

Workflow ID. Required.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

## update-options

+---------------------------------------------------------------------+
| CAUTION: Worflow update-options is experimental. Workflow Execution |
| properties are subject to change. |
+---------------------------------------------------------------------+

Modify properties of Workflow Executions:

```
temporal workflow update-options [options]
```

It can override the Worker Deployment configuration of a
Workflow Execution, which controls Worker Versioning.

For example, to force Workers in the current Deployment execute the
next Workflow Task change behavior to `auto_upgrade`:

```
temporal workflow update-options \
    --workflow-id YourWorkflowId \
    --versioning-override-behavior auto_upgrade
```

or to pin the workflow execution to a Worker Deployment, set behavior
to `pinned`:

```
temporal workflow update-options \
    --workflow-id YourWorkflowId \
    --versioning-override-behavior pinned \
    --versioning-override-deployment-name YourDeploymentName \
    --versioning-override-build-id YourDeploymentBuildId
```

To remove any previous overrides, set the behavior to
`unspecified`:

```
temporal workflow update-options \
    --workflow-id YourWorkflowId \
    --versioning-override-behavior unspecified
```

To see the current override use `temporal workflow describe`

Use the following options to change the behavior of this command.

**Flags:**

**--query**, **-q** _string_

Content for an SQL-like `QUERY` List Filter. You must set either --workflow-id or --query.

**--reason** _string_

Reason for batch operation. Only use with --query. Defaults to user name.

**--rps** _float_

Limit batch's requests per second. Only allowed if query is present.

**--run-id**, **-r** _string_

Run ID. Only use with --workflow-id. Cannot use with --query.

**--versioning-override-behavior** _string-enum_

Override the versioning behavior of a Workflow. Required. Accepted values: unspecified, pinned, auto_upgrade.

**--versioning-override-build-id** _string_

When overriding to a `pinned` behavior, specifies the Build ID of the version to target.

**--versioning-override-deployment-name** _string_

When overriding to a `pinned` behavior, specifies the Deployment Name of the version to target.

**--workflow-id**, **-w** _string_

Workflow ID. You must set either --workflow-id or --query.

**--yes**, **-y** _bool_

Don't prompt to confirm signaling. Only allowed when --query is present.

**Global Flags:**

**--address** _string_

Temporal Service gRPC endpoint. (default "localhost:7233")

**--api-key** _string_

API key for request.

**--codec-auth** _string_

Authorization header for Codec Server requests.

**--codec-endpoint** _string_

Remote Codec Server endpoint.

**--codec-header** _string[]_

HTTP headers for requests to codec server. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers.

**--color** _string-enum_

Output coloring. Accepted values: always, never, auto. (default "auto")

**--command-timeout** _duration_

The command execution timeout. 0s means no timeout.

**--config-file** _string_

File path to read TOML config from, defaults to `$CONFIG_PATH/temporal/temporal.toml` where `$CONFIG_PATH` is defined as `$HOME/.config` on Unix, "$HOME/Library/Application Support" on macOS, and %AppData% on Windows.

:::note

Option is experimental.

:::

**--disable-config-env** _bool_

If set, disables loading environment config from environment variables.

:::note

Option is experimental.

:::

**--disable-config-file** _bool_

If set, disables loading environment config from config file.

:::note

Option is experimental.

:::

**--env** _string_

Active environment name (`ENV`). (default "default")

**--env-file** _string_

Path to environment settings file. Defaults to `$HOME/.config/temporalio/temporal.yaml`.

**--grpc-meta** _string[]_

HTTP headers for requests. Format as a `KEY=VALUE` pair. May be passed multiple times to set multiple headers. Can also be made available via environment variable as `TEMPORAL_GRPC_META_[name]`.

**--identity** _string_

The identity of the user or client submitting this request. Defaults to "temporal-cli:$USER@$HOST".

**--log-format** _string-enum_

Log format. Accepted values: text, json. (default "text")

**--log-level** _string-enum_

Log level. Default is "info" for most commands and "warn" for `server start-dev`. Accepted values: debug, info, warn, error, never. (default "info")

**--namespace**, **-n** _string_

Temporal Service Namespace. (default "default")

**--no-json-shorthand-payloads** _bool_

Raw payload output, even if the JSON option was used.

**--output**, **-o** _string-enum_

Non-logging data output format. Accepted values: text, json, jsonl, none. (default "text")

**--profile** _string_

Profile to use for config file.

:::note

Option is experimental.

:::

**--time-format** _string-enum_

Time format. Accepted values: relative, iso, raw. (default "relative")

**--tls** _bool_

Enable base TLS encryption. Does not have additional options like mTLS or client certs. This is defaulted to true if api-key or any other TLS options are present. Use --tls=false to explicitly disable.

**--tls-ca-data** _string_

Data for server CA certificate. Can't be used with --tls-ca-path.

**--tls-ca-path** _string_

Path to server CA certificate. Can't be used with --tls-ca-data.

**--tls-cert-data** _string_

Data for x509 certificate. Can't be used with --tls-cert-path.

**--tls-cert-path** _string_

Path to x509 certificate. Can't be used with --tls-cert-data.

**--tls-disable-host-verification** _bool_

Disable TLS host-name verification.

**--tls-key-data** _string_

Private certificate key data. Can't be used with --tls-key-path.

**--tls-key-path** _string_

Path to x509 private key. Can't be used with --tls-key-data.

**--tls-server-name** _string_

Override target TLS server name.

---

## Audit Logging - AWS Kinesis

## Configure Audit Logging using AWS Kinesis {#configure-audit-logging}

To set up Audit Logging, you must have an Amazon Web Services (AWS) account and set up Kinesis Data Streams.

1. If you don't have an AWS account, follow the instructions from AWS in [Create and activate an AWS account](https://aws.amazon.com/premiumsupport/knowledge-center/create-and-activate-aws-account/).
2. To set up Kinesis Data Streams, open the [AWS Management Console](https://aws.amazon.com/console/), search for Kinesis, and start the setup process.

You can use [this AWS CloudFormation template](https://temporal-auditlogs-config.s3.us-west-2.amazonaws.com/cloudformation/iam-role-for-temporal-audit-logs.yaml) to create an IAM role with access to a Kinesis stream you have in your account.

Be aware that Kinesis has a rate limit of 1,000 messages per second and quotas for both the number of records written and the size of the records.
For more information, see [Why is my Kinesis data stream throttling?](https://aws.amazon.com/premiumsupport/knowledge-center/kinesis-data-stream-throttling/)

### Create an Audit Log sink

1. In the Temporal Cloud UI, select **Settings**.
1. On the **Settings** page, select **Integrations**.
1. In the **Audit Logging** card, select **Configure Audit Logs**.
1. On the **Audit Logging** page, choose your **Access method** (either **Auto** or **Manual**).
   - **Auto:** Configure the AWS CloudFormation stack in your AWS account from the Cloud UI.
   - **Manual:** Use a generated AWS CloudFormation template to set up Kinesis manually.
1. In **Kinesis ARN**, paste the Kinesis ARN from your AWS account.
1. In **Role name**, provide a name for a new IAM Role.
1. In **Select an AWS region**, select the appropriate region for your Kinesis stream.

If you chose the **Auto** access method, continue with the following steps:

1. Select **Save and launch stack**.
1. In **Stack name** in the AWS CloudFormation console, specify a name for the stack.
1. In the lower-right corner of the page, select **Create stack**.

If you chose the **Manual** access method, continue with the following steps:

1. Select **Save and download template**.
1. Open the [AWS CloudFormation console](https://console.aws.amazon.com/cloudformation/).
1. Select **Create Stack**.
1. On the **Create stack** page, select **Template is ready** and **Update a template file**.
1. Select **Choose file** and specify the template you generated in step 1.
1. Select **Next** on this page and on the next two pages.
1. On the **Review** page, select **Create stack**.

## Consume an Audit Log {#consume-an-audit-log}

**How to consume an Audit Log**

After you create an Audit Log sink, wait for the logs to flow into the Kinesis stream.
You should see the first logs 2–10 minutes after you configure the sink.
Subsequent logs arrive every 2 minutes if any actions occurred during that 2-minute window.

:::note

You must configure and implement your own consumer of the Kinesis stream.
For an example, see [Example of consuming an Audit Log](#example-of-consuming-an-audit-log).

:::

### Example of consuming an Audit Log

The following Go code is an example of consuming Audit Logs from a Kinesis stream and delivering them to an S3 bucket.

```go
func main() {
   fmt.Println("print audit log from S3")
   cfg, err := config.LoadDefaultConfig(context.TODO(),
      config.WithSharedConfigProfile("your_profile"),
   )
   if err != nil {
      fmt.Println(err)
   }
   s3Client := s3.NewFromConfig(cfg)
   response, err := s3Client.GetObject(
      context.Background(),
      &s3.GetObjectInput{
         Bucket: aws.String("your_bucket_name"),
         Key:    aws.String("your_s3_file_path")})
   if err != nil {
      fmt.Println(err)
   }
   defer response.Body.Close()

   content, err := io.ReadAll(response.Body)

   fmt.Println(string(content))
}
```

The preceding code also prints the logs in the terminal.
The following is a sample result.

```json
{
  "emit_time": "2023-11-14T07:56:55Z",
  "level": "LOG_LEVEL_INFO",
  "caller_ip_address": "10.1.2.3, 10.4.5.6",
  "user_email": "user1@example.com",
  "operation": "DeleteUser",
  "details": {
    "target_users": ["d7dca96f-adcc-417d-aafc-e8f5d2ba9fe1"],
    "search_attribute_update": {}
  },
  "status": "OK",
  "category": "LOG_CATEGORY_ADMIN",
  "log_id": "0mc69c0323b871293ce231dd1c7fb639",
  "request_id": "445297d3-43a7-4793-8a04-1b1dd1999640",
  "principal": {
    "id": "988cb80b-d6be-4bb5-9c87-d09f93f58ed3",
    "type": "user",
    "name": "user1@example.com"
  }
}
```

---

## Audit Logging - GCP Pub/Sub

## Manual Setup Prerequisites

:::note

These steps are only required for manual setup.
If you use Terraform for your deployment, you don't need to complete these prerequisites.

:::

Before configuring the manual Audit Log sink, complete the following steps in Google Cloud:

1. Create a Pub/Sub topic and make a note of its topic name, such as `test-auditlog`.
1. Set up a service account in the same project in Google Cloud and follow the instructions in the
   Temporal Cloud UI to configure the permissions for that service account.

## Create an Audit Log sink

1. In the Temporal Cloud UI, select **Settings**.
1. On the **Settings** page, select **Audit Logging**.
1. In the **Audit Logging** card, select **Set Up Audit Log Integration**.
1. On the Set Up Audit Log Integration page, select **Pub/Sub**.
1. In the **service account email** field, enter the email of the service account you created in the prerequisites.
1. In the **Topic name** field, enter the topic name of the Pub/Sub topic you created in the prerequisites.
1. There are two ways to configure the service account to write to the Pub/Sub sink: select **Manual** to configure the account manually, or **Deploy with Terraform** to use Terraform.
   If you use Terraform, you don't need to complete the prerequisite steps above.
1. Follow the instructions in the Temporal Cloud UI for the method you chose.
1. Click **Create** to configure the audit log.
   This process may take a few minutes.

![Temporal Cloud UI Setup for Audit Logging with GCP Pub/Sub](/img/cloud/gcp/audit-logging-pub-sub-gcp.png)

:::info MORE INFORMATION

For more details, refer to [Audit Logging with Temporal Cloud](https://docs.temporal.io/cloud/audit-logging).

:::

---

## Audit Logging - Temporal Cloud feature guide

Audit Logging is a feature of [Temporal Cloud](/cloud/overview) that provides forensic access information for a variety of operations in the Temporal Cloud control plane.

Audit Logging answers "who, when, and what" questions about Temporal Cloud resources.
These answers can help you evaluate the security of your organization, and they can provide information that you need to satisfy audit and compliance requirements.

:::info

Audit Logging does NOT capture data plane events, like Workflow Start, Workflow Terminate, Schedule Create, etc.
Instead, explore the [Export](/cloud/export) feature, which does let you send closed Workflow Histories to external storage.

:::

## Which integrations are supported by Audit Logging? {#supported-integrations}

Audit Logging supports both [Amazon Kinesis](/cloud/audit-logging-aws) and [Google Cloud Pub/Sub](/cloud/audit-logging-gcp) streaming-data platforms.

## Which events are supported by Audit Logging? {#supported-events}

- Account
  - `ChangeAccountPlanType`: Change Account Plan Type
  - `UpdateAccountAPI`: Configure Audit Logging, Configure Observability Endpoint
- API Keys
  - `CreateAPIKey`: Create API Key
  - `DeleteAPIKey`: Delete API Key
  - `UpdateAPIKey`: Update API Key
- Connectivity Rules
  - `CreateConnectivityRule`: Create Connectivity Rule
  - `DeleteConnectivityRule`: Delete Connectivity Rule
- Namespace
  - `CreateNamespaceAPI`: Create Namespace
  - `DeleteNamespaceAPI`: Delete Namespace
  - `FailoverNamespacesAPI`: Failover (for High Availability Namespaces)
  - `RenameCustomSearchAttributeAPI`: Rename Custom Search Attribute
  - `UpdateNamespaceAPI`: Includes retention period changes, replica edits, authentication method updates, custom search attribute updates, and connectivity rule bindings
- Namespace Export
  - `CreateNamespaceExportSink`: Create Namespace Export Sink
  - `DeleteNamespaceExportSink`: Delete Namespace Export Sink
  - `UpdateNamespaceExportSink`: Update Namespace Export Sink
  - `ValidateNamespaceExportSink`: Validate Namespace Export Sink
- Nexus Endpoint
  - `CreateNexusEndpoint`: Create Nexus Endpoint
  - `DeleteNexusEndpoint`: Delete Nexus Endpoint
  - `UpdateNexusEndpoint`: Update Nexus Endpoint
- Service Accounts
  - `CreateServiceAccount`: Create Service Account
  - `CreateServiceAccountAPIKey`: Create Service Account API Key
  - `DeleteServiceAccount`: Delete Service Account
  - `UpdateServiceAccount`: Update Service Account
- User
  - `CreateUserAPI`: Create Users
  - `DeleteUserAPI`: Delete Users
  - `InviteUsersAPI`: Invite Users
  - `SetUserNamespaceAccessAPI`: Set User Namespace Access
  - `UpdateIdentityNamespacePermissionsAPI`: Update Identity Namespace Permissions
  - `UpdateUserAPI`: Update User Account-level Roles
  - `UpdateUserNamespacePermissionsAPI`: Update User Namespace Permissions
- User Groups
  - `CreateUserGroup`: Create User Group
  - `DeleteUserGroup`: Delete User Group
  - `SetUserGroupNamespaceAccess`: Set User Group Namespace Access
  - `UpdateUserGroup`: Update User Group

### Audit Log format

Audit Logs use the following JSON format:

```json
{
  "operation":  // Operation that was performed
  "principal": // Information about who initiated the operation
  "details":  // Details of the operation
  "user_email":  // Email address of the user who initiated the operation
  "caller_ip_address": // Customer IP address in the X-Forwarded-For format
  "category":  // Category of the log entry: Admin or System
  "emit_time": // Time the operation was recorded
  "level": // Level of the log entry, such as info, warning, or error
  "log_id": // Unique ID of the log entry
  "request_id": // Optional async request id set by the user when sending a request
  "status": // Status, such as OK or ERROR
  "version": // Version of the log entry
}
```

:::note

The [`X-Forwarded-For`](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For) format is a comma-separated list of IP addresses which should be evaluated from the last to the first, until meeting the first untrusted IP address of the list. This allows for instance to consider proxies in the path.

Temporal provides the caller IP address in that format to allow customers to identify a caller IP address even if one (or more proxies) are in the network path to reach Temporal Cloud.

:::

### Example of an Audit Log

```json
{"emit_time":"2023-10-24T08:19:41Z","level":"LOG_LEVEL_INFO","caller_ip_address":"10.1.2.3, 10.4.5.6","user_email":"user1@example.com","operation":"UpdateAccount","details":{"client_ca_fingerprints":["5bb99d14fa602f7d39b7d048674a2251"],"search_attribute_update":{}},"status":"OK","category":"LOG_CATEGORY_ADMIN","log_id":"0mc69c0323b871293ce231dd1c7fb634","principal":{"id":"988cb80b-d6be-4bb5-9c87-d09f93f58ed3","type":"user","name":"user1@example.com"}}
**********
{"emit_time":"2023-10-25T21:16:42Z","level":"LOG_LEVEL_INFO","caller_ip_address":"10.7.8.9","user_email":"user2@example.com","operation":"DeleteUser","details":{"target_users":["0b741c47-e093-47d1-9b74-f2359129f78f"],"search_attribute_update":{}},"status":"OK","category":"LOG_CATEGORY_ADMIN","log_id":"0mc69c0323b871293ce231dd1c7fb635","request_id":"445297d3-43a7-4793-8a04-1b1dd1999641","principal":{"id":"b160473e-e40d-4a81-90d1-f4218269e6e4","type":"user","name":"user2@example.com"}}
**********
{"emit_time":"2023-11-03T19:31:45Z","level":"LOG_LEVEL_INFO","caller_ip_address":"10.1.2.3, 10.10.11.12","user_email":"user3@example.com","operation":"InviteUsers","details":{"target_users":["user3@example.net"],"search_attribute_update":{}},"status":"OK","category":"LOG_CATEGORY_ADMIN","log_id":"0mc69c0323b871293ce231dd1c7fb636","principal":{"id":"35fdc757-9637-446b-b386-12ed475511ad","type":"user","name":"user3@example.com"}}
**********
{"emit_time":"2023-11-08T08:06:40Z","level":"LOG_LEVEL_INFO","caller_ip_address":"10.1.2.3, 10.4.5.6","user_email":"user1@example.com","operation":"UpdateUser","details":{"target_users":["user1@example.net"],"search_attribute_update":{}},"status":"OK","category":"LOG_CATEGORY_ADMIN","log_id":"0mc69c0323b871293ce231dd1c7fb637","request_id":"445297d3-43a7-4793-8a04-1b1dd1999640","principal":{"id":"988cb80b-d6be-4bb5-9c87-d09f93f58ed3","type":"user","name":"user1@example.com"}}
**********
{"emit_time":"2023-11-08T08:14:09Z","level":"LOG_LEVEL_INFO","caller_ip_address":"10.1.2.3, 10.4.5.6","user_email":"user1@example.com","operation":"UpdateNamespace","details":{"namespace":"audit-log-test.example-dev","client_ca_fingerprints":["f186d0bd971ff7d52dc6cc9d9b6f7644"],"search_attribute_update":{}},"status":"OK","category":"LOG_CATEGORY_ADMIN","log_id":"0mc69c0323b871293ce231dd1c7fb638","principal":{"id":"988cb80b-d6be-4bb5-9c87-d09f93f58ed3","type":"user","name":"user1@example.com"}}
**********
{"emit_time":"2023-11-08T09:20:22Z","level":"LOG_LEVEL_INFO","caller_ip_address":"10.1.2.3, 10.4.5.6","user_email":"user1@example.com","operation":"UpdateUserNamespacePermissions","details":{"namespace":"audit-log-test.example-dev","search_attribute_update":{}},"status":"OK","category":"LOG_CATEGORY_ADMIN","log_id":"0mc69c0323b871293ce231dd1c7fb639","principal":{"id":"988cb80b-d6be-4bb5-9c87-d09f93f58ed3","type":"user","name":"user1@example.com"}}
**********
```

## How to configure Audit Logging {#configure-audit-logging}

Audit logging can be configured in AWS Kinesis or GCP Pub/Sub.

- [AWS Kinesis Instructions](/cloud/audit-logging-aws)
- [GCP Pub/Sub Instructions](/cloud/audit-logging-gcp)

## Consume an Audit Log {#consume-an-audit-log}

**How to consume an Audit Log**

After you create an Audit Log sink, wait for the logs to flow into the stream.
You should see the first logs 2–10 minutes after you configure the sink.
Subsequent logs arrive every 2 minutes if any actions occurred during that 2-minute window.

:::note

You must configure and implement your own consumer of the stream.

:::

## How to troubleshoot Audit Logging {#troubleshoot-audit-logging}

The Audit Logging page of the Temporal Cloud UI provides the current status of an Audit Log sink.

- If an error is detected, a summary of the error appears below the page title.
- If the Audit Log sink is functioning normally, an **On** badge appears next to the page heading.

After an Admin Operation is performed, users can see Audit Log messages flow through the stream.

Upon successful configuration of the Audit Log sink and set up of a stream, you will receive events within the hour of setup.
Temporal is able to retain Audit Log information for up to 30 days.
To retrieve logs up to the past 30 days, you will need to file a request.

If you experience an issue with an Audit Log sink, we can provide the missing audit information.
Open a support ticket to request assistance.

## How to delete an Audit Log sink {#delete-an-audit-log-sink}

When you no longer need Audit Logging, you can delete the Audit Log sink.

1. In the Temporal Cloud UI, select **Settings**.
1. On the **Settings** page, select **Integrations**.
1. In the **Audit Logging** card, select **Configure Audit Logs**.
1. At the bottom of the **Audit Logging** page, choose **Delete**.

After you confirm the deletion, the Audit Log Sink is removed from your account and logs stop flowing to your stream.

---

## Exporting Workflow Event History to AWS S3

## Prerequisites {#prerequisites}

Before configuring the Export Sink, ensure you have the following:

1. An AWS account with write permission to an S3 bucket.
2. An AWS S3 bucket.
   - The S3 bucket must reside in the same region as your Namespace.
3. (optional) A KMS ARN associated with the S3 bucket.

## Configure Workflow History Export using Temporal Cloud UI or `tcld`

You can use either the [Temporal Cloud UI](#using-temporal-cloud-ui) or [`tcld`](#using-tcld) to configure the Workflow History Export.

The Temporal Cloud UI provides two ways for configuring Workflow History Export:

- [Automated setup](#automated-setup) (recommended): The Cloud UI launches the AWS CloudFormation Console to create a stack, with write permission to the S3 bucket.
- [Manual setup](#manual-setup): The Cloud UI provides a CloudFormation template for users to manually configure a CloudFormation stack.

:::note Why does Temporal Cloud provision multiple service accounts for Export?

Temporal Cloud creates multiple intermediary service accounts for export operations primarily for security purposes. 
The system randomly selects from these accounts when writing to your storage sink, which provides several benefits:

- **Security isolation**: If one service account is compromised or needs to be decommissioned, other accounts remain available
- **Load distribution**: Avoid relying on a single account, reducing security risk
- **Warm standby**: Keeps multiple accounts active to avoid potential throttling when switching between accounts
- **Reliability**: Provides resilience against cloud provider account-level issues that could affect a single service account

This approach prioritizes security and availability, ensuring robust export operations even if individual service accounts encounter issues.
:::

### Using Temporal Cloud UI

The following steps guide you through setting up Workflow History Export using the Temporal Cloud UI.

![](/img/cloud/gcp/export-sink-ui.png)

:::tip

Don't forget to click **Create** at the end of your setup to confirm your export.

:::

#### Automated setup

You can use the automated setup to create a CloudFormation stack with write permission to your S3 bucket.
Make sure to verify the export setup before you save the configuration.

1. Open the Temporal Cloud UI and navigate to the Namespace you want to configure.
2. Select **Configure** from the **Export** card.
3. Provide the following information to configure the export sink and then select **Create and launch stack**:
   - Name: A name for the export sink.
   - AWS S3 Bucket Name: The name of the configured AWS S3 bucket to send Closed Workflow Histories to.
   - AWS Account ID: The AWS account ID.
   - Role Name: The name of the AWS IAM role to use for the CloudFormation stack that has write permission to the S3 bucket.
   - KMS ARN: (optional) The ARN of the AWS KMS key to use for encryption of the exported Workflow History.
4. You will be taken to the CloudFormation Console to create the stack with pre-populated information.
   - Review the information and then select **Create stack**.

#### Manual setup

You can manually configure a CloudFormation stack using the provided template.

1. Open the Temporal Cloud UI and navigate to the Namespace you want to configure.
2. Select **Configure** from the **Export** card.
3. Select **Manual** from **Access method**.
   - Enter the Template URL into your web browser to download your copy of the CloudFormation template.
   - Configure the CloudFormation template for your export sink.
   - Follow the steps in the [AWS documentation](https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-using-console-create-stack-template.html) by uploading the template to the CloudFormation console.

### Using `tcld`

Run the `tcld namespace export s3 create` command and provide the following information.

- `--namespace` : The Namespace to configure export for.
- `--sink-name`: The name of the export sink.
- `--role-arn`: The ARN of the AWS IAM role to use for the CloudFormation stack that has write permission to the S3 bucket.
- `--s3-bucket-name`: The name of the AWS S3 bucket.

For example:

```command
tcld namespace export s3 create --namespace "your-namespace.your-account" --sink-name "your-sink-name" --role-arn "arn:aws:iam::123456789012:role/test-sink" --s3-bucket-name "your-aws-s3-bucket-name"
```

Retrieve the status of this command by running the `tcld namespace export s3 get` command.

For example:

```command
tcld namespace export s3 get --namespace "your-namespace.your-account" --sink-name "your-sink-name"
```

The following is an example of the output:

```json
{
  "name": "your-sink-name",
  "resourceVersion": "a6442895-1c07-4da4-aaca-58d57d338345",
  "state": "Active",
  "spec": {
    "name": "your-sink-name",
    "enabled": true,
    "destinationType": "S3",
    "s3Sink": {
      "roleName": "your-export-test",
      "bucketName": "your-export-test",
      "region": "us-east-1",
      "kmsArn": "",
      "awsAccountId": "123456789012"
    }
  },
  "health": "Ok",
  "errorMessage": "",
  "latestDataExportTime": "0001-01-01T00:00:00Z",
  "lastHealthCheckTime": "2023-08-14T21:30:02Z"
}
```

### Next Steps

- [Verify export setup](/cloud/export#verify)
- [Monitor export progress](/cloud/export#monitor)
- [Work with exported files](/cloud/export#working-with-exported-files)

---

## AWS PrivateLink Connectivity

[AWS PrivateLink](https://aws.amazon.com/privatelink/) allows you to open a path to Temporal without opening a public egress.
It establishes a private connection between your Amazon Virtual Private Cloud (VPC) and Temporal Cloud.
This one-way connection means Temporal cannot establish a connection back to your service.
This is useful if normally you block traffic egress as part of your security protocols.
If you use a private environment that does not allow external connectivity, you will remain isolated.

## Requirements

Your AWS PrivateLink endpoint must be in the same region as your Temporal Cloud namespace. If using [replication for High Availability](/cloud/high-availability), the PL connection must be in the same region as one of the replicas.

AWS Cross Region endpoints are not supported.

## Creating an AWS PrivateLink connection

Set up PrivateLink connectivity with Temporal Cloud with these steps:

1. Open the AWS console with the region you want to use to establish the PrivateLink.
2. Search for "VPC" in _Services_ and select the option.

   ![AWS console showing services, features, resources](/img/cloud/privatelink/aws-console.png)
3. Select _Virtual private cloud_ > _Endpoints_ from the left menu bar.
4. Click the _Create endpoint_ button to the right of the _Actions_ pulldown menu.
5. Under _Type_ category, select _Endpoint services that use NLBs and GWLBs_.
   This option lets you find services shared with you by service name.
6. Under _Service settings_, fill in the _Service name_ with the PrivateLink Service Name for the region you’re trying to connect from:
:::tip

PrivateLink endpoint services are regional.
Individual Namespaces do not use separate services.

:::

   | Region           | PrivateLink Service Name                                       |
   | ---------------- | -------------------------------------------------------------- |
   | `ap-northeast-1` | `com.amazonaws.vpce.ap-northeast-1.vpce-svc-08f34c33f9fb8a48a` |
   | `ap-northeast-2` | `com.amazonaws.vpce.ap-northeast-2.vpce-svc-08c4d5445a5aad308` |
   | `ap-south-1`     | `com.amazonaws.vpce.ap-south-1.vpce-svc-0ad4f8ed56db15662`     |
   | `ap-south-2`     | `com.amazonaws.vpce.ap-south-2.vpce-svc-08bcf602b646c69c1`     |
   | `ap-southeast-1` | `com.amazonaws.vpce.ap-southeast-1.vpce-svc-05c24096fa89b0ccd` |
   | `ap-southeast-2` | `com.amazonaws.vpce.ap-southeast-2.vpce-svc-0634f9628e3c15b08` |
   | `ca-central-1`   | `com.amazonaws.vpce.ca-central-1.vpce-svc-080a781925d0b1d9d`   |
   | `eu-central-1`   | `com.amazonaws.vpce.eu-central-1.vpce-svc-073a419b36663a0f3`   |
   | `eu-west-1`      | `com.amazonaws.vpce.eu-west-1.vpce-svc-04388e89f3479b739`      |
   | `eu-west-2`      | `com.amazonaws.vpce.eu-west-2.vpce-svc-0ac7f9f07e7fb5695`      |
   | `sa-east-1`      | `com.amazonaws.vpce.sa-east-1.vpce-svc-0ca67a102f3ce525a`      |
   | `us-east-1`      | `com.amazonaws.vpce.us-east-1.vpce-svc-0822256b6575ea37f`      |
   | `us-east-2`      | `com.amazonaws.vpce.us-east-2.vpce-svc-01b8dccfc6660d9d4`      |
   | `us-west-2`      | `com.amazonaws.vpce.us-west-2.vpce-svc-0f44b3d7302816b94`      |

7. Confirm your service by clicking on the _Verify service_ button. AWS should respond "Service name verified."

   ![The service name field is filled out and the Verify service button is shown](/img/cloud/privatelink/service-settings.png)
8. Select the VPC and subnets to peer with the Temporal Cloud service endpoint.
9. Select the security group that will control traffic sources for this VPC endpoint.
   The security group must accept TCP ingress traffic to port 7233 for gRPC communication with Temporal Cloud.
10. Click the _Create endpoint_ button at the bottom of the screen.
    If successful, AWS reports "Successfully created VPC endpoint." and lists the new endpoint.
    The new endpoint appears in the Endpoints list, along with its ID.

    ![The created endpoint appears in the Endpoints list](/img/cloud/privatelink/endpoint-created.png)
11. Click on the VPC endpoint ID in the Endpoints list to check its status.
    Wait for the status to be “Available”.
    This can take up to 10 minutes.
12. Once the status is "Available", the AWS PrivateLink is ready for use.

:::caution
You still need to set up private DNS or override client configuration for your clients to actually use the new PrivateLink connection to connect to Temporal Cloud.

See [configure private DNS for AWS PrivateLink](#configuring-private-dns-for-aws-privatelink)
:::
    
    ![Highlighted DNS names section shows your hostname](/img/cloud/privatelink/details.png)

## Configuring Private DNS for AWS PrivateLink

### Why configure private DNS?

When you connect to Temporal Cloud through AWS PrivateLink you normally must:

1. **Point your SDKs/Workers at the PrivateLink DNS name** for the VPC Endpoint (e.g., `vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com`), **and**
2. **Override the Server Name Indicator (SNI)** so that the TLS handshake still presents the public Temporal Cloud hostname (e.g., `my-namespace.my-account.tmprl.cloud`).

By creating a Route 53 **private hosted zone (PHZ)** that maps the public Temporal Cloud hostname (or region hostname) to your VPC Endpoint, you can:

- Keep using the standard Temporal Cloud hostnames in code and configuration.
- Eliminate the need to set a custom SNI override.
- Make future Endpoint rotations transparent—only the PHZ record changes.

This approach is **optional**; Temporal Cloud works without it. It simply streamlines configuration and operations. If you cannot use private DNS, refer to [our guide for updating the server and TLS settings on your clients](/cloud/connectivity#update-dns-or-clients-to-use-private-connectivity).

### Prerequisites

| Requirement                                           | Notes                                                                                                                              |
| ----------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| AWS VPC with DNS resolution and DNS hostnames enabled | _VPC console → Edit DNS settings → enable both checkboxes._                                                                        |
| Interface VPC Endpoint for Temporal Cloud             | Subnets must be associated with the VPC and Security Group must allow TCP ingress traffic to port 7233 from the appropriate hosts. |
| Route 53 available in your AWS account                | You need permission to create Private Hosted Zones and records.                                                                    |
| Namespace details                                     | Needed to choose the correct override domain pattern below.                                                                        |

### Choose the override domain and endpoint

| Temporal Cloud setup                       | Use this PHZ domain     | Example                                         |
| ------------------------------------------ | ----------------------- | ----------------------------------------------- |
| Single-region namespace with mTLS auth     | `<account>.tmprl.cloud` | `payments.abcde.tmprl.cloud` ↔ `vpce-...`       |
| Multi-region namespace **or** API-key auth | `region.tmprl.cloud`    | `aws-us-east-1.region.tmprl.cloud` ↔ `vpce-...` |

### Step-by-step instructions

#### 1. Collect your PrivateLink endpoint DNS name

```bash
aws ec2 describe-vpc-endpoints \
  --vpc-endpoint-ids $VPC_ENDPOINT_ID \
  --query "VpcEndpoints[0].DnsEntries[0].DnsName" \
  --output text

# Example output:
# vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com
```

Save the **`vpce-*.amazonaws.com`** value -- you will target it in the CNAME record.

#### 2. Create a Route 53 Private Hosted Zone

1. Open _Route 53 → Hosted zones → Create hosted zone_.
2. Enter the domain chosen from the table above, e.g., `payments.abcde.tmprl.cloud`.
3. Type: _Private hosted zone for Temporal Cloud_.
4. Associate the hosted zone with every VPC that contains Temporal Workers and/or SDK clients.
5. Create hosted zone.

#### 3. Add a CNAME record

Inside the new PHZ:

| Field           | Value                                                                                 |
| --------------- | ------------------------------------------------------------------------------------- |
| **Record name** | the namespace endpoint (e.g., `payments.abcde.tmprl.cloud`).                          |
| **Record type** | `CNAME`                                                                               |
| **Value**       | Your VPC Endpoint DNS name (`vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com`) |
| **TTL**         | 60s is typical; 15s for MRN namespaces; adjust as needed.                             |

#### 4. Verify DNS resolution from inside the VPC

```bash
dig payments.abcde.tmprl.cloud
```

If the record resolves to the VPC Endpoint, you are ready to use Temporal Cloud without SNI overrides.

### Updating your workers/clients

With private DNS in place, configure your SDKs exactly as the public-internet examples show (filling in your own namespace):

```go
clientOptions := client.Options{
    HostPort: "payments.abcde.tmprl.cloud:7233",
    Namespace: "payments",
    // No TLS SNI override needed
}
```

The DNS resolver inside your VPC returns the private endpoint, while TLS still validates the original hostname—simplifying both code and certificate management.

## Configure Private DNS for Multi-Region Namespaces

:::tip Namespaces with High Availability features and AWS PrivateLink

Proper networking configuration is required for failover to be transparent to clients and workers when using PrivateLink.
This page describes how to configure routing for Namespaces with High Availability features on AWS PrivateLink.

:::

To use AWS PrivateLink with High Availability features, you may need to:

- Override the regional DNS zone.
- Ensure network connectivity between the two regions.

This page provides the details you need to set this up.

### Customer side solutions

When using PrivateLink, you connect to Temporal Cloud through a VPC Endpoint, which uses addresses local to your network.
Temporal treats each `region.<tmprl_domain>` as a separate zone.
This setup allows you to override the default zone, ensuring that traffic is routed internally for the regions you’re using.

A Namespace's active region is reflected in the target of a CNAME record.
For example, if the active region of a Namespace is AWS us-west-2, the DNS configuration would look like this:

| Record name                         | Record type | Value                            |
| ----------------------------------- | ----------- | -------------------------------- |
| ha-namespace.account-id.tmprl.cloud | CNAME       | aws-us-west-2.region.tmprl.cloud |

After a failover, the CNAME record will be updated to point to the failover region, for example:

| Record name                         | Record type | Value                            |
| ----------------------------------- | ----------- | -------------------------------- |
| ha-namespace.account-id.tmprl.cloud | CNAME       | aws-us-east-1.region.tmprl.cloud |

The Temporal domain did not change, but the CNAME updated from us-west-2 to us-east-1.

<CaptionedImage
    src="/img/cloud/high-availability/private-link.png"
    title="Customer side solution example"
    zoom="true"
/>

### Setting up the DNS override

To set up the DNS override, configure specific regions to target the internal VPC Endpoint IP addresses.
For example, you might set aws-us-west-1.region.tmprl.cloud to target 192.168.1.2.
In AWS, this can be done using a Route 53 private hosted zone for `region.tmprl.cloud`.
Link that private zone to the VPCs you use for Workers.

When your Workers connect to the Namespace, they first resolve the `<ns>.<acct>.<tmprl_domain>` record.
This points to `<aws-active-region>.region.tmprl.cloud`, which then resolves to your internal IP addresses.

Consider how you’ll configure Workers for this setup.
You can either have Workers run in both regions continuously or establish connectivity between regions using Transit Gateway or VPC Peering.
This way, Workers can access the newly activated region once failover occurs.

## Available AWS regions, PrivateLink endpoints, and DNS record overrides

The following table lists the available Temporal regions, PrivateLink endpoints, and regional endpoints used for DNS record overrides:

<AWSRegions />

---

## Google Private Service Connect Connectivity

[Google Cloud Private Service Connect](https://cloud.google.com/vpc/docs/private-service-connect) allows you to open a path to Temporal without opening a public egress.
It establishes a private connection between your Google Virtual Private Cloud (VPC) and Temporal Cloud.
This one-way connection means Temporal cannot establish a connection back to your service.
This is useful if normally you block traffic egress as part of your security protocols.
If you use a private environment that does not allow external connectivity, you will remain isolated.

:::warning Namespaces with High Availability features and GCP Private Service Connect

Automatic failover via Temporal Cloud DNS is not currently supported with GCP Private Service Connect.
If you use GCP Private Service Connect, you must manually update your workers to point to the active region's Private Service Connect endpoint when a failover occurs.

:::

## Requirements

Your GCP Private Service Connect connection must be in the same region as your Temporal Cloud namespace. If using [replication for High Availability](/cloud/high-availability), the PSC connection must be in the same region as one of the replicas.

## Creating a Private Service Connect connection

Set up Private Service Connect with Temporal Cloud with these steps:

1. Open the Google Cloud console
2. Navigate to **Network Services**, then **Private Service Connect**. If you haven't used **Network Services** recently, you might have to find it by clicking on **View All Products** at the bottom of the left sidebar.

   ![GCP console showing Network Services, and the View All Products button](/img/cloud/gcp/gcp-console.png)

3. Go to the **Endpoints** section. Click on **Connect endpoint**.

   ![GCP console showing the endpoints, and the Connect endpoint button](/img/cloud/gcp/connect-endpoint-button.png)

4. Under **Target**, select **Published service**, this will change the contents of the form to allow you to fill the rest as described below

   ![GCP console showing the endpoints, and the Connect endpoint button](/img/cloud/gcp/connect-endpoint.png)

- For **Target service**, fill in the **Service name** with the Private Service Connect Service Name for the region you’re trying to connect to:

:::tip

GCP Private Service Connect services are regional.
Individual Namespaces do not use separate services.

:::

  | Region         | Private Service Connect Service Name                                                       |
  | -------------- | ------------------------------------------------------------------------------------------ |
  | `asia-south1`  | `projects/prod-d5spc2sfeshws33bg33vwdef7/regions/asia-south1/serviceAttachments/pl-7w7tw`  |
  | `europe-west3` | `projects/prod-kwy7d4faxp6qgrgd9x94du36g/regions/europe-west3/serviceAttachments/pl-acgsh` |
  | `us-central1`  | `projects/prod-d9ch6v2ybver8d2a8fyf7qru9/regions/us-central1/serviceAttachments/pl-5xzng`  |
  | `us-east4`     | `projects/prod-y399cvr9c2b43es2w3q3e4gvw/regions/us-east4/serviceAttachments/pl-8awsy`     |
  | `us-west1`     | `projects/prod-rbe76zxxzydz4cbdz2xt5b59q/regions/us-west1/serviceAttachments/pl-94w0x`     |

- For **Endpoint name**, enter a unique identifier to use for this endpoint. It could be for instance `temporal-api` or `temporal-api-<namespace>` if you want a different endpoint per namespace.
- For **Network** and **Subnetwork**, choose the network and subnetwork where you want to publish your endpoint.
- For **IP address**, click the dropdown and select **Create IP address** to create an internal IP from your subnet dedicated to the endpoint. Select this IP.
- Check **Enable global access** if you intend to connect the endpoint to virtual machines outside of the selected region. We recommend regional connectivity instead of global access, as it can be better in terms of latency for your workers. _**Note:** this requires the network routing mode to be set to **GLOBAL**._

5. Click the **Add endpoint** button at the bottom of the screen.

6. Once the status is "Accepted", the GCP Private Service Connect endpoint is ready for use.
   
  - Take note of the **IP address** that has been assigned to your endpoint, as it will be used to connect to Temporal Cloud.

:::caution
You still need to set up private DNS or override client configuration for your clients to actually use the new Private Service Connect connection to connect to Temporal Cloud.

See [configuring private DNS for GCP Private Service Connect](#configuring-private-dns-for-gcp-private-service-connect)
:::

## Configuring Private DNS for GCP Private Service Connect

### Why configure private DNS?

When you connect to Temporal Cloud through GCP Private Service Connect you normally must:

1. **Point your SDKs/Workers at the Private Service Connect endpoint IP address** _and_
2. **Override the Server Name Indicator (SNI)** so that the TLS handshake still presents the public Temporal Cloud hostname (e.g., `my-namespace.my-account.tmprl.cloud`).

By creating a **private Cloud DNS zone (PZ)** that maps the public TemporalC Cloud hostname (or the region hostname) directly to the PSC endpoint IP address, you can:

- Keep using the standard Temporal Cloud hostnames in code and configuration.
- Eliminate the need to set a custom SNI override.
- Make future endpoint rotations transparent—only the DNS record changes.

This approach is **optional**; Temporal Cloud works without it. It simply streamlines configuration and operations. If you cannot use private DNS, refer to [our guide for updating the server and TLS settings on your clients](/cloud/connectivity#update-dns-or-clients-to-use-private-connectivity).

### Prerequisites

| Requirement                                           | Notes                                                                             |
| ----------------------------------------------------- | --------------------------------------------------------------------------------- |
| Google Cloud VPC Network with DNS enabled             | PSC endpoints and the DNS zone must live in (or be attached to) the same network. |
| Private Service Connect endpoint for Temporal Cloud   | Create an endpoint and reserve an internal IP in the namespace region             |
| Cloud DNS API enabled and roles/dns.admin permissions | Needed to create private zones and records.                                       |
| Namespace details                                     | Determines which hostname pattern you override (table below).                     |

### Choose the override domain and endpoint

| Temporal Cloud setup                       | Use this PHZ domain     | Example                                        |
| ------------------------------------------ | ----------------------- | ---------------------------------------------- |
| Single-region namespace with mTLS auth     | `<account>.tmprl.cloud` | `payments.abcde.tmprl.cloud` ↔ `X.X.X.X`       |
| Multi-region namespace **or** API-key auth | `region.tmprl.cloud`    | `aws-us-east-1.region.tmprl.cloud` ↔ `X.X.X.X` |

### Step-by-step instructions

#### 1. Collect your PSC endpoint IP address

```shell
# List the forwarding rule you created for the endpoint
gcloud compute forwarding-rules list \
  --filter="NAME:<endpoint-name>" \
  --format="value(IP_ADDRESS)"
# Example output: 10.1.2.3
```

Save the internal IP -- you will point the A record at it.

#### 2. Create a Cloud DNS private zone

1. Open _Network Services → Cloud DNS → Create zone_.
2. Select zone type **Private**.
3. Enter a **Zone name** (e.g., `temporal-cloud`).
4. Enter a **DNS name** based on the table above (e.g., `payments.abcde.tmprl.cloud` or `aws-us-east-1.region.tmprl.cloud`).
5. Select **Add networks** and choose the Project and Network that contains your PSC endpoint.
6. Click **Create**.

#### 3. Add an A record

Inside the new zone, add a _standard A record_:

| Field                | Value                                                          |
| -------------------- | -------------------------------------------------------------- |
| DNS name             | the namespace endpoint (e.g. `payments.abcde.tmprl.cloud`)     |
| Resource record type | A                                                              |
| TTL                  | 60s is typical, but you can adjust as needed.                  |
| IPv4 Address         | the internal IP address of your PSC endpoint (e.g. `10.1.2.3`) |

#### 4. Verify DNS resolution from inside the Network

```shell
dig payments.abcde.tmprl.cloud
```

If the hostname resolves to the PSC endpoint IP address from a VM in the bound network, the override is working.

### Updating your workers/clients

With private DNS in place, configure your SDKs exactly as the public-internet examples show (filling in your own namespace):

```go
clientOptions := client.Options{
    HostPort: "payments.abcde.tmprl.cloud:7233",
    Namespace: "payments",
    // No TLS SNI override needed
}
```

The DNS resolver inside your network returns the private endpoint IP address, while TLS still validates the original hostname—simplifying both code and certificate management.

## Available GCP regions, PSC endpoints, and DNS record overrides

The following table lists the available Temporal regions, PrivateLink endpoints, and regional endpoints used for DNS record overrides:

<GCPRegions />

---

## Connectivity

## Private network connectivity for namespaces

Temporal Cloud supports private connectivity to namespaces via AWS PrivateLink or GCP Private Services Connect in addition to the default internet endpoints.

Namespace access is always securely authenticated via [API keys](/cloud/api-keys#overview) or [mTLS](/cloud/certificates), regardless of how you choose to connect.

### Required steps

To use private connectivity with Temporal Cloud:

1. Set up the private connection from your VPC to the region where your Temporal namespace is located.
1. Update your private DNS and/or worker configuration to use the private connection.
1. (Required to complete Google PSC setup, optional if using AWS PrivateLink): create a connectivity rule for the private connection and attach it to the target namespace(s). This will block all access to the namespace that is not over the private connection, but you can also add a public rule to also allow internet connectivity.

For steps 1 and 2, follow our guides for the target namespace's cloud provider:
- [AWS PrivateLink](/cloud/connectivity/aws-connectivity) creation and private DNS setup
- [Google Cloud Private Service Connect](/cloud/connectivity/gcp-connectivity) creation and private DNS setup

:::caution Finish client setup (complete step 2)

After creating a private connection, you must set up private DNS or update the configuration of all clients you want to use the private connection.

We recommend using private DNS.

Without this step, your clients may connect to the namespace over the internet if they were previously using public connectivity, or they will not be able to connect at all.

If that's not an option for you, refer to [our guide for updating the server and TLS settings on your clients](/cloud/connectivity#update-dns-or-clients-to-use-private-connectivity).

:::

For step 3, keep reading for details on [connectivity rules](/cloud/connectivity#connectivity-rules).

## Connectivity rules

:::tip Support, stability, and dependency info

Connectivity rules are currently in [public preview](/evaluate/development-production-features/release-stages#public-preview).

:::

### Definition

Connectivity rules are Temporal Cloud's mechanism for limiting the network access paths that can be used to access a namespace.

By default, a namespace has zero connectivity rules, and is accessible from 1. the public internet and 2. all private connections you've configured to the region containing the namespace. Namespace access is always securely authenticated via [API keys](/cloud/api-keys#overview) or [mTLS](/cloud/certificates), regardless of connectivity rules.

When you attach one or more connectivity rules to a namespace, Temporal Cloud will immediately block all traffic that does not have a corresponding connectivity rule from accessing the namespace. One namespace can have multiple connectivity rules, and may mix both public and private rules.

Each connectivity rule specifies either generic public (i.e. internet) access or a specific private connection.

A public connectivity rule takes no parameters.

An AWS PrivateLink (PL) private connectivity rule requires the following parameters:

- `connection-id`: The VPC endpoint ID of the PL connection (ex: `vpce-00939a7ed9EXAMPLE`)
- `region`: The region of the PL connection, prefixed with aws (ex: `aws-us-east-1`). Must be the same region as the namespace. Refer to the [Temporal Cloud region list](/cloud/regions) for supported regions.

A GCP Private Service Connect (PSC) private connectivity rule requires the following parameters:

- `connection-id`: The ID of the PSC connection (ex: `1234567890123456789`)
- `region`: The region of the PSC connection, prefixed with gcp (ex: `gcp-us-east1`). Must be the same region as the namespace. Refer to the [Temporal Cloud region list](/cloud/regions) for supported regions.
- `gcp-project-id`: The ID of the GCP project where you created the PSC connection (ex: `my-example-project-123`)

Connectivity rules can be created and managed with [tcld](https://docs.temporal.io/cloud/tcld/), [Terraform](https://github.com/temporalio/terraform-provider-temporalcloud/), or the [Cloud Ops API](/ops)

### Permissions and limits

Only [Account Admins and Account Owners](/cloud/users#account-level-roles) can create and manage connectivity rules. Connectivity rules are visible to Account Developers, Account Admins, and Account Owners.

By default each namespace is limited to 5 private connectivity rules, and each account is limited to 50 private connectivity rules. You can [contact support](/cloud/support#support-ticket) to request a higher limit.

There is only one public rule allowed per account, because it's generic and can be reused for all namespaces that you want to be available on the internet. Trying to create more than one public rule will throw an error.

## Creating a connectivity rule

### Temporal Cloud CLI (tcld)

Create private connectivity rule (AWS):

```bash
tcld connectivity-rule create --connectivity-type private --connection-id "vpce-abcde" --region "aws-us-east-1"
```

Create private connectivity rule (GCP):

```bash
tcld connectivity-rule create --connectivity-type private --connection-id "1234567890" --region "gcp-us-central1" --gcp-project-id "my-project-123"
```

Create public connectivity rule (you only need to do this once ever in your account):

```bash
tcld connectivity-rule create --connectivity-type public
```

The `cr` alias works the same way:

Private connectivity rule:

```bash
tcld cr create --connectivity-type private --connection-id "vpce-abcde" --region "aws-us-east-1"
```

```bash
tcld cr create --connectivity-type public
```

### Terraform

[Examples in the Terraform repo](https://github.com/temporalio/terraform-provider-temporalcloud/blob/main/examples/resources/temporalcloud_connectivity_rule/resource.tf)

## Attach connectivity rules to a namespace

Be careful! When any connectivity rules are set on a namespace, that namespace is ONLY accessible via the connections defined in those rules. If you remove a connectivity rule that your workers are using, your traffic will be interrupted.

If you already have workers using a namespace, adding both a public rule and any private rules simultaneously can help you avoid unintended loss of access. You can then ensure all workers are using private connections, and then remove the public rule.

### Temporal Cloud CLI (tcld)

Setting the connectivity rules on a namespace:

```bash
tcld namespace set-connectivity-rules --namespace "my-namespace.abc123" --connectivity-rule-ids "rule-id-1" --connectivity-rule-ids "rule-id-2"
```

Or using aliases:

```bash
tcld n scrs -n "my-namespace.abc123" --ids "rule-id-1" --ids "rule-id-2"
```

Connectivity rules are attached as a set, so if rules `rule-a`, `rule-b`, and `rule-c` were attached to a namespace and you wanted to detach `rule-c` only, you'd make one call attaching both `rule-a` and `rule-b`:

```bash
tcld namespace set-connectivity-rules --namespace "my-namespace.abc123 --ids rule-a --ids rule-b
```

Remove all connectivity rules (this will make the namespace public):

```bash
tcld namespace set-connectivity-rules --namespace "my-namespace.abc123" --remove-all
```

### Terraform

[Example in the Terraform repo](https://github.com/temporalio/terraform-provider-temporalcloud/tree/main/examples/resources/temporalcloud_namespace/resource.tf#L113-L128)

## View the connectivity rules for a namespace

You have two ways to view the connectivity rules attached to a particular namespace.

### Get namespace

Connectivity rules are included in the namespace details returned by the `namespace get` command. 

```bash
tcld namespace get -n "my-namespace.abc123"
```

### List connectivity rules by namespace

To see only the connectivity rules for a specific namespace (without other namespace details), use the `connectivity-rule list` command with a namespace argument.

```bash
tcld connectivity-rule list -n "my-namespace.abc123"
```

## Update DNS or clients to use private connectivity

We strongly recommend using private DNS instead of updating client server and TLS settings: 

- [How to set up private DNS in AWS](/cloud/connectivity/aws-connectivity#configuring-private-dns-for-aws-privatelink) 
- [How to set up private DNS in GCP](/cloud/connectivity/gcp-connectivity#configuring-private-dns-for-gcp-private-service-connect)

If you are unable to configure private DNS, you must update two settings in your Temporal clients:

1. Set the endpoint server address to the PrivateLink or Private Services Connect endpoint (e.g. `vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233` or `<GCP PSC IP address>:7233`)
2. Set TLS configuration to override the TLS server name (e.g., my-namespace.my-account.tmprl.cloud)

Updating these settings depends on the client you're using.

#### temporal CLI
```bash
TEMPORAL_ADDRESS=vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233
TEMPORAL_NAMESPACE=my-namespace.my-account
TEMPORAL_TLS_CERT=<path/to/cert.pem>
TEMPORAL_TLS_KEY=<path/to/cert.key>
TEMPORAL_TLS_SERVER_NAME=my-namespace.my-account.tmprl.cloud

temporal workflow count -n $TEMPORAL_NAMESPACE
```

#### grcpurl
```bash
grpcurl \
    -servername my-namespace.my-account.tmprl.cloud \
    -cert path/to/cert.pem \
    -key path/to/cert.key \
    vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233 \
    temporal.api.workflowservice.v1.WorkflowService/GetSystemInfo
```

#### Temporal SDKs
<SdkTabs>
<SdkTabs.Go>
```go
c, err := client.Dial(client.Options{
	HostPort:  "vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233",
	Namespace: "namespace-name.accId",
	ConnectionOptions: client.ConnectionOptions{
		TLS: &tls.Config{
			Certificates: []tls.Certificate{cert},
			ServerName:   "my-namespace.my-account.tmprl.cloud",
		},
	},
})
```
</SdkTabs.Go>
<SdkTabs.Java>
```java
WorkflowServiceStubs service =
        WorkflowServiceStubs.newServiceStubs(
            WorkflowServiceStubsOptions.newBuilder()
                .setSslContext(sslContext)
                .setTarget("vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233")
                .setChannelInitializer(
                    c -> c.overrideAuthority("my-namespace.my-account.tmprl.cloud"))
                .build());
```
</SdkTabs.Java>
<SdkTabs.TypeScript>
```ts
const connection = await NativeConnection.connect({
  address: "vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233",
  tls: {
    serverNameOverride: "my-namespace.my-account.tmprl.cloud" ,
    //serverRootCACertificate,
    // See docs for other TLS options
    clientCertPair: {
      crt: fs.readFileSync(clientCertPath),
      key: fs.readFileSync(clientKeyPath),
    },
  },
});
```
</SdkTabs.TypeScript>
<SdkTabs.Python>
```python
client_config["tls"] = TLSConfig(
    client_cert=bytes(crt, "utf-8"),
    client_private_key=bytes(key, "utf-8"),
    domain="my-namespace.my-account.tmprl.cloud",
)

client = await Client.connect("vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233")
```
</SdkTabs.Python>
<SdkTabs.DotNet>
```dotnet
// Create client 
var client = await TemporalClient.ConnectAsync(
  new(ctx.ParseResult.GetValueForOption(targetHostOption)!)
  {
    Namespace = ctx.ParseResult.GetValueForOption (namespaceOption)!,
    // Set TLS options with client certs. Note, more options could 
    // be added here for server CA (i.e. "ServerRootCACert") or SNI 
    // override (i.e. "Domain") for self-hosted environments with 
    // self-signed certificates. 
    Tls = new() 
    {
      ClientCert = 
        await File.ReadAllBytesAsync(ctx.ParseResult.GetValueForOption(clientCertOption) !.FullName), 
      ClientPrivateKey = 
        await File.ReadAllBytesAsync(ctx.ParseResult.GetValueFor0ption(clientKey0ption)!.FullName), Domain = "my-namespace.my-account.tmprl.cloud",
  },
});

// dotnet run --target-host "vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com:7233"
```
</SdkTabs.DotNet>
</SdkTabs>

To check whether your client has network connectivity to the private endpoint in question, run:
```bash
nc -zv vpce-0123456789abcdef-abc.us-east-1.vpce.amazonaws.com 7233
```

## Control plane connectivity

Using the Temporal Cloud [web UI](/web-ui), [Terraform provider](/production-deployment/cloud/terraform-provider), [`tcld` CLI](/cloud/tcld), or [Cloud Ops APIs](/ops) requires network access to the Temporal Cloud control plane. Different hostnames are used for different parts of the service.

- `saas-api.tmprl.cloud` (required for Terraform, tcld, and Cloud Ops APIs) 
- `web.onboarding.tmprl.cloud` (required for Web UI)
- `web.saas-api.tmprl.cloud` (required for Web UI)

---

## Workflow History Export

:::tip Support, stability, and dependency info

Workflow History Export is in [Public Preview](/evaluate/development-production-features/release-stages#public-preview).

:::

Workflow History Export allows users to export closed Workflow Histories from Temporal Cloud to cloud object storage (AWS S3 or GCP GCS), enabling:

- Compliance and audit trails of complete Workflow History data in [proto format](https://github.com/temporalio/api/blob/master/temporal/api/export/v1/message.proto)
- Analytics on Workflow History when ingested to the data platform of your choice

Workflow History Export in Temporal Cloud provides similar functionality as [Archival](/self-hosted-guide/archival) in a Self-Hosted Temporal Server. 
Archival is not supported in Temporal Cloud.

Exports run hourly, beginning 10 minutes after the hour. 
The time at which a closed Workflow appears in the exported file may vary, but it is typically available within one to four hours. 
Delivery is guaranteed at least once.

## Prerequisites {#prerequisites}

To use Workflow History Export, you must have:

1. A cloud account in the cloud provider where your Namespace is hosted.
2. An object storage bucket available to receive the exported History.

## Configure Workflow History Export {#configure}

### AWS

[AWS S3 Export Configuration](/cloud/export/aws-export-s3)

### GCP

[GCP GCS Export Configuration](/cloud/export/gcp-export-gcs)

## Verify export setup {#verify}

From the Export configuration page, select **Verify**.
This validates that Temporal can successfully write a test file to your object storage.

If everything is configured correctly, you will see a `Success` status indicating Temporal has written to the object store.

## Monitor export progress {#monitor}

After Export has been configured, you can check that it's still working in several ways:

1. **Object Storage**:

   - File Delivery: After the initial hour of setting up, inspect your object storage.
     You should see the exported Workflow History files.
   - Directory Structure: Your exported files will adhere to the following naming convention and path:

   ```bash
   //[bucket-name]/temporal-workflow-history/export/[Namespace]/[Year]/[Month]/[Day]/[Hour]/[Minute]/
   ```   

2. **Temporal Cloud Web UI**:

   - Export UI:

      - Last Successful Export: This displays the timestamp of the most recent successful export.
      - Last Status Check: This reflects the timestamp of the latest internal Workflow healthcheck.

   - Usage Dashboard:
      - Actions from the Export Job are included in the [Usage Dashboard](/cloud/billing-and-cost).

3. **Metrics**:
   - Export-related metrics are available from the [Cloud metrics endpoint](/cloud/metrics/), specifically the metric `temporal_cloud_v0_total_action_count` with the label `is_background="true"`.

## Working with exported files

Use the proto schema defined [here](https://github.com/temporalio/api/blob/master/temporal/api/export/v1/message.proto) to deserialize exported files.

## Export and High Availability Namespaces {#export-ha}

### Export Region Persistence

When Export is configured for a [High Availability](/cloud/high-availability) Namespace, the export is tied to the specific region where it was initially set up. The export configuration does not automatically failover with the Namespace.

- If Export is configured in Region A, it will continue to export from Region A's storage even after a Namespace failover to Region B
- Exports always read from and write to the same region where they were originally configured
- The export process is independent of Namespace failover events
- Export does not fail over automatically because we prioritize data completeness and consistency over real-time availability for exports. HA data replication has inherent latency, which could result in incomplete or inconsistent exports during a failover.

### Failover Scenarios

**Namespace Failover with Healthy Primary Region**: When a Namespace fails over to a secondary region but the primary region remains healthy (including its blob storage), the export job continues to operate from the primary region. It does not automatically switch to export data from the secondary region.

**Primary Region Outage**: If the primary region (where Export was configured) experiences a complete outage including S3/GCS storage: Exports will be unavailable until the primary region recovers. Once the primary region recovers, export will resume and include any Workflow histories that occurred during the outage. There may be delays in export processing, but the complete dataset will eventually be available. It does not automatically switch to export data from the secondary region.

---

## Exporting Workflow Event History to GCS

## Prerequisites {#prerequisites}

Before configuring the Export sink, complete the following steps in Google Cloud.

1. Create a GCS bucket and take note of its bucket name, for example, "test-export"

- Enable customer-managed encryption keys (CMEK) if you need additional security for your GCS bucket.
- Currently, only single region buckets are supported (or “Region” option when creating the bucket in GCS, not “Multi-region” or “Same-region”)
- The region of the bucket must be the same as the region of your Temporal Cloud Namespace.

2. Record the GCP Project ID that owns the bucket.
3. Create a service account in the same project that grants Temporal permission to write to your GCS bucket.
4. Follow the instructions in the Temporal Cloud UI, there are two ways to set up this service account:
   - Manual Setup:
     - Input the service account ID, GCP project ID and GCS bucket name.
     - Follow the instructions, manually set up a new service account.
   - Automated Setup:
     - Use the [Terraform template](https://github.com/temporalio/terraform-modules/tree/main/modules/gcp-sink-sa) to create the service account.

## Configure Workflow History Export

You can use either the [Temporal Cloud UI](#using-temporal-cloud-ui) or [tcld](#using-tcld) to configure the Workflow History Export.

:::note Why does Temporal Cloud provision multiple service accounts for Export?

Temporal Cloud creates multiple intermediary service accounts for export operations primarily for security purposes. The system randomly selects from these accounts when writing to your storage sink, which provides several benefits:

- **Security isolation**: If one service account is compromised or needs to be decommissioned, other accounts remain available
- **Load distribution**: Prevents exclusively using a single account, reducing security risk
- **Warm standby**: Keeps multiple accounts active to avoid potential throttling when switching between accounts
- **Reliability**: Provides resilience against cloud provider account-level issues that could affect a single service account

This approach prioritizes security and availability, ensuring robust export operations even if individual service accounts encounter issues.
:::

### Using Temporal Cloud UI

The following steps guide you through setting up Workflow History Export using the Temporal Cloud UI.

![](/img/cloud/gcp/export-sink-ui-gcp.png)

1. In the Cloud UI, navigate to the Namespaces section. Confirm that the Export feature is visible and properly displayed.
2. Configure the Export Sink for a Namespace:
   1. Choose GCS as the Sink type.
   2. Provide the following information:
      1. Name
      2. Service account ID
      3. GCP Project ID
      4. GCS bucket name
3. After inputting the necessary values, click on **Verify**.
   You should be able to write to the sink successfully.
   If not, please fix any errors or reach out to support for help.
   - If you just created the GCS bucket and granted the permission for your service account, it may take some time for it to populate the permission, thus, you may need to wait for several minutes (up to 5 minutes) then you can click the **Verify** button to verify the connection.
4. Clicking **Create** will complete the Export sink set up
5. The page will auto-refresh and you should see the status “Enabled” on the Export screen.
   You are now ready to export Workflow histories.
6. You can toggle the enable button if you want to stop export and resume in the future.
   **Note**: when you re-enable the feature, it will start from the current point in time, and not from the time when you disabled export.
7. You can also delete export by clicking **Delete**.

:::tip

Don't forget to click Create at the end of your setup to confirm your export.

:::

### Using tcld

To access export-related commands in tcld, please follow these steps:

1. Download the latest version of tcld. [https://docs.temporal.io/cloud/tcld/#install-tcld]
2. Make sure tcld version is v0.35.0 or above.
3. Run the command: `tcld n export gcs`:
   ```bash
   NAME:
      tcld namespace export gcs - Manage GCS export sink

   USAGE:
      tcld namespace export gcs command [command options] [arguments...]

   COMMANDS:
      create, c    Create export sink
      update, u    Update export sink
      validate, v  Validate export sink
      get, g       Get export sink
      delete, d    Delete export sink
      list, l      List export sinks
      help, h      Shows a list of commands or help for one command

   OPTIONS:
      --help, -h  show help
   ```

4. Run the `tcld n export gcs create` command and provide the following information:
   - —namespace
   - —sink-name
   - —service-account-email
   - —gcs-bucket
   - For Example:

   ```bash
   tcld n export gcs create -n test.ns --sink-name test-sink --service-account-email test-sink@test-export-sink.iam.gserviceaccount.com --gcs-bucket test-export-validation
   ```
5. Check the status of this command by either viewing the Namespace Export status in the Temporal Cloud UI or using the following command and looking for the state of “Active”.

```bash
tcld n export gcs g -n test.ns --sink-name test-sink
{
	"name": "test.ns",
	"resourceVersion": "b954de0c-c6ae-4dcc-90bd-3918b52c3f28",
	"state": "Active",
	"spec": {
		"name": "test-sink",
		"enabled": true,
		"destinationType": "Gcs",
		"s3Sink": null,
		"gcsSink": {
			"saId": "test-sink",
			"bucketName": "test-export-validation",
			"gcpProjectId": "test-export-sink",
		}
	},
	"health": "Ok",
	"errorMessage": "",
	"latestDataExportTime": "0001-01-01T00:00:00Z",
	"lastHealthCheckTime": "2024-01-23T06:40:02Z"
}
```

### Next Steps

- [Verify export setup](/cloud/export#verify)
- [Monitor export progress](/cloud/export#monitor)
- [Work with exported files](/cloud/export#working-with-exported-files)

---

## Manage API keys

Temporal Cloud API keys offer industry-standard identity-based authentication for Temporal users and [Service Accounts](/cloud/service-accounts).
This document introduces Temporal Cloud's API key features:

- [API key overview](#overview)
- [API key best practices](#best-practices)
- [Global Administrator and Account Owner API key management](#manage-api-keys)
- [User API key management](#user-api-keys)
- [Manage API keys for Service Accounts](#serviceaccount-api-keys)
- [API keys for Namespace authentication](#namespace-authentication)
- [Use API keys to authenticate](#using-apikeys)
- [Troubleshoot your API key use](#troubleshooting)
- [API keys: Frequently Asked Questions](#faqs)

## API key overview {#overview}

Each Temporal Cloud API key is a unique identity linked to role-based access control (RBAC) settings to ensure secure and appropriate access.

The authentication process follows this pathway:

<CaptionedImage
    src="/img/cloud/apikeys/apikeyrbac.png"
    title="API key (authentication) → Identity (user or Service Account) → RBAC (authorization)"
/>

## API key best practices {#best-practices}

- **Keep it secret; keep it safe**: Treat your API key like a password.
  Do not expose it in client-side code, public repositories, or other easily accessible locations.
- **Rotate keys regularly**: Change your API keys periodically to reduce risks from potential leaks.
- **Design your code for key updates**: Use key management practices that retrieve your API keys without hard-coding them into your apps.
  This lets you restart your Workers to refresh your rotated keys without recompiling your code.
- **Monitor API key usage**: Check usage metrics and logs regularly.
  Revoke the key immediately if you detect any unexpected or unauthorized activity.
- **Use a Key Management System (KMS)**: Employ a Key Management System to minimize the risk of key leaks.

### API key use cases

API keys are used for the following scenarios:

- _**Cloud operations automation**_:
  API keys work with most Temporal Cloud operational tools, including [`tcld`](/cloud/tcld), [Cloud Ops APIs](/ops), and [the Terraform provider](/production-deployment/cloud/terraform-provider).
  Use them to manage your Temporal Cloud account, Namespaces, certificates, and user identities.
- _**Namespace authentication**_:
  API keys serve as an authentication mechanism for executing and managing Workflows via the SDK and Temporal CLI, offering an alternative to mTLS-based authentication.

### API key supported tooling

Use API keys to authenticate with:

- [The Temporal CLI](/cli)
- [Temporal SDKs](/develop)
- [`tcld`](/production-deployment/cloud/tcld/index.mdx)
- [The Cloud Operations API](/production-deployment/cloud/operation-api.mdx)
- [Temporalʼs Terraform provider](/production-deployment/cloud/terraform-provider)

### API key permissions

API keys support both users and Service Accounts.
Here are the differences in their permissions:

- Any user can create, delete, and update their own API key access using the Cloud UI or `tcld`.
- Only Global Administrators and Account Owners can create, delete, and update access to API keys for Service Accounts.

### API key prerequisites

Check these setup details before using API keys:

- The Global Administrator or Account Owner may need to [enable API keys access](#manage-api-keys) for your Temporal Account.
- Have access to the [Temporal Cloud UI](https://cloud.temporal.io/) or Temporal Cloud CLI ([tcld](https://docs.temporal.io/cloud/tcld/)) to create an API key.

## Global Administrator and Account Owner API key management {#manage-api-keys}

Global Administrators and Account Owners can monitor, manage, disable, and delete API keys for any user or Service Account within their account.
To manage your account’s API keys:

1. [Log in](https://cloud.temporal.io/) to the Temporal Cloud UI.
1. [Select **Settings** and choose **API keys**](https://cloud.temporal.io/settings/api-keys).

Administrators can disable the creation of new API keys using the **Disable API Keys** button on the **API Keys** Settings page.
Existing API keys can still be used to authenticate into Temporal Cloud normally until they are either disabled, deleted, or expired.

To disable or delete an individual API key use the vertical ellipsis next to the API key row or view the API key detail page.

To find an API key, you can filter by API key state and identity type (Global Administrators and Account Owners only).

:::caution DISABLED API KEYS

Deleting or disabling a key removes its ability to authenticate into Temporal Cloud.
If you delete or disable an API key for a running Workflow, that Workflow will fail until a new API key secret is created and configured.

:::

## User API key management {#user-api-keys}

Manage your personal API keys with the Temporal Cloud UI or `tcld`.
These sections show you how to generate, manage, and remove API keys for a user.

### Generate an API key

Create API keys using one of the following methods:

:::caution

- Once generated, copy and securely save the API key.
  It will be displayed only once for security purposes.

:::

#### Generate API keys with the Temporal Cloud UI

[Log in](https://cloud.temporal.io/) to the Temporal Cloud UI and navigate to your [Profile Page → API keys](https://cloud.temporal.io/profile/api-keys).
Then select **Create API key** and provide the following information:

- API key name: a short identifiable name for the key
- API key description: a longer form description of the key's use
- Expiration date: the end-date for the API key

Finish by selecting **Generate API key**.

#### Generate API keys with tcld

To generate an API key, log into your account and issue the following command:

```command
tcld login
tcld apikey create \
    --name <api-key-name> \
    --description "<api-key-description>" \
    --duration <api-key-duration>
```

Duration specifies the time until the API key expires, for example: "30d", "4d12h", etc.

### Enable or Disable an API Key

You can enable or disable API keys.
When disabled, an API key cannot authenticate with Temporal Cloud.

#### Manage API Key State with the Temporal Cloud UI

Follow these steps:

1. [Log in](https://cloud.temporal.io/) to the Temporal Cloud UI.
1. Go to your [Profile Page → API Keys](https://cloud.temporal.io/profile/api-keys).
1. Select the three vertical dots next to the API key’s row.
1. Choose **Enable** or **Disable**.

#### Manage API Key State with tcld

To manage an API key, log into your account and use one of the following commands to enable or disable it:

```command
tcld login
tcld apikey disable --id <api-key-id>
tcld apikey enable --id <api-key-id>
```

### Delete an API key

Deleting an API key stops it from authenticating with Temporal Cloud.

:::caution

Deleting an API key for a running Workflow will cause it to fail unless you rotate the key with a new one.
This can affect long-running Workflows that outlast the API key's lifetime.

:::

#### Delete API keys with the Temporal Cloud UI

Follow these steps to remove API keys:

1. [Log in](https://cloud.temporal.io/) to the Temporal Cloud UI.
1. Navigate to your [Profile Page → API keys](https://cloud.temporal.io/profile/api-keys).
1. Select the three vertical dots next to the API key's row.
1. Choose **Delete**.

#### Delete API keys with tcld

To delete an API key, log into your account and issue the following:

```command
tcld login
tcld apikey delete --id <api-key-id>
```

### Rotate an API key

Temporal API keys automatically expire based on the specified expiration time.
Follow these steps to rotate API keys:

1. Create a new key.
   You may reuse key names if that helps.
1. Ensure that both the original key and new key function properly before moving to the next step.
1. Switch clients to load the new key and start using it.
1. Delete the old key after it is no longer in use.

## Manage API keys for Service Accounts {#serviceaccount-api-keys}

Global Administrators and Account Owners can manage API keys for all Service Accounts in their account and generate API keys for Service Accounts.
This is different for users, who generate their own API keys.

### Generate an API Key for a Service Account

Create API keys for Service Accounts using one of the following methods:

:::caution

- Once generated, copy and securely save the API key.
  It will be displayed only once for security purposes.

:::

#### Generate API Keys with the Temporal Cloud UI

[Log in](https://cloud.temporal.io/) to the Temporal Cloud UI and go to [API keys settings](https://cloud.temporal.io/settings/api-keys).
Select **Create API key**, then choose **Service Account** from the "Create an API key for" dropdown.
In the "Mapped to identity" input box, select a Service account and provide the following information:

- **API key name**: A short, identifiable name for the key
- **API key description**: A longer description of the key's use
- **Expiration date**: The end date for the API key

Finish by selecting **Generate API key**.

#### Generate API keys with tcld

To create an API key for a Service Account, use `tcld apikey create` with the `--service-account-id` flag:

```
tcld apikey create \
    --name <api-key-name> \
    --description "<api-key-description>" \
    --duration <api-key-duration> \
    --service-account-id <service-account-id>
```

### Enable or disable an API key

Global Administrators and Account Owners can manage API key access for any user in their account using the Temporal Cloud UI or `tcld`.

#### Manage keys with Temporal Cloud UI

Follow these steps:

1. Log into Temporal Cloud.
1. Go to [https://cloud.temporal.io/settings/api-keys](https://cloud.temporal.io/settings/api-keys) and find the identity that owns the API key.
1. Click the Disable/Enable button to perform the action.
   There may be a delay after changing the status.
   Once successful, the updated API key status will be shown in the row.

#### Manage keys with tcld

Use the `tcld apikey disable` or `tcld apikey enable` command to disable or enable an API key:

```
tcld login
tcld apikey disable --id <api-key-id>
tcld apikey enable --id <api-key-id>
```

This command is the same for users and Service Accounts.

### Delete an API key for a Service Account

Global Administrators and Account Owners can delete API keys for any user or Service Account in their account using the Temporal Cloud UI or `tcld`.
Deleting a key removes its ability to authenticate with Temporal Cloud.
If you delete an API key for a running Workflow, that Workflow will fail unless you rotate the API key with a new one.

#### Delete a Service Account API key with Temporal Cloud UI

Follow these steps:

1. Navigate to [https://cloud.temporal.io/settings/api-keys](https://cloud.temporal.io/settings/api-keys).
1. Locate the identity that owns the API key and click on the row to view the API keys associated with that identity.
1. Click the Delete button.
   There may be a delay after deleting the API key.
1. Once successful, the updated API key status will be reflected in the row.

#### Delete a Service Account API key with tcld

Use the `tcld apikey delete` command to delete an API key.
The process for deleting an API key is the same for a user or Service Account.

```
tcld login
tcld apikey delete --id <api-key-id>
```

### Rotate a Service Account API key

Temporal API keys automatically expire based on the specified expiration time.
Follow these steps to rotate API keys:

1. Create a new key.
   You may reuse key names if that helps.
1. Ensure that both the original key and new key function properly before moving to the next step.
1. Switch clients to load the new key and start using it.
1. Delete the old key after it is no longer in use.

:::tip

Service Accounts can rotate their own API keys irrespective of their configured permissions.
To use this feature, have your Service Account create a new API key using the [Cloud Ops APIs](/ops) or [`tcld`](/cloud/tcld) before the current one expires.
Service Accounts cannot delete their own API keys without the requisite permissions, which helps keep Workflow access secure.

:::

## API keys for Namespace authentication {#namespace-authentication}

Create a Namespace with API key authentication as an alternative to mTLS-based authentication by selecting "Allow API key authentication" during setup.
The gRPC endpoint format for the Namespace depends on the authentication method:

- For API key connections, use the gRPC regional endpoint `<region>.<cloud_provider>.api.temporal.io:7233`.

Use this gRPC endpoint in the Temporal CLI or SDK to connect to Temporal Cloud with an API key.

:::info

For [Namespaces with High Availability features](/cloud/high-availability) with API key authentication enabled, use the gRPC Namespace endpoint: `<namespace>.<account>.tmprl.cloud:7233`.
This allows automated failover without needing to switch endpoints.

:::

See the following documentation for [accessing Namespaces](/cloud/namespaces#access-namespaces) for more information.

## Use API keys to authenticate {#using-apikeys}

Authenticate with Temporal Cloud using API keys with the following clients:

- [Temporal CLI](/cli)
- [SDKs](/develop)
- [Temporal Cloud CLI `tcld`](/production-deployment/cloud/tcld/index.mdx)
- [The Cloud Operations API](/production-deployment/cloud/operation-api.mdx)
- [Temporal’s Terraform Provider](/production-deployment/cloud/terraform-provider)

### Temporal CLI

To use your API key with the Temporal CLI, either pass it with the `--api-key` flag or set an environment variable in your shell (recommended).
The CLI automatically picks up the `TEMPORAL_API_KEY` environment variable from your shell.

In addition to the API key, the following client options are required:

- `--address`: Provide the Namespace's gRPC endpoint from the Namespace UI's gRPC endpoint box.
  - For API key connections, use the format `<region>.<cloud_provider>.api.temporal.io:7233`.
  - You can set the address using an environment variable.
- `--namespace`: Provide the `namespace.accountId` from the top of the Namespace page in the UI.
  - Use the format `<namespace_id>.<account_id>`.
  - This can be set using an environment variable.

For example, to connect to Temporal Cloud from the CLI using an environment variable for the API key:

```bash
export TEMPORAL_API_KEY=<key-secret>
temporal workflow list \
    --address <endpoint> \
    --namespace <namespace_id>.<account_id>
```

:::tip ENVIRONMENT VARIABLES

Do not confuse environment variables, set with your shell, with temporal env options.

:::

### SDKs

To use your API key with a Temporal SDK, see the instructions in each SDK section.

[How to connect to Temporal Cloud using an API Key with the Go SDK](/develop/go/temporal-client#connect-to-temporal-cloud-api-key)

[How to connect to Temporal Cloud using an API Key with the Java SDK](/develop/java/temporal-client#connect-to-temporal-cloud-api-key)

[How to connect to Temporal Cloud using an API Key with the Python SDK](/develop/python/temporal-client#connect-to-temporal-cloud-api-key)

[How to connect to Temporal Cloud using an API Key with the TypeScript SDK](/develop/typescript/temporal-client#connect-to-temporal-cloud-api-key)

[How to connect to Temporal Cloud using an API Key with the .NET SDK](/develop/dotnet/temporal-client#connect-to-temporal-cloud-api-key)

### tcld

To use an API key with `tcld`, choose one of these methods:

- Use the `--api-key` flag.
- Set the `TEMPORAL_API_KEY` environment variable in your shell.

:::tip ENVIRONMENT VARIABLES

Do not confuse environment variables, set with your shell, with temporal env options.

:::

### Cloud Ops API

To use an API key with the [Cloud Ops API](/ops), securely pass the API key in your API client.
For a complete example, see [Cloud Samples in Go](https://github.com/temporalio/cloud-samples-go/blob/1dd4254b6ed1937e361005c0144410e72b8a5542/client/api/apikey.go).

### Terraform Provider

To use an API key with the [Temporal Terraform Provider](/production-deployment/cloud/terraform-provider), pass the API key as a provider argument.

## Troubleshoot your API key use {#troubleshooting}

**Invalid API key errors**: Check that you copied the key correctly and that it hasn't been revoked or expired.

## API keys: Frequently Asked Questions {#faqs}

**Q: Can I issue and use multiple API keys for the same account?**

A: Yes, you can generate multiple API keys for different services or team members.

**Q: How many API keys can be issued at once?**

A: Up to 10 non-expired keys per user and 20 non-expired keys per Service Account.

**Q: Do API keys expire?**

A: Yes, API keys expire based on the specified expiration date.
Temporal recommends rotating API keys periodically.

**Q: Whats the maximum allowed expiration for an API key?**

A: The maximum expiration time for an API key is 2 years.

**Q: What happens if I misplace or lose my API bearer token/secret key?**

A: The full key is displayed only once upon creation for security reasons.
If you lose it, generate a new one.

**Q: What is the `Generate API Key` button on the Namespace page?**

A: The `Generate API Key` button on a Namespace page generates an API key with `Admin` permissions for the given Namespace and the maximum expiration time, which is 2 years.
For additional details, refer to [Namespace Scoped Service Accounts](/cloud/service-accounts#scoped).

---

## Usage and Billing Management

Temporal strives to provide full transparency over billing and costs.
Account Owners and Finance Admins can view their [detailed billing information](https://cloud.temporal.io/billing) at any time.
Use this information to assess your spending patterns, inspect your credit ledger, check your invoice histories, update payment details,
and manage your current plan as needed.
You can see namespace-level cost estimates on the [usage dashboard](https://cloud.temporal.io/usage).

For more information on current Temporal Cloud pricing for Actions, storage, and services/support, please visit our [Pricing](/cloud/pricing) page.

The [billing](https://cloud.temporal.io/billing) page includes the following information.
If you're not on a standard plan, your billing page may show a subset of this list:

- [Current balance](#current-balance): Your balance to date for this billing cycle
- [Recent bill](#recent-bill): The amount of your most recent bill
- [Invoice history](#invoice): Access to all past invoices
- [Credit ledger](#credit-table): A record of all credit related transactions including details on credit grants, purchases, usage, and remaining credits, if applicable
- [Plan](#plans): Your current plan, consumption pricing, and entitlements, with the ability to manage upgrades and downgrades, payment method, and account deletion

The [Usage](https://cloud.temporal.io/usage) page shows the cost breakdown by Namespace.
If your organization separates projects by Namespace -- for architectural reasons, for development/production differentiation, for different products, etc -- you can view individual costs for each Namespace.

## Current balance {#current-balance}

Your current balance card shows the balance for your current billing cycle and the date it was last updated.
This balance adjusts with use and appears on the first line of your Invoices table.

:::note Billing Cycles

Billing cycles normally begin on the first of the month (UTC).
The minimum support fee for your first month is prorated based on your sign-up date.

:::

## Recent bill {#recent-bill}

The "Recent Bill" card displays the previous bill amount.

![Recent bill card showing a balance of $0.00](/img/cloud/billing/billing-card.png)

- If you pay your invoices through Stripe, you'll see a **Pay Now** button.
  It takes you to the Stripe portal to complete your payment
- If your account is set up for auto-payment, you don’t need manually pay bills.
  However, you can choose to make manual payments whenever you wish

## Invoices {#invoice}

To review your invoices, follow these steps:

1. Click **Billing** on your left-side vertical navigation.
2. Under the **Invoices** section, select and download the invoice(s) you want to review.

The Invoices table shows the following information:

- Date (UTC): The date range covered by the invoice
- Type: The type of invoice, such as credit purchase or cloud usage
- Credit Granted: The total credits added to your account
- Credit Purchase Amount: The amount paid for purchasing credits
- Credit Usage: The credits used during the billing cycle
- Subtotal: The total amount of the invoice before any adjustments
- Balance Due: The amount to pay after applying credits

![Billing page showing Invoices tab](/img/cloud/billing/billing-invoices.png)

:::note Current Month Invoice

During the current billing period, your invoice will not be finalized and the download option will not be available.

:::

## Credits {#credit-table}

The following information appears under the credits table:

- Effective At (UTC): The date when the credit grant became effective
- Type: Indicates whether the transaction was a deduction, expiry, or grant
- Amount: The credit amount that was granted, deducted, or expired
- Credits Remaining: The remaining credit available in the account

![Billing page showing Credits tab](/img/cloud/billing/billing-credits.png)

## Cost by Namespace {#cost-by-namespace}

Account Owners can access a cost column on the Usage page.
This allows you to monitor your cost on a per Namespace basis.
If your organization separates work by Namespace—for development, production, or different products—you can view costs for each.

![Billing page showing Usage](/img/cloud/billing/billing-usage.png)

:::note Cost Breakdown Limitations

Namespace cost details are not available for "last 90 days" or "last 120 days".
Cost breakdowns are estimated as the total invoices prorated by usage across namespaces to account for Actions/Storage
included in your Temporal plan.

:::

You may download your Invoices prior to this calendar month by clicking the download icon by the date.

## Plans {#plans}

Account owners and Finance Admin can access their Temporal Plan information on the plans page.
For customers on a standard agreement you will be able to:

- View current plan information, pricing details and entitlements
- View other available plans, pricing details and entitlements
- View Pay-as-You-Go pricing rates applicable to your plan
- Upgrade and Downgrade between plans available on a standard agreement

![Billing page showing Plans tab](/img/cloud/billing/billing-plans.png)

Requests to upgrade your plan are processed immediately and you will be billed on a pro-rated basis for that billing period.
Your monthly entitlements will reflect the full volume of included Actions and Storage of the upgrade plan for that billing month.
After an upgrade, a downgrade cannot be processed until the following billing period.

Requests to downgrade will be processed immediately. Billing and entitlements will be backdated to the beginning of the billing period.

## Account Cancellation

The way you created your Temporal account determines how you can cancel your subscription and remove the account.

- **For accounts managed by our sales team**. 
  Please submit a support ticket so we can help you.

- **For accounts created through our self-signup portal**. 
  Account owners can delete their accounts on the Temporal Cloud Billing page, under the **Plan** tab.
  If you're no longer using Temporal Cloud, use the Delete Account button to begin the process.

  - Permanently deleted accounts will immediately cease billing and be scheduled for full deletion within 72 hours.

  - Account Data and Active Storage will be permanently. Retained Storage will be deleted in accordance with its configured retention period.

![Billing page showing the Plan tab. The contents on the tab include "Manage Payment Method" and "Delete Account" buttons. The "Delete Account" button is placed below text asking "No longer using Temporal Cloud?"](/img/cloud/billing/billing-cancel.png)

---

## Manage certificates

[Temporal Cloud](https://temporal.io/cloud) requires security certificates for secure access and communication.

Temporal Cloud access is secured by the mutual Transport Layer Security (mTLS) protocol, which requires a CA certificate from the user.

A [Worker Process](/workers#worker-process) requires a CA certificate and private key to connect to Temporal Cloud.
Temporal Cloud does not require an exchange of secrets; only the certificates produced by private keys are used for verification.

:::caution Don't let your certificates expire

An expired root CA certificate invalidates all downstream certificates.

An expired end-entity certificate prevents a [Temporal Client](/encyclopedia/temporal-sdks#temporal-client) from connecting to a Namespace or starting a Workflow Execution.
If the client is on a Worker, any current Workflow Executions that are processed by that Worker either run indefinitely without making progress until the Worker resumes or fail because of timeouts.

To update certificates, see [How to add, update, and remove certificates in a Temporal Cloud Namespace](#manage-certificates).

:::

All certificates used by Temporal Cloud must meet the following requirements.

## Requirements for CA certificates in Temporal Cloud {#certificate-requirements}

Certificates provided to Temporal for your [Namespaces](/namespaces) _must_ meet the following requirements.

### CA certificates

A CA certificate is a type of X.509v3 certificate used for secure communication and authentication.
In Temporal Cloud, CA certificates are required for configuring mTLS.

CA certificates _must_ meet the following criteria:

- The certificates must be X.509v3.
- Each certificate in the bundle must be either a root certificate or issued by another certificate in the bundle.
- Each certificate in the bundle must include `CA: true`.
- A certificate cannot be a well-known CA (such as DigiCert or Let's Encrypt) _unless_ the user also specifies certificate filters.
- The signing algorithm must be either RSA or ECDSA and must include SHA-256 or stronger message authentication.
  SHA-1 and MD5 cannot be used.
- The certificates cannot be generated with a passphrase.

:::info

A certificate bundle can contain up to 16 CA certificates.
A certificate bundle can have a maximum payload size of 32 KB before base64 encoding.

:::

### End-entity certificates

An end-entity certificate is a type of X.509v3 certificate used by clients to authenticate themselves.
Temporal Cloud lets you limit access to specific end-entity certificates by using [certificate filters](#manage-certificate-filters).

An end-entity (leaf) certificate _must_ meet the following criteria:

- The certificate must be X.509v3.
- Basic constraints must include `CA: false`.
- The key usage must include Digital Signature.
- The signing algorithm must be either RSA or ECDSA and must include SHA-256 or stronger message authentication.
  SHA-1 and MD5 cannot be used.

When a client presents an end-entity certificate, and the whole certificate chain is constructed, each certificate in the chain (from end-entity to the root) must have a unique Distinguished Name.

:::caution

Distinguished Names are _not_ case sensitive; that is, uppercase letters (such as ABC) and lowercase letters (such as abc) are equivalent.

:::

## How to issue root CA and end-entity certificates {#issue-certificates}

Temporal Cloud authenticates a client connection by validating the client certificate against one or more CA certificates that are configured for the specified Namespace.

Choose one of the following options to generate and manage the certificates:

### Option 1: You already have certificate management infrastructure

If you have existing certificate management infrastructure that supports issuing CA and end-entity certificates,
export the CA and generate an end-entity certificates using your existing tools.

Ensure that the CA certificate is long-lived and that the end-entity certificate expires before the CA certificate.

Follow the instructions to [upload the CA certificate](/cloud/certificates#update-certificates-using-temporal-cloud-ui) and [configure your client](/cloud/certificates#configure-clients-to-use-client-certificates) with the end-entity certificate.

### Option 2: You don't have certificate management infrastructure

If you don't have an existing certificate management infrastructure, issue the CA and end-entity certificates using [tcld](#use-tcld-to-generate-certificates) or open source tools such as [certstrap](#use-certstrap-to-generate-certificates).

#### Use tcld to generate certificates

You can generate CA and end-entity certificates by using [tcld](/cloud/tcld).

Although Temporal Cloud supports long-lived CA certificates, a CA certificate generated by [tcld](/cloud/tcld) has a maximum duration of 1 year (`-d 1y`).
You must set an end-entity certificate to expire before its root CA certificate, so specify its duration appropriately.

To create a new CA certificate, use `tcld gen ca`.

```sh
mkdir temporal-certs
cd temporal-certs
tcld gen ca --org temporal -d 1y --ca-cert ca.pem --ca-key ca.key
```

The contents of the generated `ca.pem` should be pasted into the "CA Certificates" section of your Namespace settings page.

To create a new end-entity certificate, use `tcld gen leaf`.

```sh
tcld gen leaf --org temporal -d 364d --ca-cert ca.pem --ca-key ca.key --cert client.pem --key client.key
```

You can now use the generated CA certificate (`ca.pem`) with Temporal Cloud and configure your client with these certs (`client.pem`, `client.key`).

Upload the contents of the `ca.pem` file to the **CA Certificates** section of your **Namespace** settings.

Follow the instructions to [upload the CA certificate](/cloud/certificates#update-certificates-using-temporal-cloud-ui) and [configure your client](/cloud/certificates#configure-clients-to-use-client-certificates) with the end-entity certificate.

#### Use certstrap to generate certificates

Temporal Cloud requires client certificates for authentication and secure communication.
[Certstrap](https://github.com/square/certstrap) is a popular and easy-to-use tool for issuing certificates.

Before you begin, ensure you have installed Certstrap by following the instructions in the [Certstrap README](https://github.com/square/certstrap#getting-started).

A Certificate Authority (CA) is a trusted entity that issues digital certificates.
These certificates certify the ownership of a public key by the named subject of the certificate.
End-entity certificates are issued and signed by a CA, and they are used by clients to authenticate themselves to Temporal Cloud.

Create a self-signed CA certificate and use it to issue an end-entity certificate for your Temporal Cloud namespace.

##### 1. Create a Certificate Authority (CA)

Create a new Certificate Authority (CA) using Certstrap:

```command
./certstrap init --common-name "CertAuth"
```

This command creates a self-signed CA certificate named `CertAuth.crt` in the `out` folder within the Certstrap directory.
This CA certificate will be used to sign and issue end-entity certificates.

##### 2. Set the Namespace Name

Set the Namespace Name as the common name for the end-entity certificate:

<Tabs>
  <TabItem value="macos" label="macOS" default>

For Linux or macOS:

```command
export NAMESPACE_NAME=your-namespace
```

</TabItem>
    <TabItem value="windows" label="Windows" default>

For Windows:

```command
set NAMESPACE_NAME=your-namespace
```

</TabItem>
</Tabs>

Replace `your-namespace` with the name of your Temporal Cloud namespace.

##### 3. Request an End-Entity Certificate

Next, request a certificate with a common name equal to the Namespace Name:

```command
./certstrap request-cert --common-name ${NAMESPACE_NAME}
```

This command creates a Certificate Signing Request (CSR) for an end-entity certificate, but not the actual certificate itself.

##### 4. Sign the Certificate Request

Sign the certificate request and generate the end-entity certificate:

```command
./certstrap sign ${NAMESPACE_NAME} --CA "CertAuth"
```

This command takes the CSR from the previous step and signs it with your CA (`CertAuth`).
The result is an end-entity certificate (`your-namespace.crt`) that is now a valid certificate signed by your CA.

##### 5. (optional) Convert to PKCS8 Format for Java SDK

If you are using the Temporal Java SDK, you will need to convert the PKCS1 file format to PKCS8 file format.
Export the end-entity's private key to a PKCS8 file:

```command
openssl pkcs8 -topk8 -inform PEM -outform PEM -in out/${NAMESPACE_NAME}.key -out out/${NAMESPACE_NAME}.pkcs8.key -nocrypt
```

##### 6. Use the Certificates with Temporal Cloud

You can now use the generated client certificate (`your-namespace.crt`) and the CA certificate (`CertAuth.crt`) with Temporal Cloud.

Upload the contents of the `CertAuth.crt` file to the **CA Certificates** section of your **Namespace** settings.

Follow the instructions to [upload the CA certificate](/cloud/certificates#update-certificates-using-temporal-cloud-ui) and [configure your client](/cloud/certificates#configure-clients-to-use-client-certificates) with the end-entity certificate.

## How to control authorization for Temporal Cloud Namespaces {#control-authorization}

Because Temporal Cloud uses mTLS for authorization, we recommend that an end-entity certificate be scoped to a specific Namespace.
Temporal Cloud requires full CA chains, so you can achieve authorization in two ways.

### Option 1: Issue a separate root certificate for each Namespace

Each certificate must belong to a chain up to the root CA certificate.
Temporal uses the root CA certificate as the trusted authority for access to your Namespaces.

1. Ensure that your certificates meet the [certificate requirements](#certificate-requirements).
1. [Add client CA certificates to a Cloud Namespace](/cloud/tcld/namespace/#add).

### Option 2: Use the same root certificate for all Namespaces but create a separate certificate filter for each Namespace

[How to manage certificate filters in Temporal Cloud](#manage-certificate-filters)

## How to receive notifications about certificate expiration {#expiration-notifications}

To keep your Namespace secure and online, you must update the CA certificate for the Namespace _before_ the certificate expires.

To help you remember to do so, Temporal Cloud sends email notifications to users who have the Account Owner or Global Admin [roles](/cloud/users#account-level-roles) or the Namespace Admin [permission](/cloud/users#namespace-level-permissions) 15 days before expiration and, if necessary, 10 days before expiration.

If the certificate is not updated, 5 days before expiration Temporal Cloud creates a support ticket on behalf of the Account Owner, Global Admins, and Namespace Admins.

To ensure that you receive email notifications, configure your junk-email filters to permit email from `noreply@temporal.io`.

After a support ticket is created, admins should expect a follow-up from the Temporal Developer Success team.

To change who receives certificate-expiration notifications for a Namespace (or to provide feedback about such notifications), [create a support ticket](/cloud/support#support-ticket).

## How to handle a compromised end-entity certificate

:::warning

Temporal does not support or check certificate revocation lists (CRLs). Customers are expected to keep their certificates up to date.

:::

The recommended approach to avoiding compromised certificates is to have short-lived end-entity certificates.
A short-lived compromised certificate can be left to expire on its own. Seek guidance from your infosec team to
determine an appropriate value of "short-lived" for your business.

If you suspect or confirm that an end-entity certificate has been compromised, and leaving it to expire is not an option,
take immediate action to secure your Temporal Cloud Namespace and prevent unauthorized access.

If you're using certificate filters, you can set the filters to block a compromised certificate. Follow the instructions in
[How to manage certificate filters in Temporal Cloud](#manage-certificate-filters).

If you need to replace a compromised certificate manually, follow these steps:

### 1. Generate a new CA certificate

Follow the instructions in [How to issue CA and end-entity certificates](#issue-certificates).
All end-entity certificates that can be reached by the previous CA must be regenerated.
Ensure the new CA certificate meets [the certificate requirements](#certificate-requirements).

### 2. Deploy the new CA certificate to the Namespace

Follow the instructions for issuing a [new CA certificate to a Namespace](#option-1-issue-a-separate-root-certificate-for-each-namespace).
Deploy the new CA certificate alongside the existing one, so you don’t lose connectivity with old end-entity certificates before the new ones are generated and deployed.

### 3. Regenerate end-entity certificates with the new CA certificate

[Configure all clients](https://docs.temporal.io/cloud/certificates#configure-clients-to-use-client-certificates)
(Temporal CLI, SDKs, or Workers) to use the new certificate and private key alongside the compromised key.
Update the client configuration as described in [Configure clients to use client certificates](#configure-clients-to-use-client-certificates).

Test the new certificate to confirm clients can connect to the Namespace without issues.

### 4. Remove the compromised CA certificate

Follow the instructions in [How to add, update, and remove certificates in a Temporal Cloud Namespace](#manage-certificates)
to remove the compromised CA certificate from the Namespace.

### 5. Monitor and audit

After implementing the changes, monitor your Namespace for unauthorized access attempts or unusual activity in audit logs.
Review your certificate management practices to identify how the compromise occurred.
Consider implementing stricter controls, such as:

- Limiting end-entity certificates to specific Namespaces
- Rotating certificates regularly as a preventive measure
- [Audit logs on a regular schedule](https://docs.temporal.io/cloud/audit-logging)

## How to add, update, and remove certificates in a Temporal Cloud Namespace {#manage-certificates}

:::note

To manage certificates for a Namespace, a user must have [Namespace Admin](/cloud/users#namespace-level-permissions) permission for that Namespace.

:::

To manage certificates for Temporal Cloud Namespaces, use the **Namespaces** page in Temporal Cloud UI or the [tcld namespace accepted-client-ca](/cloud/tcld/namespace/#accepted-client-ca) commands.

Don't let your certificates expire!
Add reminders to your calendar to issue new CA certificates well before the expiration dates of the existing ones.
Temporal Cloud begins sending notifications 15 days before expiration.
For details, see the previous section ([How to receive notifications about certificate expiration](#expiration-notifications)).

When updating CA certificates, it's important to follow a rollover process (sometimes referred to as "certificate rotation").
Doing so enables your Namespace to serve both CA certificates for a period of time until traffic to your old CA certificate ceases. This prevents any service disruption during the rollover process.

{/* How to update certificates in Temporal Cloud using Temporal Cloud UI */}

### Update certificates using Temporal Cloud UI

Updating certificates using the following strategy allows for a zero-downtime rotation of certificates.

1. On the left side of the window, select **Namespaces**.

2. Select the name of the Namespace to update.

3. In the top-right portion of the page for the Namespace, select **Edit**.

4. On the **Edit** page, select the **CA Certificates** card to expand it.

5. In the certificates box, scroll to the end of the existing certificate (that is, past `-----END CERTIFICATE-----`).

6. On the following new line, paste the entire PEM block of the new certificate.

7. Select **Save**.

8. Wait until all Workers are using the new certificate.

9. Return to the **Edit** page of the Namespace and select the **CA Certificates** card.

10. In the certificates box, delete the old certificate, leaving the new one in place.

11. Select **Save**.

{/* How to update certificates in Temporal Cloud using tcld */}

### Update certificates using tcld

Updating certificates using the following strategy allows for a zero-downtime rotation of certificates.

1. Create a single file that contains both your old and new CA certificate PEM blocks.
   Just concatenate the PEM blocks on adjacent lines.

   ```
   -----BEGIN CERTIFICATE-----
   ... old CA cert ...
   -----END CERTIFICATE-----
   -----BEGIN CERTIFICATE-----
   ... new CA cert ...
   -----END CERTIFICATE-----
   ```

1. Run the `tcld namespace accepted-client-ca set` command with the CA certificate bundle file.

   ```bash
   tcld namespace accepted-client-ca set --ca-certificate-file <path>
   ```

1. Monitor traffic to your old certificate until it ceases.

1. Create another file that contains only the new CA certificate.

1. Run the `tcld namespace accepted-client-ca set` command again with the updated CA certificate bundle file.

## How to manage certificate filters in Temporal Cloud {#manage-certificate-filters}

To limit access to specific [end-entity certificates](#end-entity-certificates), create certificate filters.
Each filter contains values for one or more of the following fields:

- commonName (CN)
- organization (O)
- organizationalUnit (OU)
- subjectAlternativeName (SAN)

Corresponding fields in the client certificate must match every specified value in the filter.

The values for the fields are case-insensitive.
If no wildcard is used, each specified value must match its field exactly.

To match a substring, place a single `*` wildcard at the beginning or end (but not both) of a value.
You cannot use a `*` wildcard by itself.

You can create a maximum of 25 certificate filters in a Namespace.

If you provide a well-known CA certificate, you cannot clear a certificate filter.
A well-known CA certificate is one that is typically included in the certificate store of an operating system.

**Examples**

In the following example, only the CN field of the certificate's subject is checked, and it must be exactly `code.example.com`.
The other fields are not checked.

```json
AuthorizedClientCertificate {
  CN : "code.example.com"
}
```

In the following example, the CN field must be `stage.example.com` and the O field must be `Example Code Inc.`

```json
AuthorizedClientCertificate {
  CN : "stage.example.com"
  O : "Example Code Inc."
}
```

When using a `*` wildcard, the following values are valid:

- `*.example.com` matches `code.example.com` and `text.example.com`.
- `Example Code*` matches `Example code` and `Example Code Inc`.

The following values are not valid:

- `.example.*`
- `code.*.com`
- `*`

{/* How to manage certificate filters in Temporal Cloud using Temporal Cloud UI */}

### Manage certificate filters using Temporal Cloud UI

To add or remove a certificate filter, follow these steps:

1. On the left side of the window, click **Namespaces**.
1. On the **Namespaces** page, click the name of the Namespace to manage.
1. On the right side of the page for the selected Namespace, click **Edit**.
1. On the **Edit** page, click **Certificate Filters**.
   - To add a certificate filter, click **Add a Certificate Filter** and enter values in one or more fields.
   - To remove a certificate filter, click the **×** in the upper-right corner of the filter details.
1. To cancel your changes, click **Back to Namespace**. To save your changes, click **Save**.

{/* How to manage certificate filters in Temporal Cloud using tcld */}

### Manage certificate filters using tcld

To set or clear certificate filters, use the following [tcld](/cloud/tcld) commands:

- [tcld namespace certificate-filters import](/cloud/tcld/namespace/#import)
- [tcld namespace certificate-filters clear](/cloud/tcld/namespace/#clear)

To view the current certificate filters, use the [tcld namespace certificate-filters export](/cloud/tcld/namespace/#export) command.

## Configure clients to use client certificates {#configure-clients-to-use-client-certificates}

- [Go SDK](/develop/go/temporal-client#connect-to-temporal-cloud)
- [Java SDK](/develop/java/temporal-client#connect-to-temporal-cloud)
- [PHP SDK](/develop/php/temporal-client#connect-to-a-dev-cluster)
- [Python SDK](/develop/python/temporal-client#connect-to-temporal-cloud)
- [TypeScript SDK](/develop/typescript/temporal-client#connect-to-temporal-cloud)
- [.NET SDK](/develop/dotnet/temporal-client#connect-to-temporal-cloud)

### Configure Temporal CLI {#configure-temporal-cli}

To connect to a Temporal Namespace using the Temporal CLI and certificate authentication, specify your credentials and the TLS server name:

```sh
temporal <command> <subcommand> \
    --tls-ca-path <Path to server CA certificate> \
    --tls-cert-path <Path to x509 certificate> \
    --tls-key-path <Path to private certificate key> \
    --tls-server-name <Override for target TLS server name>
```

For more information on Temporal CLI environment variables, see [Environment variables](/cli#environment-variables).

---

## Get started with Temporal Cloud

Getting started with Temporal Cloud involves a few key steps to ensure your environment is set up correctly.
However you're using Temporal, begin the process by covering essential tasks, such as account setup, Namespace creation, authentication configuration, and Worker deployment.

You’ll find links here to help you configure your Temporal Cloud account, authenticate your Clients and Workers, and set up the necessary infrastructure to get your Workflows running efficiently.

## Sign up for Temporal Cloud

To create a Temporal Cloud account, you can:

- Sign up [on our site](https://temporal.io/get-cloud); or
- Subscribe at the AWS Marketplace for [Temporal Cloud Pay-As-You-Go](https://aws.amazon.com/marketplace/pp/prodview-xx2x66m6fp2lo).
  Signing up through the AWS Marketplace is similar to signing up directly on the Temporal Cloud site, but billing goes through your AWS account.
- To purchase Temporal Cloud on the Google Cloud Marketplace, please contact our team at sales@temporal.io.

For information about Temporal Cloud Pricing, see our [Pricing Page](/cloud/pricing).

## Accept Account Owner permissions

After sign-up, you will receive email from Temporal welcoming you to your new Temporal account.
Your email address is now the first [Account Owner](/cloud/users#account-level-roles) for your account.

**An Account Owner**:

- Has full administrative permissions across the account, including users, usage, and billing
- Has Namespace Admin permissions on all Namespaces in the account

## Establish your authentication credentials

Temporal Cloud supports both TLS and API key authentication.
The following two sections explain these approaches.

### TLS authentication and certificates

For TLS authentication, you must provide your own CA certificates.
These certificates are used to create a Namespace, which in turn used grants Temporal Clients and Workers access to it.
For certificate requirements, see the following:

- [Requirements for CA certificates](/cloud/certificates#certificate-requirements)
- [Issue root CA and end-entity certificates](/cloud/certificates#issue-certificates)

### API keys

To enable and use API key access, see the following:

- [API key overview](/cloud/api-keys#overview)
- [API key best practices](/cloud/api-keys#best-practices)
- [Troubleshoot your API key use](/cloud/api-keys#troubleshooting)
- [API keys: Frequently Asked Questions](/cloud/api-keys#faqs)

### Authentication and SDKs {#auth-and-sdks}

Each SDK has a way to use your CA certificates and private keys to authenticate and authorize access to your Temporal Cloud Namespace.

- [Connect to Temporal Cloud in Go](/develop/go/temporal-client#connect-to-temporal-cloud)
- [Connect to Temporal Cloud in Java](/develop/java/temporal-client#connect-to-temporal-cloud)
- [Connect to Temporal Cloud in Python](/develop/python/temporal-client#connect-to-temporal-cloud)
- [Connect to Temporal Cloud in TypeScript](/develop/typescript/core-application#connect-to-temporal-cloud)
- [Connect to Temporal Cloud in .NET](/develop/dotnet/temporal-client#connect-to-temporal-cloud)
- [Connect to Temporal Cloud in PHP](/develop/php/temporal-client#connect-to-temporal-cloud)

## Create a Namespace

If you don’t have a Namespace yet--or want to create an additional one--[create a Namespace in Temporal Cloud](/cloud/namespaces#create-a-namespace) using the Temporal Cloud UI or the `tcld` CLI.
If using mTLS authentication, don't forget to follow the step that has you add the CA certificate to the Namespace.

<DiscoverableDisclosure prompt="" label="Namespace Setup - Details">

<NamespaceContent />

</DiscoverableDisclosure>

## Invite users

Adding a user to your Temporal Cloud Account dispatches an email invite, which users must accept to join.
To add users, see [How to invite users to your Temporal Cloud account](/cloud/users#invite-users).

<DiscoverableDisclosure prompt="" label="Invite Users - Details">

<InvitationContent />

</DiscoverableDisclosure>

## Connect to Temporal Cloud

After having updated your Temporal Client and your Workers to [use your Temporal Cloud Namespace credentials](#auth-and-sdks), you can deploy your Workers, so they are ready to execute your Workflows and Activities:

### SDK-specific Worker configuration

- [Run a Temporal Cloud Worker in Go](/develop/go/core-application#run-a-temporal-cloud-worker)
- [Run a Temporal Cloud Worker in TypeScript](/develop/typescript/core-application#run-a-temporal-cloud-worker)

---

## Namespace creation - Temporal Cloud feature guide

## How to create a Namespace in Temporal Cloud {#create-a-namespace}

:::info

The user who creates a [Namespace](/namespaces) is automatically granted [Namespace Admin](/cloud/users#namespace-level-permissions) permission for that Namespace.

To create a Namespace, a user must have the Developer, Account Owner, or Global Admin account-level [Role](/cloud/users#account-level-roles).

:::

:::tip

By default, each account is allocated with a limit of ten Namespaces.
As you start using Namespaces by scheduling Workflows, Temporal Cloud automatically raises your allowance.
This automatic adjustment happens whenever all your Namespaces are in use, up to a maximum of 100 Namespaces.
You can request further increases beyond the 100 Namespace limit by opening a [support ticket](/cloud/support#support-ticket).

:::

### Information needed to create a Namespace

To create a Namespace in Temporal Cloud, gather the following information:

- [Namespace Name](/cloud/namespaces#temporal-cloud-namespace-name), region, and Cloud Provider
- [Retention Period](/temporal-service/temporal-server#retention-period) for the [Event History](/workflow-execution/event#event-history) of closed [Workflow Executions](/workflow-execution).
- [CA certificate](/cloud/certificates#certificate-requirements) for the Namespace, if you are using mTLS authentication.
- [Codec Server endpoint](/production-deployment/data-encryption#set-your-codec-server-endpoints-with-web-ui-and-cli) to show decoded payloads to users in the Event History for Workflow Executions in the Namespace. For details, see [Securing your data](/production-deployment/data-encryption).
- [Permissions](/cloud/users#namespace-level-permissions) for each user.

<Tabs>

<TabItem value="namespace-webui" label="Web UI">

### Create a Namespace using Temporal Cloud UI

1. Gather the information listed earlier in [Information needed to create a Namespace](#information-needed-to-create-a-namespace).
1. Go to the Temporal Cloud UI and log in.
1. On the left side of the window, click **Namespaces**.
1. On the **Namespaces** page, click **Create Namespace** in the upper-right portion of the window.
1. On the **Create Namespace** page in **Name**, enter the Namespace Name.
1. In **Cloud Provider**, select the cloud provider in which to host this Namespace.
1. In **Region**, select the region in which to host this Namespace.
1. In **Retention Period**, specify a value from 1 to 90 days.
   When choosing this value, consider your needs for Event History versus the cost of maintaining that Event History.
   Typically, a development Namespace has a short retention period and a production Namespace has a longer retention period.
   (If you need to change this value later, contact [Temporal Support](/cloud/support#support-ticket).)
1. Select your authentication method: [API keys](/cloud/api-keys) or [mTLS](/cloud/certificates).
1. If using mTLS authentication, paste the CA certificate for this Namespace.
1. Optional: In **Codec Server**, enter the HTTPS URL (including the port number) of your Codec Server endpoint.
   You may also enable "Pass the user access token with your endpoint" and "Include cross-origin credentials."
   For details, see [Hosting your Codec Server](/production-deployment/data-encryption#set-your-codec-server-endpoints-with-web-ui-and-cli).
1. Click **Create Namespace**.

</TabItem>

<TabItem value="namespace-tcld" label="tcld">

See the [`tcld` namespace create](/cloud/tcld/namespace/#create) command reference for details.

</TabItem>

</Tabs>

---

## Manage Namespaces

A Namespace is a unit of isolation within the Temporal Platform.

- [Create a Namespace](#create-a-namespace)
- [Access a Namespace](#access-namespaces)
- [Manage Namespaces](#manage-namespaces)
- [Delete a Namespace](#delete-a-namespace)
- [Tag a Namespace](#tag-a-namespace)

## What is a Cloud Namespace Name? {#temporal-cloud-namespace-name}

A Cloud Namespace Name is a customer-supplied name for a [Namespace](/namespaces) in Temporal Cloud.
Each Namespace Name, such as `accounting-production`, is unique within the scope of a customer's account.
It cannot be changed after the Namespace is provisioned.

Each Namespace Name must conform to the following rules:

- A Namespace Name must contain at least 2 characters and no more than 39 characters.
- A Namespace Name must begin with a letter, end with a letter or number, and contain only letters, numbers, and the hyphen (-) character.
- Each hyphen (-) character must be immediately preceded _and_ followed by a letter or number; consecutive hyphens are not permitted.
- All letters in a Namespace Name must be lowercase.

## What is a Temporal Cloud Account ID? {#temporal-cloud-account-id}

A Temporal Cloud Account ID is a unique customer identifier assigned by Temporal Technologies.
Each Id is a short string of numbers and letters like `f45a2`, at least five characters long.
This account identifier is retained throughout the time each customer uses Temporal Cloud.

At times you may need to know your customer Account ID.
Accessing the account's Namespaces provides an easy way to capture this information.
Each Temporal Namespace use an Account ID suffix.
This is the alphanumeric character string found after the period in any Temporal Cloud Namespace name.

You can retrieve an Account ID from the [Temporal Cloud](https://cloud.temporal.io) Web UI or by using the `tcld` utility at a command line interface (CLI).
Follow these steps.

<Tabs>

    <TabItem value="webui" label="Web UI">
    Follow these steps to retrieve your Account ID:

    1. Log into Temporal Cloud.
    1. Select your account avatar at the top right of the page.
       A profile dropdown menu appears.
    1. Copy the Cloud Account ID from the menu.
       <ZoomingImage
           src="/img/cloud/cloud-guide/cloud-account-id.png"
           alt="Temporal Cloud user profile dropdown menu. The dropdown includes a Cloud Account ID and copy button, with role, profile and logout options, and links to community resources."
       />

    In this example, the Account ID is `123de`.

    </TabItem>

    <TabItem value="tcldcli" label="tcld">
    1. Use the `tcld` utility to log into an account.

       ```
       tcld login
       ```

       The `tcld` output presents a URL with an activation code at the end. Take note of this code. The utility blocks until the login/activation process completes.

       ```
       Login via this url: https://login.tmprl.cloud/activate?user_code=KTGC-ZPWQ
       ```

       A Web page automatically opens for authentication in your default browser.

    1. Visit the browser.
       Ensure the user code shown by the CLI utility matches the code shown in the Web browser.
       Then, click Confirm in the browser to continue.
       After confirmation, Web feedback lets you know that the CLI "device" is now connected.

    1. Return to the command line.
       Issue the following command.

       ```
       tcld namespace list
       ```

       The CLI tool returns a short JSON packet with your namespace information.
       This is the same list found in the Temporal Cloud Web UI Namespaces list.
       Like the browser version, each Namespace uses an Account ID suffix.

       ```
       {
         "namespaces": [
           "your-namespace.123de",
           "another-namespace.123de"
         ],
         "nextPageToken": ""
       }
       ```

    Each Namespace automatically appends an Account ID suffix to its customer-supplied identifier.
    This five-character-or-longer string appears after the name, separated by a period.
    In this Namespace listing sample, the Account ID is 123de.

    </TabItem>

</Tabs>

## What is a Cloud Namespace Id? {#temporal-cloud-namespace-id}

A Cloud Namespace Id is a globally unique identifier for a [Namespace](/namespaces) in Temporal Cloud.
A Namespace Id is formed by concatenating the following:

1. A [Namespace Name](#temporal-cloud-namespace-name)
1. A period (.)
1. The [Account ID](#temporal-cloud-account-id) to which the Namespace belongs

For example, for the Account ID `123de` and Namespace Name `accounting-production`, the Namespace Id is `accounting-production.123de`.

## What is a Cloud gRPC Endpoint? {#temporal-cloud-grpc-endpoint}

Temporal Clients communicate between application code and a Temporal Server by sending and receiving messages via the gRPC protocol.
gRPC is a Remote Procedure Call framework featuring low latency and high performance.
gRPC provides Temporal with an efficient, language-agnostic communication framework.

Every Temporal Namespace uses a gRPC endpoint for communication.
When migrating to Temporal Cloud, you'll need to switch the gRPC endpoint in your code from your current hosting, whether self-hosted or locally-hosted, to Temporal Cloud.

A gRPC endpoint appears on the detail page for each Cloud Namespace.
Follow these steps to find it:

1. Log into your account on [cloud.temporal.io](https://cloud.temporal.io/namespaces).
2. Navigate to the Namespace list page from the left-side vertical navigation.
3. Tap or click on the Namespace Name to select and open the page for the Namespace whose endpoint you want to retrieve.
4. On the Namespace detail page, click on the "Connect" button in the top right corner of the page.
5. Click the copy icon next to the gRPC address to copy it to your clipboard.

See [How to access a Namespace in Temporal Cloud](/cloud/namespaces/#access-namespaces) for more information on different gRPC endpoint types and how to access them.

<NamespaceCreationContent />

## What are some Namespace best practices? {#best-practices}

This section provides general guidance for organizing [Namespaces](/namespaces) across use cases, services, applications, or domains.
Temporal Cloud provides Namespace–as-a-service, so the Namespace is the endpoint.
Customers should consider not only a Namespace naming convention but also how to group or isolate workloads using the Namespace as a boundary.

Each team can have their own Namespace for improved modularity, security, debugging, and fault isolation.
Namespaces contain the blast radius of misbehaving Workers that may exhaust rate limits.
Sensitive Workflow state (PCI data) can be secured with per-Namespace permissions and encrypted with a separate encryption key.

Temporal Applications in different Namespaces may be connected with [Nexus](/cloud/nexus) by exposing a clean service contract for others to use with built-in [Nexus access controls](/cloud/nexus/security).
Nexus supports cross-team, cross-domain, multi-region, and multi-cloud use cases.

### Constraints and limitations

Before considering an appropriate Namespace configuration, you should be aware of the following constraints:

- By default, each account is allocated with a limit of ten Namespaces.
  As you create and use your Namespaces, for example by scheduling Workflows, Temporal Cloud automatically raises your limit.
  Our service identifies your usage patterns.
  It responds by slowly increasing your allowance, up to 100 Namespaces.
  You can request further increases beyond the 100 Namespace limit by opening a [support ticket](/cloud/support#support-ticket).
- Each Namespace has a rate limit, which is measured in Actions per second (APS).
  A namespace may be throttled when its throughput becomes too high.
  Throttling means limiting the rate at which actions are performed to prevent overloading the system.
  A Namespace's default limit is set at 400 APS and automatically adjusts based on recent usage (over the prior 7 days).
  Your APS limit will never fall below this default value.
- Each Namespace has a default service-level agreement (SLA) of 99.9% uptime.
- You can opt-in to using [High Availability features](https://docs.temporal.io/cloud/high-availability) with a 99.99% contractual SLA.
- A Namespace is a security isolation boundary.
  Access to Temporal by [Worker Processes](/workers#worker-process) is permitted at the Namespace level.
  Isolating applications or environments (development, test, staging, production) should take this into consideration.
- A Namespace is provisioned with an endpoint for executing your Workflows.
  Accessing a Namespace from a Temporal Client requires [API keys](/cloud/api-keys) or [mTLS](/cloud/certificates) authentication.
- [Workflow Id](/workflow-execution/workflowid-runid#workflow-id)uniqueness is per Namespace.
- [Task Queue](/task-queue) names are unique per Namespace.
- Closed Workflow retention is per Namespace.
- RBAC [permissions](/cloud/users#namespace-level-permissions) are implemented at the Namespace level.

### General guidance

Namespace configuration requires some consideration.
Following are some general guidelines to consider.

- Namespaces are usually defined per use case.
  A use case can encompass a broad range of Workflow types and a nearly unlimited scale of concurrent [Workflow Executions](/workflow-execution).
- Namespaces can be split along additional boundaries such as service, application, domain or even sub-domain.
- Environments such as production and development usually have requirements for isolation.
  We recommend that each environment has its own Namespace.
- Namespaces should be used to reduce the "blast radius" for mission-critical applications.
- Workflows that need to communicate with each other should (for now) be in the same Namespace.
- If you need to share Namespaces across team or domain boundaries, be sure to ensure the uniqueness of Workflow Ids.

### Examples

Following are some ideas about how to organize Namespaces.

#### Example 1: Namespace per use case and environment

We recommend using one Namespace for each use case and environment combination for simple configurations in which multiple services and team or domain boundaries don't exist.

Sample naming convention:

<pre>&lt;use-case>_&lt;environment></pre>

#### Example 2: Namespace per use case, service, and environment

We recommend using one Namespace for each use case, service, and environment combination when multiple services that are part of same use case communicate externally to Temporal via API (HTTP/gRPC).

Sample naming convention:

<pre>&lt;use-case>_&lt;service>_&lt;environment></pre>

#### Example 3: Namespace per use case, domain, and environment

We recommend using one namespace per use case, domain, and environment combination when multiple services that are part of the same use case need to communicate with each another via [Signals](/sending-messages#sending-signals) or by starting [Child Workflows](/child-workflows).
In this case, though, you must be mindful about Workflow Id uniqueness by prefixing each Workflow Id with a service-specific string.
The name of each Task Queue must also be unique.
If multiple teams are involved, the domain could also represent a team boundary.

Sample naming convention:

<pre>&lt;use-case>_&lt;domain>_&lt;environment></pre>

Sample workflowId convention:

<pre>&lt;service-string>_&lt;workflow-id></pre>

## How to access a Namespace in Temporal Cloud {#access-namespaces}

{/* How to access a Namespace in Temporal Cloud */}

Temporal Cloud normally supports authentication to Namespaces using [API keys](/cloud/api-keys) _or_ [mTLS](/cloud/certificates).
If you need to migrate from one authentication method to another, or you require both API key and mTLS authentication to be enabled on your Namespace, please contact [Support](https://docs.temporal.io/cloud/support#support-ticket).

See the documentation for [API keys](/cloud/api-keys) and [mTLS certificates](/cloud/certificates) for more information on how to create and manage your credentials.

Authentication methods require specific endpoints in order to programmatically access your Namespace.

- For the API key authentication method, use the gRPC regional endpoint `<region>.<cloud_provider>.api.temporal.io:7233`.
- For the mTLS authentication method, use the gRPC Namespace endpoint `<namespace>.<account>.tmprl.cloud:7233`.
- For [Namespaces with High Availability features](/cloud/high-availability) use the gRPC Namespace endpoint `<namespace>.<account>.tmprl.cloud:7233`, regardless of your authentication method.
  This allows automated failover without needing to switch your endpoint.

For information on how to connect to Clients using a specific authentication method see the following documentation.

- To use API keys to connect with the [Temporal CLI](/cli), [Client SDK](/develop), [tcld](/cloud/tcld), [Cloud Ops API](/ops), and [Terraform](/production-deployment/cloud/terraform-provider), see [Use API keys to authenticate](/cloud/api-keys#using-apikeys).
- To use mTLS to connect with the [Temporal CLI](/cli) and [Client SDK](/develop), see [Configure Clients to use Client certificates](/cloud/certificates#configure-clients-to-use-client-certificates).

For accessing the Temporal Web UI, use the HTTPS endpoint in the form: `https://cloud.temporal.io/namespaces/<namespace>.<account>`.
For example: `https://cloud.temporal.io/namespaces/accounting-production.f45a2`.

To ensure the security of your data, all traffic to and from your Namespace is encrypted.
However, for enhanced protection, you have additional options:

- (recommended) Set up private connectivity by [creating a ticket for Temporal Support](/cloud/support#support-ticket).
- Set up your allow list for outgoing network requests from your Clients and Workers with the IP address ranges of the Cloud Provider region in which your Namespace is located:
  - [AWS IP address ranges](https://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html)
  - [GCP IP address ranges](https://cloud.google.com/compute/docs/faq#find_ip_range)

## How to manage Namespaces in Temporal Cloud {#manage-namespaces}

{/* How to manage Namespaces in Temporal Cloud using Temporal Cloud UI */}

### Manage Namespaces in Temporal Cloud using Temporal Cloud UI

To list Namespaces:

- On the left side of the window, select **Namespaces**.

To edit a Namespace (including custom Search Attributes, certificates, certificate filters, Codec Server endpoint, permissions, and users), find the Namespace and do either of the following:

- On the right end of the Namespace row, select the three vertical dots (⋮). Click **Edit**.
- Select the Namespace name. In the top-right portion of the page, select **Edit**.

On the **Edit** page, you can do the following:

- Add a [custom Search Attribute](/search-attribute#custom-search-attribute).
- [Manage CA certificates](/cloud/certificates).
- [Manage certificate filters](/cloud/certificates#manage-certificate-filters-using-temporal-cloud-ui).
- Set [Codec Server endpoint](/production-deployment/data-encryption#set-your-codec-server-endpoints-with-web-ui-and-cli) for all users on the Namespace.
  Each user on the Namespace has the option to [override this setting](/production-deployment/data-encryption#web-ui) in their browser.
- Manage [Namespace-level permissions](/cloud/users#namespace-level-permissions).
- Add users.

To add a user to a Namespace, scroll to the bottom of the page and select **Add User**.

After you make changes, select **Save** in the top-right or bottom-left portion of the page.

{/* How to manage Namespaces in Temporal Cloud using tcld */}

### Manage Namespaces in Temporal Cloud using tcld

To list Namespaces and get information about them, use the following [tcld](/cloud/tcld/) commands:

- [tcld namespace list](/cloud/tcld/namespace/#list)
- [tcld namespace get](/cloud/tcld/namespace/#get)

To manage certificates, use the [tcld namespace accepted-client-ca](/cloud/tcld/namespace/#accepted-client-ca) commands.
For more information, see [How to manage certificates in Temporal Cloud](/cloud/certificates).

To manage certificate filters, use the [tcld namespace certificate-filters](/cloud/tcld/namespace/#certificate-filters) commands.
For more information, see [How to manage certificate filters in Temporal Cloud](/cloud/certificates#manage-certificate-filters).

## How to delete a Namespace in Temporal Cloud {#delete-a-namespace}

:::info

To delete a Namespace, a user must have Namespace Admin [permission](/cloud/users#namespace-level-permissions) for that Namespace.

:::

### Delete a Namespace using Temporal Cloud UI

1. Go to the Temporal Cloud UI and log in.
1. On the left side of the window, select **Namespaces**.
1. On the **Namespaces** page, select a Namespace Name.
1. On the Namespace page, select **Edit** in the upper-right portion of the window.
1. On the **Edit** Namespace page, select **Delete Namespace** in the upper-right portion of the window.
1. In the **Delete Namespace** dialog, type `DELETE` to confirm the deletion of that Namespace.
1. Select **Delete**.

After deleting a Temporal Cloud Namespace, the Temporal Service immediately removes the Namespace's Workflow Executions and Task Queues.
Make sure all Workflows have been completed, canceled, or terminated before removing a Namespace.
The Namespace removal is permanent.

Closed Workflow Histories remain in Temporal storage until the user-defined retention period expires.
This period reflects the policy in effect when the Workflow Execution was closed.

For further questions or concerns, contact [Support](https://docs.temporal.io/cloud/support#support-ticket).

### Delete a Namespace using tcld

See the [tcld namespace delete](/cloud/tcld/namespace/#delete) command reference for details.

### Namespace deletion protection {#delete-protection}

To prevent accidental Namespace deletion, Temporal Cloud provides a protection feature.
When you enable Deletion Protection for your production environment Namespace, you ensure that critical data won't be deleted unintentionally.

Follow these steps:

- Visit the [Namespaces page](https://cloud.temporal.io/namespaces) on Temporal Cloud.
- Open your Namespace details page.
- Select the Edit button.
- Scroll down to Security and click the disclosure button (downward-facing caret).
- Enable **Deletion Protection**

<CaptionedImage
    src="/img/cloud/namespace/deletion-protection.png"
    title="Deletion Protection is enabled by toggling the switch"
/>

To enable or disable this feature using [`tcld`](/cloud/tcld), use the following command.
Set the value to `true` to enable or `false` to disable:

```
tcld namespace lifecycle set \
    --namespace <namespace_id.account_id> \
    --enable-delete-protection <Boolean>
```

## How to tag a Namespace in Temporal Cloud {#tag-a-namespace}

:::tip Support, stability, and dependency info

Namespace tags are currently in [Public Preview](/evaluate/development-production-features/release-stages#public-preview).

:::

Tags are key-value metadata pairs that can be attached to namespaces in Temporal Cloud to help operators organize, track, and manage namespaces more easily.

### Tag Structure and Limits

- Each namespace can have a maximum of 10 tags
- Each key must be unique for a given namespace (e.g., a namespace cannot have both `team:foo` and `team:bar` tags)
- Keys and values must be 1-63 characters in length
- Allowed characters: lowercase letters (`a-z`), numbers (`0-9`), periods (`.`), underscores (`_`), and hyphens (`-`)
- Tags are not a secure storage mechanism and should not store PII or PHI
- Tags will not change the behavior of the tagged resource
- There is a soft limit of 1000 unique tag keys per account

### Permissions

- Only [**Account Admins** and **Account Owners**](/cloud/users#account-level-roles) can create and edit tags
- All users with access to a namespace can view its tags

### tcld

See the [tcld namespace tags](/cloud/tcld/namespace/#tags) command reference for details.

### Terraform

See the [Terraform provider](https://github.com/temporalio/terraform-provider-temporalcloud/blob/main/docs/resources/namespace_tags.md) for details.

### Web UI

Tags can be viewed and managed through the Temporal Cloud web interface. When viewing a namespace, you'll see tags displayed and can add, edit, or remove them if you have the appropriate permissions.

<CaptionedImage
    src="/img/cloud/tags/Namespace-DetailsWithTags.png"
    title="Tags appear in namespace details"
/>

<CaptionedImage
    src="/img/cloud/tags/Namespaces-IndexWithTags.png"
    title="Tags appear on the list of namespaces"
/>

<CaptionedImage
    src="/img/cloud/tags/CreateNamespace-AddNewTag.png"
    title="Where to add tags during namespace creation"
/>

<CaptionedImage
    src="/img/cloud/tags/CreateNamespace-AddedTag.png"
    title="After adding a tag during namespace creation"
/>

---

## Manage service accounts

Temporal Cloud provides Account Owner and Global Admin [roles](/cloud/users#account-level-roles) with the option to create machine identities named Service Accounts.

Service Accounts are a type of identity in Temporal Cloud.
Temporal Cloud supports User identities as a representation of a human user who uses Temporal Cloud.
Service Accounts afford Temporal Cloud Account Owner and Global Admin [roles](/cloud/users#account-level-roles) the ability to create an identity for machine authentication, an identity not associated with a human user.

With the addition of Service Accounts, Temporal Cloud now supports 2 identity types:

- Users (tied to a human, identified by email address or ID)
- Service Accounts (not tied to a human, email address optional, identified by name or ID)

Service Accounts use API Keys as the authentication mechanism to connect to Temporal Cloud.
You should use Service Accounts to represent a non-human identity when authenticating to Temporal Cloud for operations automation or the Temporal SDKs and the Temporal CLI for Workflow Execution and management.

## Get started

To get started with Service Accounts, ensure you are Temporal Cloud user.

**Prerequisites:**

- A Cloud user account with Account Owner or Global Admin [role](/cloud/users#account-level-roles) permissions
- Access to the Temporal Cloud UI or Temporal Cloud CLI (tcld)
- Enable access to API Keys for your Account
- To manage Service Accounts using the Temporal Cloud CLI (tcld), upgrade to the latest version of tcld (v0.18.0 or higher) using `brew upgrade tcld`.
  - If using a version of tcld less than v0.31.0, enable Service Account commands with `tcld feature toggle-service-account`.

## Managing Service Accounts

Account Owner and Global Admin [roles](/cloud/users#account-level-roles) can manage Service Accounts by creating, viewing, updating, deleting Service Accounts using the following tools:

- Temporal Cloud UI
- Temporal Cloud CLI (tcld)
  - Use `tcld service-account --help` for a list of all service-account commands

Account Owner and Global Admin [roles](/cloud/users#account-level-roles) also have the ability to manage API Keys for Service Accounts.

### Create a Service Account

Create a Service Account using the Temporal Cloud UI or tcld.
While User identities are invited to Temporal Cloud, Service Accounts are created in Temporal Cloud.

#### Using the Cloud UI

1. Navigate to https://cloud.temporal.io/settings/identities
2. Click the `Create Service Account` button located near the top right of the `Identities` page
3. Provide the following information:
   - **Name** (required)
   - **Description** (optional)
   - **Account Level Role** (required)
   - **Namespace Permissions** (optional)
     - Use this section of the Create Service Account page to grant the Service Account access to individual Namespaces
4. Click `Create Service Account` at the bottom of the page
   - A status message is displayed at the bottom right corner of the screen and on the next screen
   - You will be prompted to create an API Key for the Service Account (optional)
5. (Optional) Create API Key
   - It is recommended to create an API Key for the Service Account right after you create the Service Account, though you can create/manage API Keys for Service Accounts at any time
   - See the API Key [documentation](/cloud/api-keys) for more information on creating and managing API Keys

#### Using tcld

To create a Service Account using tcld, use the `tcld service-account create` command:

```
tcld service-account create -n "sa_test" -d "this is a test SA" --ar "Read"
```

This example creates a Service Account with the name `"sa_test"`, description `"this is a test SA"`, and a `Read` Account Role.

Creating a Service Account requires the following attributes: `name` and `account-role` (as above).
You can also provide the Namespace Permissions for the Service Account using the `—-np` flag.
Creating a Service Account returns the `ServiceAccountId` which is used to retrieve, update, or delete a Service Account.

### View Service Accounts

View a single or all Service Account(s) using the Temporal Cloud UI or tcld.

#### Using the Cloud UI

Service Accounts are listed on the `Identities` section of the `Settings` page, along with Users.
To locate a Service Account:

1. Navigate to https://cloud.temporal.io/settings/identities
2. Select the `Service Accounts` filter

#### Using tcld

To view all Service Accounts in your account using tcld, use the `tcld service-account list` command:

```
tcld service-account list
```

### Delete a Service Account

Delete a Service Account using the Temporal Cloud UI or tcld.

#### Using the Cloud UI

1. Navigate to https://cloud.temporal.io/settings/identities
2. Find the relevant Service Account
3. Click the three vertical dots in the Service Account row
4. Select `Delete` from the menu displayed
5. Confirm the delete action when prompted

#### Using tcld

To delete a Service Account using tcld, use the `tcld service-account delete` command:

```
tcld service-account delete --service-account-id "e9d87418221548"
```

Use the tcld Service Account list command to validate the Service Account has been removed from the account.
The Service Account is deleted when it is no longer visible in the output of .

### Update a Service Account {#update}

Update a Service Account's description using the Temporal Cloud UI or tcld.

#### Using the Cloud UI

1. Navigate to https://cloud.temporal.io/settings/identities
2. Find the relevant Service Account
3. Click the three vertical dots in the Service Account row
4. Select `Edit` from the menu displayed
5. Make changes to the Service Account
   - You can change the Service Account's name, description, Account Level Role, and Namespace Permissions
6. Click the `Save` button located in the bottom left of the screen
   - A status message is displayed at the bottom right corner of the screen

#### Using tcld

Three different commands exist to help users update a Service Account using tcld:

- `tcld service-account update`: to update a Service Account's name or description field
- `tcld service-account set-account-role`: to update a Service Account's Account Role
- `tcld service-account set-namespace-permissions`: to update a Service Account's Namespace Permissions

Example:

```
tcld service-account update --id "2f68507677904e09b9bcdbf93380bb95" -d "new description"
```

## Namespace Scoped Service Accounts {#scoped}

There is a special type of Service Account, called a Namespace Scoped Service Account, which shares the
same functionality as the Service Accounts above, but is limited (or scoped) to a single namespace.

In particular, a Namespace Scoped Service Account must _always_ have:

- A `Read` Account Role
- A single Namespace Permission

Note that a Namespace Scoped Service Account cannot be reassigned to a different Namespace after creation, but its Namespace Permission can be modified (e.g. from `Read` to `Write`).

Namespace Scoped Service Accounts are useful in situations when you need to restrict a client's access to a single Namespace.

You can retrieve, update, and delete a Namespace Scoped Service Account using the same process and commands as above, but creation is slightly different.

### Create a Namespace Scoped Service Account

As with regular Service Accounts, Namespace Scoped Service Accounts can be created using Temporal Cloud UI or tcld.

#### Using the Cloud UI

Currently, creating a Namespace Scoped Service Account from the Temporal Cloud UI happens on an individual [Namespace](/cloud/namespaces#manage-namespaces) page.
If the current Namespace has API key authentication enabled, then there will be a `Generate API Key` button as a banner on the top of the Namespace page or in the `Authentication` section.

By clicking on the `Generate API Key` button, a Namespace Scoped Service Account will be automatically created for the given Namespace (if one does not already exist) and an associated API key will be displayed. This key will have the maximum expiration time, which is 2 years.

The resulting Namespace Scoped Service Account will be named `<namespace>-service-account` and will have an `Admin` Namespace Permission by default.

#### Using tcld

To create a Namespace Scoped Service Account with tcld, use the `tcld service-accounted create-scoped` command:

```
tcld service-account created-scoped -n "test_scoped_sa" --np "foo=Admin"
```

This example creates a Namespace Scoped Service Account for the Namespace `foo`, named `"sa_scoped_test"`, with an `Admin` Namespace Permission.
Note that the Account Role is omitted, since Namespace Scoped Service Accounts always have a `Read` Account Role.

### Lifecycle

When a Namespace is deleted, all associated Namespace Scoped Service Accounts are automatically deleted as well.
Therefore, you do not need to manually remove Namespace Scoped Service Accounts after deleting a Namespace.

---

## User management - Temporal Cloud feature guide

:::caution
Access to Temporal Cloud can be authorized through email and password, Google single sign-on, Microsoft single sign-on, or SAML, depending on your setup.

If you are using Google OAuth for single sign-on and an email address is not associated with a Google Account, the user must follow the instructions in the [Use an existing email address](https://support.google.com/accounts/answer/27441?hl=en#existingemail) section of [Create a Google Account](https://support.google.com/accounts/answer/27441).

**Important:** Do _not_ create a Gmail account when creating a Google Account.

If your organization uses Google Workspace or Microsoft Entra ID, and your IT administrator has enabled controls over single sign-on permissions, then you will need to work with your IT administrator to allow logins to Temporal Cloud.

:::

When a user is created in Temporal Cloud, they receive an invitation email with a link.
They must use this link to finalize their setup and access Temporal Cloud.
Accounts with SAML configurations can ignore this email.
However, those using Google/Microsoft SSO or email and password authentication need to accept the invitation link for their initial login to Temporal Cloud.
For future logins, they must use the same authentication method they originally signed up with.

:::info

To invite users, a user must have the Global Admin or Account Owner account-level [role](/cloud/users#account-level-roles).

:::

### Roles and permissions

Each user in Temporal Cloud is assigned a role.
Each user can be assigned permissions for individual Namespaces.

- [Account-level roles](/cloud/users#account-level-roles)
- [Namespace-level permissions](/cloud/users#namespace-level-permissions)

<Tabs>

<TabItem value="invite-webui" label="Web UI">

To invite users using the Temporal Cloud UI:

1. In Temporal Web UI, select **Settings** in the left portion of the window.
1. On the **Settings** page, select **Create Users** in the upper-right portion of the window.
1. On the **Create Users** page in the **Email Addresses** box, type or paste one or more email addresses.
1. In **Account-Level Role**, select a [Role](/cloud/users#account-level-roles).
   The Role applies to all users whose email addresses appear in **Email Addresses**.
1. If the account has any Namespaces, they are listed under **Grant access to Namespaces**.
   To add a permission, select the checkbox next to a Namespace, and then select a [permission](/cloud/users#namespace-level-permissions).
   Repeat as needed.
1. When all permissions are assigned, select **Send Invite**.

Temporal sends an email message to each user.
To join Temporal Cloud, a user must select **Accept Invite** in the message.

</TabItem>

<TabItem value="invite-tcld" label="tcld">

To invite users using tcld, see the [tcld user invite](/cloud/tcld/user/#invite) command.

Temporal sends an email message to the specified user.
To join Temporal Cloud, the user must select **Accept Invite** in the message.

</TabItem>

<TabItem value="invite-ops-api" label="Cloud Ops API">

You can invite users pragmatically using the Cloud Ops API.

1. Create a connection to your Temporal Service using the Cloud Operations API.
2. Use the [CreateUser service](https://github.com/temporalio/api-cloud/blob/main/temporal/api/cloud/cloudservice/v1/service.proto) to create a user.

</TabItem>

</Tabs>

### Frequently Asked Questions

#### Can the same email be used across different Temporal Cloud accounts?

No — each email address can only be associated with a single Temporal Cloud account.
If you need access to multiple accounts, you’ll need a separate invite for each one using a different email address.

#### Can I use Google or Microsoft SSO after signing up with email and password?

If you originally signed up for Temporal Cloud using an email and password, you won’t be able to log in using Google or Microsoft single sign-on.

If you prefer SSO, ask your Account Owner to delete your current user and send you a new invitation.
During re-invitation, be sure to sign up using your preferred authentication method.

#### How do I complete the `Secure Your Account` step?

If you signed up to Temporal Cloud using an email and password, you're required to set up multi-factor authentication (MFA) for added security.
Currently, only authenticator apps are supported as an additional factor (such as Google Authenticator, Microsoft Authenticator, and Authy).

To proceed:

1. Download a supported authenticator app on your mobile device.
2. Scan the QR code shown on the **Secure Your Account** screen.
3. Enter the verification code from your app to complete MFA setup.
4. Securely store your recovery code.
   This code allows you to access your account if you lose access to your authenticator app.

Once MFA is configured, you’ll be able to continue using Temporal Cloud.

#### What if I lose access to my authenticator app?

If you lose access to your authenticator app, you can still log in by clicking **Try another method** on the MFA screen.
From there, you can either:

- Enter your recovery code (provided when you first set up MFA)
- Receive a verification code through email

Once you're logged in, you can reset your authenticator app by navigating to **My Profile** > **Password and Authentication** and then clicking **Authenticator App** > **Remove method**.

#### How do I reset my password?

If you're currently logged in and would like to change your password, click your profile icon at the top right of the Temporal Cloud UI,
navigate to **My Profile** > **Password and Authentication**, and then click **Reset Password**.

If you're not currently logged in, navigate to the login page of the Temporal Cloud UI, enter your email address, click **Continue**, and then select **Forgot password**.
In both cases, you will receive an email with instructions on how to reset your password.

---

## Manage users

- [How to invite users to your Temporal Cloud account](#invite-users)
- [What are the account-level roles?](#account-level-roles)
- [What are the Namespace-level permissions?](#namespace-level-permissions)
- [How to update an account-level Role in Temporal Cloud](#update-roles)
- [How to update Namespace-level permissions in Temporal Cloud](#update-permissions)
- [How to delete a user from your Temporal Cloud account](#delete-users)

## How to invite users to your Temporal Cloud account {#invite-users}

<InvitationContent />

## What are the account-level roles for users in Temporal Cloud? {#account-level-roles}

When an Account Owner or Global Admin invites a user to join an account, they select one of the following roles for that user:

- **Global Admin**
  - Has full administrative permissions across the account, including users and usage
  - Can create and manage [Namespaces](/namespaces) and [Nexus Endpoints](/nexus/endpoints)
  - Has Namespace Admin [permissions](#namespace-level-permissions) on all Namespaces in the account.
    This permission cannot be revoked
- **Developer**
  - Can create Namespaces
  - Is granted [Namespace Admin](/cloud/users#namespace-level-permissions) permission for each Namespace they create.
    This permission can be revoked
  - Can create and manage Nexus Endpoints where they are a [Namespace Admin](/cloud/users#namespace-level-permissions) on the Endpoint's target Namespace
- **Read-Only**
  - Can read information
  - Can be granted Namespace [permissions](#namespace-level-permissions), for example to read or write Workflow state in a given Namespace
  - Can view all Nexus Endpoints in the account, which have separate [runtime access controls](/nexus/security#runtime-access-controls)

In addition, there are two roles that the Global Admin cannot assign:

- **Account Owner**
  - Has full administrative permissions across the account, including users, usage and [billing](/cloud/billing-and-cost)
  - Can create and manage Namespaces and Nexus Endpoints
  - Has Namespace Admin [permissions](#namespace-level-permissions) on all [Namespaces](/namespaces) in the account.
    This permission cannot be revoked
- **Finance Admin**
  - Has permissions to view [billing](/cloud/billing-and-cost) information and update payment information
  - Otherwise, has the same permissions as Account Read-only users
  - Can only be assigned by an Account Owner

:::note Default Role

When the account is created, the initial user who logs in is automatically assigned the Account Owner role.
If your account does not have an Account Owner, please reach out to [Support](https://temporalsupport.zendesk.com/) to assign the appropriate individual to this role.

:::

## Using the Account Owner role

The Account Owner role (i.e., users with the Account Owner system role) holds the highest level of access in the system.
This role configures account-level parameters and manages Temporal billing and payment information.
It allows users to perform all actions within the Temporal Cloud account.

:::tip Best Practices

Temporal strongly recommends the following precautions when assigning the Account Owner role to users:

- Assign the role to at least two users in your organization.
  Otherwise, limit the number of users with this role.
- Associate a person’s direct email address to the Account Owner, rather than a shared or generic address, so Temporal Support can contact the right person in urgent situations.

This latter rule is useful for anyone on your team who may need to be contacted urgently, regardless of their Account role.

:::

## What are the Namespace-level permissions for users in Temporal Cloud? {#namespace-level-permissions}

An Account Owner or Global Admin can assign permissions for any [Namespace](/namespaces) in an account.
A Developer can assign permissions for a Namespace they create.

For a Namespace, a user can have one of the following permissions:

- **Namespace Admin:**
  - Can [manage the Namespace](/cloud/namespaces#manage-namespaces) including identities and permissions
  - Can create, rename, update, and delete [Workflows](/workflows) within the Namespace
- **Write:**
  - Can create, rename, update, and delete [Workflows](/workflows) within the Namespace
- **Read-Only:**
  - Can only read information from the Namespace

## How to update an account-level role in Temporal Cloud {#update-roles}

With Global Admin or Account Owner privileges, you can update any user's account-level [role](#account-level-roles) using either the Web UI or the tcld CLI utility.
The Account Owner role can only be granted by existing Account Owners.

For security reasons, changes to the Account Owner role must be made through Temporal Support.
To change or delete an Account Owner, you must submit a [support ticket](https://temporalsupport.zendesk.com/).

{/* How to update an account-level role in Temporal Cloud using Web UI */}

### How to update an account-level role using Web UI

1. In Temporal Web UI, select **Settings** in the left portion of the window.
1. On the **Settings** page, select the user.
1. On the user profile page, select **Edit User**.
1. On the **Edit User** page in **Account Level Role**, select the role.
1. Select **Save**.

{/* How to update an account-level role in Temporal Cloud using tcld */}

### How to update an account-level role using tcld

For details, see the [tcld user set-account-role](/cloud/tcld/user/#set-account-role) command.

## How to update Namespace-level permissions in Temporal Cloud {#update-permissions}

You can update Namespace-level [permissions](#namespace-level-permissions) by using either Web UI or tcld.

{/* How to update Namespace-level permissions for a Namespace in Temporal Cloud using Web UI */}

### How to use the Web UI to update a user's permissions across multiple Namespaces

1. In Temporal Web UI, select **Namespaces** in the left portion of the window.
1. On the **Namespaces** page, select the Namespace.
1. If necessary, scroll down to the list of permissions
1. On the user profile page in **Namespace permissions**, select the Namespace.
1. On the Namespace page in **Account Level Role**, select the role.
1. Select **Save**.

{/* How to update Namespace-level permissions for a user in Temporal Cloud using Web UI */}

### How to use the Web UI to update permissions for multiple users within a single Namespace

:::note

A user with the Account Owner or Global Admin account-level [role](#account-level-roles) has Namespace Admin permissions for all Namespaces.

:::

1. In Temporal Web UI, select **Settings** in the left portion of the window.
1. On the **Settings** page in the **Users** tab, select the user.
1. On the user profile page, select **Edit User**.
1. On the **Edit User** page in **Namespace permissions**, change the permissions for one or more Namespaces.
1. Select **Save**.

{/* How to update an account-level role in Temporal Cloud using tcld */}

### How to use tcld to update Namespace-level permissions

For details, see the [tcld user set-namespace-permissions](/cloud/tcld/user/#set-namespace-permissions) command.

## How to delete a user from your Temporal Cloud account {#delete-users}

You can delete a user from your Temporal Cloud Account by using either Web UI or tcld.

:::info

To delete a user, a user must have the Account Owner or Global Admin account-level [role](#account-level-roles).

:::

{/* How to delete a user from your Temporal Cloud account using Web UI */}

### How to update an account-level role using Web UI

1. In Temporal Web UI, select **Settings** in the left portion of the window.
1. On the **Settings** page, find the user and, on the right end of the row, select **Delete**.
1. In the **Delete User** dialog, select **Delete**.

You can delete a user in two other ways in Web UI:

- User profile page: Select the down arrow next to **Edit User** and then select **Delete**.
- **Edit User** page: Select **Delete User**.

{/* How to delete a user from your Temporal Cloud account using tcld */}

### How to update an account-level role using tcld

For details, see the [tcld user delete](/cloud/tcld/user/#delete) command.

## Account-level roles and Namespace-level permissions {#account-level-roles-and-namespace-level-permissions}

Temporal account-level roles and Namespace-level permissions provide access to specific Temporal Workflow and Temporal Cloud operational APIs.
The following table provides the API details associated with each account-level role and Namespace-level permission.

:::note

Account Owners and Global Admins have Namespace Admin permissions on all Namespaces.

:::

#### Account-level role details

This table provides API-level details for the permissions granted to a user through account-level roles. These permissions are configured per user.

| Permission                        | Read-only | Developer | Finance Admin | Global Admin | Account Owner |
| --------------------------------- | --------- | --------- | ------------- | ------------ | ------------- |
| CountIdentities                   | ✔         | ✔         | ✔             | ✔            | ✔             |
| CreateAPIKey                      | ✔         | ✔         | ✔             | ✔            | ✔             |
| CreateNamespace                   |           | ✔         |               | ✔            | ✔             |
| CreateNexusEndpoint               |           | ✔         |               | ✔            | ✔             |
| CreateServiceAccount              |           |           |               | ✔            | ✔             |
| CreateServiceAccountAPIKey        |           |           |               | ✔            | ✔             |
| CreateStripeCustomerPortalSession |           |           | ✔             |              | ✔             |
| CreateUser                        |           |           |               | ✔            | ✔             |
| DeleteAPIKey                      | ✔         | ✔         | ✔             | ✔            | ✔             |
| DeleteNexusEndpoint               |           | ✔         |               | ✔            | ✔             |
| DeleteServiceAccount              |           |           |               | ✔            | ✔             |
| DeleteUser                        |           |           |               | ✔            | ✔             |
| GetAccount                        | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetAccountFeatureFlags            | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetAccountLimits                  | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetAccountSettings                | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetAccountUsage                   |           |           |               | ✔            | ✔             |
| GetAPIKey                         | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetAPIKeys                        | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetAsyncOperation                 | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetDecodedCertificate             | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetIdentities                     | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetIdentity                       | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetNamespaces                     | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetNamespacesUsage                |           |           |               | ✔            | ✔             |
| GetNexusEndpoint                  | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetNexusEndpoints                 | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetRegion                         | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetRegions                        | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetRequestStatus                  | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetRequestStatuses                |           |           |               | ✔            | ✔             |
| GetRequestStatusesForNamespace    | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetRequestStatusesForUser         | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetRoles                          | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetRolesByPermissions             | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetServiceAccount                 | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetServiceAccounts                | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetStripeInvoice                  |           |           | ✔             |              | ✔             |
| GetUser                           | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetUsers                          | ✔         | ✔         | ✔             | ✔            | ✔             |
| GetUsersWithAccountRoles          | ✔         | ✔         | ✔             | ✔            | ✔             |
| InviteUsers                       |           |           |               | ✔            | ✔             |
| ListCreditLedgerEntries           |           |           | ✔             |              | ✔             |
| ListGrants                        |           |           | ✔             |              | ✔             |
| ListMetronomeInvoices             |           |           | ✔             |              | ✔             |
| ListMetronomeInvoicesForNamespace |           |           | ✔             |              | ✔             |
| ListNamespaces                    | ✔         | ✔         | ✔             | ✔            | ✔             |
| ListPromotionGrantBalances        |           |           | ✔             |              | ✔             |
| ResendUserInvite                  |           |           |               | ✔            | ✔             |
| SetAccountSettings                |           |           |               | ✔            | ✔             |
| SyncCurrentUserInvite             | ✔         | ✔         | ✔             | ✔            | ✔             |
| UpdateAccount                     |           |           |               | ✔            | ✔             |
| UpdateAPIKey                      | ✔         | ✔         | ✔             | ✔            | ✔             |
| UpdateNexusEndpoint               |           | ✔         |               | ✔            | ✔             |
| UpdateServiceAccount              |           |           |               | ✔            | ✔             |
| UpdateUser                        |           |           |               | ✔            | ✔             |

#### Namespace-level permissions details

This table provides API-level details for the permissions granted to a user through Namespace-level permissions.
These permissions are configured per Namespace per user.

| Permission                         | Read | Write | Namespace Admin |
| ---------------------------------- | ---- | ----- | --------------- |
| CountWorkflowExecutions            | ✔    | ✔     | ✔               |
| CreateExportSink                   |      | ✔     | ✔               |
| CreateSchedule                     |      | ✔     | ✔               |
| DeleteExportSink                   |      | ✔     | ✔               |
| DeleteNamespace                    |      | ✔     | ✔               |
| DeleteSchedule                     |      | ✔     | ✔               |
| DescribeBatchOperation             | ✔    | ✔     | ✔               |
| DescribeNamespace                  | ✔    | ✔     | ✔               |
| DescribeSchedule                   | ✔    | ✔     | ✔               |
| DescribeTaskQueue                  | ✔    | ✔     | ✔               |
| DescribeWorkflowExecution          | ✔    | ✔     | ✔               |
| FailoverNamespace                  |      |       | ✔               |
| GetExportSink                      | ✔    | ✔     | ✔               |
| GetExportSinks                     | ✔    | ✔     | ✔               |
| GetNamespace                       | ✔    | ✔     | ✔               |
| GetNamespaceUsage                  | ✔    | ✔     | ✔               |
| GetReplicationStatus               | ✔    | ✔     | ✔               |
| GetSearchAttributes                | ✔    | ✔     | ✔               |
| GetUsersForNamespace               | ✔    | ✔     | ✔               |
| GetWorkerBuildIdCompatibility      | ✔    | ✔     | ✔               |
| GetWorkerTaskReachability          | ✔    | ✔     | ✔               |
| GetWorkflowExecutionHistory        | ✔    | ✔     | ✔               |
| GetWorkflowExecutionHistoryReverse | ✔    | ✔     | ✔               |
| GlobalizeNamespace                 |      |       | ✔               |
| ListBatchOperations                | ✔    | ✔     | ✔               |
| ListClosedWorkflowExecutions       | ✔    | ✔     | ✔               |
| ListExportSinks                    | ✔    | ✔     | ✔               |
| ListFailoverHistoryByNamespace     | ✔    | ✔     | ✔               |
| ListOpenWorkflowExecutions         | ✔    | ✔     | ✔               |
| ListReplicaStatus                  | ✔    | ✔     | ✔               |
| ListScheduleMatchingTimes          | ✔    | ✔     | ✔               |
| ListSchedules                      | ✔    | ✔     | ✔               |
| ListTaskQueuePartitions            | ✔    | ✔     | ✔               |
| ListWorkflowExecutions             | ✔    | ✔     | ✔               |
| PatchSchedule                      |      | ✔     | ✔               |
| PollActivityTaskQueue              |      | ✔     | ✔               |
| PollWorkflowTaskQueue              |      | ✔     | ✔               |
| QueryWorkflow                      | ✔    | ✔     | ✔               |
| RecordActivityTaskHeartbeat        |      | ✔     | ✔               |
| RecordActivityTaskHeartbeatById    |      | ✔     | ✔               |
| RenameCustomSearchAttribute        |      | ✔     | ✔               |
| RequestCancelWorkflowExecution     |      | ✔     | ✔               |
| ResetStickyTaskQueue               |      | ✔     | ✔               |
| ResetWorkflowExecution             |      | ✔     | ✔               |
| RespondActivityTaskCanceled        |      | ✔     | ✔               |
| RespondActivityTaskCanceledById    |      | ✔     | ✔               |
| RespondActivityTaskCompleted       |      | ✔     | ✔               |
| RespondActivityTaskCompletedById   |      | ✔     | ✔               |
| RespondActivityTaskFailed          |      | ✔     | ✔               |
| RespondActivityTaskFailedById      |      | ✔     | ✔               |
| RespondQueryTaskCompleted          |      | ✔     | ✔               |
| RespondWorkflowTaskCompleted       |      | ✔     | ✔               |
| RespondWorkflowTaskFailed          |      | ✔     | ✔               |
| SetUserNamespaceAccess             |      |       | ✔               |
| SignalWithStartWorkflowExecution   |      | ✔     | ✔               |
| SignalWorkflowExecution            |      | ✔     | ✔               |
| StartBatchOperation                |      | ✔     | ✔               |
| StartWorkflowExecution             |      | ✔     | ✔               |
| StopBatchOperation                 |      | ✔     | ✔               |
| TerminateWorkflowExecution         |      | ✔     | ✔               |
| UpdateExportSink                   |      | ✔     | ✔               |
| UpdateNamespace                    |      | ✔     | ✔               |
| UpdateSchedule                     |      | ✔     | ✔               |
| UpdateUserNamespacePermissions     |      |       | ✔               |
| ValidateExportSink                 |      | ✔     | ✔               |
| ValidateGlobalizeNamespace         |      |       | ✔               |

Account Owners and Global Admins will have Namespace Admin permissions on Namespaces.

---

## How to enable replication

You can enable High Availability (Single-region Replication, Multi-region Replication, Multi-cloud Replication) for a new or existing Namespace by adding a replica.
When you add a replica, Temporal Cloud begins the replication of ongoing and existing Workflow Executions.
Once the replication is complete and the replica is ready, your Namespace is ready for failover.

## Enabling High Availability features

:::tip Support, stability, and dependency info

Same-region Replication and Multi-cloud Replication are in [Public Preview](/evaluate/development-production-features/release-stages#public-preview) for Temporal Cloud.

:::

Not all replication options are available in all regions. See the [region documentation](/cloud/regions) for the replication options available in each region.

There are charges associated with Replication and enabling High Availability features.
For pricing details, visit Temporal Cloud's [Pricing](/cloud/pricing) page.
This page explains how to enable and manage these features.

## Create a Namespace with High Availability features {#create}

To create a new Namespace with High Availability features, you can use the Temporal Cloud UI or the tcld command line utility.
The following instructions explain how:

<Tabs>

<TabItem value="webui" label="Web UI">

    1. Visit Temporal Cloud in your Web browser.
    1. During Namespace creation, specify the primary [region](/cloud/regions) for the Namespace.
    1. Select "Add a replica".
    1. Choose the [region](/cloud/regions) for the replica.

    The web interface will present an estimated time for replication to complete.
    This time is based on your selection and the size and scale of the Workflows in your Namespace.

    Temporal Cloud sends an email alert to all Namespace Admins once your Namespace replica is ready for use.

</TabItem>

<TabItem value="tcldcli" label="tcld">

At the command line, enter:

```
tcld namespace create \
   --namespace <namespace_id>.<account_id> \
   --region <primary_region> \
   --region <replica_region>
```

Specify the [region codes](/cloud/regions) as arguments to the two `--region` flags.

- Using the same region replicates to an isolation domain within that region.
- Using a different region replicates across regions.

If using API key authentication with the `--api-key` flag, you must add it directly after the tcld command and before `namespace create`.

</TabItem>

</Tabs>

## Upgrade an existing Namespace with High Availability functionality {#upgrade}

Upgrade an existing standard Namespace by adding High Availability features.
Adding a replica unlocks that functionality.

The following instructions explain how:

<Tabs>

<TabItem value="webui" label="Web UI">

1. Visit Temporal Cloud Namespaces in your Web browser.
1. Navigate to the Namespace details page.
1. Select the “Add a replica” button.
1. Choose the [region](/cloud/regions) for the replica.

The web interface will present an estimated time for replication to complete.
This time is based on your selection and the size and scale of the Workflows in your Namespace.

Temporal Cloud sends an email alert to all Namespace Admins once your Namespace replica is ready for use.

</TabItem>

<TabItem value="tcldcli" label="tcld">

At the command line, enter:

```
tcld namespace add-region \
   --namespace <namespace_id>.<account_id> \
   --region <replica_region>
```

Specify the [region code](/cloud/regions) of the region where you want to create the replica as an argument to the `--region` flag.

If using API key authentication with the `--api-key` flag, you must add it directly after the tcld command and before `namespace add-region`.

Temporal Cloud sends an email alert once your Namespace is ready for use.

</TabItem>

</Tabs>

## Change a replica location {#changing}

:::caution

We discourage changing the location of your replica for deployed applications, except under exceptional circumstances.
Changing the location of your Namespace replica will result in a mandatory 7-day waiting period before you can re-enable High Availability Namespace features.

:::

Temporal Cloud can't change replica locations directly.
To update the location, you need to remove the current replica and add a new one.
Follow these steps to change the replica location:

1. [Remove your replica](#discontinuing).
   This disables High Availability for your Namespace.
2. Wait through the required 7-day waiting period.
3. [Add a new replica](#upgrade) to your Namespace.

You will receive an email alert once your Namespace is ready for use.

## Discontinue High Availability features {#discontinuing}

Removing a Namespace replica disables High Availability and automatic failover features.
Follow these steps to disable these features and end High Availability charges:

<Tabs>

<TabItem value="webui" label="Web UI">

1. Navigate to the Namespace details page in Temporal Cloud
1. Select the option to "Remove Replica" on the "Region" card.

</TabItem>

<TabItem value="tcldcli" label="tcld">

At the command line, enter:

```
tcld namespace delete-region \
    --namespace <namespace_id>.<account_id> \
    --region <replica_region>
```

If using API key authentication with the `--api-key` flag, you must add it directly after the tcld command and before `namespace delete-region`

</TabItem>

</Tabs>

After following these instructions, Temporal Cloud deletes the replica.
Your Namespace will no longer use High Availability features and you will no longer be charged for this feature.

:::note

After removing a replica, Temporal Cloud can't re-enable replication for a given Namespace for seven days.

:::

---

## How replication works

Keeping services available is crucial in distributed applications, especially during failures or incidents.
Temporal’s replication and automated failover features ensure high availability.
By enabling High Availability replication, you allow Temporal to copy Namespace metadata and Workflow Executions to a <ToolTipTerm term="replica"/>.
This redundancy, combined with failover capability, enhances availability during outages.

## Replication

Replication is the process of copying and synchronizing data or services across Temporal Server deployments.
This ensures availability and consistency in the event of a failure.
Temporal uses replication to support high availability, ensuring that Workflows and data remain available even if parts of the system fail or become unreachable.

In Temporal, replication operates at the Namespace level.
Each Namespace is replicated across <ToolTipTerm term="isolation domains" /> or separate regions.
If one Namespace becomes unavailable, a replica can take over, ensuring that Workflows continue without interruption.

Temporal Cloud replicates both Workflow Execution details and metadata, including configurations such as retention periods, Search Attributes, and other settings.
All parts of the system will eventually synchronize to a consistent view of the Namespace metadata, even if the primary and its replica temporarily lose communication.

<DiscoverableDisclosure label="Workflow replication restrictions">
Temporal Cloud restricts certain Workflow operations to the primary:

- You may only update Workflows in the primary.
- You may only dispatch Workflow Tasks and Activity Tasks from the primary.
  Because of this, forward progress in a Workflow Execution can only be made in the primary.

These limits mean that certain requests, such as Start Workflow and Signal Workflow, are processed by and limited to the primary.
Replicas may receive API requests from Clients and Workers.
They automatically forward these requests to the primary for execution.

Namespaces with High Availability features provide an “all-active” experience for Temporal users.
This helps limit or eliminate downtime during Namespace failover.
There's a short time window from when a replica becomes active to when Clients and Workers receive a DNS update.
During this time requests forward from the now passive (formerly active) primary to the newly active (formerly passive) replica.

As Workflow Executions progress and are operated on, replication Tasks created in the primary are dispatched to the replica.
Processing these replication Tasks ensures that the replica undergoes the same state transitions as the active primary.
This enables replicated tasks to synchronize and achieve the same state as the original tasks.

Replicas do not distribute Workflow or Activity Tasks.
Instead, they perform verification tasks to confirm that intended operations are executed so Workflows reach the desired state.
This mechanism ensures consistency and reliability in the replication process.
</DiscoverableDisclosure>

## Failovers

Occasionally, a Namespace may become temporarily unavailable due to an unexpected incident.
Temporal Cloud detects these issues using regular health checks.

### Health checks

Temporal Cloud monitors error rates, latencies, and infrastructure problems, such as request timeouts.
If it finds unhealthy conditions where indicators exceed the allowed thresholds, Temporal automatically switches the primary to the replica.
In most cases, the replica is unaffected by the issue.
This process is known as failover.

### Automatic failovers

Failovers prevent data loss and application interruptions.
Existing Workflows continue, and new Workflows start as the incident is addressed.
Once the incident is resolved, Temporal Cloud performs a "failback," shifting Workflow Execution processing back to the original Namespace.

Temporal Cloud handles failovers automatically, ensuring continuity without manual intervention.

<CaptionedImage src="/img/cloud/high-availability/failover.png" title="On failover, the replica becomes active and the Namespace endpoint directs access to it." />

For more control over the failover process, you can [disable automated failovers](/cloud/high-availability/failovers#disabling-temporal-initiated).

:::tip

You can test the failover of Namespace with High Availability features by manually triggering a failover using the UI or the 'tcld' CLI utility.
In most scenarios, we recommend you let Temporal handle failovers for you.

After failover, be aware of the following points:

- When working with Multi-region Namespaces, your CNAME may change.
  For example, it may switch from aws-us-west-1.region.tmprl.com to aws-us-east-1.region.tmprl.com.
  This change doesn't affect same-region Namespaces.

- Your Namespace endpoint _will not change_.
  If it is `my_namespace.my_account.tmprl.cloud:7233` before failover, it will be `my_namespace.my_account.tmprl.cloud:7233` after failover.

:::

### The failover process {#failover-process}

Temporal's automated failover process works as follows:

- During normal operation, the primary asynchronously copies operations and metadata to its replica, keeping them in sync.
- If the primary becomes unavailable, Temporal detects the issue through health checks.
  It automatically switches to the replica, using one of its available [failover scenarios](#scenarios).
- The replica takes over the active role and becomes the primary.
  Operations continue with minimal disruption.
- When the original primary recovers, the roles can either switch back (failback, by default) or remain as they are, based on your Namespace settings.
  Automatic role switching with failover and failback minimizes downtime for consistent availability.

:::info

A Namespace failover, which updates the "active region" field in the Namespace record, is a metadata update.
This update is replicated through the Namespace metadata mechanism.

:::

## Failover scenarios {#scenarios}

The Temporal Cloud failover mechanism supports several modes for executing Namespace failovers.
These modes include graceful failover ("handover"), forced failover, and a hybrid mode.
The hybrid mode is Temporal Cloud’s default Namespace behavior.

### Graceful failover (handover) {#graceful-failover}

In this mode, Temporal Cloud fully processes and drains replication Tasks.
Temporal Cloud pauses traffic to the Namespace before the failover.
Graceful failover prevents the loss of progress and avoids data conflicts.

The Namespace experiences a short period of unavailability, defaulting to 10 seconds.
During this period:

- Existing Workflows stop progress.
- Temporal Cloud returns a "Service unavailable error".
  This error is retryable by the Temporal SDKs.
- State transitions will not happen and tasks are not dispatched.
- User requests like start/signal Workflow are rejected.
- Operations are paused during handover.

This mode favors _consistency_ over availability.

### Forced failover {#forced-failover}

In this mode, a Namespace immediately activates in the replica.
Events not replicated due to replication lag undergo conflict resolution upon reaching the new active Namespace.

This mode prioritizes _availability_ over consistency.

### Hybrid failover mode {#hybrid-failover}

While graceful failovers are preferred for consistency, they aren’t always practical.
Temporal Cloud’s hybrid failover mode (the default mode) limits the initial graceful failover attempt to 10 seconds or less.

During this period:

- Existing Workflows stop progress.
- Temporal Cloud returns a "Service unavailable error", which is retried by SDKs.

If the graceful approach doesn’t resolve the issue, Temporal Cloud automatically switches to a forced failover.

This strategy balances _consistency_ and _availability_ requirements.

### Scenario summary

| Failover Scenario            | Characteristics                                         |
| ---------------------------- | ------------------------------------------------------- |
| Graceful failover (handover) | Favors _consistency_ over availability.                 |
| Forced failover              | Prioritizes _availability_ over consistency.            |
| Hybrid failover mode         | Balances _consistency_ and _availability_ requirements. |

## Network partitions

At any time only the primary or the replica is active.
The only exception occurs in the event of a [network partition](https://en.wikipedia.org/wiki/Network_partition), when a Network splits into separate subnetworks.
Should this occur, you can promote a replica to active status.
**Caution:** This temporarily makes both regions active.
After the network partition is resolved and communication between the isolation domains/regions is restored, a conflict resolution algorithm determines whether the primary or replica remains active.

:::tip

In traditional active/active replication, multiple nodes serve requests and accept writes simultaneously, ensuring strong synchronous data consistency.
In contrast, with a Temporal Cloud Namespace with High Availability Features, only the primary accepts requests and writes at any given time.
Workflow History Events are written to the primary first and then asynchronously replicated to the replica, ensuring that the replica remains in sync.

:::

## Conflict resolution {#conflict-resolution}

Namespaces with replicas rely on asynchronous event replication.
Updates made to the primary may not immediately be reflected in the replica due to <ToolTipTerm term="replication lag" />, particularly during failovers.
In the event of a non-graceful failover, replication lag may cause a temporary setback in Workflow progress.

Namespaces that aren't replicated can be configured to provide _at-most-once_ semantics for Activities execution when a retry policy's [maximum attempts](https://docs.temporal.io/retry-policies#maximum-attempts) is set to 0.
High Availability Namespaces provide _at-least-once_ semantics for execution of Activities.
Completed Activities _may_ be re-dispatched in a newly active Namespace, leading to repeated executions.

When a Workflow Execution is updated in a newly active replica following a failover, events from the previously active Namespace that arrive after the failover can't be directly applied.
At this point, Temporal Cloud has forked the Workflow History.

After failover, Temporal Cloud creates a new branch history for execution, and begins its <ToolTipTerm term="conflict resolution"/> process.
The Temporal Service ensures that Workflow Histories remain valid and are replayable by SDKs post-failover or after conflict resolution.
This capability is crucial for ensuring Workflow Executions continue forward without losing progress, and for maintaining consistency across replication, even during incidents that cause disruptions in replication.

---

## Authenticating to Namespaces with High Availability Features

Temporal Cloud supports authentication to Namespaces with High Availability features using [API keys](/cloud/api-keys) or [mTLS](/cloud/certificates).
A Namespace only supports one authentication method at a time.
This is determined at Namespace creation.

:::tip

If you need to migrate from one authentication method to another, please contact [Support](https://support.temporal.io).

:::

Use the gRPC Namespace endpoint `<namespace>.<account>.tmprl.cloud:7233` regardless of your authentication method.
This allows automated failover without needing to switch your endpoint.

Please visit the [Accessing Namespaces](/cloud/namespaces#access-namespaces) page to find further in-depth information and a discussion on how to use authentication with Clients.

### Related reading:

- [API keys](/cloud/api-keys)
- [mTLS authentication](/cloud/certificates)
- [Namespace access](/cloud/namespaces#access-namespaces)

---

## Triggering manual failovers

Temporal Cloud automatically initiates failovers when an incident or outage affects a Namespace with High Availability features.
Namespace replicas duplicate data and prevent data loss during failover.

- [Manual failovers](#triggering-failovers)
  - [Disabling Temporal-initiated failovers](#disabling-temporal-initiated)
- [Failover testing](#testing)
- [Preparing Worker deployment](#worker)

## Perform a manual failover {#triggering-failovers}

For some users, Temporal's automated health checks and failovers don't provide sufficient nuance and control.
For this reason, you can manually trigger failovers based on your own custom alerts and for testing purposes.
This section explains how and what to expect afterward.

:::warning Check Your Replication Lag

Always check the <ToolTipTerm term="replication lag" /> before initiating a failover.
A forced failover when there is a significant replication lag has a higher likelihood of rolling back Workflow progress.

:::

### Trigger the failover {#manual-failovers}

You can trigger a failover manually using the Temporal&nbsp;CloudWeb&nbsp;UI or the tcld CLI, depending on your preference and setup.
The following instructions outline the steps for each method:

<Tabs>

<TabItem value="webui" label="Web UI">

1. Visit the [Namespace page](https://cloud.temporal.io/namespaces) on the Temporal Cloud Web UI.
1. Navigate to your Namespace details page and select the **Trigger a failover** option from the menu.
1. Confirm your action.
   After confirmation, Temporal initiates the failover.

</TabItem>

<TabItem value="tcldcli" label="tcld">

To manually trigger a failover, run the following command in your terminal:

```
tcld namespace failover \
    --namespace <namespace_id>.<account_id> \
    --region <target_region>
```

If using API key authentication with the `--api-key` flag, you must add it directly after the tcld command and before `namespace failover`.

</TabItem>

</Tabs>

Temporal fails over the primary to the replica.
When you're ready to fail back, follow these failover instructions to move the primary back to the original.

### Post-failover event information {#info}

After any failover, whether triggered by you or by Temporal, an event appears in both the [Temporal Cloud Web UI](https://cloud.temporal.io/namespaces) (on the Namespace detail page) and in your audit logs.
The audit log entry for Failover uses the `"operation": "FailoverNamespace"` event.
After failover, the replica becomes active, taking over in the isolation domain or region.

You don't need to monitor Temporal Cloud's failover response in real time.
Whenever there is a failover event, users with the Account Owner and Global Admin roles automatically receive an alert email.

### Returning to the primary with failbacks

After Temporal-initiated failovers, Temporal Cloud shifts Workflow Execution processing back to the original region or isolation domain that was active before the incident once the incident is resolved.
This is called a "failback".

:::note

To failback a manually-initiated failover, follow the [Manual Failover](#manual-failovers) directions to failover back to the original primary.

:::

## Disabling Temporal-initiated failovers {#disabling-temporal-initiated}

When you add a replica to a Namespace, in the event of an incident or an outage Temporal Cloud automatically fails over the Namespace to its replica.
_This is the recommended and default option._

However if you prefer to disable Temporal-initiated failovers and handle your own failovers, you can do so by following these instructions:

<Tabs>

<TabItem value="webui" label="Web UI">

1. Navigate to the Namespace detail page in Temporal Cloud.
1. Choose the "Disable Temporal-initiated failovers" option.

</TabItem>

<TabItem value="tcldcli" label="tcld">

To disable Temporal-initiated failovers, run the following command in your terminal:

```
tcld namespace update-high-availability \
    --namespace <namespace_id>.<account_id> \
    --disable-auto-failover=true
```

If using API key authentication with the `--api-key` flag, you must add it directly after the tcld command and before `namespace update-high-availability`

</TabItem>

</Tabs>

Temporal Cloud disables its health-check initiated failovers.
To restore the default behavior, unselect the option in the WebUI or change `true` to `false` in the CLI command.

## Best practices: Workers and failovers {#worker}

Enabling High Availability for Namespaces doesn't require specific Worker configuration.
The process is invisible to the Workers.
When a Namespace fails over to the replica, the DNS redirection orchestrated by Temporal ensures that your existing Workers continue to poll the Namespace without interruption.

When a Namespace fails over to a replica in a different region, Workers will be communicating cross-region.

- If your application can’t tolerate this latency, deploy a second set of Workers in the replica's region or opt for a replica in the same region:
- In the case of a complete regional outage, Workers in the original region may fail alongside the original Namespace.
  To keep Workflows moving during this level of outage, deploy a second set of Workers to the secondary region.

:::tip

Temporal Cloud enforces a maximum connection lifetime of 5 minutes.
This offers your Workers an opportunity to re-resolve the DNS.

:::

## Best practices: scheduled failover testing {#testing}

Microservices and external dependencies will fail at some point.
Testing failovers ensures your app can handle these failures effectively.
Temporal recommends regular and periodic failover testing for mission-critical applications in production.
By testing in non-emergency conditions, you verify that your app continues to function, even when parts of the infrastructure fail.

<DiscoverableDisclosure label="Why test?">

:::tip Safety First

If this is your first time performing a failover test, run it with a test-specific namespace and application.
This helps you gain operational experience before applying it to your production environment.
Practice runs help ensure the process runs smoothly during real incidents in production.

:::

Failover testing (also known as "<ToolTipTerm term="trigger testing" />)" can:

- **Validate replicated deployments**:
  In multi-region setups, failover testing ensures your app can run from another region when the primary region experiences outages.
  In standard setups, failover testing instead works with an isolation domain.
  This maintains high availability in mission-critical deployments.
  Manual testing confirms the failover mechanism works as expected, so your system handles incidents effectively.

- **Assess replication lag**:
  In multi-region deployment, monitoring [replication lag](/cloud/high-availability/monitor#metrics) between regions is crucial.
  Check the lag before initiating a failover to avoid rolling back Workflow progress.
  This is less important when using isolation domains as failover is usually instantaneous.
  Manual testing helps you practice this critical step and understand its impact.

- **Assess recovery time**:
  Manual testing helps you measure actual recovery time.
  You can check if it meets your expected Recovery Time Objective (RTO) of 20 minutes or less, as stated in the [High Availability Namespace SLA](/cloud/sla).

- **Identify potential issues**:
  Failover testing uncovers problems not visible during normal operation.
  This includes issues like [backlogs and capacity planning](https://temporal.io/blog/workers-in-production#testing-failure-paths-2438) and how external dependencies behave during a failover event.

- **Validate fault-oblivious programming**:
  Temporal uses a "fault-oblivious programming" model, where your app doesn’t need to explicitly handle many types of failures.
  Testing failovers ensures that this model works as expected in your app.

- **Operational readiness**:
  Regular testing familiarizes your team with the failover process, improving their ability to handle real incidents when they arise.

Testing failovers regularly ensures your Temporal-based applications remain resilient and reliable, even when infrastructure fails.

</DiscoverableDisclosure>

---

## How-to guides

Temporal’s High Availability features ensure that your Workflows remain operational, even during disruptions.
The pages in this section provide how-to support for triggering failovers, setting up routing, and more.

---

[**How do I trigger a failover?**](/cloud/high-availability/failovers)

In certain scenarios, such as testing or proactively managing failovers before Temporal’s automated health checks take over, you can perform manual failovers.
This allows you to switch between primary Namespaces and their replicas, test the failover mechanism, or just stay ahead of Temporal's automatic failovers when it matters.
This is especially useful in environments that require precise control over failover timing or configuration.

[**How do I authenticate with High Availability features?**](/cloud/high-availability/api-authentication)

Temporal Cloud supports Namespace authentication with [API keys](/cloud/api-keys) or [mTLS](/cloud/certificates).

[**How do I resolve DNS?**](/cloud/high-availability/secure-routing)

Resolving a Namespace’s DNS record correctly is an important skill when your Namespace's region or isolation domain changes after failover.

[**How do I set up AWS PrivateLink for High Availability routing?**](/cloud/high-availability/private-link)

For more secure communication, AWS PrivateLink configurations enable you to isolate data transfer between your Temporal instance and your internet services.
This setup enhances the security of your high-availability architecture and helps protect sensitive data while ensuring continuous operations.

[**How do I migrate between regions?**](/cloud/high-availability/migrate)

Temporal Cloud's High Availability features allow you to migrate a namespace from one region or cloud provider to another with zero downtime.

---

## Migrate between regions

Temporal Cloud's High Availability features allow you to migrate a namespace from one region or cloud provider to another with zero downtime.

[Using High Availability features affects pricing](/cloud/pricing#high-availability-features).

1. Add a namespace replica in the region you want to migrate to. See [regions](/cloud/regions) for a list of available regions and supported multi-region and multi-cloud configurations.

<CaptionedImage
    src="/img/cloud/high-availability/migrate/1-add-replica.png"
    title="Add a namespace replica"
    zoom="true"
/>

<CaptionedImage
    src="/img/cloud/high-availability/migrate/2-choose-region.png"
    title="Choose the region for the replica"
    zoom="true"
/>

2. Wait for the replica to become active. The Cloud UI will display a time estimate, and namespace admins will receive an email when the replica is active.
3. If your workers are using API key authentication: ensure your workers (and all other client code) are updated to [use the regional endpoint of the new replica](/cloud/namespaces#access-namespaces).
4. Trigger a failover to the new region.

<CaptionedImage
    src="/img/cloud/high-availability/migrate/3-failover.png"
    title="Initiate failover to the new region"
    zoom="true"
/>

5. Remove the namespace replica in the region you are migrating from.

:::note
If using [API keys](/cloud/api-keys) for worker authentication, you must open a [support ticket](/cloud/support#support-ticket) to remove the replica.

:::

<CaptionedImage
    src="/img/cloud/high-availability/migrate/4-remove-replica.png"
    title="Remove the replica for the original region"
    zoom="true"
/>

:::note
All replica changes are subject to a [cooldown period](/cloud/high-availability/enable#changing) before further replica changes can be made.

:::

---

## AWS PrivateLink routing

:::tip Namespaces with High Availability features and AWS PrivateLink

Proper networking configuration is required for failover to be transparent to clients and workers when using PrivateLink.
This page describes how to configure routing for Namespaces with High Availability features on AWS PrivateLink.

:::

To use AWS PrivateLink with High Availability features, you may need to:

- Override the regional DNS zone.
- Ensure network connectivity between the two regions.

This page provides the details you need to set this up.

## Customer side solutions

When using PrivateLink, you connect to Temporal Cloud through a VPC Endpoint, which uses addresses local to your network.
Temporal treats each `region.<tmprl_domain>` as a separate zone.
This setup allows you to override the default zone, ensuring that traffic is routed internally for the regions you’re using.

A Namespace's active region is reflected in the target of a CNAME record.
For example, if the active region of a Namespace is AWS us-west-2, the DNS configuration would look like this:

| ha-namespace.account-id.tmprl.cloud | CNAME | aws-us-west-2.region.tmprl.cloud |
| ----------------------------------- | ----- | -------------------------------- |

After a failover, the CNAME record will be updated to point to the failover region, for example:

| ha-namespace.account-id.tmprl.cloud | CNAME | aws-us-east-1.region.tmprl.cloud |
| ----------------------------------- | ----- | -------------------------------- |

The Temporal domain did not change, but the CNAME updated from us-west-2 to us-east-1.

<CaptionedImage
    src="/img/cloud/high-availability/private-link.png"
    title="Customer side solution example"
    zoom="true"
/>

## Setting up the DNS override

:::caution

Private connectivity is not yet offered for GCP Multi-region Namespaces.

:::

To set up the DNS override, configure specific regions to target the internal VPC Endpoint IP addresses.
For example, you might set aws-us-west-1.region.tmprl.cloud to target 192.168.1.2.
In AWS, this can be done using a Route 53 private hosted zone for `region.tmprl.cloud`.
Link that private zone to the VPCs you use for Workers.

When your Workers connect to the Namespace, they first resolve the `<ns>.<acct>.<tmprl_domain>` record.
This points to `<aws-active-region>.region.tmprl.cloud`, which then resolves to your internal IP addresses.

Consider how you’ll configure Workers for this setup.
You can either have Workers run in both regions continuously or establish connectivity between regions using Transit Gateway or VPC Peering.
This way, Workers can access the newly activated region once failover occurs.

## Available regions, PrivateLink endpoints, and DNS record overrides

:::caution

The `sa-east-1` region is not yet available for use with Multi-region Namespaces. Currently, it is the only region on the continent.

:::

The following table lists the available Temporal regions, PrivateLink endpoints, and DNS record overrides:

| Region           | PrivateLink Service Name                                       | DNS Record Override                     |
| ---------------- | -------------------------------------------------------------- | --------------------------------------- |
| `ap-northeast-1` | `com.amazonaws.vpce.ap-northeast-1.vpce-svc-08f34c33f9fb8a48a` | `aws-ap-northeast-1.region.tmprl.cloud` |
| `ap-northeast-2` | `com.amazonaws.vpce.ap-northeast-2.vpce-svc-08c4d5445a5aad308` | `aws-ap-northeast-2.region.tmprl.cloud` |
| `ap-south-1`     | `com.amazonaws.vpce.ap-south-1.vpce-svc-0ad4f8ed56db15662`     | `aws-ap-south-1.region.tmprl.cloud`     |
| `ap-south-2`     | `com.amazonaws.vpce.ap-south-2.vpce-svc-08bcf602b646c69c1`     | `aws-ap-south-2.region.tmprl.cloud`     |
| `ap-southeast-1` | `com.amazonaws.vpce.ap-southeast-1.vpce-svc-05c24096fa89b0ccd` | `aws-ap-southeast-1.region.tmprl.cloud` |
| `ap-southeast-2` | `com.amazonaws.vpce.ap-southeast-2.vpce-svc-0634f9628e3c15b08` | `aws-ap-southeast-2.region.tmprl.cloud` |
| `ca-central-1`   | `com.amazonaws.vpce.ca-central-1.vpce-svc-080a781925d0b1d9d`   | `aws-ca-central-1.region.tmprl.cloud`   |
| `eu-central-1`   | `com.amazonaws.vpce.eu-central-1.vpce-svc-073a419b36663a0f3`   | `aws-eu-central-1.region.tmprl.cloud`   |
| `eu-west-1`      | `com.amazonaws.vpce.eu-west-1.vpce-svc-04388e89f3479b739`      | `aws-eu-west-1.region.tmprl.cloud`      |
| `eu-west-2`      | `com.amazonaws.vpce.eu-west-2.vpce-svc-0ac7f9f07e7fb5695`      | `aws-eu-west-2.region.tmprl.cloud`      |
| `sa-east-1`      | `com.amazonaws.vpce.sa-east-1.vpce-svc-0ca67a102f3ce525a`      | `aws-sa-east-1.region.tmprl.cloud`      |
| `us-east-1`      | `com.amazonaws.vpce.us-east-1.vpce-svc-0822256b6575ea37f`      | `aws-us-east-1.region.tmprl.cloud`      |
| `us-east-2`      | `com.amazonaws.vpce.us-east-2.vpce-svc-01b8dccfc6660d9d4`      | `aws-us-east-2.region.tmprl.cloud`      |
| `us-west-2`      | `com.amazonaws.vpce.us-west-2.vpce-svc-0f44b3d7302816b94`      | `aws-us-west-2.region.tmprl.cloud`      |

---

## Monitoring the Namespace DNS record

When using a Namespace with High Availability features, the Namespace's DNS record `<ns>.<acct>.<tmprl_domain>` points to a regional DNS record in the format `<region>.region.<tmprl_domain>`.
Here, `<region>` is the currently active region for your Namespace.

During failover, Temporal Cloud changes the target of the Namespace DNS record from one region to another.
Namespace DNS records are configured with a 15 second TTL.
Any DNS cache should re-resolve the record within this time.
As a rule of thumb, receiving an updated DNS record takes about twice (2x) the TTL.
Clients should converge to the newly targeted region within, at most, a 30-second delay.

:::info AWS PrivateLink

AWS PrivateLink customers should visit the [dedicated AWS PrivateLink page](/cloud/high-availability/private-link) for configuration details.

:::

---

## High Availability

Temporal Cloud provides a 99.9% contractual Service Level Agreement ([SLA](/cloud/sla)) guarantee against service errors for all Namespaces.
High Availability asynchronously replicates Workflows across multiple <ToolTipTerm term="isolation domains" /> for a 99.99% [SLA](/cloud/sla) (10x the default).

<DiscoverableDisclosure label="Namespaces and built-in stability">

Each standard Temporal Namespace uses replication across three availability zones to ensure high availability.
An availability zone is a part of the system where tasks or operations are handled and executed.
This design helps manage workloads and ensure tasks are completed.
This improves resource use and reduces delays.

Replication makes sure that any changes to Workflow state or History are saved in all three zones _before_ the Temporal Service acknowledges a change back to the Client.
As a result, your standard Temporal Namespace stays operational even if one of its three zones becomes unavailable.
This provides the basis of our 99.9% service level.

</DiscoverableDisclosure>

## High Availability features {#high-availability-features}

When you enable High Availability features, Temporal deploys your primary and its replica across separate isolation domains. You control the location of both the primary and the replica.

| **Deployment**                          | **Description**                                            |
| --------------------------------------- | ---------------------------------------------------------- |
| **Same&#8209;region&nbsp;Replication**  | Isolation domains are co-located within the same region.   |
| **Multi&#8209;region&nbsp;Replication** | Isolation domains are located in separate regions.         |
| **Multi&#8209;cloud&nbsp;Replication**  | Isolation domains are located in separate cloud providers. |

### Same-region Replication

Temporal replicates Namespaces across isolation domains within one region.
This option is a good fit when your application is built for one region and you prefer to failover within that region.
This provides a reliable failover mechanism while maintaining deployment simplicity.

### Multi-region Replication

Temporal replicates Namespaces across regions, making sure Workflows and data are available even if a region fails.
Asynchronous replication means changes aren’t immediately reflected in other regions but will sync over time, ensuring data integrity.
This setup allows failovers between replicas without needing immediate consistency across regions.
Replication across different regions enhances resilience and reliability.

### Multi-cloud Replication

Temporal asynchronously replicates all Workflows (live and historical) and data to a Namespace in an entirely different cloud provider.
If a provider outage, regional outage, service disruption, or network issue occurs, traffic automatically shifts to the replica.
Replicated data is securely encrypted and transmitted across the public internet between cloud providers.
Internet connectivity allows workers in one cloud to fail over to a replica in a different cloud.

:::caution

When you adopt Temporal's High Availability features, don't forget to consider the reliability of your own workers, infrastructure, and dependencies.
Issues like network outages, hardware failures, or misconfigurations in your own systems can affect your application performance.

For the highest level of reliability, distribute your dependencies across regions, and use our Multi-region or Multi-cloud replication features.
Using physically separated regions improves the fault tolerance of your application.

:::

[See more detail about how replication works](/cloud/high-availability/how-it-works).

## Failover

In case of an incident or an outage, Temporal will automatically <ToolTipTerm term="fail over" src="failover" /> your Namespace from the primary to the replica.
This lets Workflow Executions continue with minimal interruptions or data loss.
You can also [manually initiate failovers}(/cloud/high-availability/failovers) based on your situational monitoring or for testing.

Returning control from the replica to the primary is called a <ToolTipTerm term="failback" />.
The replica is active for a brief duration during an incident.
After the incident, Temporal fails back to the primary.

[See more detail about how failovers work](/cloud/high-availability/how-it-works#failovers).

## SLA for High Availability features {#sla}

**What guarantees does Temporal offer for replication features?**

Namespace replication offers 99.99% availability, enforced by Temporal Cloud's [service error rates SLA](/cloud/sla).
Our system is designed to limit data loss after recovery when the incident triggering the failover is resolved.

Our recovery point objective (<ToolTipTerm term="RPO" />) is near-zero.
There may be a short period of time during an incident or forced failover when some data is unavailable in the replica region.
Some Workflow History data won't arrive until network issues are fixed, enabling the History to finish replicating and the divergent History branches to reconcile.

Temporal Cloud proactively responds to incidents by triggering failovers.
Our recovery time objective (<ToolTipTerm term="RTO" />) is 20 minutes or less per incident.

:::info

During a disaster scenario in which the data in the primary Namespace cannot be recovered, the duration of data loss may be as high as the [replication lag](/cloud/high-availability/monitor) at the time of disaster.

:::

---

## Monitoring health

:::tip Support, stability, and dependency info

Same-region Replication is in [Public Preview](/evaluate/development-production-features/release-stages#public-preview) for Temporal Cloud.

:::

This section provides how-to instructions for monitoring replica and Service health when using Namespaces with High Availability features:

- [Replica health](#replica-health)
- [Service health and latency metrics](#metrics)
  - [Monitoring and observability](#observe)
  - [Checking failovers](#auditing)

## Replica health {#replica-health}

You can monitor your replica status with the Temporal Cloud UI.
If the replica is unhealthy, Temporal Cloud diables the “Trigger a failover” option to prevent failing over to an unhealthy replica.
An unhealthy replica might be due to:

- **Data synchronization issues:** The replica fails to remain in sync with the primary due to network or performance problems.
- **Replication lag:** The replica falls behind the primary, causing it to be out of sync.
- **Network issues:** Loss of communication between the replica and the primary causes problems.
- **Failed health checks:** If the replica fails health checks, it’s marked as unhealthy.

These issues prevent the replica from being used during a failover, ensuring system stability and consistency.

## Service health and latency metrics {#metrics}

Temporal Cloud’s High Availability features use asynchronous replication between the primary and the replica.
Workflow updates in the primary, along with associated History Events, are transmitted to the replica.
Replication lag refers to the transmission delay of Workflow updates and history events from the primary to the replica.

:::tip

Temporal Cloud strives to maintain a <ToolTipTerm term="P95" /> replication lag of less than 1 minute.
In this context, P95 means 95% of updates are processed faster than this limit.

:::

A forced failover, when there is significant replication lag, increases the likelihood of rolling back Workflow progress.
Always check the replication lag metrics before initiating a failover.

Temporal Cloud emits three replication lag-specific [metrics](/production-deployment/cloud/metrics/reference#replication-lag).
The following samples demonstrate how you can use these metrics to monitor and explore replication lag:

**P99 replication lag histogram**:

```
histogram_quantile(0.99, sum(rate(temporal_cloud_v0_replication_lag_bucket[$__rate_interval])) by (temporal_namespace, le))
```

**Average replication lag**:

```
sum(rate(temporal_cloud_v0_replication_lag_sum[$__rate_interval])) by (temporal_namespace)
/
sum(rate(temporal_cloud_v0_replication_lag_count[$__rate_interval])) by (temporal_namespace)
```

### Monitoring and observability {#observe}

You can view and set alerts for key Cloud metrics using the Web UI, the 'tcld' CLI utility, or Temporal Cloud APIs.
For instance, when adding a region to a Namespace, you can track how Workflow replication progresses.
If any errors occur, they will be displayed in the Namespace Web UI.

:::tip

If a Namespace is using a replica, you may notice that the Action count in `temporal_cloud_v0_total_action_count` is doubled (2x).
This happens because operations are replicated; they occur on both the primary and the replica.

:::

### Checking failovers {#auditing}

Temporal Cloud offers several ways to monitor failovers:

- When Temporal triggers failovers, the audit log will update with details.
  Look for `"operation": "FailoverNamespace"` in the logs.
- You can set up alerts for Temporal-initiated failover events.
- After a failover, verify that the Namespace is active in the new region using the Temporal Cloud Web UI.

---

## References

Temporal’s High Availability features ensure that your Workflows remain operational, even during disruptions.
The pages in this section provide deeper insights into Temporal's High Availability implementation.

- [**Service regions**](/cloud/regions): Regions supported by Temporal Cloud Namespaces

---

## Temporal Cloud guide

Welcome to the Temporal Cloud guide.

In this guide you will find information about Temporal Cloud, onboarding, features, and how to use them.

To create a Temporal Cloud account, sign up [here](https://temporal.io/get-cloud).

**[Get started with Temporal Cloud.](/cloud/get-started)**

## Become familiar with Temporal Cloud

- [Introduction to Temporal Cloud](/cloud/introduction)
  - [Security model](/cloud/security)
  - [Service availability](/cloud/service-availability) (availability, region support, throughput, latency, and limits)
  - [Account, Namespace, and application level configurations](/cloud/limits)
  - [Service Level Agreement (SLA)](/cloud/sla)
  - [Pricing](/cloud/pricing)
  - [Support](/cloud/support)

## Feature guides

- [Get started with Temporal Cloud](/cloud/get-started)
  - [Manage certificates](/cloud/certificates)
  - [Manage API keys](/cloud/api-keys)
  - [Manage Namespaces](/cloud/namespaces)
  - [Manage users](/cloud/users)
  - [Manage billing](/cloud/billing-and-cost)
  - [Manage service accounts](/cloud/service-accounts)
- [API key feature guide](/cloud/api-keys)
- [Metrics feature guide](/cloud/metrics)
- [Temporal Nexus](/cloud/nexus)
- [SAML authentication feature guide](/cloud/saml)
- [Cloud Ops API](/ops)
- [Audit logging feature guide](/cloud/audit-logging)
- [`tcld` (Temporal Cloud command-line interface) reference](/cloud/tcld)

---

## Datadog metrics setup - Temporal Cloud feature guide

:::note

Datadog in partnership with Temporal Cloud has created a native integration with Temporal Cloud metrics.
This integration is in preview mode and available to all Datadog customers.

Benefits of using this integration include:

- Out-of-the-box Temporal Cloud metrics dashboard in Datadog
- Simpler metrics integration (no need for the promql-to-dd scraper)

For detailed instructions on how to use the integration, see [the documentation on Datadog's site](https://docs.datadoghq.com/integrations/temporal_cloud/).
If you prefer not to use the native integration, the method described on this page also works.

:::

Exporting cloud metrics to Datadog provides enhanced observability, allowing you to monitor, alert, and visualize key performance indicators of your applications and infrastructure.
Temporal's integration with Datadog extends the monitoring capabilities of your Temporal Cloud deployment.

:::note

This tutorial provides an example application to help users capture metrics from Temporal's PromQL endpoint and export to Datadog.

:::

### What will you learn?

You will set up your environment to export metrics from Temporal Cloud to Datadog, including:

- Preparing your environment with the necessary prerequisites
- Configuring certificates for secure communication
- Deploying the integration using Helm and Minikube
- Verifying the setup to ensure metrics are being exported correctly

## Prerequisites

Before you begin, ensure you have the following:

- A [Datadog account](https://www.Datadoghq.com/) with an [API Key](https://app.Datadoghq.com/account/settings#api).
- A [Temporal Cloud account](https://cloud.temporal.io/).
- Helm installed [for managing Kubernetes applications](https://helm.sh/docs/intro/install/).
- K9s for [Kubernetes CLI UI management](https://github.com/derailed/k9s).
- Minikube for running a [local Kubernetes cluster](https://minikube.sigs.k8s.io/docs/start/).
- A GitHub account [for accessing repositories](https://github.com/).

## Step 1. Set up the GitHub project

Temporal provides a script demonstrating the minimum work necessary to read recently generated metrics from a Temporal Cloud account using the Prometheus API and import them into Datadog while handling some common edge and error cases.

The following tutorial uses the [Prometheus Querying Language to Datadog in Go](https://github.com/temporalio/samples-server/tree/main/cloud/observability/promql-to-dd-go) (PromQL); however, you can use and customize this code and others to suit your needs.

Temporal also provides a [scrape version](https://github.com/temporalio/samples-server/tree/main/cloud/observability/promql-to-scrape) which can be used by the Otel or Datadog agents.

Temporal also provides examples in other languages:

- [PromQL to Datadog in Python](https://github.com/temporalio/samples-server/blob/main/cloud/observability/README.md)
- [PromQL to Datadog in Typescript](https://github.com/temporalio/samples-server/tree/main/cloud/observability/promql-to-dd-ts)

Clone the `promql-to-dd-go` directory from the Temporal samples server and navigate into it:

```bash
gh repo clone temporalio/samples-server
cd samples-server/cloud/observability/promql-to-dd-go
```

:::note

These examples are provided as-is, without support.
They are intended as reference material only.

:::

Metrics are exported on a per-account basis.

## Step 2. Create your certificates

Choose a method for generating certificates.
You can use one of the methods provided, or if your organization has its own certification manager, use that.

These certificates are used to communicate with your Temporal Cloud account.
For more information on certifications and Temporal Cloud, see [Certificate management](/cloud/certificates).

### Using tcld

Use the tcld to authenticate, generate, and add certificates to your Cloud account.

1. **Login**: Authenticate with your Temporal Cloud account.
   ```bash
   tcld login
   ```
2. **Create certs**: Generate the necessary certificates for secure communication.
   ```bash
   tcld generate-certificates certificate-authority-certificate --org ${ACCOUNT_ID} -d 1y --ca-cert ca.pem --ca-key ca.key
   ```
3. **Add certificates to Cloud account**: Ensure your Temporal Cloud Namespace is configured with the generated certificates.
   ```bash
   tcld namespace accepted-client-ca add --ca-certificate-file ca.pem
   ```

Replace `${ACCOUNT_ID}` with your Temporal Cloud account ID.
This is the assigned account identifier.

### Using certstrap

You can also use certification managers like certstrap.

1. Follow the [certstrap README](https://github.com/square/certstrap) to download and install certstrap.
2. Create a new certificate authority with `certstrap init --common-name CertAuth`.
3. Request a certificate key pair with `certstrap request-cert --common-name metrics-cert`.
4. Sign the certificate request to generate the end-entity certificate with `certstrap sign metrics-cert --CA CertAuth`.
5. Locate your newly created certificates in the `out` folder within the certstrap directory.
6. Add the certificates to your Cloud Account, for more information see [How to add, update, and remove certificates in a Temporal Cloud Namespace](/cloud/certificates#update-certificates-using-temporal-cloud-ui).

:::note

Certificate names must be unique per account.

:::

Next, verify that your certificates are set up correctly.

### Verifying certificates setup

Now that you've created and set your certifications, test them to ensure they are working correctly.

<Tabs>
  <TabItem value="input" label="Input" default>
Test your setup with the following command:
```bash
curl --cert ca.pem --key ca.key "https://<Organization_ID>.tmprl.cloud/prometheus/api/v1/query?query=temporal_cloud_v0_state_transition_count" | jq .
```

Provide the Organization ID of your Temporal Cloud account.

</TabItem>
<TabItem value="ouput" label="Output">
Expect a successful response indicating your setup is correct.

```json
{
  "status": "success",
  "data": {
    "resultType": "vector",
    "result": [
      {
        "metric": {
          "__name__": "temporal_cloud_v0_state_transition_count",
          "__rollup__": "true",
          "operation": "WorkflowContext",
          "temporal_namespace": "namespace.id",
          "temporal_service_type": "history"
        },
        "value": [123456.789, "12"]
      }
    ]
  }
}
```

</TabItem>
</Tabs>

## Step 3. Run Helm and Minikube

Use the following commands to run **Minikube** and **Helm** in your environment.
While this is using Minikube, you can deploy to any Kubernetes cluster, with your environment specific configuration.

1. **Start Minikube**:

In one terminal, start your **Minikube** instance:

```bash
minikube start
```

2. **Deploy with Helm**:

In a second terminal, start your **Helm** instance.

<Tabs>
  <TabItem value="input" label="Input" default>

Set your environment variables for the Datadog API key and [Temporal Account Id](/cloud/namespaces#temporal-cloud-account-id), then deploy using Helm:

```bash
helm install promqltodd . \
  --set prom_endpoint=https://${ACCOUNT_ID}.tmprl.cloud/prometheus \
  --set dd_api_key=${DD_API_KEY} \
  --set query_interval_seconds=15 \
  --set-file 'ca_cert=../out/metrics-cert.crt' \
  --set-file 'ca_key=../out/metrics-cert.key'
```

Update the path and the name of your certificate and key.

</TabItem>
<TabItem value="ouput" label="Output">

You'll see an output indicating successful deployment:

```bash
NAME: promqltodd
LAST DEPLOYED: [Deployment Time]
NAMESPACE: default
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Thank you for installing promql-to-dd-go.
```

</TabItem>
</Tabs>

Use the `helm status` command to confirm the deployment or `helm get all` to view the deployment.

### Deploy K9s

Start your **K9s** instance to monitor the deployment:

```bash
k9s
```

Review the logs to confirm the integration is functioning as expected.

Use a [pre-built dashboard](https://github.com/temporalio/samples-server/blob/main/cloud/observability/) to visualize your metrics in Datadog.

You've successfully set up the export of metrics from Temporal Cloud to Datadog.

### Next steps

This is just the start.

Customize and extend this code, dashboards, and deployment processes to meet your needs.

- Explore [Datadog dashboards](https://github.com/temporalio/samples-server/blob/main/cloud/observability/) to visualize your Temporal metrics.
- Set up alerts in Datadog based on the metrics received from Temporal Cloud.
- Consider integrating additional observability tools or exporting metrics to other platforms as needed.

---

## General observability setup with metrics - Temporal Cloud feature guide

This page shows how to do the following:

- [How to configure an endpoint using the UI](#configure-via-ui)
- [How to configure an endpoint using tcld](#configure-via-cli-tcld)

## Configure using the UI {#configure-via-ui}

**How to configure a metrics endpoint using Temporal Cloud UI**

:::note

To view and manage third-party integration settings, your user account must have the Account Owner or Global Admin [role](/cloud/users#account-level-roles).

:::

To assign a certificate and generate your metrics endpoint, follow these steps:

1. Log in to Temporal Cloud UI with an Account Owner or Global Admin [role](/cloud/users#account-level-roles).
2. Go to **Settings** and select **Integrations**.
3. Select **Configure Observability** (if you're setting it up for the first time) or click **Edit** in the Observability section (if it was already configured before).
4. Add your root CA certificate (.pem) and save it.
   Note that if an observability endpoint is already set up, you can append your root CA certificate here to use the generated observability endpoint in your observability tool.
5. To test your endpoint, run the following command on your host:
   ```
   curl -v --cert <path to your client-cert.pem> --key <path to your client-cert.key> "<your generated Temporal Cloud prometheus_endpoint>/api/v1/query?query=temporal_cloud_v0_state_transition_count"
   ```
   If you have Workflows running on a Namespace in your Temporal Cloud instance, you should see some data as a result of running this command.

After the page refreshes, the new metrics endpoint appears below **Endpoint**, in the form `https://<account-id>.tmprl.cloud/prometheus`.
Use the endpoint to configure your observability tool.
For example, if you use Grafana, see [Grafana data sources configuration](/cloud/metrics/prometheus-grafana#grafana-data-sources-configuration).

You can also query via the [Prometheus HTTP API](https://prometheus.io/docs/prometheus/latest/querying/api/) at URLs like:

```
https://<account-id>.tmprl.cloud/prometheus/api/v1/query?query=temporal_cloud_v0_state_transition_count
```

For example:

```
$ curl --cert client.pem --key client-key.pem "https://<account-id>.tmprl.cloud/prometheus/api/v1/query?query=temporal_cloud_v0_state_transition_count" | jq .
{
  "status": "success",
  "data": {
    "resultType": "vector",
    "result": [
      {
        "metric": {
          "__name__": "temporal_cloud_v0_state_transition_count",
          "__rollup__": "true",
          "operation": "WorkflowContext",
          "temporal_account": "your-account",
          "temporal_namespace": "your-namespace.your-account-is",
          "temporal_service_type": "history"
        },
        "value": [
          1672347471.2,
          "0"
        ]
      },
      ...
}
```

## Configure endpoint using tcld {#configure-via-cli-tcld}

**How to configure a metrics endpoint using the tcld CLI.**

To add a certificate to a metrics endpoint, use [`tcld account metrics accepted-client-ca add`](/cloud/tcld/account#add).

To enable a metrics endpoint, use [`tcld account metrics enable`](/cloud/tcld/account#enable).

To disable a metrics endpoint, use [`tcld account metrics disable`](/cloud/tcld/account#disable).

For more information, see [tcld account metrics command](/cloud/tcld/account#metrics).

---

## Temporal Cloud Observability and Metrics

Temporal offers two distinct sources of metrics: [Cloud/Server Metrics](/production-deployment/cloud/metrics/reference) and [SDK Metrics](/references/sdk-metrics).
Each source provides options for levels of granularity and filtering, monitoring-tool integrations, and configuration.
Before implementing Temporal Cloud observability, decide what you need to measure for your use case. There are two primary use cases for metrics:

- To measure the health and performance of Temporal-backed applications and key business processes.
- To measure the health and performance of Temporal infrastructure and user provided infrastructure in the form of Temporal Workers and Temporal Clients.

When measuring the performance of Temporal-backed applications and key business processes, you should rely on Temporal SDK metrics as a source of truth.
This is because Temporal SDKs provide visibility from the perspective of your application, not from the perspective of the Temporal Service.

SDK metrics monitor individual workers and your code's behavior.
Cloud metrics monitor Temporal behavior.
When used together, Temporal Cloud and SDK metrics measure the health and performance of your full Temporal infrastructure, including the Temporal Cloud Service and user-supplied Temporal Workers.

Metrics for all Namespaces in your account are available from your metrics endpoint.

Metrics lag real-time performance by about one minute.

Temporal Cloud retains raw metrics for seven days.

To ensure security of your metrics, a CA certificate dedicated to observability is required.
Only clients that use certificates signed by that CA, or that chain up to the CA, can query the metrics endpoint.
For more information about CA certificates in Temporal Cloud, see [Certificate requirements](/cloud/certificates#certificate-requirements).

- [General setup](/production-deployment/cloud/metrics/general-setup)
- [Available metrics](/production-deployment/cloud/metrics/reference)
- [Prometheus & Grafana setup](/cloud/metrics/prometheus-grafana)
- [Datadog setup](/cloud/metrics/datadog)

---

## Prometheus Grafana setup - Temporal Cloud feature guide

**How to set up Grafana with Temporal Cloud observability to view metrics.**

Temporal Cloud and SDKs generate metrics for monitoring performance and troubleshooting errors.

Temporal Cloud emits metrics through a [Prometheus HTTP API endpoint](https://prometheus.io/docs/prometheus/latest/querying/api/), which can be directly used as a Prometheus data source in Grafana or to query and export Cloud metrics to any observability platform.

The open-source SDKs require you to set up a Prometheus scrape endpoint for Prometheus to collect and aggregate the Worker and Client metrics.

This section describes how to set up your Temporal Cloud and SDK metrics and use them as data sources in Grafana.

The process for setting up observability includes the following steps:

1. Create or get your Prometheus endpoint for Temporal Cloud metrics and enable SDK metrics.
   - For Temporal Cloud, [generate a Prometheus HTTP API endpoint](/production-deployment/cloud/metrics/general-setup) on Temporal Cloud using valid certificates.
   - For SDKs, [expose a metrics endpoint](#sdk-metrics-setup) where Prometheus can scrape SDK metrics and [run Prometheus](#prometheus-configuration) on your host. The examples in this article describe running Prometheus on your local machine where you run your application code.
2. Run Grafana and [set up data sources for Temporal Cloud and SDK metrics](#grafana-data-sources-configuration) in Grafana. The examples in this article describe running Grafana on your local host where you run your application code.
3. [Create dashboards](#grafana-dashboards-setup) in Grafana to view Temporal Cloud metrics and SDK metrics. Temporal provides [sample community-driven Grafana dashboards](https://github.com/temporalio/dashboards) for Cloud and SDK metrics that you can use and customize according to your requirements.

If you're following through with the examples provided here, ensure that you have the following:

- Root CA certificates and end-entity certificates. See [Certificate requirements](/cloud/certificates#certificate-requirements) for details.
- Set up your connections to Temporal Cloud using an SDK of your choice and have some Workflows running on Temporal Cloud. See Connect to a Temporal Service for details.

  - [Go](/develop/go/temporal-client#connect-to-temporal-cloud)
  - [Java](/develop/java/temporal-client#connect-to-temporal-cloud)
  - [PHP](/develop/php/temporal-client#connect-to-a-dev-cluster)
  - [Python](/develop/python/temporal-client#connect-to-temporal-cloud)
  - [TypeScript](/develop/typescript/core-application#connect-to-temporal-cloud)
  - [.NET](/develop/dotnet/temporal-client#connect-to-temporal-cloud)

- Prometheus and Grafana installed.

## Temporal Cloud metrics setup

Before you set up your Temporal Cloud metrics, ensure that you have the following:

- Account Owner or Global Admin [role privileges](/cloud/users#account-level-roles) for the Temporal Cloud account.
- [CA certificate and key](/cloud/certificates) for the Observability integration.
  You will need the certificate to set up the Observability endpoint in Temporal Cloud.

The following steps describe how to set up Observability on Temporal Cloud to generate an endpoint:

1. Log in to Temporal Cloud UI with an Account Owner or Global Admin [role](/cloud/users#account-level-roles).
2. Go to **Settings** and select **Integrations**.
3. Select **Configure Observability** (if you're setting it up for the first time) or click **Edit** in the Observability section (if it was already configured before).
4. Add your root CA certificate (.pem) and save it.
   Note that if an observability endpoint is already set up, you can append your root CA certificate here to use the generated observability endpoint with your instance of Grafana.
5. To test your endpoint, run the following command on your host:
   ```
   curl -v --cert <path to your client-cert.pem> --key <path to your client-cert.key> "<your generated Temporal Cloud prometheus_endpoint>/api/v1/query?query=temporal_cloud_v0_state_transition_count"
   ```
   If you have Workflows running on a Namespace in your Temporal Cloud instance, you should see some data as a result of running this command.
6. Copy the HTTP API endpoint that is generated (it is shown in the UI).

This endpoint should be configured as a data source for Temporal Cloud metrics in Grafana.
See [Data sources configuration for Temporal Cloud and SDK metrics in Grafana](#grafana-data-sources-configuration) for details.

## SDK metrics setup

SDK metrics are emitted by SDK Clients used to start your Workers and to start, signal, or query your Workflow Executions.
You must configure a Prometheus scrape endpoint for Prometheus to collect and aggregate your SDK metrics.
Each language development guide has details on how to set this up.

- [Go SDK](/develop/go/observability#metrics)
- [Java SDK](/develop/java/observability#metrics)
- [TypeScript SDK](/develop/typescript/observability#metrics)
- [Python](/develop/python/observability#metrics)
- [.NET](/develop/dotnet/observability#metrics)

The following example uses the Java SDK to set the Prometheus registry and Micrometer stats reporter, set the scope, and expose an endpoint from which Prometheus can scrape the SDK metrics.

```java
//You need the following packages to set up metrics in Java.
//See the Developer's guide for packages required for other SDKs.

//…

//…
   {
     // See the Micrometer documentation for configuration details on other supported monitoring systems.
     // Set up the Prometheus registry.
     PrometheusMeterRegistry yourRegistry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);

       public static Scope yourScope(){
     //Set up a scope, report every 10 seconds
       Scope yourScope = new RootScopeBuilder()
               .tags(ImmutableMap.of(
                       "customtag1",
                       "customvalue1",
                       "customtag2",
                       "customvalue2"))
               .reporter(new MicrometerClientStatsReporter(yourRegistry))
               .reportEvery(Duration.ofSeconds(10));

     //Start Prometheus scrape endpoint at port 8077 on your local host
     HttpServer scrapeEndpoint = startPrometheusScrapeEndpoint(yourRegistry, 8077);
     return yourScope;
   }

   /**
    * Starts HttpServer to expose a scrape endpoint. See
    * https://micrometer.io/docs/registry/prometheus for more info.
    */

   public static HttpServer startPrometheusScrapeEndpoint(
           PrometheusMeterRegistry yourRegistry, int port) {
       try {
           HttpServer server = HttpServer.create(new InetSocketAddress(port), 0);
           server.createContext(
                   "/metrics",
                   httpExchange -> {
                       String response = registry.scrape();
                       httpExchange.sendResponseHeaders(200, response.getBytes(UTF_8).length);
                       try (OutputStream os = httpExchange.getResponseBody()) {
                           os.write(response.getBytes(UTF_8));
                       }
                   });
           server.start();
           return server;
       } catch (IOException e) {
           throw new RuntimeException(e);
       }
   }
}

//…

// With your scrape endpoint configured, set the metrics scope in your Workflow service stub and
// use it to create a Client to start your Workers and Workflow Executions.

//…
{
    //Create Workflow service stubs to connect to the Frontend Service.
    WorkflowServiceStubs service = WorkflowServiceStubs.newServiceStubs(
               WorkflowServiceStubsOptions.newBuilder()
                      .setMetricsScope(yourScope()) //set the metrics scope for the WorkflowServiceStubs
                      .build());

   //Create a Workflow service client, which can be used to start, signal, and query Workflow Executions.
   WorkflowClient yourClient = WorkflowClient.newInstance(service,
          WorkflowClientOptions.newBuilder().build());
}

//…
```

To check whether your scrape endpoints are emitting metrics, run your code and go to [http://localhost:8077/metrics](http://localhost:8077/metrics) to verify that you see the SDK metrics.

You can set up separate scrape endpoints in your Clients that you use to start your Workers and Workflow Executions.

For more examples on setting metrics endpoints in other SDKs, see the metrics samples:

- [Java SDK Samples](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/metrics)
- [Go SDK Samples](https://github.com/temporalio/samples-go/tree/main/metrics)

## SDK metrics Prometheus Configuration {#prometheus-configuration}

**How to configure Prometheus to ingest Temporal SDK metrics.**

For Temporal SDKs, you must have Prometheus running and configured to listen on the scrape endpoints exposed in your application code.

For this example, you can run Prometheus locally or as a Docker container.
In either case, ensure that you set the listen targets to the ports where you expose your scrape endpoints.
When you run Prometheus locally, set your target address to port 8077 in your Prometheus configuration YAML file. (We set the scrape endopint to port 8077 in the [SDK metrics setup](#sdk-metrics-setup) example.)

Example:

```yaml
global:
  scrape_interval: 10s # Set the scrape interval to every 10 seconds. Default is every 1 minute.
#...

# Set your scrape configuration targets to the ports exposed on your endpoints in the SDK.
scrape_configs:
  - job_name: 'temporalsdkmetrics'
    metrics_path: /metrics
    scheme: http
    static_configs:
      - targets:
          # This is the scrape endpoint where Prometheus listens for SDK metrics.
          - localhost:8077
        # You can have multiple targets here, provided they are set up in your application code.
```

See the [Prometheus documentation](https://prometheus.io/docs/introduction/first_steps/) for more details on how you can run Prometheus locally or using Docker.

Note that Temporal Cloud exposes metrics through a [Prometheus HTTP API endpoint](https://prometheus.io/docs/prometheus/latest/querying/api/) (not a scrape endpoint) that can be configured as a data source in Grafana.
The Prometheus configuration described here is for scraping metrics data on endpoints for SDK metrics only.

To check whether Prometheus is receiving metrics from your SDK target, go to [http://localhost:9090](http://localhost:9090) and navigate to **Status&nbsp;> Targets**.
The status of your target endpoint defined in your configuration appears here.

## Grafana data sources configuration {#grafana-data-sources-configuration}

**How to configure data sources for Temporal Cloud and SDK metrics in Grafana.**

Depending on how you use Grafana, you can either install and run it locally, run it as a Docker container, or log in to Grafana Cloud to set up your data sources.

If you have installed and are running Grafana locally, go to [http://localhost:3000](http://localhost:3000) and sign in.

You must configure your Temporal Cloud and SDK metrics data sources separately in Grafana.

To add the Temporal Cloud Prometheus HTTP API endpoint that we generated in the [Temporal Cloud metrics setup](/production-deployment/cloud/metrics/general-setup) section, do the following:

1. Go to **Configuration&nbsp;> Data sources**.
1. Select **Add data source&nbsp;> Prometheus**.
1. Enter a name for your Temporal Cloud metrics data source, such as _Temporal Cloud metrics_.
1. In the **Connection** section, paste the URL that was generated in the Observability section on the Temporal Cloud UI.
1. The **Authentication** section may be left as **No Authentication**.
1. In the **TLS Settings** section, select **TLS Client Authentication**:
   - Leave **ServerName** blank. This is not required.
   - Paste in your end-entity certificate and key.
   - Note that the end-entity certificate used here must be part of the certificate chain with the root CA certificates used in your [Temporal Cloud observability setup](/production-deployment/cloud/metrics/general-setup).
     <ZoomingImage src="/img/cloud/prometheus/add-prometheus-api-endpoint.png" alt="Data source configuration in Grafana" />
1. Click **Save and test** to verify that the data source is working.

If you see issues in setting this data source, verify your CA certificate chain and ensure that you are setting the correct certificates in your Temporal Cloud observability setup and in the TLS authentication in Grafana.

To add the SDK metrics Prometheus endpoint that we configured in the [SDK metrics setup](#sdk-metrics-setup) and [Prometheus configuration for SDK metrics](#prometheus-configuration) sections, do the following:

1. Go to **Configuration&nbsp;> Data sources**.
2. Select **Add data source&nbsp;> Prometheus**.
3. Enter a name for your Temporal Cloud metrics data source, such as _Temporal SDK metrics_.
4. In the **HTTP** section, enter your Prometheus endpoint in the URL field.
   If running Prometheus locally as described in the examples in this article, enter `http://localhost:9090`.
5. For this example, enable **Skip TLS Verify** in the **Auth** section.
6. Click **Save and test** to verify that the data source is working.

If you see issues in setting this data source, check whether the endpoints set in your SDKs are showing metrics.
If you don't see your SDK metrics at the scrape endpoints defined, check whether your Workers and Workflow Executions are running.
If you see metrics on the scrape endpoints, but Prometheus shows your targets are down, then there is an issue with connecting to the targets set in your SDKs.
Verify your Prometheus configuration and restart Prometheus.

If you're running Grafana as a container, you can set your SDK metrics Prometheus data source in your Grafana configuration.
See the example Grafana configuration described in the [Prometheus and Grafana setup for open-source Temporal Service](/self-hosted-guide/monitoring#grafana) article.

### Grafana dashboards setup

To set up dashboards in Grafana, you can use the UI or configure them directly in your Grafana deployment.

:::tip

Temporal provides community-driven example dashboards for [Temporal Cloud](https://github.com/temporalio/dashboards/tree/master/cloud) and [Temporal SDKs](https://github.com/temporalio/dashboards/tree/master/sdk) that you can customize to meet your needs.

:::

To import a dashboard in Grafana:

1. In the left-hand navigation bar, select **Dashboards** > **Import dashboard**.
2. You can either copy and paste the JSON from the [Temporal Cloud](https://github.com/temporalio/dashboards/tree/master/cloud) and [Temporal SDK](https://github.com/temporalio/dashboards/tree/master/sdk) sample dashboards, or import the JSON files into Grafana.
3. Save the dashboard and review the metrics data in the graphs.

To configure dashboards with the UI:

1. Go to **Create > Dashboard** and add an empty panel.
2. On the **Panel configuration** page, in the **Query** tab, select the "Temporal Cloud metrics" or "Temporal SDK metrics" data source that you configured earlier.
   If you need to add multiple queries from both data sources, choose `–Mixed–`.
3. Add your metrics queries:
   - For Temporal Cloud metrics, expand the **Metrics browser** and select the metrics you want.
     You can also select associated labels and values to sort the query data.
     The [Cloud metrics documentation](/production-deployment/cloud/metrics/reference) lists all metrics emitted from Temporal Cloud.
   - For Temporal SDK metrics, expand the **Metrics browser** and select the metrics you want.
     A list of Worker performance metrics is described in the [Developer's Guide - Worker performance](/develop/worker-performance).
     All SDK-related metrics are listed in the [SDK metrics](/references/sdk-metrics) reference.
4. The graph should now display data based on your selected queries.
   Note that SDK metrics will only show if you have Workflow Execution data and running Workers.
   If you don't see SDK metrics, run your Worker and Workflow Executions, then monitor the dashboard.

---

## Temporal Cloud metrics reference

A metric is a measurement or data point that provides insights into the performance and health of a system.
This document describes the metrics available on the Temporal Cloud platform.
Temporal Cloud metrics help you monitor performance and troubleshoot errors.
They provide insights into different aspects of the Service.

This guide covers these topics:

- **[Gather metrics](#gather)**:
  Capture Temporal Cloud metrics using a Prometheus-style endpoint so they can be visualized using Prometheus and Grafana or exported to observability platforms like Datadog.
- **[Available Temporal Cloud metrics](#available-metrics)**:
  The metrics emitted by Temporal Cloud include counts of gRPC errors, requests, successful task matches to a poller, and more.
- **[Metrics labels](#metrics-labels)**:
  Temporal Cloud metrics labels can filter metrics and help categorize and differentiate results.
- **[Operations](#metrics-operations)**:
  An operation is a special type of label that categorizes the type of operation being performed when the metric was collected.

:::info SDK METRICS

This document discusses metrics emitted by [Temporal Cloud](/cloud).
Temporal SDKs also emit metrics, sourced from Temporal Clients and Worker processes.
You can find information about Temporal SDK metrics on its [dedicated page](/references/sdk-metrics).

Please note:

- SDK metrics start with the phrase `temporal_`.
- Temporal Cloud metrics start with `temporal_cloud_`.

:::

## Gather metrics {#gather}

**How do you capture and use Temporal Cloud metrics?**

Temporal Cloud emits metrics in a Prometheus-supported format.
Prometheus is an open-source toolkit for alerting and monitoring.
The Temporal Service exposes Cloud metrics with a [Prometheus HTTP API endpoint](https://prometheus.io/docs/prometheus/latest/querying/api/).
Temporal Cloud metrics provide a compatible data source for visualizing, monitoring, and observability platforms like Grafana and Data Dog.

You can use functions like `rate` or `increase` to calculate the rate of increase for a Temporal Cloud metric:

```
rate(temporal_cloud_v0_frontend_service_request_count[$__rate_interval])
```

Or you might use Prometheus to calculate average latencies or histogram quartiles:

```
# Average latency
rate(temporal_cloud_v0_service_latency_sum[$__rate_interval])
/ rate(temporal_cloud_v0_service_latency_count[$__rate_interval])

# Approximate 99th percentile latency broken down by operation
histogram_quantile(0.99, sum(rate(temporal_cloud_v0_service_latency_bucket[$__rate_interval])) by (le, operation))
```

Metrics are scraped every 30 seconds and exposed to the metrics endpoint with a 1-minute lag.\
The endpoint returns data with a 15-second resolution, which results in displaying the same value twice.

Set up Grafana with Temporal Cloud observability to view metrics by creating or getting your Prometheus endpoint for Temporal Cloud metrics and enabling SDK metrics.

<RelatedReadContainer>
  <RelatedReadItem path="/cloud/metrics/prometheus-grafana" text="How to set up Grafana with Temporal Cloud observability" archetype="feature-guide" />
  <RelatedReadItem path="/production-deployment/cloud/worker-health" text="How to monitor Worker Health with Temporal Cloud Metrics" archetype="feature-guide" />
  <RelatedReadItem path="/production-deployment/cloud/service-health" text="How to monitor Service Health with Temporal Cloud Metrics" archetype="feature-guide" />
</RelatedReadContainer>

## Available Temporal Cloud metrics {#available-metrics}

**What metrics are emitted from Temporal Cloud?**

The following metrics are emitted for your Namespaces:

### Frontend Service metrics {#frontend}

#### temporal_cloud_v0_frontend_service_error_count

This is a count of gRPC errors returned aggregated by operation.

#### temporal_cloud_v0_frontend_service_request_count

This is a count of gRPC requests received aggregated by operation.

#### temporal_cloud_v0_resource_exhausted_error_count

gRPC requests received that were rate-limited by Temporal Cloud, aggregated by cause.

#### temporal_cloud_v0_state_transition_count

Count of state transitions for each Namespace.

#### temporal_cloud_v0_total_action_count

Approximate count of Temporal Cloud Actions.

### Poll metrics {#poll}

#### temporal_cloud_v0_poll_success_count

Tasks that are successfully matched to a poller.

#### temporal_cloud_v0_poll_success_sync_count

Tasks that are successfully sync matched to a poller.

#### temporal_cloud_v0_poll_timeout_count

When no tasks are available for a poller before timing out.

### Replication lag metrics {#replication-lag}

#### temporal_cloud_v0_replication_lag_bucket

A histogram of [replication lag](/cloud/high-availability/monitor) during a specific time interval for a Namespace with high availability.

#### temporal_cloud_v0_replication_lag_count

The [replication lag](/cloud/high-availability/monitor) count during a specific time interval for a Namespace with high availability.

#### temporal_cloud_v0_replication_lag_sum

The sum of [replication lag](/cloud/high-availability/monitor) during a specific time interval for a Namespace with high availability.

### Schedule metrics {#schedule}

#### temporal_cloud_v0_schedule_action_success_count

Successful execution of a Scheduled Workflow.

#### temporal_cloud_v0_schedule_buffer_overruns_count

When average schedule run length is greater than average schedule interval while a `buffer_all` overlap policy is configured.

#### temporal_cloud_v0_schedule_missed_catchup_window_count

Skipped Scheduled executions when Workflows were delayed longer than the catchup window.

#### temporal_cloud_v0_schedule_rate_limited_count

Workflows that were delayed due to exceeding a rate limit.

### Service latency metrics {#service-latency}

#### temporal_cloud_v0_service_latency_bucket

Latency for `SignalWithStartWorkflowExecution`, `SignalWorkflowExecution`, `StartWorkflowExecution` operations.

#### temporal_cloud_v0_service_latency_count

Count of latency observations for `SignalWithStartWorkflowExecution`, `SignalWorkflowExecution`, `StartWorkflowExecution` operations.

#### temporal_cloud_v0_service_latency_sum

Sum of latency observation time for `SignalWithStartWorkflowExecution`, `SignalWorkflowExecution`, `StartWorkflowExecution` operations.

### Workflow metrics {#workflow}

#### temporal_cloud_v0_workflow_cancel_count

Workflows canceled before completing execution.

#### temporal_cloud_v0_workflow_continued_as_new_count

Workflow Executions that were Continued-As-New from a past execution.

#### temporal_cloud_v0_workflow_failed_count

Workflows that failed before completion.

#### temporal_cloud_v0_workflow_success_count

Workflows that successfully completed.

#### temporal_cloud_v0_workflow_terminate_count

Workflows terminated before completing execution.

#### temporal_cloud_v0_workflow_timeout_count

Workflows that timed out before completing execution.

## Metrics labels {#metrics-labels}

**What labels can you use to filter metrics?**

Temporal Cloud metrics include key-value pairs called labels in their associated metadata.
Labels help you categorize and differentiate metrics for precise filtering, querying, and aggregation.
Use labels to specific attributes or compare values, such as numeric buckets in histograms.
This added context enhances the monitoring and analysis capabilities, providing deeper insights into your data.

Metrics for all Namespaces in your account are available from the [metrics endpoint](#gather).
Use the following labels to filter metrics:

| Label                      | Explanation                                                                                                                                                                                                                                                                                |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `le`                       | Less than or equal to (`le`) is used in histograms to categorize observations into buckets based on their value being less than or equal to a predefined upper limit.                                                                                                                      |
| `operation`                | This includes gRPC operations and general Cloud operations such as:SignalWorkflowExecutionStartBatchOperationStartWorkflowExecutionTaskQueueMgrTerminateWorkflowExecutionUpdateNamespaceUpdateSchedule See: [Metric Operations](#metrics-operations) and [Temporal Cloud Operation reference](/references/operation-list)|
| `resource_exhausted_cause` | Cause for resource exhaustion.                                                                                                                                                                                                                                                             |
| `task_type`                | Activity, Workflow, or Nexus.                                                                                                                                                                                                                                                              |
| `temporal_account`         | Temporal Account.                                                                                                                                                                                                                                                                          |
| `temporal_namespace`       | Temporal Namespace.                                                                                                                                                                                                                                                                        |
| `temporal_service_type`    | Frontend or Matching or History or Worker.                                                                                                                                                                                                                                                 |
| `is_background`            | This label on `temporal_cloud_v0_total_action_count` indicates when actions are produced by a Temporal background job, for example: hourly Workflow Export.                                                                                                                                |
| `namespace_mode`           | This label on `temporal_cloud_v0_total_action_count` indicates if actions are produced by an active vs a standby Namespace. For a regular Namespace, `namespace_mode` will always be “active”.                                                                                             |

The following is an example of how you can filter metrics using labels:

```text
temporal_cloud_v0_poll_success_count{__rollup__="true", operation="TaskQueueMgr", task_type="Activity", temporal_account="12345", temporal_namespace="your_namespace.12345", temporal_service_type="matching"}
```

## Operations {#metrics-operations}

**What operation labels are captured by Temporal Cloud?**

Operations are a special class of metrics label.
They describe the context during which a metric was captured.
Temporal Cloud includes the following operations labels:

- AdminDescribeMutableState
- AdminGetWorkflowExecutionRawHistory
- AdminGetWorkflowExecutionRawHistoryV2
- AdminReapplyEvents
- CountWorkflowExecutions
- CreateSchedule
- DeleteSchedule
- DeleteWorkflowExecution
- DescribeBatchOperation
- DescribeNamespace
- DescribeSchedule
- DescribeTaskQueue
- DescribeWorkflowExecution
- GetWorkerBuildIdCompatibility
- GetWorkerTaskReachability
- GetWorkflowExecutionHistory
- GetWorkflowExecutionHistoryReverse
- ListBatchOperations
- ListClosedWorkflowExecutions
- OperatorDeleteNamespace
- PatchSchedule
- PollActivityTaskQueue
- PollNexusTaskQueue
- PollWorkflowExecutionHistory
- PollWorkflowExecutionUpdate
- PollWorkflowTaskQueue
- QueryWorkflow
- RecordActivityTaskHeartbeat
- RecordActivityTaskHeartbeatById
- RegisterNamespace
- RequestCancelWorkflowExecution
- ResetStickyTaskQueue
- ResetWorkflowExecution
- RespondActivityTaskCanceled
- RespondActivityTaskCompleted
- RespondActivityTaskCompletedById
- RespondActivityTaskFailed
- RespondActivityTaskFailedById
- RespondNexusTaskCompleted
- RespondNexusTaskFailed
- RespondQueryTaskCompleted
- RespondWorkflowTaskCompleted
- RespondWorkflowTaskFailed
- SignalWithStartWorkflowExecution
- SignalWorkflowExecution
- StartBatchOperation
- StartWorkflowExecution
- StopBatchOperation
- TerminateWorkflowExecution
- UpdateNamespace
- UpdateSchedule
- UpdateWorkerBuildIdCompatibility
- UpdateWorkflowExecution

As the following table shows, certain [metrics groups](#available-metrics) support [operations](#metrics-operations) for aggregation and filtering:

| Metrics Group / Operations                      | All Operations | SignalWithStartWorkflowExecution / SignalWorkflowExecution / StartWorkflowExecution | TaskQueueMgr | CompletionStats |
| ----------------------------------------------- | -------------- | ----------------------------------------------------------------------------------- | ------------ | --------------- |
| **[Frontend Service Metrics](#frontend)**       | X              |                                                                                     |              |                 |
| **[Service Latency Metrics](#service-latency)** |                | X                                                                                   |              |                 |
| **[Poll Metrics](#poll)**                       |                |                                                                                     | X            |                 |
| **[Workflow Metrics](#workflow)**               |                |                                                                                     |              | X               |

---

## Nexus - Temporal Cloud feature guide

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability).
Learn why you should use Nexus in the [evaluation guide](/evaluate/nexus).

:::

[Temporal Nexus](/nexus) allows you to connect Temporal Applications across (and within) isolated Namespaces.
This provides all the benefits of Durable Execution across team and application boundaries with improved modularity, security, debugging, and fault isolation.
Nexus supports cross-team, cross-domain, cross-namespace, multi-region, and multi-cloud use cases.

<CaptionedImage
    src="/img/cloud/nexus/nexus-overview-short.png"
    title="Nexus Overview"
/>

Temporal Cloud support is built on top of the [core Nexus experience](/nexus) and adds a global Nexus Registry within an Account, enhanced security, and multi-region connectivity within and across AWS and GCP.

:::tip RELATED

- [Evaluate](/evaluate/nexus) why you should use Nexus and learn more about [Nexus use cases](/evaluate/nexus#use-cases).
- [Learn Nexus concepts](/nexus) in the Encyclopedia.

:::

## Global Nexus Registry

The Nexus Registry in Temporal Cloud is scoped to an Account.
Workers in any Namespace can host Nexus Services for others to use within an Account.

## Built-in access controls

Temporal Cloud has built-in Endpoint access controls to restrict which callers can use a Nexus Endpoint.

## Audit logging

Temporal Cloud supports audit log streaming for Nexus Registry actions to create, update, or delete Endpoints.

## Multi-region connectivity

Nexus requests in Temporal Cloud are routed across Namespaces, within and across AWS and GCP, using a global mTLS-secured Envoy mesh.
Built-in Nexus Machinery provides reliable at-least-once execution and Workflow policy can deduplicate requests for exactly-once execution, even across multi-region boundaries.

## Terraform support

The [Terraform provider for Temporal Cloud](/production-deployment/cloud/terraform-provider#manage-temporal-cloud-nexus-endpoints-with-terraform) supports managing Nexus Endpoints.

## Learn more

- [Evaluate](/evaluate/nexus) why you should use Nexus and watch the [Nexus keynote and demo](https://youtu.be/qqc2vsv1mrU?feature=shared&t=2082).
- [Learn key Nexus concepts](/nexus) and how Nexus works in the [Nexus deep dive talk](https://www.youtube.com/watch?v=izR9dQ_eIe4&t=934s)
- Explore [additional resources](/evaluate/nexus#learn-more) to learn more about Nexus.

---

## Latency and Availability - Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability).
Learn why you should use Nexus in the [evaluation guide](/evaluate/nexus).

:::

Nexus requests (commands, polling) have the same latency SLOs and error rate SLAs as other Worker requests in both the caller and handler Namespaces.

## Latency metrics

Nexus supports various [latency metrics](/nexus/metrics).

## Worker to Temporal Cloud interactions

Nexus interactions between a Worker and Temporal Cloud use the Worker's Namespace gRPC endpoint.
Nexus-related Worker interactions with Temporal Cloud have the same [latency SLOs](/cloud/service-availability#latency) and [availability SLAs](/cloud/sla) as other calls to a Namespaces's gRPC endpoint.

<CaptionedImage
    src="/img/cloud/nexus/nexus-workers-short.png"
    title="Interaction between Workers and Temporal Cloud"
/>

This applies to the following Nexus-related interactions between a Worker and Temporal Cloud:

- Caller Namespace
  - RespondWorkflowTaskCompleted \- schedule a Nexus Operation.
- Handler Namespace
  - PollNexusTaskQueue \- get a [Nexus Task](/tasks#nexus-task) to process, for example to start a Nexus Operation.
  - RespondNexusTaskCompleted \- report the Nexus Task was successful.
  - RespondNexusTaskFailed \- report the Nexus Task failed.

## Nexus connectivity across Namespaces

Nexus connectivity in Temporal Cloud is provided by a global mTLS secured Envoy mesh.
The cross-namespace latency between the caller's Nexus Machinery and the handler's Nexus Machinery varies based on the locality of the caller and handler Namespaces, which may be placed in different regions.

Communication between Namespaces in the same region will have lower latency.
Communication across different regions will have higher latency.
Consult the cross-region latency tables for your cloud provider(s) to estimate the latency for Nexus communication across Namespaces in Temporal Cloud.

---

## Limits - Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability).
Learn why you should use Nexus in the [evaluation guide](/evaluate/nexus).

:::

Temporal Cloud has default limits for several aspects of Nexus.
Many of these defaults are configurable, so if you need them changed please open a support ticket.

## Rate Limiting

Nexus requests (commands, polling) are counted as part of the overall Namespace RPS limit in both the caller and handler Namespaces.
Default Namespace RPS limits are set at 1600 and automatically adjust based on recent usage (over prior 7 days).

## Operational Limits

Nexus has operational limits for thing like the maximum number of Nexus Endpoints and the maximum request handler timeout.

### Max Nexus Endpoints

By default, each account is provisioned with a max of 10 Nexus Endpoints.
You can request further increases beyond the initial 10 Endpoint limit by opening a support ticket.

### Workflow Max Nexus Operations

A single Workflow Execution can have a maximum of 30 in-flight Nexus Operations.

See the Nexus Encyclopedia entry for [additional details](/workflow-execution/limits#workflow-execution-nexus-operation-limits).

### Nexus Request Handler Timeout

Nexus Operation handlers have less than 10 seconds to process a single Nexus start or cancel request.
Handlers should observe the context deadline and ensure they do not exceed it.
This includes fully processing a synchronous Nexus operation and starting an asynchronous Nexus operation, for example one that starts a Workflow.
If a handler doesn’t respond within a context deadline, a context deadline exceeded error will be tracked in the caller Workflow’s pending Nexus operations, and the Nexus Machinery will retry the Nexus request with an exponential backoff policy.

### Nexus Operation Maximum Duration

Each Nexus Operation has a maximum ScheduleToClose duration of 60 days, which is most applicable to asynchronous Nexus Operations that are completed with an asynchronous callback using a separate Nexus request from the handler back to the caller Namespace.
The 60 day maximum is a limit we will look to increase at some point in the future.
While the caller of a Nexus Operation can configure the ScheduleToClose duration to be shorter than 60 days, the maximum duration can not be extended beyond 60 days and will be capped by the server to 60 days.

---

## Obserability - Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability).
Learn why you should use Nexus in the [evaluation guide](/evaluate/nexus).

:::

Nexus provides metrics and audit log streaming, in addition to integrated [execution debugging](/nexus/execution-debugging).

## Metrics

Nexus provides the following metrics:

- [SDK metrics](/nexus/metrics#sdk-metrics) \- emitted by a Worker.
- [Cloud metrics](/nexus/metrics#cloud-metrics) \- emitted by Temporal Cloud.

## Audit Logging

The following Nexus control plane actions are sent to the [Audit Logging](/cloud/audit-logging) integrations:

- Create Nexus Endpoint: `CreateNexusEndpoint`
- Update Nexus Endpoint: `UpdateNexusEndpoint`
- Delete Nexus Endpoint: `DeleteNexusEndpoint`

---

## Pricing for Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability).
Learn why you should use Nexus in the [evaluation guide](/evaluate/nexus).

:::

The pricing for [Temporal Nexus](/evaluate/nexus) is:

- **One Action to start or cancel a Nexus Operation** in the caller Namespace.
  The underlying Temporal primitives such as Workflows, Activities, Signals created by a Nexus Operation handler (directly or indirectly) result in the normal Actions for those primitives.
  This includes retries for underlying Temporal primitives like Activities.
- **No Action results for handling or retrying the Nexus Operation itself**.
  However, while the retry of the Nexus Operation incurs no charge, any billable action initiated by the handler (such as an Activity) will be charged if it fails and is subsequently retried.

See [Pricing](/cloud/pricing) for additional details.

## Learn more

- [Evaluate](/evaluate/nexus) why you should use Nexus and watch the [Nexus keynote and demo](https://youtu.be/qqc2vsv1mrU?feature=shared&t=2082).
- Learn how Nexus works in the [Nexus deep dive talk](https://www.youtube.com/watch?v=izR9dQ_eIe4) and [Encyclopedia](/nexus).
- [Additional resources](/evaluate/nexus#learn-more) to learn more about Nexus.

---

## Security - Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability).
Learn why you should use Nexus in the [evaluation guide](/evaluate/nexus).

:::

Temporal Cloud has built-in Nexus security.
It provides secure Nexus connectivity across Namespaces with an mTLS secured Envoy mesh.
Workers authenticate to their Namespace with mTLS client certificates or API keys, as allowed by their Namespace.
Encryption for Nexus payloads is also supported, for example using shared symmetric keys and compatible Data Converters.

## Registry roles and permissions

Nexus Endpoints are Account-scoped resources, similar to a Namespace.
The following roles and permissions are required to manage and view Nexus Endpoints in the Nexus Registry:

- Viewing and browsing the full list of Nexus Endpoints in an Account:
  - Read-only role (or higher)
- Managing a Nexus Endpoint (create, update, delete):
  - Developer role (or higher) and Namespace Admin permission on the Endpoint’s target Namespace

## Runtime access controls

The Nexus Registry allows setting Endpoint access policy on each Endpoint.
This currently includes an allow list of caller Namespaces that can use the Endpoint at runtime.
Endpoint access control policies are enforced at runtime:

1. Caller's Worker authenticates with their Namespace as they do today with mTLS certificates or API keys.
   This establishes the caller's identity and caller Namespace.
2. Caller Workflow executes a Nexus Operation on a Nexus Endpoint.
3. Endpoint access control policy is enforced, checking if the caller Namespace is in the Endpoint allow list.

See [Runtime Access Controls](/nexus/security#runtime-access-controls) and [Configuring Runtime Access Controls](/nexus/registry#configure-runtime-access-controls) for additional details.

## Secure connectivity

Nexus Endpoints are only privately accessible from within a Temporal Cloud and mTLS is used for all Nexus communication, including across cloud cells and regions.
Workers authenticate to their Namespaces through mTLS or an API key as allowed by their Namespace configuration.

<CaptionedImage
    src="/img/cloud/nexus/nexus-workers-short.png"
    title="Nexus Security"
/>

See [Nexus Secure Connectivity](/nexus/security#secure-connectivity) for additional details.

## Payload encryption

For payload encryption, the DataConverter works the same for a Nexus Operation as it does for other payloads sent between a Worker and Temporal Cloud.

See [Nexus Payload Encryption & Data Converter](/nexus/security#payload-encryption-data-converter) for additional details.

---

## Operations API - Temporal Cloud feature guide

:::tip Support, stability, and dependency info

Temporal Cloud Operations API is in [Public Preview](/evaluate/development-production-features/release-stages#public-preview) for Temporal Cloud.

:::

The [Temporal Cloud Operations API](https://github.com/temporalio/api-cloud/tree/main) (Cloud Ops API) is a library for managing the automation of Users, Namespaces, and Temporal Cloud Accounts.

Cloud Ops API is an open source, public gRPC API. You can use the provided proto files to generate client libraries in your desired programming language. In addition to being available on GitHub, the proto files are also hosted on [Buf](https://buf.build/temporalio/cloud-api/docs/main:temporal.api.cloud.account.v1), which provides a clean web interface for browsing and visualizing the APIs, and offers more streamlined dependency management.

## Get started

Begin by ensuring your registration as a Temporal Cloud user.
If you're not yet a user, [sign up here](https://temporal.io/get-cloud).

Explore API functionalities through [Go language samples](https://github.com/temporalio/cloud-samples-go) showcasing Cloud Ops API usage.

**Prerequisites:**

This process assumes you have basic familiarity with gRPC and Protocol Buffers (protobuf).

- [Temporal Cloud user account](/cloud/get-started)
- [API Key](/cloud/tcld/apikey#create) for authentication
- [Protocol Buffers](https://github.com/protocolbuffers/protobuf/releases)
- [gRPC](https://grpc.io/docs/languages/) in your preferred programming language

### Compile the API

Download the gRPC protobufs from the [Cloud Ops API repository](https://github.com/temporalio/api-cloud/tree/main/temporal/api/cloud).

Use [gRPC](https://grpc.io/docs/) to compile and generate code in your preferred [programming language](https://grpc.io/docs/#official-support).

1. **Clone the Temporal Cloud API repository:**

   ```command
   git clone https://github.com/temporalio/api-cloud.git
   cd api-cloud
   ```

2. **Copy Protobuf files:**

   - Navigate to the `temporal` directory.
   - Copy the protobuf files to your project directory.

3. **Compile the Protobuf files:**
   :::note
   Python requires [gRPC tools](https://grpc.io/docs/languages/python/quickstart/#grpc-tools) to be installed.
   :::
   1. The following is an example of how to use the generated code for Python; however, this approach can be adapted for other supported programming languages:
   ```python
   python -m grpc_tools.protoc -I./ --python_out=./ --grpc_python_out=./ *.proto
   ```
   - `-I` specifies the directory of the `.proto` files.
   - `--python_out=` sets the output directory for generated Python classes.
   - `--grpc_python_out=` sets the output directory for generated gRPC service classes.
   - `*.proto` processes all `.proto` files.

## Use the generated code

After compiling the Protobuf files, you will have generated code files in your project directory.
These files enable interaction with the Temporal Cloud API in your chosen programming language.

The following is an example of how to use the generated code for Python; however, this approach can be adapted for other programming languages:

1. **Import the Generated Files:**

   - Locate the Python files (.py) generated in your project directory.
   - Import these files into your Python application where you intend to interact with the Temporal Cloud API.

2. **Utilize the API:**
   - Use the classes and methods defined in the imported files to communicate with the Temporal Cloud services.
   - Ensure to handle any required authentication or configuration as needed for Temporal Cloud.

This approach can be adapted for other programming languages by following their respective import and usage conventions for the generated code files.

### Use the API

When interacting with the Temporal Cloud Ops API, follow these guidelines:

1. **API Version Header:**

   - Always include the `temporal-cloud-api-version` header in your requests, specifying the API version identifier.
   - The current API version can be found [here](https://github.com/temporalio/api-cloud/blob/main/VERSION#L1C1-L1C14).

2. **Connection URL:**

   - Connect to the Temporal Cloud using the gRPC URL: `saas-api.tmprl.cloud:443`.

3. **Engagement Steps:**
   - **Generate API Key:**
     - Obtain an [API Key for authentication](/cloud/api-keys#manage-api-keys). Note that many operations may require Admin privileges.
   - **Set Up Client:**
     - Establish a secure connection to the Temporal Cloud. Refer to the example [Client setup in Go](https://github.com/temporalio/cloud-samples-go/blob/main/client/temporal/client.go) for guidance.
   - **Execute Operations:**
     - For operation specifics, refer to the `cloudservice/v1/request_response.proto` for gRPC messages and `cloudservice/v1/service.proto` for gRPC services.

These steps provide a structured approach to utilizing the Temporal Cloud Ops API effectively, ensuring proper authentication and connection setup.

## Rate limits

The Temporal Cloud Operations API implements rate limiting to ensure system stability and fair usage across all users. Rate limits are applied based on identity type, with different limits for users and service accounts.

### Account-level rate limit

**Total rate limit: 40 requests per second (RPS)**

This limit applies to all requests made to the Temporal Cloud control plane by any client (tcld, UI, Cloud Ops API) or identity type (user, service account) within your account. The total account throughput cannot exceed 160 RPS regardless of the number of users or service accounts making requests.

### Per-identity rate limits

**User rate limit: 10 RPS per user**

This limit applies to all requests made by each user through any client (tcld, UI, Cloud Ops API), regardless of the authentication method used (SSO or API keys).

**Service account rate limit: 20 RPS per service account**

This limit applies to all requests made by each service account through any client (tcld, Cloud Ops API).

### Important considerations

- Rate limits are enforced across all Temporal Cloud control plane operations
- Multiple clients used by the same identity (user or service account) share the same rate limit
- Authentication method (SSO, API keys) does not affect rate limiting
- These limits help ensure system stability and prevent any single account or identity from overwhelming the service

### Requesting limit increases

If your use case requires higher rate limits, you can request an increase by [submitting a support ticket](/cloud/support#support-ticket). When requesting a limit increase, please provide:

- Your current usage patterns and requirements
- The specific limits you need increased
- A description of your use case and why higher limits are necessary

### Provide feedback

Your input is valuable.
While the Temporal Cloud Ops API is in a Public Preview release status, we welcome your feedback.

You can provide feedback through the following channels:

- Submit request or feedback through a ZenDesk [ticket](/cloud/support#support-ticket)
- Open an issue in the [GitHub Repo](https://github.com/temporalio/api-cloud)

---

## Awsregions

### Asia Pacific - Tokyo (`ap-northeast-1`)

- **Cloud API Code**: `aws-ap-northeast-1`
- **Regional Endpoint**: `aws-ap-northeast-1.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.ap-northeast-1.vpce-svc-08f34c33f9fb8a48a`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-ap-northeast-2`
  - `aws-ap-south-1`
  - `aws-ap-south-2`
  - `aws-ap-southeast-1`
  - `aws-ap-southeast-2`
- **Multi-Cloud Replication**:
  - `gcp-asia-south1`

### Asia Pacific - Seoul (`ap-northeast-2`)

- **Cloud API Code**: `aws-ap-northeast-2`
- **Regional Endpoint**: `aws-ap-northeast-2.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.ap-northeast-2.vpce-svc-08c4d5445a5aad308`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-ap-northeast-1`
  - `aws-ap-south-1`
  - `aws-ap-south-2`
  - `aws-ap-southeast-1`
  - `aws-ap-southeast-2`
- **Multi-Cloud Replication**:
  - `gcp-asia-south1`

### Asia Pacific - Mumbai (`ap-south-1`)

- **Cloud API Code**: `aws-ap-south-1`
- **Regional Endpoint**: `aws-ap-south-1.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.ap-south-1.vpce-svc-0ad4f8ed56db15662`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-ap-northeast-1`
  - `aws-ap-northeast-2`
  - `aws-ap-south-2`
  - `aws-ap-southeast-1`
  - `aws-ap-southeast-2`
- **Multi-Cloud Replication**:
  - `gcp-asia-south1`

### Asia Pacific - Hyderabad (`ap-south-2`)

- **Cloud API Code**: `aws-ap-south-2`
- **Regional Endpoint**: `aws-ap-south-2.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.ap-south-2.vpce-svc-08bcf602b646c69c1`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-ap-northeast-1`
  - `aws-ap-northeast-2`
  - `aws-ap-south-1`
  - `aws-ap-southeast-1`
  - `aws-ap-southeast-2`
- **Multi-Cloud Replication**:
  - `gcp-asia-south1`

### Asia Pacific - Singapore (`ap-southeast-1`)

- **Cloud API Code**: `aws-ap-southeast-1`
- **Regional Endpoint**: `aws-ap-southeast-1.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.ap-southeast-1.vpce-svc-05c24096fa89b0ccd`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-ap-northeast-1`
  - `aws-ap-northeast-2`
  - `aws-ap-south-1`
  - `aws-ap-south-2`
  - `aws-ap-southeast-2`
- **Multi-Cloud Replication**:
  - `gcp-asia-south1`

### Asia Pacific - Sydney (`ap-southeast-2`)

- **Cloud API Code**: `aws-ap-southeast-2`
- **Regional Endpoint**: `aws-ap-southeast-2.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.ap-southeast-2.vpce-svc-0634f9628e3c15b08`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-ap-northeast-1`
  - `aws-ap-northeast-2`
  - `aws-ap-south-1`
  - `aws-ap-south-2`
  - `aws-ap-southeast-1`
- **Multi-Cloud Replication**:
  - `gcp-asia-south1`

### Europe - Frankfurt (`eu-central-1`)

- **Cloud API Code**: `aws-eu-central-1`
- **Regional Endpoint**: `aws-eu-central-1.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.eu-central-1.vpce-svc-073a419b36663a0f3`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-eu-west-1`
  - `aws-eu-west-2`
- **Multi-Cloud Replication**:
  - `gcp-europe-west3`

### Europe - Ireland (`eu-west-1`)

- **Cloud API Code**: `aws-eu-west-1`
- **Regional Endpoint**: `aws-eu-west-1.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.eu-west-1.vpce-svc-04388e89f3479b739`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-eu-central-1`
  - `aws-eu-west-2`
- **Multi-Cloud Replication**:
  - `gcp-europe-west3`

### Europe - London (`eu-west-2`)

- **Cloud API Code**: `aws-eu-west-2`
- **Regional Endpoint**: `aws-eu-west-2.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.eu-west-2.vpce-svc-0ac7f9f07e7fb5695`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-eu-central-1`
  - `aws-eu-west-1`
- **Multi-Cloud Replication**:
  - `gcp-europe-west3`

### North America - Central Canada (`ca-central-1`)

- **Cloud API Code**: `aws-ca-central-1`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.ca-central-1.vpce-svc-080a781925d0b1d9d`
- **Regional Endpoint**: `aws-ca-central-1.region.tmprl.cloud`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-us-east-1`
  - `aws-us-east-2`
  - `aws-us-west-2`
- **Multi-Cloud Replication**:
  - `gcp-us-central1`
  - `gcp-us-west1`
  - `gcp-us-east4`

### North America - Northern Virginia (`us-east-1`)

- **Cloud API Code**: `aws-us-east-1`
- **Regional Endpoint**: `aws-us-east-1.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.us-east-1.vpce-svc-0822256b6575ea37f`
- **Same Region Replication**:  Available
- **Multi-Region Replication**:
  - `aws-ca-central-1`
  - `aws-us-east-2`
  - `aws-us-west-2`
- **Multi-Cloud Replication**:
  - `gcp-us-central1`
  - `gcp-us-west1`
  - `gcp-us-east4`

### North America - Ohio (`us-east-2`)

- **Cloud API Code**: `aws-us-east-2`
- **Regional Endpoint**: `aws-us-east-2.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.us-east-2.vpce-svc-01b8dccfc6660d9d4`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `aws-ca-central-1`
  - `aws-us-east-1`
  - `aws-us-west-2`
- **Multi-Cloud Replication**:
  - `gcp-us-central1`
  - `gcp-us-west1`
  - `gcp-us-east4`

### North America - Oregon (`us-west-2`)

- **Cloud API Code**: `aws-us-west-2`
- **Regional Endpoint**: `aws-us-west-2.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.us-west-2.vpce-svc-0f44b3d7302816b94`
- **Same Region Replication**:  Available
- **Multi-Region Replication**:
  - `aws-ca-central-1`
  - `aws-us-east-1`
  - `aws-us-east-2`
- **Multi-Cloud Replication**:
  - `gcp-us-central1`
  - `gcp-us-west1`
  - `gcp-us-east4`

### South America - São Paulo (`sa-east-1`)

- **Cloud API Code**: `aws-sa-east-1`
- **Regional Endpoint**: `aws-sa-east-1.region.tmprl.cloud`
- **PrivateLink Endpoint Service**: `com.amazonaws.vpce.sa-east-1.vpce-svc-0ca67a102f3ce525a`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - None
- **Multi-Cloud Replication**:
  - None

---

## Gcpregions

### North America - Iowa (`us-central1`)

- **Cloud API Code**: `gcp-us-central1`
- **Regional Endpoint**: `gcp-us-central1.region.tmprl.cloud`
- **Private Service Connect Service Attachment URI**: `projects/prod-d9ch6v2ybver8d2a8fyf7qru9/regions/us-central1/serviceAttachments/pl-5xzng`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `gcp-us-west1`
  - `gcp-us-east4`
- **Multi-Cloud Replication**:
  - `aws-ca-central-1`
  - `aws-us-east-1`
  - `aws-us-east-2`
  - `aws-us-west-2`

### North America - Oregon (`us-west1`)

- **Cloud API Code**: `gcp-us-west1`
- **Regional Endpoint**: `gcp-us-west1.region.tmprl.cloud`
- **Private Service Connect Service Attachment URI**: `projects/prod-rbe76zxxzydz4cbdz2xt5b59q/regions/us-west1/serviceAttachments/pl-94w0x`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `gcp-us-central1`
  - `gcp-us-east4`
- **Multi-Cloud Replication**:
  - `aws-ca-central-1`
  - `aws-us-east-1`
  - `aws-us-east-2`
  - `aws-us-west-2`

### North America - Northern Virginia (`us-east4`)

- **Cloud API Code**: `gcp-us-east4`
- **Regional Endpoint**: `gcp-us-east4.region.tmprl.cloud` 
- **Private Service Connect Service Attachment URI**: `projects/prod-y399cvr9c2b43es2w3q3e4gvw/regions/us-east4/serviceAttachments/pl-8awsy`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - `gcp-us-central1`
  - `gcp-us-west1`
- **Multi-Cloud Replication**:
  - `aws-ca-central-1`
  - `aws-us-east-1`
  - `aws-us-east-2`
  - `aws-us-west-2`

### Europe - Frankfurt (`europe-west3`)

- **Cloud API Code**: `gcp-europe-west3`
- **Regional Endpoint**: `gcp-europe-west3.region.tmprl.cloud`
- **Private Service Connect Service Attachment URI**: `projects/prod-kwy7d4faxp6qgrgd9x94du36g/regions/europe-west3/serviceAttachments/pl-acgsh`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - None
- **Multi-Cloud Replication**:
  - `aws-eu-central-1`
  - `aws-eu-west-1`
  - `aws-eu-west-2`

### Asia Pacific - Mumbai (`asia-south1`)

- **Cloud API Code**: `gcp-asia-south1`
- **Regional Endpoint**: `gcp-asia-south1.region.tmprl.cloud`
- **Private Service Connect Service Attachment URI**: `projects/prod-d5spc2sfeshws33bg33vwdef7/regions/asia-south1/serviceAttachments/pl-7w7tw`
- **Same Region Replication**:  Not Available
- **Multi-Region Replication**:
  - None
- **Multi-Cloud Replication**:
  - `aws-ap-northeast-1`
  - `aws-ap-northeast-2`
  - `aws-ap-south-1`
  - `aws-ap-south-2`
  - `aws-ap-southeast-1`
  - `aws-ap-southeast-2`

---

## Private Service

| Region                 | Private Service Connect Service Name                                                      |
| ---------------------- | ----------------------------------------------------------------------------------------- |
| `asia-south1`          | `projects/prod-d5spc2sfeshws33bg33vwdef7/regions/asia-south1/serviceAttachments/pl-7w7tw` |
| `us-central1`          | `projects/prod-d9ch6v2ybver8d2a8fyf7qru9/regions/us-central1/serviceAttachments/pl-5xzn`   |
| `us-west1   `          | `projects/prod-rbe76zxxzydz4cbdz2xt5b59q/regions/us-west1/serviceAttachments/pl-94w0x`    |

---

## RPO and RTO - Temporal Cloud feature guide

Recovery Point Objective (RPO) and Recovery Time Objective (RTO) define data durability and service restoration timelines, respectively.
In Temporal Cloud, these objectives shift depending on the scale of failure and whether affecting an availability zone, a region, or spanning multiple regions.
Therefore, Recovery Point Objective and Recovery Time Objective for Temporal Cloud can be considered within three scenarios:

1. The near-zero RPO/20 minutes or less RTO for Temporal Cloud with [High Availability](/cloud/high-availability)
2. The eight-hour RPO/RTO Temporal Cloud reports for _regional_ failures for single-region namespaces
3. The RPO/RTO Temporal Cloud guarantees for _availability zone_ failure

Which objective is relevant to your organization is driven by whether you map data center loss to a _regional_ loss or a _zonal_ loss.
Temporal Cloud delivers different RPO/RTOs based on these scenarios because of the way our platform performs writes to our data provider.

## High Availability, Regional Failure

Temporal Cloud offers [High Availability](/cloud/high-availability).
High availability ensures that a system remains operational with minimal downtime.

As Workflows progress in the active region, history events are asynchronously replicated to the standby region.
In case of an incident or outage in the active region, Temporal Cloud will fail over to the standby region so that existing Workflow Executions will continue to run and new Executions can be started.

**Recovery Point Objective (RPO) - Near Zero**

Temporal Cloud is designed to limit data loss after recovery when the incident triggering the failover is resolved.
The recovery point objective RPO is near-zero.
There may be a short period of time—the replication lag—during the incident when some data may be unavailable

**Recovery Time Objective (RTO) - 20 minutes**

Recovery time objective (RTO) for Temporal Cloud is 20 minutes or less per incident.

## Single Region Namespace, Regional Failure

Temporal Cloud Namespace data is backed up by our data provider.
For a single region Namespace, data must be restored in order to recover in the event of regional failure (i.e., logical corruption).

Temporal Cloud is beholden to our data provider backup constraints, so in this scenario it leads to the following objectives for regional failure:

**Recovery Point Objective (RPO) - 8 hours**

- Our data provider “snapshot” duration which is _4 hours_
- The time window of _4 hours_ allocated to detection of corruption point before we mitigate.

**Recovery Time Objective (RTO) - 8 hours**

- The time window of _4 hours_ allocated to detection of corruption point.
- Our data provider restore time can be up to _4 hours_

## Availability Zone Failure

Temporal Cells are deployed in three Availability Zones (AZs) in the same region.
Our data provider is deployed with the same topology in three AZs in the same region.

**All writes to storage are synchronously replicated across AZs**, including our writes to ElasticSearch.
ElasticSearch is eventually consistent, but this does not impact our RPO as there is no data loss.

This means there is _no_ logical corruption and restoration is done from a live replicated instance.
This applies for both single region Namespaces and multi region Namespaces.

This leads to the following objectives for availability zone failure:

**Recovery Point Objective (RPO) - 0**

Anything that gets committed into the zone is protected by replication in another AZ.

**Recovery Time Objective (RTO) - 0**

Temporal is active-active across AZs.
The RTO is stated to be zero, meaning there should be no downtime in such scenarios.

---

## SAML authentication - Temporal Cloud feature guide

To authenticate the users of your Temporal Cloud account, you can connect an identity provider (IdP) to your account by using Security Assertion Markup Language (SAML) 2.0.

:::info

Enabling this feature adds a charge to your account.
For more information, contact your account manager.

:::

## Integrate SAML with your Temporal Cloud account

1. Locate your [Temporal Cloud Account Id](/cloud/namespaces#temporal-cloud-account-id).
   One way to do so is to sign in to Temporal Cloud and find your [Namespace Id](/cloud/namespaces#temporal-cloud-namespace-id).
   The Account Id is the five or six characters following the period (.), such as `f45a2`.
   You will need the Account Id to construct your callback URL and your entity identifier.
1. Configure SAML with your IdP by following one of these sets of instructions:
   - [Microsoft Entra ID](#configure-saml-with-azure-ad)
   - [Okta](#configure-saml-with-okta)
1. [Share your connection information with us and test your connection.](#finish-saml-configuration)

## How to configure SAML with Microsoft Entra ID {#configure-saml-with-azure-ad}

If you want to use the general Microsoft login mechanism, you don't need to set up SAML with Entra ID.
Just select **Continue with Microsoft** on the Temporal Cloud sign-in page.

To use Entra ID as your SAML IdP, create a Microsoft Entra ID Enterprise application.

1. Sign in to the [Microsoft Entra ID](https://portal.azure.com/).
1. On the home page, under **Manage Microsoft Entra ID**, select **View**.
1. On the **Overview** page near the top, select **Add > Enterprise application**.
1. On the **Browse Microsoft Entra ID Gallery** page near the top, select **Create your own application**.
1. In the **Create your own application** pane, provide a name for your application (such as `temporal-cloud`) and select **Integrate any other application you don't find in the gallery**.
1. Select **Save**.
1. In the **Getting Started** section, select **2. Set up single sign on**.
1. On the **Single sign-on** page, select **SAML**.
1. In the **Basic SAML Configuration** section of the **SAML-based Sign-on** page, select **Edit**.
1. In **Identifier (Entity ID)**, enter the following entity identifier, including your Account Id where indicated:

   ```bash
   urn:auth0:prod-tmprl:ACCOUNT_ID-saml
   ```

   A correctly formed entity identifier looks like this:

   ```bash
   urn:auth0:prod-tmprl:f45a2-saml
   ```

1. In **Reply URL (Assertion Consumer Service URL)**, enter the following callback URL, including your Account Id where indicated:

   ```bash
   https://login.tmprl.cloud/login/callback?connection=ACCOUNT_ID-saml
   ```

   A correctly formed callback URL looks like this:

   ```bash
   https://login.tmprl.cloud/login/callback?connection=f45a2-saml
   ```

1. In **Sign on URL**, enter the following login url, including your Account Id where indicated:

   ```bash
   https://cloud.temporal.io/login/saml?connection=ACCOUNT_ID-saml
   ```

   A correctly formed login URL looks like this:

   ```bash
   https://cloud.temporal.io/login/saml?connection=f45a2-saml
   ```

1. You can leave the other fields blank.
   Near the top of the pane, select **Save**.
1. In the **Attributes & Claims** section, select **Edit**.
1. We require the user's full email address when connecting to Temporal.
   In the **Required claim** section, set **email** and **name**.
   Verify that **Unique User Identifier (NameID)** is set to `user.userprincipalname [nameid-format:emailAddress]`.
1. Collect information that you need to send to us:
   - In the **SAML Certificates** section of the **SAML-based Sign-on** page, select the download link for **Certificate (Base64)**.
   - In the **Set up _APPLICATION_NAME_** section of the **SAML-based Sign-on** page, copy the value of **Login URL**.

To finish setting up Microsoft Entra ID as your SAML IdP, see [Finish SAML configuration](#finish-saml-configuration).

## How to configure SAML with Okta {#configure-saml-with-okta}

To use Okta as your SAML IdP, configure a new Okta application integration.

1. Sign in to the [Okta Admin Console](https://www.okta.com/login/).
1. In the left navigation pane, select **Applications > Applications**.
1. On the **Applications** page, select **Create App Integration**.
1. In the **Create a new app integration** dialog, select **SAML 2.0** and then select **Next**.
1. On the **Create SAML Integration** page in the **General Settings** section, provide a name for your application (such as `temporal-cloud`) and then select **Next**.
1. In the **Configure SAML** section in **Single sign on URL**, enter the following callback URL, including your Account Id where indicated:

   ```bash
   https://login.tmprl.cloud/login/callback?connection=ACCOUNT_ID-saml
   ```

   A correctly formed callback URL looks like this:

   ```bash
   https://login.tmprl.cloud/login/callback?connection=f45a2-saml
   ```

1. In **Audience URI (SP Entity ID)**, enter the following entity identifier, including your Account Id where indicated:

   ```bash
   urn:auth0:prod-tmprl:ACCOUNT_ID-saml
   ```

   A correctly formed entity identifier looks like this:

   ```bash
   urn:auth0:prod-tmprl:f45a2-saml
   ```

1. We require the user's full email address when connecting to Temporal.
   - In **Name ID format**, select `EmailAddress`.
   - In **Attribute Statements**, set **email** and **name**.
1. Select **Next**.
1. In the **Feedback** section, select **Finish**.
1. On the **Applications** page, select the name of the application integration you just created.
1. On the application integration page, select the **Sign On** tab.
1. Under **SAML Setup**, select **View SAML setup instructions**.
1. Collect information that you need to send to us:
   - Copy the IdP settings.
   - Download the active certificate.

To finish setting up Okta as your SAML IdP, see the next section, [Finish SAML configuration](#finish-saml-configuration).

## How to finish your SAML configuration {#finish-saml-configuration}

After you configure SAML with your IdP, we can finish the configuration on our side.
[Create a support ticket](/cloud/support#support-ticket) that includes the following information:

- The sign-in URL from your application
- The X.509 SAML sign-in certificate
- One or more IdP domains to map to the SAML connection

Generally, the provided IdP domain is the same as the domain for your email address.
You can provide multiple IdP domains.

When you receive confirmation from us that we have finished configuration, log in to Temporal Cloud.
This time, though, enter your email address in **Enterprise identity** and select **Continue**.
Do not select **Continue with Google** or **Continue with Microsoft**.
You will be redirected to the authentication page of your IdP.

---

## SCIM user management - Temporal Cloud feature guide

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

This feature is in [Public Preview](/evaluate/development-production-features/release-stages#public-preview).

:::

## Supported IDP Vendors

Supported upstream IDP vendors include:
* [Okta](#configure-scim-with-okta)
* Microsoft Entra ID (Azure AD)
* Google Workspace
* OneLogin
* CyberArk
* JumpCloud
* PingFederate
* Custom SCIM 2.0 providers

## Preparing for SCIM

Before starting your work with SCIM, you'll need to complete this checklist:

1. Configure [SAML](/cloud/saml) SSO.
1. Ensure that critical traffic is configured to authenticate using [mTLS](/cloud/certificates) or [API keys](/cloud/api-keys#overview) attached to Temporal Cloud accounts.
   This ensures that Workflows will continue uninterrupted if there is any problem with your integration.
1. Decide on your **IDP administrator**, who is responsible for configuring and managing your SCIM integration.
   Specify their contact details when you reach out to support in the next stage of this process.

After completing these steps, you're ready to submit your [support ticket](/cloud/support#support-ticket) to enable SCIM.

:::tip Adding and removing users

When you use SCIM for user management, you can manage users outside of SCIM until you disable user lifecycle management. You can change a user's or group's Account Role from the Temporal Cloud interface.

:::

## Onboarding with SCIM and Okta {#configure-scim-with-okta}

1. Temporal Support enables the SCIM integration on your account.
   Enabling integration automatically emails a configuration link to your Okta administrator.
   This authorizes them to set up the integration.
1. Your Okta administrator opens the supplied link.
   The link leads to step-by-step instructions for configuring the integration.
1. Once configured in Okta, Temporal Cloud will begin to receive SCIM messages and automatically onboard and offboard the users and groups configured in Okta.

Some points to note:

- User and group change events are applied within 10 minutes of them being made in Okta.
- User lifecycle management with SCIM also allows user roles to be derived from group membership.
- Once a group has been synced in Temporal Cloud, you can use tcld to assign roles to the group.
  For instructions, see the [User Group Management](https://github.com/temporalio/tcld?tab=readme-ov-file#user-group-management) page.

---

## Service health

Temporal Cloud metrics help monitor the Service health of production deployments.
This documentation covers best practices for monitoring Service health.

## Monitor availability issues

When you see a sudden drop in Worker resource utilization, verify whether Temporal Cloud's API is showing increased latency and error rates.

### Reference Metrics

- [temporal\_cloud\_v0\_service\_latency\_bucket](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_service_latency_bucket)

This metric measures latency for `SignalWithStartWorkflowExecution`, `SignalWorkflowExecution`, `StartWorkflowExecution` operations.
These operations are mission critical and never [throttled](/cloud/service-availability#throughput).
This metric is a good indicator of your lowest possible latency.

### Prometheus Query for this Metric

P99 service lag (histogram):

```
histogram_quantile(0.99, sum(rate(temporal_cloud_v0_service_latency_bucket[$__rate_interval])) by (temporal_namespace, operation, le))
```

## Monitor Temporal Service errors

Check for Temporal Service gRPC API errors.
Note that Service API errors are not equivalent to guarantees mentioned in the [Temporal Cloud SLA](/cloud/sla).

### Reference Metrics

- [temporal\_cloud\_v0\_frontend\_service\_error\_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_frontend_service_error_count)
- [temporal\_cloud\_v0\_frontend\_service\_request\_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_frontend_service_request_count)

### Prometheus Query for this Metric

Measure your daily average errors over 10-minute windows:

```
avg_over_time((
    (

        (
            sum(increase(temporal_cloud_v0_frontend_service_request_count{temporal_namespace=~"$namespace", operation=~"StartWorkflowExecution|SignalWorkflowExecution|SignalWithStartWorkflowExecution|RequestCancelWorkflowExecution|TerminateWorkflowExecution"}[10m]))
            -
            sum(increase(temporal_cloud_v0_frontend_service_error_count{temporal_namespace=~"$namespace", operation=~"StartWorkflowExecution|SignalWorkflowExecution|SignalWithStartWorkflowExecution|RequestCancelWorkflowExecution|TerminateWorkflowExecution"}[10m]))
        )
        /
        sum(increase(temporal_cloud_v0_frontend_service_request_count{temporal_namespace=~"$namespace", operation=~"StartWorkflowExecution|SignalWorkflowExecution|SignalWithStartWorkflowExecution|RequestCancelWorkflowExecution|TerminateWorkflowExecution"}[10m]))
    )

    or vector(1)

    )[1d:10m])
```

## Monitor replication lag for Namespaces with High Availability features

Replication lag refers to the transmission delay of Workflow updates and history events from the primary Namespace to the replica.
Always check the [metric replication lag](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_replication_lag_bucket) before initiating a failover.
A forced failover when there is a large replication lag has a higher likelihood of rolling back Workflow progress.

**Who owns the replication lag?**
Temporal owns replication lag.

**What guarantees are available?**
There is no SLA for replication lag.
Temporal recommends that customers do not trigger failovers except for testing or emergency situations.
High Availability feature's four-9 guarantee SLA means Temporal will handle failovers and ensure high availability.
Temporal also monitors replication lag.
Customer who decide to trigger failovers should look at this metric before moving forward.

**If the lag is high, what should you do?**
We don't expect users to failover.
Please contact Temporal support if you feel you have a pressing need.

**Where can you read more?**
See [operations and metrics](/cloud/high-availability) for Namespaces with High Availability features.

### Reference Metrics

- [temporal\_cloud\_v0\_replication\_lag\_bucket](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_replication_lag_bucket)
- [temporal\_cloud\_v0\_replication\_lag\_sum](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_replication_lag_sum)
- [temporal\_cloud\_v0\_replication\_lag\_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_replication_lag_count)

### Prometheus Query for this Metric

P99 replication lag (histogram):

```
histogram_quantile(0.99, sum(rate(temporal_cloud_v0_replication_lag_bucket[$__rate_interval])) by (temporal_namespace, le))
```

Average replication lag:

```
sum(rate(temporal_cloud_v0_replication_lag_sum[$__rate_interval])) by (temporal_namespace)
/
sum(rate(temporal_cloud_v0_replication_lag_count[$__rate_interval])) by (temporal_namespace)
```

---

## tcld account command reference

The `tcld account` commands manage accounts in Temporal Cloud.

Alias: `a`

- [tcld account get](#get)
- [tcld account metrics](#metrics)

## get

The `tcld account get` command gets information about the Temporal Cloud account you are logged into.

Alias: `g`

`tcld account get`

The command has no modifiers.

## metrics

The `tcld account metrics` commands configure the metrics endpoint for the Temporal Cloud account that is currently logged in.

Alias: `m`

- [tcld account metrics enable](#enable)
- [tcld account metrics disable](#disable)
- [tcld account metrics accepted-client-ca](#accepted-client-ca)

### accepted-client-ca

The `tcld account metrics accepted-client-ca` commands manage the end-entity certificates for the metrics endpoint of the Temporal Cloud account that is currently logged in.

:::info

The end-entity certificates for the metrics endpoint must chain up to the CA certificate used for the account. For more information, see [Certificate requirements](/cloud/certificates#certificate-requirements).

:::

Alias: `ca`

- [tcld account metrics accepted-client-ca add](#add)
- [tcld account metrics accepted-client-ca list](#list)
- [tcld account metrics accepted-client-ca set](#set)
- [tcld account metrics accepted-client-ca remove](#remove)

#### add

The `tcld account metrics accepted-client-ca add` command adds end-entity certificates to the metrics endpoint of a Temporal Cloud account.

:::info

The end-entity certificates for the metrics endpoint must chain up to the CA certificate used for the account. For more information, see [Certificate requirements](/cloud/certificates#certificate-requirements).

:::

`tcld account metrics accepted-client-ca add --ca-certificate <value>`

Alias: `a`

The following modifiers control the behavior of the command.

##### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld account metrics accepted-client-ca add --request-id <request_id> --ca-certificate <encoded_certificate>
```

##### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld account metrics accepted-client-ca add --resource-version <etag> --ca-certificate <encoded_certificate>
```

##### --ca-certificate

_Required modifier unless `--ca-certificate-file` is specified_

Specify a base64-encoded string of a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-c`

**Example**

```bash
tcld account metrics accepted-client-ca add --ca-certificate <encoded_certificate>
```

##### --ca-certificate-file

_Required modifier unless `--ca-certificate` is specified_

Specify a path to a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-f`

**Example**

```bash
tcld account metrics accepted-client-ca add --ca-certificate-file <path>
```

#### list

The `tcld account metrics accepted-client-ca list` command lists the end-entity certificates that are currently configured for the metrics endpoint of a Temporal Cloud account.

`tcld account metrics accepted-client-ca list`

Alias: `l`

The command has no modifiers.

#### remove

The `tcld account metrics accepted-client-ca remove` command removes end-entity certificates from the metrics endpoint of a Temporal Cloud account.

`tcld account metrics accepted-client-ca remove --ca-certificate <value>`

Alias: `r`

The following modifiers control the behavior of the command.

##### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld account metrics accepted-client-ca remove --request-id <request_id> --ca-certificate <encoded_certificate>
```

##### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld account metrics accepted-client-ca remove --resource-version <etag> --ca-certificate <encoded_certificate>
```

##### --ca-certificate

_Required modifier unless `--ca-certificate-fingerprint` or `--ca-certificate-file` is specified_

Specify a base64-encoded string of a CA certificate PEM file.

If `--ca-certificate-fingerprint` is also specified, both `--ca-certificate` and `--ca-certificate-file` are ignored.

If `--ca-certificate-file` is also specified but `--ca-certificate-fingerprint` is not, only `--ca-certificate` is used.

Alias: `-c`

**Example**

```bash
tcld account metrics accepted-client-ca remove --ca-certificate <encoded_certificate>
```

##### --ca-certificate-file

_Required modifier unless `--ca-certificate-fingerprint` or `--ca-certificate` is specified_

Specify a path to a CA certificate PEM file.

If `--ca-certificate-fingerprint` is also specified, both `--ca-certificate-file` and `--ca-certificate` are ignored.

If `--ca-certificate` is also specified but `--ca-certificate-fingerprint` is not, only `--ca-certificate` is used.

Alias: `-f`

**Example**

```bash
tcld account metrics accepted-client-ca remove --ca-certificate-file <path>
```

##### --ca-certificate-fingerprint

_Required modifier unless `--ca-certificate` or `--ca-certificate-file` is specified_

Specify the fingerprint of a CA certificate.

If `--ca-certificate`, `--ca-certificate-file`, or both are also specified, they are ignored.

Alias: `--fp`

**Example**

```bash
tcld account metrics accepted-client-ca remove --ca-certificate-fingerprint <fingerprint>
```

#### set

The `tcld account metrics accepted-client-ca set` command sets the end-entity certificates for the metrics endpoint of a Temporal Cloud account.

:::info

The end-entity certificates for the metrics endpoint must chain up to the CA certificate used for the account. For more information, see [Certificate requirements](/cloud/certificates#certificate-requirements).

:::

`tcld account metrics accepted-client-ca set --ca-certificate <value>`

Alias: `s`

The following modifiers control the behavior of the command.

##### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld account metrics accepted-client-ca set --request-id <request_id> --ca-certificate <encoded_certificate>
```

##### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld account metrics accepted-client-ca set --resource-version <etag> --ca-certificate <encoded_certificate>
```

##### --ca-certificate

_Required modifier unless `--ca-certificate-file` is specified_

Specify a base64-encoded string of a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-c`

**Example**

```bash
tcld account metrics accepted-client-ca set --ca-certificate <encoded_certificate>
```

##### --ca-certificate-file

_Required modifier unless `--ca-certificate` is specified_

Specify a path to a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-f`

**Example**

```bash
tcld account metrics accepted-client-ca set --ca-certificate-file <path>
```

### enable

The `tcld account metrics enable` command enables the metrics endpoint for the Temporal Cloud account that is currently logged in.

:::info

The end-entity for the metrics endpoint _must_ be configured before the endpoint can be enabled. See the [tcld account metrics accepted-client-ca](#accepted-client-ca) commands.

:::

`tcld account metrics enable`

The command has no modifiers.

### disable

The `tcld account metrics disable` command disables the metrics endpoint for the Temporal Cloud account that is currently logged in.

`tcld account metrics disable`

The command has no modifiers.

---

## tcld apikey command reference

The `tcld apikey` commands manage API Keys in Temporal Cloud.

Alias: `ak`

- [tcld apikey create](#create)
- [tcld apikey get](#get)
- [tcld apikey list](#list)
- [tcld apikey delete](#delete)
- [tcld apikey disable](#disable)
- [tcld apikey enable](#enable)

## create

The `tcld apikey create` command creates an API Key in Temporal Cloud.

`tcld apikey create --name <name> --description <description> --duration <duration> --expiry <expiry> --request-id <request_id>`

The following options control the behavior of the command.

#### --name

_Required modifier_

Specify the display name of the API Key.

Alias: `-n`

**Example**

```bash
tcld apikey create --name <name>
```

#### --description

Specify a description for the API Key.

Alias: `-desc`

**Example**

```bash
tcld apikey create --name <name> --description "Your API Key"
```

#### --duration

Specify the duration from now when the API Key will expire.
This will be ignored if the expiry flag is set.

Example format: `24h` (default: 0s).

Alias: `-d`

**Example**

```bash
tcld apikey create --name <name> --duration 24h
```

#### --expiry

Specify the absolute timestamp (RFC3339) when the API Key will expire.

Example: `2023-11-28T09:23:24-08:00`.

Alias: `-e`

**Example**

```bash
tcld apikey create --name <name> --expiry '2023-11-28T09:23:24-08:00'
```

#### --request-id

Specify a request-id for the asynchronous operation.
If not set, the server will assign one.

Alias: `-r`

**Example**

```bash
tcld apikey create --name <name> --request-id <request_id>
```

## get

The `tcld apikey get` command retrieves the details of a specified API Key in Temporal Cloud.

`tcld apikey get --id <id>`

The following option controls the behavior of the command.

#### --id

_Required modifier_

Specify the ID of the API Key to retrieve.

Alias: `-i`

**Example**

```bash
tcld apikey get --id <apikey_id>
```

## list

The `tcld apikey list` command lists all API Keys in Temporal Cloud.

`tcld apikey list`

This command does not require any specific options.

Alias: `l`

**Example**

```bash
tcld apikey list
```

## delete

The `tcld apikey delete` command deletes an API Key in Temporal Cloud.

`tcld apikey delete --id <id> [--resource-version <version>] [--request-id <request_id>]`

The following options control the behavior of the command.

#### --id

_Required modifier_

Specify the ID of the API Key to delete.

Alias: `-i`

**Example**

```bash
tcld apikey delete --id <apikey_id>
```

#### --resource-version

Specify the resource-version (etag) to update from.
If not set, the CLI will use the latest.

Alias: `-v`

**Example**

```bash
tcld apikey delete --id <apikey_id> --resource-version <version>
```

#### --request-id

Specify a request-id for the asynchronous operation.
If not set, the server will assign one.

Alias: `-r`

**Example**

```bash
tcld apikey delete --id <apikey_id> --request-id <request_id>
```

## disable

The `tcld apikey disable` command disables an API Key in Temporal Cloud.

`tcld apikey disable --id <id> [--resource-version <version>] [--request-id <request_id>]`

The following options control the behavior of the command.

#### --id

_Required modifier_

Specify the ID of the API Key to disable.

Alias: `-i`

**Example**

```bash
tcld apikey disable --id <apikey_id>
```

#### --resource-version

Specify the resource-version (etag) to update from. If not set, the CLI will use the latest.

Alias: `-v`

**Example**

```bash
tcld apikey disable --id <apikey_id> --resource-version <version>
```

#### --request-id

Specify a request-id for the asynchronous operation. If not set, the server will assign one.

Alias: `-r`

**Example**

```bash
tcld apikey disable --id <apikey_id> --request-id <request_id>
```

## enable

The `tcld apikey enable` command enables a disabled API Key in Temporal Cloud.

`tcld apikey enable --id <id> [--resource-version <version>] [--request-id <request_id>]`

The following options control the behavior of the command.

#### --id

_Required modifier_

Specify the ID of the API Key to enable.

Alias: `-i`

**Example**

```bash
tcld apikey enable --id <apikey_id>
```

#### --resource-version

Specify the resource-version (etag) to update from.
If not set, the CLI will use the latest.

Alias: `-v`

**Example**

```bash
tcld apikey enable --id <apikey_id> --resource-version <version>
```

#### --request-id

Specify a request-id for the asynchronous operation.
If not set, the server will assign one.

Alias: `-r`

**Example**

```bash
tcld apikey enable --id <apikey_id> --request-id <request_id>
```

---

## tcld connectivity-rule command reference

The `tcld connectivity-rule` commands manage [connectivity rules](/cloud/connectivity#connectivity-rules) in Temporal Cloud.

Alias: `cr`

- [tcld connectivity-rule create](#create)
- [tcld connectivity-rule delete](#delete)
- [tcld connectivity-rule get](#get)
- [tcld connectivity-rule list](#list)

## create

The `tcld connectivity-rule create` command creates a connectivity rule.

Alias: `c`

#### --connection-id

The connection ID of the private connection.

Alias: `ci`

#### --connectivity-type

The type of connectivity, currently only support 'private' and 'public'.

Alias: `ct`

#### --gcp-project-id

The GCP project ID of the connection, required if the cloud provider is 'gcp'.

Alias: `gpi`

#### --region

The region of the connection.

Alias: `r`

## delete

The `tcld connectivity-rule delete` command deletes a connectivity rule.

Alias: `d`

#### --connectivity-rule-id

The connectivity rule ID.

Alias: `id`

## get

The `tcld connectivity-rule get` command gets a connectivity rule.

Alias: `g`

#### --connectivity-rule-id

The connectivity rule ID.

Alias: `id`

## list

The `tcld connectivity-rule list` command lists connectivity rules.

Alias: `l`

#### --namespace

The namespace hosted on temporal cloud.

Alias: `n`

---

## tcld feature command reference

The `tcld feature` commands manage features in Temporal Cloud.

Alias: `f`

- [tcld feature get](#get)
- [tcld feature toggle](#toggle)

## get

The `tcld feature get` command gets information about the Temporal Cloud features you've enabled.

Alias: `g`

`tcld feature get`

The command has no modifiers.

**Example**

`tcld feature get`

The following is an example output:

```json
[
  {
    "Name": "enable-apikey",
    "Value": true
  }
]
```

## toggle

The `tcld feature toggle-*` command turns on or off the `*` feature in Temporal Cloud.

:::note

The `*` symbol represents the name of the feature.
Replace `*` with the name of the available feature to toggle.

:::

Alias: `tak`

`tcld feature toggle-*`

The command has no modifiers.

**Example**

`tcld feature toggle-apikey`

The following is an example output:

```json
Feature flag enable-apikey is now true
```

:::note

The feature `apikey` is an example.
Update the feature name to toggle a different feature.

:::

---

## tcld generate-certificates command reference

The `tcld generate-certificates` commands generate certificate authority (CA) and end-entity TLS certificates for Temporal Cloud.

Alias: `gen`

- [tcld generate-certificates certificate-authority-certificate](#certificate-authority-certificate)
- [tcld generate-certificates end-entity-certificate](#end-entity-certificate)

## tcld generate-certificates certificate-authority-certificate {#certificate-authority-certificate}

The `tcld generate-certificates certificate-authority-certificate` command generates certificate authority (CA) certificates for Temporal Cloud.

`tcld generate-certificates certificate-authority-certificate <modifiers>`

Alias: `ca`

The following modifiers control the behavior of the command.

#### --organization

Specify an organization name for certificate generation.

Alias: `--org`

**Example**

```bash
tcld generate-certificates certificate-authority-certificate --organization <value>
```

#### --validity-period

Specify the duration for which the certificate is valid.
Format values as d/h (for example, `30d10h` for a certificate lasting 30 days and 10 hours).

Alias: `-d`

**Example**

```bash
tcld generate-certificates certificate-authority-certificate --validity-period <value>
```

#### --ca-certificate-file

Specify a path to a `.pem` file where the generated X.509 certificate file will be stored.

Alias: `--ca-cert`

**Example**

```bash
tcld generate-certificates certificate-authority-certificate --ca-certificate-file <path>
```

#### --ca-key-file

Specify a path to a `.key` file where the certificate's private key will be stored.

Alias: `--ca-key`

**Example**

```bash
tcld generate-certificates certificate-authority-certificate --ca-key-file <path>
```

#### --rsa-algorithm

When enabled, a 4096-bit RSA key pair is generated for the certificate instead of an ECDSA P-384 key pair.
Because an ECDSA P-384 key pair is the recommended default, this option is disabled.

Alias: `--rsa`

**Example**

```bash
tcld generate-certificates certificate-authority-certificate --rsa-algorithm <boolean>
```

## tcld generate-certificates end-entity-certificate {#end-entity-certificate}

The `tcld generate-certificates end-entity-certificate` command generates end-entity (leaf) certificates for Temporal Cloud.

`tcld generate-certificates end-entity-certificate <modifiers>`

Alias: `leaf`

The following modifiers control the behavior of the command.

#### --organization

Specify an organization name for certificate generation.

Alias: `--org`

**Example**

```bash
tcld generate-certificates end-entity-certificate --organization <value>
```

#### --organization-unit

Optional: Specify the name of the organization unit.

**Example**

```bash
tcld generate-certificates end-entity-certificate --organization-unit <value>
```

#### --validity-period

Specify the duration for which the certificate is valid.
Format values as d/h (for example, `30d10h` for a certificate lasting 30 days and 10 hours).

Alias: `-d`

**Example**

```bash
tcld generate-certificates end-entity-certificate --validity-period <value>
```

#### --ca-certificate-file

Specify the path of the X.509 CA certificate in a `.pem` file for the certificate authority.

Alias: `--ca-cert`

**Example**

```bash
tcld generate-certificates end-entity-certificate --ca-certificate-file <path>
```

#### --ca-key-file

Specify the path of the private key in a `.key` file for the certificate authority.

Alias: `--ca-key`

**Example**

```bash
tcld generate-certificates end-entity-certificate --ca-key-file <path>
```

#### --certificate-file

Specify a path to a `.pem` file where the generated X.509 leaf certificate file will be stored.

Alias: `--cert`

**Example**

```bash
tcld generate-certificates end-entity-certificate --certificate-file <path>
```

#### --key-file

Specify a path to a `.key` file where the leaf certificate's private key will be stored.

Alias: `--key`

**Example**

```bash
tcld generate-certificates end-entity-certificate --key-file <path>
```

---

## tcld command reference

The Temporal Cloud CLI (tcld) is a command-line tool that you can use to interact with Temporal Cloud.

- [How to install tcld](#install-tcld)

### tcld commands

- [tcld account](/cloud/tcld/account)
- [tcld apikey](/cloud/tcld/apikey)
- [tcld connectivity-rule](/cloud/tcld/connectivity-rule)
- [tcld feature](/production-deployment/cloud/tcld/feature)
- [tcld generate-certificates](/cloud/tcld/generate-certificates)
- [tcld login](/cloud/tcld/login)
- [tcld logout](/cloud/tcld/logout/)
- [tcld namespace](/cloud/tcld/namespace)
- [tcld nexus](/cloud/tcld/nexus)
- [tcld request](/cloud/tcld/request)
- [tcld user](/cloud/tcld/user)
- [tcld version](/cloud/tcld/version/)

### Global modifiers

#### --auto_confirm

Automatically confirm all prompts.

You can specify the value for this modifier by setting the AUTO_CONFIRM environment variable.
The default value is `false`.

## How to install tcld {#install-tcld}

You can install [tcld](/cloud/tcld) in two ways.

### Install tcld by using Homebrew

```bash
brew install temporalio/brew/tcld
```

### Build tcld from source

1. Verify that you have Go 1.18 or later installed.

   ```bash
   go version
   ```

   If Go 1.18 or later is not installed, follow the [Download and install](https://go.dev/doc/install) instructions on the Go website.

1. Clone the tcld repository and run make.

   ```bash
   git clone https://github.com/temporalio/tcld.git
   cd tcld
   make
   ```

1. Copy the tcld executable to any directory that appears in the PATH environment variable, such as `/usr/local/bin`.

   ```bash
   cp tcld /usr/local/bin/tcld
   ```

1. Verify that tcld is installed.

   ```bash
   tcld version
   ```

---

## tcld login command reference

The `tcld login` command logs in a user to Temporal Cloud.

Follow instructions in the browser to log in to your Temporal account.

Alias: `l`

`tcld login`

The command has no modifiers.

---

## tcld logout command reference

The `tcld logout` command logs a user out of Temporal Cloud.

Alias: `lo`

`tcld logout`

The following modifier controls the behavior of the command.

#### --disable-pop-up

Disables a browser pop-up if set to `true`. The default value is `false`.

---

## tcld namespace command reference

The `tcld namespace` commands enable [Namespace](/namespaces) operations in Temporal Cloud.

Alias: `n`

- [tcld namespace add-region](#add-region)
- [tcld namespace create](#create)
- [tcld namespace delete](#delete)
- [tcld namespace failover](#failover)
- [tcld namespace get](#get)
- [tcld namespace list](#list)
- [tcld namespace export](#export)
- [tcld namespace accepted-client-ca](#accepted-client-ca)
- [tcld namespace certificate-filters](#certificate-filters)
- [tcld namespace search-attributes](#search-attributes)
- [tcld namespace retention](#retention)
- [tcld namespace update-codec-server](#update-codec-server)
- [tcld namespace update-high-availability](#update-high-availability)
- [tcld namespace tags](#tags)
- [tcld namespace set-connectivity-rules](#set-connectivity-rules)

## add-region

Use `tcld namespace add-region` to add a <ToolTipTerm term="replica" /> to an existing Temporal Cloud [Namespace](/namespaces).
Adding a replica upgrades the Namespace to [High Availability features](/cloud/high-availability).
Once provisioned, High Availability features enable Temporal Cloud to start replicating Workflow Execution data from the primary to the replica and trigger failover during adverse conditions.

Alias: _none_

The following modifiers control the behavior of the command.

#### --request-id

The request identifier to use for the asynchronous operation.
If not set, the server assigns an identifier.

Alias: `-r`

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable `$TEMPORAL_CLOUD_NAMESPACE` is used.

Alias: `-n`

_Required modifier_

#### --region

The region to add to the existing Namespace.
See [Regions](/cloud/regions) for a list of supported regions.

:::tip Choosing Replica Regions

- GCP Namespaces support Multi-region Replication but do not support Same-region Replication.
- The AWS `sa-east-1` region supports Same-region Replication but does not support Multi-region Replication.
- You must select a region using the same Cloud provider for your replica as your primary.

:::

Alias: `--re`

_Required modifier_

**Example**

```bash
tcld namespace add-region \
    --namespace <namespace_id> \
    --region <replica_region>
```

When using API key authentication, add your API credentials before pressing Enter:

```bash
tcld --api-key <your_api_key> \
    add-region \
    --namespace <namespace_id> \
    --region <replica_region>
```

Specify the region code of the region where you want to create the replica as an argument to the `--region` flag:

- Using the current region replicates to an <ToolTipTerm term="isolation domain" src="isolation domains" /> within your existing region.
- Using a different region (within the same continent) replicates across regions.
- You cannot create a Multi-region deployment on separate continents.

Temporal Cloud sends an email alert once your Namespace is ready for use.

#### --cloud-provider

The cloud provider of the region.

Default: aws (default: "aws")

## create

The `tcld namespace create` command creates a Temporal [Namespace](/namespaces) in Temporal Cloud.
Use it to create a standard Namespace or a Namespace with [High Availability features](/cloud/high-availability).

Alias: `c`

`tcld namespace create`

The following modifiers control the behavior of the command.

#### --request-id

The request identifier to use for the asynchronous operation.
If not set, the server assigns an identifier.

Alias: `-r`

#### --ca-certificate

_Required modifier unless `--ca-certificate-file` is specified_

A base64-encoded CA certificate.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-c`

#### --connectivity-rule-ids

The list of connectivity rule IDs, can be used in create namespace and update namespace. example: --ids id1 --ids id2 --ids id3.

Alias: `ids`

```bash
tcld namespace create \
    --namespace <namespace_id> \
    --region us-west-2 \
    --retention-days 60 \
    --certificate-filter-input '{"filters": [{"commonName": "test1"}]}' \
    --user-namespace-permission "user@example.com=Admin" \
    --search-attribute "customer_id=Int" \
    --search-attribute "customer_name=Text" \
    --endpoint "https://test-codec-server.com" \
    --pass-access-token \
    --include-credentials \
    --connectivity-rule-ids <rule_id1> \
    --connectivity-rule-ids <rule_id2> // if adding multiple rules
```

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --region

The region to create the Namespace in.

- Supplying a single `--region` flags creates a standard Namespace.
- Supplying two `--region` flags creates a Namespace that uses <ToolTipTerm term="replication" /> and <ToolTipTerm term="failover" /> for continued service availability in case of failures of incidents.

**Example**

```bash
tcld namespace create \
    --namespace <namespace_id> \
    --region <primary_region> [\]
    [--region <replica_region>] // if adding replica
```

When using API key authentication, add your API credentials before pressing Enter:

```bash
tcld --api-key <your_api_key> \
    namespace create \
    --namespace <namespace_id> \
    --region <primary_region> [\]
    [--region <replica_region>] // if adding replica
```

When using High Availability features, specify the region code of the region where you want to create the replica as an argument to the `--region` flag:

- Using the current region replicates to an <ToolTipTerm term="isolation domain" src="isolation domains" /> within your existing region.
  This enables Same-region replication.
- Using a different region (within the same continent) replicates across regions.
  This enables Multi-region replication.

Temporal Cloud sends an email alert once your Namespace is ready for use.

:::tip Choosing Replica Regions

- GCP Namespaces support Multi-region Replication but do not support Same-region Replication.
- The AWS `sa-east-1` region supports Same-region Replication but does not support Multi-region Replication.
- You must select a region using the same Cloud provider for your replica as your primary.
- You cannot create a Multi-region deployment on separate continents.

:::

Alias: `--re`

_Required modifier_

#### --retention-days

The number of days that data about closed Workflow Executions will be retained (default: 30).

Alias: `--rd`

#### --ca-certificate-file

_Required modifier unless `--ca-certificate` is specified_

A path to a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `--cf`

#### --certificate-filter-file

_Required modifier unless `--certificate-filter-input` is specified_

Path to a JSON file that defines the certificate filters to be applied to the Namespace.
The specified filters replace any existing filters.

Sample JSON: `{ "filters": [ { "commonName": "test1" } ] }`

If both `--certificate-filter-file` and `--certificate-filter-input` are specified, the command returns an error.

Alias: `--cff`

#### --certificate-filter-input

_Required modifier unless `--certificate-filter-file` is specified_

A JSON string that defines the certificate filters to be applied to the Namespace.
The specified filters replace any existing filters.

Sample JSON: `{ "filters": [ { "commonName": "test1" } ] }`

If both `--certificate-filter-input` and `--certificate-filter-file` are specified, the command returns an error.

Alias: `--cfi`

#### --search-attribute

_Required modifier; can be specified more than once_

A custom Search Attribute in the form '_name_=_type_'.

Valid values for _type_: `Bool` | `Datetime` | `Double` | `Int` | `Keyword` | `Text`

Alias: `--sa`

#### --user-namespace-permission

_Can be specified more than once_

A [Namespace-level permission](/cloud/users#namespace-level-permissions) for a user in the form '_email_=_permission_'.

Valid values for _permission_: `Admin` | `Write` | `Read`

Alias: `-p`

#### --endpoint

The codec server endpoint to decode payloads for all users interacting with this Namespace. Must be HTTPS.

Alias: `-e`

#### --pass-access-token

Pass the user access token to the remote endpoint (default: false).

Alias: `--pat`

#### --include-credentials

Include cross-origin credentials (default: false).

Alias: `--ic`

#### --tag

A tag in the form "_key_=_value_".

[Tag structure and limits](/cloud/namespaces#tag-structure-and-limits).

Alias: `--t`

**Example**

```bash
tcld namespace create \
    --namespace <namespace_id> \
    --region us-west-2 \
    --retention-days 60 \
    --certificate-filter-input '{"filters": [{"commonName": "test1"}]}' \
    --user-namespace-permission "user@example.com=Admin" \
    --search-attribute "customer_id=Int" \
    --search-attribute "customer_name=Text" \
    --endpoint "https://test-codec-server.com" \
    --pass-access-token \
    --include-credentials \
    --tag "key=value"
```

## delete

The `tcld namespace delete` command deletes the specified [Namespace](/namespaces) in Temporal Cloud.

Alias: `d`

`tcld namespace delete`

The following modifiers control the behavior of the command.

#### --namespace

Specify the Namespace hosted on Temporal Cloud to be deleted.

Alias: `-n`

_Required modifier_

#### --request-id

The request identifier to use for the asynchronous operation.
If not set, the server assigns an identifier.

Alias: `-r`

#### --resource-version

A resource version (ETag) to update from.
If not set, the CLI uses the latest.

Alias: `-v`

**Example**

```bash
tcld namespace delete \
    --namespace <namespace_id>
```

## delete-region

Use `tcld namespace delete-region` to remove a <ToolTipTerm term="replica" /> for an existing Temporal Cloud [Namespace](/namespaces).
Removing a replica disables [High Availability features](/cloud/high-availability).

:::tip

Disabling replication by removing a region results in a mandatory 7-day waiting period before you can re-enable High Availability Namespace features.

:::

Alias: _none_

The following modifiers control the behavior of the command.

#### --request-id

The request identifier to use for the asynchronous operation.
If not set, the server assigns an identifier.

Alias: `-r`

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable `$TEMPORAL_CLOUD_NAMESPACE` is used.

Alias: `-n`

_Required modifier_

#### --region

The region to remove from the Namespace.
Upon removal, Temporal stops replication and the Namespace becomes a Standard Namespace.
You cannot re-add a region or add a new region for seven days after removing a Namespace region.

Alias: `--re`

_Required modifier_

**Example**

```bash
tcld namespace delete-region \
    --namespace <namespace_id>\
    --region <replica_region>
```

When using API key authentication, add your API credentials before pressing Enter:

```bash
tcld --api-key <your_api_key> \
    delete-region \
    --namespace <namespace_id> \
    --region <replica_region>
```

#### --cloud-provider

The cloud provider of the region to failover to.

Default: aws (default: "aws")

## failover

Failover a Temporal Namespace with [High Availability features](/cloud/high-availability).
A failover switches a Namespace region from a primary Namespace to its replica.

**Example**

```bash
tcld namespace failover \
    --namespace <namespace_id> \
    --region <target_region>
```

When using API key authentication, add your API credentials before pressing Enter:

```bash
tcld --api-key <your_api_key> \
    namespace failover \
    --namespace <namespace_id> \
    --region <target_region>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation.
If not specified, the server assigns a request identifier.

Alias: `-r`

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --region

The region to failover _to_.

See [Regions](/cloud/regions) for a list of supported regions.

Alias: `--re`

_Required modifier_

#### --ca-certificate

_Required modifier unless `--ca-certificate-file` is specified_.

A base64-encoded CA certificate.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-c`

#### --cloud-provider

The cloud provider of the region to failover to.

Default: aws (default: "aws")

## get

The `tcld namespace get` command gets information about the specified [Namespace](/namespaces) in Temporal Cloud.

Alias: `g`

`tcld namespace get`

The following modifier controls the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace get \
    --namespace <namespace_id>
```

## list

The `tcld namespace list` command lists all [Namespaces](/namespaces) in Temporal Cloud.

Alias: `l`

`tcld namespace list`

The command has no modifiers.

## export

The `tcld namespace export s3` commands manage Workflow History Exports.

Valid options: `s3`

Alias: `es`

- [tcld namespace export s3 create](#create)
- [tcld namespace export s3 get](#get)
- [tcld namespace export s3 delete](#delete)
- [tcld namespace export s3 list](#list)
- [tcld namespace export s3 update](#update)
- [tcld namespace export s3 validate](#validate)

### create

The `tcld namespace export s3 create` command allows users to create an export sink for the Namespace of a Temporal Cloud account.

**Example**

```bash
tcld namespace export s3 create \
    --namespace <namespace_id> \
    --sink-name <sink_name> \
    --s3-bucket-name <bucket_name> \
    --role-arn <role_arn>
```

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --sink-name

Provide a name for the export sink.

_Required modifier_

#### --role-arn

Provide role arn for the IAM Role.

_Required modifier_

#### --s3-bucket-name

Provide the name of an AWS S3 bucket that Temporal will send closed workflow histories to.

_Required modifier_

#### --request-id

Specify a request identifier to use for the asynchronous operation.
If not specified, the server assigns a request identifier.

Alias: `-r`

#### --kms-arn

Provide the ARN of the KMS key to use for encryption. Note: If the KMS ARN needs to be added or updated, users should create the IAM Role with KMS or modify the created IAM Role accordingly. Providing it as part of the input won't help.

### get

The `tcld namespace export s3 get` command allows users to retrieve details about an existing export sink from the Namespace of a Temporal Cloud account.

**Example**

```bash
tcld namespace export s3 get \
    --namespace <namespace_id> \
    --sink-name <sink_name>
```

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --sink-name

Provide the name of the export sink you wish to retrieve details for.

_Required modifier_

### delete

The `tcld namespace export s3 delete` command allows users to delete an existing export sink from the Namespace of a Temporal Cloud account.

**Example**

```bash
tcld namespace export s3 delete \
    --namespace <namespace_id> \
    --sink-name <sink_name>
```

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --sink-name

Provide the name of the export sink you wish to delete.

_Required modifier_

#### --resource-version

Specify a resource version (ETag) to delete from.
If not specified, the CLI will use the latest version.

Alias: `-v`

#### --request-id

Specify a request identifier to use for the asynchronous operation.
If not specified, the server assigns a request identifier.

Alias: `-r`

### list

The `tcld namespace export s3 list` command allows users to list all existing export sinks within the Namespace of a Temporal Cloud account.

**Example**

```bash
tcld namespace export s3 list \
    --namespace <namespace_id>
```

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --page-size

Determine the number of results to return per page for list operations. If not specified, the default value is 100.

#### --page-token

Provide the page token to continue listing results from where the previous list operation left off.

### update

The `tcld namespace export s3 update` command allows users to modify the details of an existing export sink within the Namespace of a Temporal Cloud account.

**Example**

```bash
tcld namespace export s3 update \
    --namespace <namespace_id> \
    --sink-name <sink_name> \
    --enabled true
```

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --sink-name

Provide the name of the export sink you wish to update.

_Required modifier_

#### --enabled

Specify whether the export is enabled or not.

#### --role-arn

Update the role ARN for the IAM Role.

#### --s3-bucket-name

Update the name of the AWS S3 bucket that Temporal will send closed workflow histories to.

#### --resource-version

Specify a resource version (ETag) to update from.
If not specified, the CLI will use the latest version.

Alias: `-v`

#### --kms-arn

Update the ARN of the KMS key used for encryption. Note: If the KMS ARN needs to be added or updated, users should create the IAM Role with KMS or modify the created IAM Role accordingly. Providing it as part of the input won't help.

#### --request-id

Specify a request identifier to use for the asynchronous operation.
If not specified, the server assigns a request identifier.

Alias: `-r`

### validate

The `tcld namespace export s3 validate` command allows users to validate an export sink from the Namespace of a Temporal Cloud account.

**Example**

```bash
tcld namespace export s3 validate \
    --namespace <namespace_id> \
    --sink-name <sink_name> \
    --s3-bucket-name <bucket_name> \
    --role-arn <role_arn>
```

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

_Required modifier_

#### --sink-name

Provide the name of the export sink you wish to retrieve details for.

_Required modifier_

#### --role-arn

Provide role arn for the IAM Role.

_Required modifier_

#### --s3-bucket-name

Update the name of the AWS S3 bucket that Temporal will send closed workflow histories to.

#### --kms-arn

Update the ARN of the KMS key used for encryption. Note: If the KMS ARN needs to be added or updated, users should create the IAM Role with KMS or modify the created IAM Role accordingly. Providing it as part of the input won't help.

## accepted-client-ca

The `tcld namespace accepted-client-ca` commands manage the client CA certificates of the specified [Namespace](/namespaces) in Temporal Cloud. The certificates are used to verify client connections.

:::note

Base64 versions of the CA certificate files are accepted by these commands.

:::

Alias: `ca`

- [tcld namespace accepted-client-ca add](#add)
- [tcld namespace accepted-client-ca list](#list)
- [tcld namespace accepted-client-ca set](#set)
- [tcld namespace accepted-client-ca remove](#remove)

:::important

Do not use a CA certificate that is signed with an insecure signature algorithm, such as SHA-1.
Such signatures will be rejected.
Existing CA certificates that use SHA-1 can stop working without warning.

For more information about the vulnerabilities of SHA-1, see [SHAttered](https://shattered.io/).

:::

### add

The `tcld namespace accepted-client-ca add` command adds client CA certificates to a [Namespace](/namespaces) in Temporal Cloud.

`tcld namespace accepted-client-ca add --ca-certificate <value>`

Alias: `a`

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace accepted-client-ca add \
    --namespace <namespace_id> \
    --ca-certificate <encoded_certificate>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace accepted-client-ca add \
    --request-id <request_id> \
    --ca-certificate <encoded_certificate>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace accepted-client-ca add \
    --resource-version <etag> \
    --ca-certificate <encoded_certificate>
```

#### --ca-certificate

_Required modifier unless `--ca-certificate-file` is specified_

Specify a base64-encoded string of a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-c`

**Example**

```bash
tcld namespace accepted-client-ca add \
    --ca-certificate <encoded_certificate>
```

#### --ca-certificate-file

_Required modifier unless `--ca-certificate` is specified_

Specify a path to a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-f`

**Example**

```bash
tcld namespace accepted-client-ca add \
    --ca-certificate-file <path>
```

### list

The `tcld namespace accepted-client-ca list` command lists the client CA certificates that are currently configured for a [Namespace](/namespaces) in Temporal Cloud.

`tcld namespace accepted-client-ca list`

Alias: `l`

The following modifier controls the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace accepted-client-ca list \
    --namespace <namespace_id>
```

### remove

The `tcld namespace accepted-client-ca remove` command removes client CA certificates from a [Namespace](/namespaces) in Temporal Cloud.

`tcld namespace accepted-client-ca remove --ca-certificate <value>`

Alias: `r`

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace accepted-client-ca remove \
    --namespace <namespace_id> \
    --ca-certificate <encoded_certificate>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace accepted-client-ca remove \
    --request-id <request_id> \
    --ca-certificate <encoded_certificate>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace accepted-client-ca remove \
    --resource-version <etag> \
    --ca-certificate <encoded_certificate>
```

#### --ca-certificate

_Required modifier unless `--ca-certificate-fingerprint` or `--ca-certificate-file` is specified_

Specify the base64-encoded string of a CA certificate PEM file.

If `--ca-certificate-fingerprint` is also specified, both `--ca-certificate` and `--ca-certificate-file` are ignored.

If `--ca-certificate-file` is also specified but `--ca-certificate-fingerprint` is not, only `--ca-certificate` is used.

Alias: `-c`

**Example**

```bash
tcld namespace accepted-client-ca remove \
    --ca-certificate <encoded_certificate>
```

#### --ca-certificate-file

_Required modifier unless `--ca-certificate-fingerprint` or `--ca-certificate` is specified_

Specify a path to a CA certificate PEM file.

If `--ca-certificate-fingerprint` is also specified, both `--ca-certificate-file` and `--ca-certificate` are ignored.

If `--ca-certificate` is also specified but `--ca-certificate-fingerprint` is not, only `--ca-certificate` is used.

Alias: `-f`

**Example**

```bash
tcld namespace accepted-client-ca remove \
    --ca-certificate-file <path>
```

#### --ca-certificate-fingerprint

_Required modifier unless `--ca-certificate` or `--ca-certificate-file` is specified_

Specify the fingerprint of a CA certificate.

If `--ca-certificate`, `--ca-certificate-file`, or both are also specified, they are ignored.

Alias: `--fp`

**Example**

```bash
tcld namespace accepted-client-ca remove \
    --ca-certificate-fingerprint <fingerprint>
```

### set

The `tcld namespace accepted-client-ca set` command sets the client CA certificates for a [Namespace](/namespaces) in Temporal Cloud.

`tcld namespace accepted-client-ca set --ca-certificate <value>`

Alias: `s`

{/* How to rollover accepted client CA certificates in Temporal Cloud using tcld */}

When updating CA certificates, it's important to follow a rollover process.
Doing so enables your Namespace to serve both CA certificates for a period of time until traffic to your old CA certificate ceases.

1. Create a single file that contains both your old and new CA certificate PEM blocks.
   Just concatenate the PEM blocks on adjacent lines.

   ```
   -----BEGIN CERTIFICATE-----
   ... old CA cert ...
   -----END CERTIFICATE-----
   -----BEGIN CERTIFICATE-----
   ... new CA cert ...
   -----END CERTIFICATE-----
   ```

1. Run the `tcld namespace accepted-client-ca set` command with the CA certificate bundle file.

   ```bash
   tcld namespace accepted-client-ca set \
       --ca-certificate-file <path>
   ```

1. Monitor traffic to your old certificate until it ceases.

1. Create another file that contains only the new CA certificate.

1. Run the `tcld namespace accepted-client-ca set` command again with the updated CA certificate bundle file.

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace accepted-client-ca set \
    --namespace <namespace_id>
    --ca-certificate <encoded_certificate>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace accepted-client-ca set \
    --request-id <request_id> \
    --ca-certificate <encoded_certificate>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace accepted-client-ca set \
    --resource-version <etag> \
    --ca-certificate <encoded_certificate>
```

#### --ca-certificate

_Required modifier unless `--ca-certificate-file` is specified_

Specify a base64-encoded string of a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-c`

**Example**

```bash
tcld namespace accepted-client-ca set \
    --ca-certificate <encoded_certificate>
```

#### --ca-certificate-file

_Required modifier unless `--ca-certificate` is specified_

Specify a path to a CA certificate PEM file.

If both `--ca-certificate` and `--ca-certificate-file` are specified, only `--ca-certificate` is used.

Alias: `-f`

**Example**

```bash
tcld namespace accepted-client-ca set \
    --ca-certificate-file <path>
```

## certificate-filters

The `tcld namespace certificate-filters` commands manage optional certificate filters for the specified [Namespace](/namespaces) in Temporal Cloud. The Namespace can use certificate filters to authorize client certificates based on distinguished name (DN) fields.

Alias: `cf`

- [tcld namespace certificate-filters import](#import)
- [tcld namespace certificate-filters export](#export)
- [tcld namespace certificate-filters clear](#clear)

### add

The `tcld namespace certificates-filter add` command adds additional certificate filters to the Namespace of a Temporal Cloud account.

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace certificate-filters add \
    --namespace <namespace_id> \
    --certificate-filter-file <file>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation.
If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace certificate-filters add \
    --request-id <request_id> \
    --certificate-filter-file <file>
```

#### --resource-version

Specify a resource version (ETag) to update from.
If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace certificate-filters add \
    --resource-version <etag> \
    --certificate-filter-file <file>
```

#### --certificate-filter-file

_Required modifier unless `--certificate-filter-value` is specified._

Specify a path to a JSON file defining the certificate filters for the Namespace.

Aliases: `-f`, `--file`

**Example**

```bash
tcld namespace certificate-filters add \
    --certificate-filter-file <file>
```

#### --certificate-filter-input

_Required modifier unless `--certificate-filter-file` is specified._

The certificate filters, in JSON, that will be added to the Namespace.

Aliases: `-i`, `--input`

**Example**

```bash
tcld namespace certificate-filters add \
    --certificate-filter-input <JSON>
```

### clear

The `tcld namespace certificate-filters clear` command clears all certificate filters from a [Namespace](/namespaces) in Temporal Cloud.

:::caution

Using this command allows _any_ client certificate that chains up to a configured CA certificate to connect to the Namespace.

:::

`tcld namespace certificate-filters clear`

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace certificate-filters clear \
    --namespace <namespace_id>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace certificate-filters clear
    --request-id <request_id>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace certificate-filters clear \
    --resource-version <etag>
```

### export

The `tcld namespace certificate-filters export` command exports existing certificate filters from a [Namespace](/namespaces) in Temporal Cloud.

`tcld namespace certificate-filters export --certificate-filter-file <path>`

Alias: `exp`

The following modifiers control the behavior of the command.

#### --certificate-filter-file

Specify a path to a JSON file where tcld can export the certificate filters.

Aliases: `--file`, `-f`

**Example**

```bash
tcld namespace certificate-filters export \
    --certificate-filter-file <path>
```

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace certificate-filters import \
    --namespace <namespace_id> \
    --certificate-filter-input <json>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace certificate-filters import \
    --request-id <request_id> \
    --certificate-filter-input <json>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace certificate-filters import \
    --resource-version <etag> \
    --certificate-filter-input <json>
```

### import

The `tcld namespace certificate-filters import` command sets certificate filters for a [Namespace](/namespaces) in Temporal Cloud.

`tcld namespace certificate-filters import --certificate-filter-file <path>`

Alias: `imp`

A certificate filter can include any combination (and at least one) of the following:

- `commonName`
- `organization`
- `organizationalUnit`
- `subjectAlternativeName`

The following modifiers control the behavior of the command.

#### --certificate-filter-file

_Required modifier unless `--certificate-filter-input` is specified_

Specify a path to a JSON file that defines certificate filters to be applied to the Namespace, such as `{ "filters": [ { "commonName": "test1" } ] }`. The specified filters replace any existing filters.

If both `--certificate-filter-file` and `--certificate-filter-input` are specified, the command returns an error.

Aliases: `--file`, `-f`

**Example**

```bash
tcld namespace certificate-filters import \
    --certificate-filter-file <path>
```

#### --certificate-filter-input

_Required modifier unless `--certificate-filter-file` is specified_

Specify a JSON string that defines certificate filters to be applied to the Namespace, such as `{ "filters": [ { "commonName": "test1" } ] }`. The specified filters replace any existing filters.

If both `--certificate-filter-input` and `--certificate-filter-file` are specified, the command returns an error.

Aliases: `--input`, `-i`

**Example**

```bash
tcld namespace certificate-filters import \
    --certificate-filter-input <json>
```

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace certificate-filters import \
    --namespace <namespace_id> \
    --certificate-filter-input <json>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace certificate-filters import \
    --request-id <request_id> \
    --certificate-filter-input <json>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace certificate-filters import \
    --resource-version <etag> \
    --certificate-filter-input <json>
```

## search-attributes

The `tcld namespace search-attributes` commands manage [Search Attributes](/search-attribute) of the specified [Namespace](/namespaces) in Temporal Cloud.

Alias: `sa`

- [tcld namespace search-attributes add](#add)
- [tcld namespace search-attributes rename](#rename)

If you wish to delete a Search Attribute, please contact [Support](/cloud/support) at [support.temporal.io](https://support.temporal.io).

### add

The `tcld namespace search-attributes add` command adds custom [Search Attributes](/search-attribute) to a Namespace in Temporal Cloud.

`tcld namespace search-attributes add --search-attribute <value>`

Alias: `a`

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace search-attributes add \
    --namespace <namespace_id> \
    --search-attribute <value>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace search-attributes add \
    --request-id <request_id> \
    --search-attribute <value>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace search-attributes add \
    --resource-version <etag> \
    --search-attribute <value>
```

#### --search-attribute

_Required modifier; can be specified more than once_

Specify a custom Search Attribute in the form "_name_=_type_". Valid values for _type_ are as follows:

- Bool
- Datetime
- Double
- Int
- Keyword
- Text

Alias: `--sa`

**Example**

```bash
tcld namespace search-attributes add \
    --search-attribute "YourSearchAttribute1=Text" \
    --search-attribute "YourSearchAttribute2=Double"
```

### rename

The `tcld namespace search-attributes rename` command renames a custom [Search Attribute](/search-attribute) in Temporal Cloud.

`tcld namespace search-attributes rename --existing-name <value> --new-name <value>`

The following modifiers control the behavior of the command.

#### --namespace

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace search-attributes rename \
    --namespace <namespace_id> \
    --existing-name <value> \
    --new-name <value>
```

#### --request-id

Specify a request identifier to use for the asynchronous operation. If not specified, the server assigns a request identifier.

Alias: `-r`

**Example**

```bash
tcld namespace search-attributes rename \
    --request-id <request_id> \
    --existing-name <value> \
    --new-name <value>
```

#### --resource-version

Specify a resource version (ETag) to update from. If not specified, the latest version is used.

Alias: `-v`

**Example**

```bash
tcld namespace search-attributes rename \
    --resource-version <etag> \
    --existing-name <value> \
    --new-name <value>
```

#### --existing-name

_Required modifier_

Specify the name of an existing Search Attribute.

Alias: `--en`

**Example**

```bash
tcld namespace search-attributes rename \
    --existing-name <value> \
    --new-name <value>
```

#### --new-name

_Required modifier_

Specify a new name for the Search Attribute.

Alias: `--nn`

**Example**

```bash
tcld namespace search-attributes rename \
    --existing-name <value> \
    --new-name <value>
```

## retention

The `tcld namespace retention` commands manage the length of time (in days) a closed Workflow is preserved before deletion for a given Namespace in Temporal Cloud.

Alias: `r`

- [tcld namespace retention get](#get)
- [tcld namespace retention set](#set)

### get

Retrieve the length of time (in days) a closed Workflow will be preserved before deletion for the specified Namespace.

Alias: `g`

The following modifier controls the behavior of the command.

#### --namespace

_Required modifier_

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace retention get \
    --namespace <namespace_id>
```

### set

Set the length of time (in days) a closed Workflow will be preserved before deletion for the specified Namespace.

Alias: `s`

The following modifiers control the behavior of the command.

#### --namespace

_Required modifier_

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

#### --retention-days

_Required modifier_

Specify the number of days a closed Workflow will be preserved before deletion.

Alias: `--rd`

**Example**

```bash
tcld namespace retention set \
    --namespace <namespace_id> \
    --retention-days <retention_days>
```

## update-codec-server

The `tcld namespace update-codec-server` command updates the configuration of a codec server for Temporal Cloud, which allows payloads to be decodec through a remote endpoint.

Alias: `ucs`

The following modifiers control the behavior of the command.

#### --namespace

_Required modifier._

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

**Example**

```bash
tcld namespace update-codec-server \
    --namespace <namespace_id> \
    --endpoint <http_url>
```

#### --endpoint

_Required modifier._

Specify an endpoint to decode payloads for all users interacting with this Namespace.
Endpoints must be valid https URLs.

Alias: `-e`

**Example**

```bash
tcld namespace update-codec-server \
    --namespace <namespace_id> \
    --endpoint <https_url>
```

#### --pass-access-token

Enables a user access token to be passed with the remote endpoint.
This is set to `false` by default.

Alias: `--pat`

**Example**

```bash
tcld namespace update-codec-server \
    --namespace <namespace_id> \
    --endpoint <https_url> \
    --pass-access-token <bool>
```

#### --include-credentials

Enables the inclusion of cross-origin credentials.
This is set to `false` by default.

Alias: `--ic`

**Example**

```bash
tcld namespace update-codec-server \
    --namespace <namespace_id> \
    --endpoint <https_url> \
    --include-credentials true
```

## update-high-availability {#update-high-availability}

The `tcld namespace update-high-availability` command enables you to adjust settings for your [Namespace](/namespaces) with [High Availability features](/cloud/high-availability).
This is set to `false` by default.

Alias: `uha`

The following modifiers control the behavior of the command.

#### --namespace

_Required modifier._

Specify a Namespace hosted on Temporal Cloud. If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

#### --disable-auto-failover

Specify whether Temporal Cloud should perform <ToolTipTerm term="health checks" src="health check" /> and trigger automatic failovers.

Pass `true` or `false` (default).

**Example**

```
tcld namespace update-high-availability \
    --namespace <namespace_id> \
    --disable-auto-failover=true
```

When using API key authentication, add your API credentials before pressing Enter:

```
tcld --api-key <your_api_key> \
    namespace update-high-availability \
    --namespace <namespace_id> \
    --disable-auto-failover=true
```

Alias: `-daf`

## tags

The `tcld namespace tags` commands manage [Tags](/cloud/namespaces#tag-a-namespace) of the specified [Namespace](/namespaces) in Temporal Cloud.

Alias: `t`

- [tcld namespace tags upsert](#upsert)
- [tcld namespace tags remove](#remove)

### upsert

Add new tags or update existing tag values for the specified Namespace.

Alias: `u`

The following modifier controls the behavior of the command.

#### --namespace

_Required modifier_

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

#### --request-id

The request identifier to use for the asynchronous operation.
If not set, the server assigns an identifier.

Alias: `-r`

#### --tag

_Required modifier; can be specified more than once_

A tag in the form "_key_=_value_".

[Tag structure and limits](/cloud/namespaces#tag-structure-and-limits).

Alias: `--t`

**Example**

```bash
tcld namespace tags upsert \
    --namespace <namespace_id> \
    --tag "key1=value1" \
    --tag "key2=updated"
```

### remove

Remove existing tags for the specified Namespace using the key.

Alias: `rm`

The following modifiers control the behavior of the command.

#### --namespace

_Required modifier_

Specify a Namespace hosted on Temporal Cloud.
If not specified, the value of the environment variable $TEMPORAL_CLOUD_NAMESPACE is used.

Alias: `-n`

#### --request-id

The request identifier to use for the asynchronous operation.
If not set, the server assigns an identifier.

Alias: `-r`

#### --tag-key

_Required modifier; can be specified more than once_

A tag key string.

[Tag Key structure and limits](/cloud/namespaces#tag-structure-and-limits).

Alias: `--tk`

**Example**

```bash
tcld namespace tags remove \
    --namespace <namespace_id> \
    --tag-key "key1" \
    --tag-key "key2"
```

## set-connectivity-rules

The `tcld namespace set-connectivity-rules` command enables you to set connectivity rules on your [Namespace](/namespaces).

Alias: `scrs`

#### --connectivity-rule-ids

The list of connectivity rule IDs, can be used in create namespace and update namespace. example: --ids id1 --ids id2 --ids id3.

Alias: `ids`

#### --namespace

The namespace hosted on temporal cloud.

Alias: `n`

#### --remove-all

Acknowledge that all connectivity rules will be removed, enabling connectivity from any source.

---

## tcld nexus command reference

The `tcld nexus` commands manage Nexus resources in Temporal Cloud.

Alias: `nxs`

- [tcld nexus endpoint](#endpoint)

## endpoint

The `tcld nexus endpoint` commands manage Nexus Endpoints in Temporal Cloud.

Alias: `ep`

- [tcld nexus endpoint allowed-namespace](#allowed-namespace)
- [tcld nexus endpoint create](#create)
- [tcld nexus endpoint delete](#delete)
- [tcld nexus endpoint get](#get)
- [tcld nexus endpoint list](#list)
- [tcld nexus endpoint update](#update)

### allowed-namespace

The `tcld nexus endpoint allowed-namespace` commands manage the allowed namespaces for a Nexus Endpoint.

Alias: `an`

- [tcld nexus endpoint allowed-namespace add](#add)
- [tcld nexus endpoint allowed-namespace list](#list)
- [tcld nexus endpoint allowed-namespace remove](#remove)
- [tcld nexus endpoint allowed-namespace set](#set)

#### add

The `tcld nexus endpoint allowed-namespace add` command adds allowed namespaces to a Nexus Endpoint.

Alias: `a`

##### --name

Endpoint name.

Alias: `n`

##### --namespace

Namespace that is allowed to call this endpoint.

Alias: `ns`

##### --request-id

The request-id to use for the asynchronous operation, if not set the server will assign one (optional).

Alias: `r`

##### --resource-version

The resource-version (etag) to update from, if not set the cli will use the latest (optional).

Alias: `v`

#### list

The `tcld nexus endpoint allowed-namespace list` command lists the allowed namespaces of a Nexus Endpoint.

Alias: `l`

##### --name

Endpoint name.

Alias: `n`

#### remove

The `tcld nexus endpoint allowed-namespace remove` command removes allowed namespaces from a Nexus Endpoint.

Alias: `r`

##### --name

Endpoint name.

Alias: `n`

##### --namespace

Namespace that is allowed to call this endpoint.

Alias: `ns`

##### --request-id

The request-id to use for the asynchronous operation, if not set the server will assign one (optional).

Alias: `r`

##### --resource-version

The resource-version (etag) to update from, if not set the cli will use the latest (optional).

Alias: `v`

#### set

The `tcld nexus endpoint allowed-namespace set` command sets the allowed namespaces of a Nexus Endpoint.

Alias: `s`

##### --name

Endpoint name.

Alias: `n`

##### --namespace

Namespace that is allowed to call this endpoint.

Alias: `ns`

##### --request-id

The request-id to use for the asynchronous operation, if not set the server will assign one (optional).

Alias: `r`

##### --resource-version

The resource-version (etag) to update from, if not set the cli will use the latest (optional).

Alias: `v`

### create

The `tcld nexus endpoint create` command creates a new Nexus Endpoint on the Cloud Account.
An endpoint name is used by in workflow code to invoke Nexus operations.
The endpoint target is a worker and `--target-namespace` and `--target-task-queue` must both be provided.
This will fail if an endpoint with the same name is already registered.

Alias: `c`

#### --allow-namespace

Namespace that is allowed to call this endpoint (optional).

Alias: `ans`

#### --description

Endpoint description in markdown format (optional).

Alias: `d`

#### --description-file

Endpoint description file in markdown format (optional).

Alias: `df`

#### --name

Endpoint name.

Alias: `n`

#### --request-id

The request-id to use for the asynchronous operation, if not set the server will assign one (optional).

Alias: `r`

#### --target-namespace

Namespace in which a handler worker will be polling for Nexus tasks on.

Alias: `tns`

#### --target-task-queue

Task Queue in which a handler worker will be polling for Nexus tasks on.

Alias: `ttq`

### delete

The `tcld nexus endpoint delete` command deletes a Nexus Endpoint on the Cloud Account.
.

Alias: `d`

#### --name

Endpoint name.

Alias: `n`

#### --request-id

The request-id to use for the asynchronous operation, if not set the server will assign one (optional).

Alias: `r`

#### --resource-version

The resource-version (etag) to update from, if not set the cli will use the latest (optional).

Alias: `v`

### get

The `tcld nexus endpoint get` command gets a Nexus Endpoint configuration by name from the Cloud Account.

Alias: `g`

#### --name

Endpoint name.

Alias: `n`

### list

The `tcld nexus endpoint list` command lists all Nexus Endpoint configurations on the Cloud Account.

Alias: `l`

### update

The `tcld nexus endpoint update` command updates an existing Nexus Endpoint on the Cloud Account.
An endpoint name is used by in workflow code to invoke Nexus operations.
The endpoint target is a worker and `--target-namespace` and `--target-task-queue` must both be provided.

The endpoint is patched leaving any existing fields for which flags are not provided as they were.

Alias: `u`

#### --description

Endpoint description in markdown format (optional).

Alias: `d`

#### --description-file

Endpoint description file in markdown format (optional).

Alias: `df`

#### --name

Endpoint name.

Alias: `n`

#### --request-id

The request-id to use for the asynchronous operation, if not set the server will assign one (optional).

Alias: `r`

#### --resource-version

The resource-version (etag) to update from, if not set the cli will use the latest (optional).

Alias: `v`

#### --target-namespace

Namespace in which a handler worker will be polling for Nexus tasks on (optional).

Alias: `tns`

#### --target-task-queue

Task Queue in which a handler worker will be polling for Nexus tasks on (optional).

Alias: `ttq`

#### --unset-description

Unset endpoint description.

---

## tcld request command reference

The `tcld request` commands manage asynchronous requests in Temporal Cloud.

Alias: `r`

- [tcld request get](#get)

## get

The `tcld request get` command gets the status of the specified request in Temporal Cloud.

`tcld request get --request-id <request_id>`

Alias: `g`

The following modifiers control the behavior of the command.

#### --request

_Required modifier_

Specify a request identifier.

Alias: `-r`

**Example**

```bash
tcld request get --request-id <request_id>
```

---

## tcld user command reference

The `tcld user` commands manage users in Temporal Cloud.

Alias: `u`

- [tcld user delete](#delete)
- [tcld user get](#get)
- [tcld user invite](#invite)
- [tcld user list](#list)
- [tcld user resend-invite](#resend-invite)
- [tcld user set-account-role](#set-account-role)
- [tcld user set-namespace-permissions](#set-namespace-permissions)

## delete

The `tcld user delete` command deletes the specified user in Temporal Cloud.
You must set either `--user-email` or `--user-id` to specify the user to be deleted.

Alias: `d`

The following modifiers control the behavior of the command.

#### --user-email

Specify the email address of the user to delete.

**Example**

```command
tcld user delete --user-email <test@example.com>
```

#### --user-id

Specify the user identifier of the user to delete.

**Example**

```command
tcld user delete --user-id <test-user-id>
```

#### --request-id

The request identifier to use for the asynchronous operation.

If not set, the server assigns an identifier.

Alias: `-r`

#### --resource-version

Specify a resource version (ETag) to update from.
If not specified, the latest version is used.

Alias: `-v`

## get

The `tcld user get` command gets information about the specified user in Temporal Cloud.
You must set either `--user-email` or `--user-id`.

Alias: `g`

The following modifiers control the behavior of the command.

#### --user-email

Specify the email address of the user to get information about.

**Example**

```command
tcld user delete --user-email <test@example.com>
```

#### --user-id

Specify the user identifier of the user to get information about.

**Example**

```command
tcld user delete --user-id <test-user-id>
```

## invite

The `tcld namespace invite` command invites the specified user to join Temporal Cloud.

Alias: `i`

The following modifiers control the behavior of the command.

#### --user-email

_Required modifier_

Specify the email address of the user to be invited.
You can supply this modifier multiple times to invite multiple users in a single request.

Alias: `-e`

#### --account-role

_Required modifier_

Specify the [account-level Role](/cloud/users#account-level-roles) for the invited user.

Available account roles: `admin` | `developer` | `read`.

Alias: `--ar`

#### --namespace-permission

Specify the [Namespace-level permissions](/cloud/users#namespace-level-permissions) for the invited user.
You can supply this modifier multiple times to set multiple Namespace permissions in a single request.

Each value must be in the format of `namespace=permission-type`.

Available namespace permissions: `Admin` | `Write` | `Read`.

Alias: `-p`

#### --request-id

The request identifier to use for the asynchronous operation.

If not set, the server assigns an identifier.

Alias: `-r`

```command
tcld user invite --user-email <test@example.com> --account-role developer --namespace-permission ns1=Admin --namespace-permission ns2=Write --request-id <123456>
```

## list

The `tcld user list` command returns a paginated list of users in Temporal Cloud.

Alias: `l`

**Example**

```command
tcld user list
```

The following modifiers control the behavior of the command.

#### --namespace

List users that have permissions to the Namespace.

Alias: `-n`

**Example**

```command
tcld user list --namespace <namespace_id>
```

#### --page-token

Page token for paging list users request.

Alias: `-p`

#### --page-size

Page size for paging list users request.

Defaults to 10.

Alias: `-s`

## resend-invite

The `tcld user resend-invite` command resends an invitation to the specified user in Temporal Cloud.
You must set either `--user-email` or `--user-id` to specify the user to receive another invitation.

Alias: `ri`

The following modifiers control the behavior of the command.

#### --user-email

Specify the email address of the user to resend an invitation to.

**Example**

```bash
tcld user resend-invite --user-email <test@example.com>
```

#### --user-id

Specify the user identifier of the user to resend an invitation to.

**Example**

```bash
tcld user resend-invite --user-id <test-user-id>
```

#### --request-id

The request identifier to use for the asynchronous operation.

If not set, the server assigns an identifier.

Alias: `-r`

## set-account-role

The `tcld user set-account-role` command sets an [account-level Role](/cloud/users#account-level-roles) for the specified user in Temporal Cloud.
You must set either `--user-email` or `--user-id`.

Alias: `ri`

The following modifiers control the behavior of the command.

#### --account-role

_Required modifier_

Specify the account-level Role to assign to the user.

Available account roles: `admin` | `developer` | `read`.

Alias: `-ar`

#### --user-email

Specify the email address of the user to assign an account-level Role to.

Alias: `-e`

**Example**

```command
tcld user set-account-role --user-email <test@example.com> --account-role Developer
```

#### --user-id

Specify the user identifier of the user to assign an account-level Role to.

Alias: `--id`

**Example**

```command
tcld user set-account-role --user-id <test-user-id> --account-role Developer
```

#### --request-id

The request identifier to use for the asynchronous operation.

If not set, the server assigns an identifier.

Alias: `-r`

#### --resource-version

Specify a resource version (ETag) to update from.
If not specified, the latest version is used.

Alias: `-v`

## set-namespace-permissions

The `tcld user set-namespace-permissions` command sets [Namespace-level permissions](/cloud/users#namespace-level-permissions) for a specified user in Temporal Cloud.
You must set either `--user-email` or `--user-id`.

Alias: `snp`

The following modifiers control the behavior of the command.

#### --user-email

Specify the email address of the user to assign Namespace-level permissions to.

**Example**

```command
tcld user set-namespace-permissions --user-email <test@example.com>
```

#### --user-id

Specify the user identifier of the user to assign Namespace-level permissions to.

**Example**

```command
tcld user set-namespace-permissions --user-id <test-user-id>
```

#### --request-id

The request identifier to use to assign Namespace-level permissions to.

If not set, the server assigns an identifier.

Alias: `-r`

#### --resource-version

Specify a resource version (ETag) to assign Namespace-level permissions to.
If not specified, the latest version is used.

Alias: `-v`

#### --namespace-permission

Specify the [Namespace-level permissions](/cloud/users#namespace-level-permissions) for the invited user.
You can supply this modifier multiple times to set multiple Namespace permissions in a single request.

Each value must be in the format of `namespace=permission-type`.

Available namespace permissions: `Admin` | `Write` | `Read`.

Alias: `-p`

---

## tcld version command reference

The `tcld version` command gets version information about tcld.

Alias: `v`

`tcld version`

The command has no modifiers.

---

## Temporal Cloud Terraform provider

The Terraform Temporal Cloud provider allows you to use Terraform to manage resources for Temporal Cloud.
The Terraform tool manages infrastructure as code (IaC).
With this provider, you can use Terraform to automate Temporal Cloud resource management, including Namespaces, Users, Service Accounts, API Keys and more.

:::note Terraform Management

Once a resource is managed by Terraform, you should only use Terraform to manage that resource.

:::

Resources:

- The [Temporal Cloud Terraform provider](https://registry.terraform.io/providers/temporalio/temporalcloud/latest) is available in the Terraform Registry, where you can find detailed documentation on the Provider's supported resources and data sources.
- The GitHub repository for the Terraform provider is [terraform-provider-temporalcloud](https://github.com/temporalio/terraform-provider-temporalcloud/tree/main), where you can report bugs, provide feature requests, and [contribute](https://github.com/temporalio/terraform-provider-temporalcloud/blob/main/CONTRIBUTING.md) to the provider.
  We encourage your input as we develop the provider with the community.
- To view the list of available Temporal Cloud resources supported by Terraform provider, visit the resources section of the Terraform documentation in Hashi's [registry](https://registry.terraform.io/providers/temporalio/temporalcloud/latest/docs).

### Prerequisites

To use the Terraform provider, you'll need the following:

- A [Terraform account](https://developer.hashicorp.com/terraform)
- The [Terraform CLI](https://developer.hashicorp.com/terraform/cli)
- An [API Key](/cloud/api-keys): an API Key is required to use the Terraform provider.
  - See [the API docs](https://docs.temporal.io/cloud/api-keys#generate-an-api-key) for instructions on generating an API Key.

:::note OpenTofu Registry

Our Terraform Provider is registered with [OpenTofu](https://opentofu.org), but that registration is not maintained or managed by Temporal Technologies.

:::

## Setup

Generate an [API Key](https://docs.temporal.io/cloud/api-keys#generate-an-api-key) to authenticate Terraform operations with your Temporal Cloud account or a Service Account.
Then, either use an environmental variable or pass the API Key into the provider manually to manage your Temporal Cloud Terraform resources.

Follow these examples to use an environmental variable to pass in your API Key to the provider.

<Tabs>
  <TabItem value="macos" label="macOS" default>
Export your environment variable for secure access to the API Keys.

```bash
# replace <your-secret-key> with the "secretKey": output from tcld apikey create command
export TEMPORAL_API_KEY=<your-secret-key>
```

:::tip ENVIRONMENT VARIABLES

Do not confuse environment variables, set with your shell, with temporal env options.

:::

</TabItem>
  <TabItem value="windows" label="Windows">
Export your environment variable for secure access to the API Keys.

```bash
# replace <your-secret-key> with the "secretKey": output from tcld apikey create command
set TEMPORAL_API_KEY=<your-secret-key>
```

:::tip ENVIRONMENT VARIABLES

Do not confuse environment variables, set with your shell, with temporal env options.

:::

</TabItem>
</Tabs>

Or, pass it in manually in your .tf file using the provider code block

```yml
provider "temporalcloud" {
  api_key = "my-temporalcloud-api-key"
}
```

## Manage Temporal Cloud Namespaces with Terraform

Terraform is a great way to automate the management of Temporal Namespaces.
It doesn't matter whether you want management to be centralized within a platform team or federated to different product teams.
The provider allows you to import, create, update, and delete Namespaces with Terraform.

You must use an Identity with Temporal Cloud Namespace management privileges.
This includes the Account Owner, Global Admin, or Developer Account Role.

**How do I create a Namespace with Terraform?**

1. Create a Terraform configuration file (`terraform.tf`) to define a Namespace.

   ```yml
   terraform {
     required_providers {
       temporalcloud = {
         source = "temporalio/temporalcloud"
       }
     }
   }

   provider "temporalcloud" {

   }

   resource "temporalcloud_namespace" "namespace" {
     name               = "terraform"
     regions            = ["aws-us-east-1"]
     accepted_client_ca = base64encode(file("ca.pem"))
     retention_days     = 14
   }
   ```

   In this example, you create a Temporal Cloud Namespace named `terraform`, specifying the AWS region `aws-us-east-1`, and specifying the path to the CA certificate.

1. Initialize the Terraform provider.

   Run the following command to initialize the Terraform provider.

   ```bash
   terraform init
   ```

1. Apply the Terraform configuration.

   Once initialization occurs, apply the Terraform configuration to your Temporal Cloud account.

   ```bash
   terraform apply
   ```

Follow the onscreen prompts.

Upon completion, you'll see a success message indicating your Namespace is created.

```bash
temporalcloud_namespace.terraform: Creation complete after 2m17s [id=<your-namespace>]
```

You can find more examples of Namespace management in the Terraform Provider docs located on HashiCorp's [Terraform Registry](https://registry.terraform.io/providers/temporalio/temporalcloud/latest/docs/resources/namespace).
The Terraform Provider docs show how to generate CA certs within Terraform configuration files and create a Namespace with API Key based authentication.

**How do I validate the creation of the Namespace?**

You can validate the creation of the Namespace through the Temporal Web UI or through the `tcld namespace get` command.

**Using the Temporal Web UI**

1. Log into the Temporal Cloud Web UI.
1. Navigate to the Namespaces page.
1. Search for the Namespace you created.

**Using the tcld CLI utility**

Validate the creation of your Namespace through the Terraform provider.
To validate see your Namespace in the Cloud UI or through the `tcld namespace get` command.
Run the `tcld namespace get` command and pass in your [Cloud Namespace Name](/cloud/namespaces#temporal-cloud-namespace-name) and [Cloud Account Id](/cloud/namespaces#temporal-cloud-account-id):

```bash
tcld namespace get -n "<your-namespace>.<your-account-id>"
```

**How do I update a Temporal Cloud Namespace?**

Terraform automatically recognizes changes made within `.tf` files and applies those changes to Temporal.

For example, change the retention period setting in the Terraform file from the previous example and watch Terraform apply the change without any additional steps required by you.

1. Set the retention period to 30 days.

   ```yml
   terraform {
     required_providers {
       temporalcloud = {
         source = "temporalio/temporalcloud"
         version = ">= 0.0.6"
       }
     }
   }

   provider "temporalcloud" {

   }

   resource "temporalcloud_namespace" "namespace" {
     name               = "terraform"
     regions            = ["aws-us-east-1"]
     accepted_client_ca = base64encode(file("ca.pem"))
     retention_days     = 30
   }
   ```

1. Apply your configuration.
   When prompted, answer yes to continue:

   ```command
   terraform apply
   ```

Upon completion, you will see a success message indicating your Namespace has been updated.
It may take several minutes to update a Namespace.

```text
temporalcloud_namespace.namespace: Modifications complete after 10s [id=terraform.a1bb2]
```

**How do I delete a Temporal Cloud Namespace?**

To delete the Namespace, run the following command and answer yes when prompted:

```bash
terraform destroy
```

:::note Preventing Deletion

You can prevent deletion of any Terraform resource by including the `prevent_destroy` argument in the Terraform configuration file.

:::

**How do I import a Temporal Cloud Namespace?**

If you have an existing Namespace in Temporal Cloud, you can import it into Terraform to manage the Namespace from Terraform using the `terraform import` command.

1. Provide a configuration placeholder in your Terraform configuration.

   ```yml
   resource "temporalcloud_namespace" "namespace" {
   }
   ```

1. Run the `terraform import` command from the command line and pass in the Namespace ID.
   Your Namespace ID is available at the top of the Namespace's page in the Temporal Cloud UI and is in the format `namespaceid.acctid`.

   ```bash
   terraform import temporalcloud_namespace.terraform namespaceid.acctid
   ```

The Namespace is now a part of the Terraform state and all changes to the Namespace should be managed by Terraform.

:::caution

Once a resource has been imported into Terraform, outside changes to the resource will create Terraform "drift" errors on subsequent Terraform operations.

:::

## Manage Temporal Cloud Nexus Endpoints with Terraform

Terraform provides a great way to automate the management of [Nexus Endpoints](/nexus/endpoints).
The provider allows you to import, create, update, and delete Nexus Endpoints with Terraform.

You must use an Identity with [Developer role (or higher)](/cloud/users#account-level-roles) and [Namespace Admin permission](/cloud/users#namespace-level-permissions) on the Endpoint's target Namespace.

**How do I create a Nexus Endpoint with Terraform?**

1. Create a Terraform configuration file (`terraform.tf`) to define a Nexus Endpoint.

   From the [example in the Terraform Registry](https://registry.terraform.io/providers/temporalio/temporalcloud/latest/docs/resources/nexus_endpoint):

   ```yml
   terraform {
     required_providers {
       temporalcloud = {
         source = "temporalio/temporalcloud"
       }
     }
   }

   provider "temporalcloud" {

   }

   resource "temporalcloud_namespace" "target_namespace" {
     name           = "terraform-target-namespace"
     regions        = ["aws-us-west-2"]
     api_key_auth   = true
     retention_days = 14
     timeouts {
       create = "10m"
       delete = "10m"
     }
   }

   resource "temporalcloud_namespace" "caller_namespace" {
     name           = "terraform-caller-namespace"
     regions        = ["aws-us-east-1"]
     api_key_auth   = true
     retention_days = 14
     timeouts {
       create = "10m"
       delete = "10m"
     }
   }

   resource "temporalcloud_namespace" "caller_namespace_2" {
     name           = "terraform-caller-namespace-2"
     regions        = ["gcp-us-central1"]
     api_key_auth   = true
     retention_days = 14
     timeouts {
       create = "10m"
       delete = "10m"
     }
   }

   resource "temporalcloud_nexus_endpoint" "nexus_endpoint" {
     name        = "terraform-nexus-endpoint"
     description = <<-EOT
       Service Name:
         my-hello-service
       Operation Names:
         echo
         say-hello

       Input / Output arguments are in the following repository:
       https://github.com/temporalio/samples-go/blob/main/nexus/service/api.go
     EOT
     worker_target = {
       namespace_id = temporalcloud_namespace.target_namespace.id
       task_queue   = "terraform-task-queue"
     }
     allowed_caller_namespaces = [
       temporalcloud_namespace.caller_namespace.id,
       temporalcloud_namespace.caller_namespace_2.id,
     ]
   }
   ```

   In this example, 3 Namespaces are created:
   - target Namespace for a Nexus Endpoint - Nexus requests will be routed to a Worker that polls the target Namespace.
   - caller Namespace(s) - Nexus Operations are invoked from caller Namespace, for example from a caller Workflow.

   These Namespaces are referenced in the [Nexus Endpoint](/nexus/endpoints) configuration:
   - `worker_target` (Namespace and Task Queue) - currently only a single worker_target is supported.
   - `allowed_caller_namespaces` - used to enforce Nexus Endpoint [runtime access controls](/nexus/security#runtime-access-controls).

1. Initialize the Terraform provider.

   Run the following command to initialize the Terraform provider.

   ```bash
   terraform init
   ```

1. Apply the Terraform configuration.

   Once initialization occurs, apply the Terraform configuration to your Temporal Cloud account.

   ```bash
   terraform apply
   ```

   Follow the onscreen prompts.

   Upon completion, you'll see a success message indicating 3 Namespaces and a Nexus Endpoint are created.

   ```bash
   temporalcloud_nexus_endpoint.nexus_endpoint: Creation complete after 2s [id=b158063be978471fa1d200569b03834d]
   ```

You can find more examples of Nexus Endpoint management in the Terraform Provider docs located on HashiCorp's [Terraform Registry](https://registry.terraform.io/providers/temporalio/temporalcloud/latest/docs/resources/nexus_endpoint).
The Terraform Provider docs show how to generate CA certs within Terraform configuration files and create a Namespace with API Key based authentication.

**How do I validate the creation of the Nexus Endpoint?**

You can validate the creation of the Nexus Endpoint through the Temporal Web UI or through the `tcld nexus endpoint get` command.

**Using the Temporal Web UI**

1. Log into the Temporal Cloud Web UI.
1. Navigate to [the Nexus page](https://cloud.temporal.io/nexus).
1. Search for the Nexus Endpoint you created, using only the Nexus Endpoint Name (without an account suffix).

**Using the tcld CLI utility**

Validate the creation of your Nexus Endpoint through the Terraform provider.
To validate see your Nexus Endpoint in the Cloud UI or through the `tcld nexus endpoint get` command.

Run the below command using your Nexus Endpoint Name.
Do not use the account ID suffix with this endpoint name:

```bash
tcld nexus endpoint get -n "<your-nexus-endpoint-name-without-account-suffix>"
```

**How do I update a Nexus Endpoint?**

Terraform automatically recognizes changes made within `.tf` files and applies those changes to Temporal.

For example, to change the allowed caller Namespaces on a Nexus Endpoint:

1. Add or remove allowed caller Namespaces by updating the Nexus Endpoint configuration, for example by removing `caller_namespace_2` from the configuration above:

   ```yml
   resource "temporalcloud_nexus_endpoint" "nexus_endpoint" {
     name        = "terraform-nexus-endpoint"
     description = <<-EOT
       Service Name:
         my-hello-service
       Operation Names:
         echo
         say-hello

       Input / Output arguments are in the following repository:
       https://github.com/temporalio/samples-go/blob/main/nexus/service/api.go
     EOT
     worker_target = {
       namespace_id = temporalcloud_namespace.target_namespace.id
       task_queue   = "terraform-task-queue"
     }
     allowed_caller_namespaces = [
       temporalcloud_namespace.caller_namespace.id
     ]
   }
   ```

1. Apply your configuration.
   When prompted, answer yes to continue:

   ```command
   terraform apply
   ```

   Upon completion, you will see a success message indicating your Nexus Endpoint has been updated.
   It may take several seconds to update a Nexus Endpoint in the control plane which is visibile from the Temporal UI or tcld CLI.
   Propagation of Nexus Endpoint changes to the data plane may take longer, but usually complete in less than one minute.

   ```text
   temporalcloud_nexus_endpoint.nexus_endpoint: Modifications complete after 1s [id=b158063be978471fa1d200569b03834d]
   ```

**How do I delete a Nexus Endpoint?**

To delete the Nexus Endpoint, run the following command and answer yes when prompted:

```bash
terraform destroy
```

Upon completion, you will see a success message indicating all resources have been deleted.

```text
Destroy complete! Resources: 4 destroyed.
```

**How do I import a Temporal Cloud Nexus Endpoint?**

If you have an existing Nexus Endpoint in Temporal Cloud, you can import it into Terraform to manage the Nexus Endpoint from Terraform using the `terraform import` command.

1. Initialize the Terraform provider in a new directory.

   Run the following command to initialize the Terraform provider.

   ```bash
   terraform init
   ```

1. Provide a configuration placeholder in your Terraform configuration and ensure you've included your [API key](#setup).

   ```yml
   terraform {
     required_providers {
       temporalcloud = {
         source = "temporalio/temporalcloud"
       }
     }
   }

   provider "temporalcloud" {
   }

   resource "temporalcloud_nexus_endpoint" "nexus_endpoint" {
   }
   ```

1. Run the `terraform import` command from the command line and pass in the Nexus Endpoint ID.

   ```bash
   terraform import temporalcloud_nexus_endpoint <your-nexus-endpoint-ID>
   ```

   Your Nexus Endpoint ID is available at the top of the Nexus Endpoint's page in the [Temporal Cloud UI](https://cloud.temporal.io/nexus).

   <CaptionedImage src="/img/cloud/nexus/nexus-endpoint-id.png" title="Nexus Endpoint ID" width="100%" zoom="false" />

   Upon completion, you will see a success message indicating the Nexus Endpoint was imported.

   ```text
   temporalcloud_nexus_endpoint.nexus_endpoint: Refreshing state... [id=3c0c75ccfa8144b092c13ce632463761]

   Import successful!
   ```

The Nexus Endpoint is now a part of the Terraform state and all changes to the Nexus Endpoint should be managed by Terraform.

:::caution

Once a resource has been imported into Terraform, outside changes to the resource will create Terraform "drift" errors on subsequent Terraform operations.

:::

## Manage Temporal Cloud Users with Terraform

Manage Temporal Cloud Users with the same process you use to manage Namespaces with Terraform.
The following examples create, update, delete, and import Temporal Cloud Users with `terraform apply` commands on the Terraform configuration file.

:::note User Management

Cautions about Temporal User management:

- Terraform can't manage the Temporal Account Owner role.
  While you can import an Account Owner to Terraform, you cannot create, update, or delete an Account Owner with Terraform.
- Right now, you can't manage a user's access to a Namespace from the Namespace resource.
  You must manage Namespace access from the User resource.
  This is also true for Service Accounts.
- Account Owners and Global Admins automatically gain access to all Namespaces in Temporal.
  Therefore, you cannot specify Namespace access for these roles.
  This is also true for Service Accounts.
- Follow Terraform best practices for resource management.
  Manage a specific user in one and only one .tf file.
  There's a risk that you may overwrite a user's permissions if you don't.
- To Import a user, you'll need the User's ID which is currently not available in the Temporal Cloud UI.
  You can fetch current User ID by running the `tcld user list` command.

:::

**How do I create a Temporal Cloud User with Terraform?**

1. Add a Terraform User resources configuration to your Terraform file.

   ```yml
   terraform {
     required_providers {
       temporalcloud = {
         source = "temporalio/temporalcloud"
       }
     }
   }

   provider "temporalcloud" {

   }

   resource "temporalcloud_namespace" "namespace" {
     name               = "terraform"
     regions            = ["aws-us-east-1"]
     accepted_client_ca = base64encode(file("ca.pem"))
     retention_days     = 14
   }

   resource "temporalcloud_user" "global_admin" {
     email          = <admin-email>
     account_access = "Admin"
   }

   resource "temporalcloud_user" "namespace_admin" {
     email          = <developer-email>
     account_access = "Developer"
     namespace_accesses = [
       {
         namespace_id = temporalcloud_namespace.namespace.id
         permission = "Write"
       }
     ]
   }
   ```

   Replace the email and domain values with your Temporal Cloud User email and domain.

1. Apply your configuration.
   When prompted, answer yes to continue:

   ```command
   terraform apply
   ```

Upon completion, you will see a success message indicating your User has been created.

```text
temporalcloud_user.namespace_admin: Creation complete after 1s [id=12a34bc5678910d38d9e8390636e7412]
Apply complete! Resources: 2 added, 0 changed, 0 destroyed.
```

**How do I update a Temporal Cloud User with Terraform?**

To update a User with Terraform, follow the same steps used to create a User.

**How do I delete a Temporal Cloud User with Terraform?**

To delete a User with Terraform, remove the Terraform User resources configuration from your Terraform file and run the `terraform apply` command.

1. Remove the Terraform User resources configuration from your Terraform file.

   ```yml
   terraform {
     required_providers {
       temporalcloud = {
         source = "temporalio/temporalcloud"
         version = ">= 0.0.6"
       }
     }
   }

   provider "temporalcloud" {

   }

   resource "temporalcloud_namespace" "namespace" {
     name               = "terraform"
     regions            = ["aws-us-east-1"]
     accepted_client_ca = base64encode(file("ca.pem"))
     retention_days     = 14
   }

   resource "temporalcloud_user" "global_admin" {
     email          = <admin-email>
     account_access = "Admin"
   }

   # resource "temporalcloud_user" "namespace_admin" {
   #   email          = <developer-email>
   #   account_access = "Developer"
   #   namespace_accesses = [
   #     {
   #       namespace_id = temporalcloud_namespace.namespace.id
   #       permission = "Write"
   #     }
   #   ]
   # }
   ```

1. Run the `terraform apply` command.
   When prompted, answer yes to continue:

   ```command
   terraform apply
   ```

Upon completion, you will see a success message indicating your User has been deleted.

```text
temporalcloud_user.namespace_admin: Destruction complete after 2s
Apply complete! Resources: 0 added, 0 changed, 1 destroyed.
```

**How do I import a Temporal User?**
If you have an existing User in Temporal Cloud, you can import it into Terraform using the `terraform import` command.

1. Provide a configuration placeholder in your Terraform configuration.

   ```yml
   resource "temporalcloud_user" "user" {
   }
   ```

````
1. Run the `terraform import` command and pass in the User ID
 Your User ID is available using the Temporal Cloud CLI `tcld u l` command.

 ```bash
 terraform import temporalcloud_user.user 72360058153949edb2f1d47019c1e85f
````

The User is now a part of the Terraform state and all changes to the User should be managed by Terraform.

## Manage Temporal Cloud Service Accounts with Terraform

The process and steps to managing a Service Account with Terraform are very similar to managing a User with Terraform with a few small differences:

- Service Accounts use the Service Account Terraform resource not the User resource.
- Service Accounts do not have email addresses, they have names instead.
  This means you should specify a name for a Service Account instead of an email.

Everything else about managing Services Accounts with Terraform follows the same process, guidance, and limitations of managing Users with Terraform.

## Manage Temporal Cloud API Keys with Terraform

You can manage your own, personal API Keys and Service Account API Keys with Terraform.
The process and steps to managing an API Key with Terraform are very similar to managing other resources with Terraform.
You can create, delete, update and import API Keys with Terraform.
One difference between working with API Keys as a Terraform resource compared to other Temporal Cloud resources is the need to access an API Keys secure token output from Terraform.
Walk through the process of securely accessing the API Key Token in the Create section of this guide.

:::note Limits and Best Practices

- See the API Key [documentation](https://docs.temporal.io/cloud/api-keys) for information about the limits and best practices for managing API Keys.
- See Terraform's documentation on working with [sensitive data](https://www.terraform.io/docs/language/values/variables.html#sensitive-values) for more information on how to manage sensitive data in Terraform.

:::

**How do I create a Temporal Cloud API Key with Terraform?**

1. Add a Terraform API Key resources configuration to your Terraform file.

   ```yml
   terraform {
     required_providers {
       temporalcloud = {
         source = "temporalio/temporalcloud"
       }
     }
   }

   provider "temporalcloud" {

   }

   resource "temporalcloud_service_account" "global_service_account" {
     name           = "admin"
     account_access = "Admin"
   }

   resource "temporalcloud_apikey" "global_apikey" {
     display_name = "admin"
     owner_type   = "service-account"
     owner_id     = temporalcloud_service_account.global_service_account.id
     expiry_time  = "2024-11-01T00:00:00Z"
     disabled     = false
   }
   ```

   Make sure to:

   - Replace the display_name, expiry_time, and disabled values with your Temporal Cloud API Key configuration.
   - Replace the owner_type and owner_id values with your Temporal Cloud Service Account or other Identity information.

1. Create an output.tf file and add the following code to output the API Key Token.

   ```yml
   output "apikey_token" {
     value = temporalcloud_apikey.global_apikey.token
     sensitive = true
   }
   ```

1. Apply your configuration.
   When prompted, answer yes to continue:

   ```command
   terraform apply
   ```

   Upon completion, you will see a success message indicating the API Key has been created.

   ```text
   temporalcloud_apikey.global_apikey: Creation complete after 1s [id=kayBf38JIWkMPmnfr59iEIaEk2L7uqR4]
   ```

1. Access the API Key Token securely.
   You'll notice that if you view the state for the API Key resource, the token value is not displayed.

   ```bash
   terraform state show temporalcloud_apikey.global_apikey

   # temporalcloud_apikey.global_apikey:
   resource "temporalcloud_apikey" "global_apikey" {
       disabled     = false
       display_name = "adminKey3"
       expiry_time  = "2024-12-01T00:00:00Z"
       id           = "kayBf38JIWkMPmnfr59iEIaEk2L7uqR4"
       owner_id     = "b81336a6097449cba75c2e5500df3d31"
       owner_type   = "service-account"
       state        = "active"
       token        = (sensitive value)
   }
   ```

To access the token, you can use the Terraform output command.

```bash
terraform output -json apikey_token
```

This will display the token value in the terminal.

:::info Security and API Keys

Remember, keep your Terraform state files secure if you're managing API Keys with Terraform.
The state file contains sensitive information, like the API Key Token, that should not be shared or exposed.

:::

**How do I update a Temporal Cloud API Key with Terraform?**

To update an API Key with Terraform, follow the same steps used to create an API Key.

:::note Editing Fields

You can only edit an API Key's name or description field.
Updating an API Key does not generate a new secure token

:::

**How do I delete a Temporal Cloud API Key with Terraform?**

To delete an API Key with Terraform, remove the Terraform API Key resources configuration from your Terraform and output.tf files and run the `terraform apply` command.

**How do I Import a Temporal API Key?**

You cannot import an API Key into Terraform.
Once created, the API Key secret isn't stored and can't be retrieved, so you can't access it using import.

Instead, Temporal recommends creating a new API Key using Terraform directly.

## Data Sources - Regions and Namespaces

The Terraform provider also supports 2 data sources that provide you access to the available Regions and Namespaces in your Temporal Cloud account.

:::note Terraform Data Sources

See Terraform [documentation](https://developer.hashicorp.com/terraform/language/data-sources) to learn more about Terraform Data Sources

:::

For example, to retrieve a list of regions available for your account, you can use the regions data_source

```yml
data "temporalcloud_regions" "regions" {}

output "regions" {
  value = data.temporalcloud_regions.regions.regions
}
```

## Community Involvement

Do you have feedback about the provider? Want to report a bug or request a feature? We'd love to hear from you.

- Please reach out to us in the Temporal Community [Slack](https://join.slack.com/t/temporalio/shared_invite/zt-2u2ey8ilu-LRxnd3PSoAk9GZ94UuzoBA) in the #terraform channel
- Feel free to create issues and contribute PRs in the Temporal Terraform [GitHub repository](https://github.com/temporalio/terraform-provider-temporalcloud/tree/main)

---

## Worker health - Temporal Cloud feature guide

This page is a guide to monitoring a Temporal Worker fleet and covers the following scenarios:

- [Configuring minimal observations](#minimal-observations)
- [How to detect a backlog of Tasks](#detect-task-backlog)
- [How to detect greedy Worker resources](#detect-greedy-workers)
- [How to detect misconfigured Workers](#detect-misconfigured-workers)
- [How to configure Sticky cache](#configure-sticky-cache)

## Minimal Observations {#minimal-observations}

These alerts should be configured and understood first to gain intelligence into your application health and behaviors.

1. Create monitors and alerts for Schedule-To-Start latency SDK metrics (both [Workflow Executions](/references/sdk-metrics#workflow_task_schedule_to_start_latency) and [Activity Executions](/references/sdk-metrics#activity_schedule_to_start_latency)).
   See [Detect Task backlog section](#detect-task-backlog) to explore [sample queries](#prometheus-query-samples) and appropriate responses that accompany these values.

- Alert at >200ms for your p99 value
- Plot >100ms for your p95 value

2. Create a [Grafana](/cloud/metrics/prometheus-grafana) panel called Sync Match Rate.
   See the [Sync Match Rate section](#sync-match-rate) to explore example queries and appropriate responses that accompany these values.

- Alert at \<95% for your p99 value
- Plot \<99% for your p95 value

3. Create a [Grafana](/cloud/metrics/prometheus-grafana) panel called Poll Success Rate.
   See the [Detect greedy Workers section](#detect-greedy-workers) for example queries and appropriate responses that accompany these values.

- Alert at \<90% for your p99 value
- Plot \<95% for your p95 value

The following alerts build on the above to dive deeper into specific potential causes for Worker related issues you might be experiencing.

1. Create monitors and alerts for the [temporal_worker_task_slots_available](/references/sdk-metrics#worker_task_slots_available) SDK metric.
   See the [Detect misconfigured Workers section](#detect-misconfigured-workers) for appropriate responses based on the value.

- Alert at 0 for your p99 value

2. Create monitors for the [temporal_sticky_cache_size](/references/sdk-metrics#sticky_cache_size) SDK metric.
   See the [Configure Sticky Cache section](#configure-sticky-cache) for more details on this configuration.

- Plot at \{value\} > \{WorkflowCacheSize.Value\}

3. Create monitors for the [temporal_sticky_cache_total_forced_eviction](/references/sdk-metrics#sticky_cache_total_forced_eviction) SDK metric.
   This metric is available in the Go SDK, and the Java SDK only.
   See the [Configure Sticky Cache section](#configure-sticky-cache) for more details and appropriate responses.

- Alert at >\{predetermined_high_number\}

## Detect Task Backlog {#detect-task-backlog}

**How to detect a backlog of Tasks.**

Metrics to monitor:

- **SDK metric**: [workflow_task_schedule_to_start_latency](/references/sdk-metrics#workflow_task_schedule_to_start_latency)
- **SDK metric**: [activity_schedule_to_start_latency](/references/sdk-metrics#activity_schedule_to_start_latency)
- **Temporal Cloud metric**: [temporal_cloud_v0_poll_success_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_poll_success_count)
- **Temporal Cloud metric**: [temporal_cloud_v0_poll_success_sync_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_poll_success_sync_count)

### Schedule To Start latency

The Schedule-To-Start metric represents how long Tasks are staying unprocessed, in the Task Queues.
But differently, it is the time between when a Task is enqueued and when it is picked up by a Worker.
This time being long (likely) means that your Workers can't keep up — either increase the number of Workers (if the host load is already high) or increase the number of pollers per Worker.

If your Schedule-To-Start latency alert triggers or is high, check the [Sync Match Rate](#sync-match-rate) to decide if you need to adjust your Worker or fleet, or contact Temporal Cloud support.
If your Sync Match Rate is low, contact [Temporal Cloud support](/cloud/support#support-ticket).
If your Sync Match Rate is low, you can contact Temporal Cloud support.

The schedule_to_start_latency SDK metric for both [Workflow Executions](/references/sdk-metrics#workflow_task_schedule_to_start_latency) and [Activity Executions](/references/sdk-metrics#activity_schedule_to_start_latency) should have alerts.

#### Prometheus query samples

**Workflow Task Latency, 99th percentile**

```
histogram_quantile(0.99, sum(rate(temporal_workflow_task_schedule_to_start_latency_seconds_bucket[5m])) by (le, namespace, task_queue))
```

**Workflow Task Latency, average**

```
sum(increase(temporal_workflow_task_schedule_to_start_latency_seconds_sum[5m])) by (namespace, task_queue)
/
sum(increase(temporal_workflow_task_schedule_to_start_latency_seconds_count[5m])) by (namespace, task_queue)
```

**Activity Task Latency, 99th percentile**

```
histogram_quantile(0.99, sum(rate(temporal_activity_schedule_to_start_latency_seconds_bucket[5m])) by (le, namespace, task_queue))
```

**Activity Task Latency, average**

```
sum(increase(temporal_activity_schedule_to_start_latency_seconds_sum[5m])) by (namespace, task_queue)
/
sum(increase(temporal_activity_schedule_to_start_latency_seconds_count[5m])) by (namespace, task_queue)
```

**Target**

This latency should be very low, close to zero.
Any higher value indicates a bottleneck.
Anything else indicates bottlenecking.

### Sync Match Rate {#sync-match-rate}

The Sync Match Rate measures the rate of Tasks that can be delivered to Workers without having to be persisted (Workers are up and available to pick them up) to the rate of all delivered Tasks.

**Calculate Sync Match Rate**

```
temporal_cloud_v0_poll_success_sync_count ÷ temporal_cloud_v0_poll_success_count = N
```

#### Prometheus query samples

**sync_match_rate query**

```
sum by(temporal_namespace) (
    rate(
        temporal_cloud_v0_poll_success_sync_count{temporal_namespace=~"$namespace"}[5m]
    )
)
/
sum by(temporal_namespace) (
    rate(
        temporal_cloud_v0_poll_success_count{temporal_namespace=~"$namespace"}[5m]
    )
)
```

**Target**

The Sync Match Rate should be at least >95%, but preferably >99%.

**Interpretation**

There is not enough or under-powered resources.
If the Schedule-To-Start latency is high and the Sync Match Rate is high, the TaskQueue is experiencing a backlog of Tasks.

There are three typical causes for this:

- There are not enough Workers to perform work
- Each Worker is either under resourced, or is misconfigured, to handle enough work
- There is congestion caused by the environment (eg., network) hosting the Worker(s) and Temporal Cloud.

**Actions**

Consider the following:

- Increasing either the number of available Workers, OR
- Verifying that your Worker hosts are appropriately resourced, OR
- Increasing the Worker configuration value for concurrent pollers for Workers/Task executions (if your Worker resources can accommodate the increased load), OR
  - TypeScript: [Workflows](https://typescript.temporal.io/api/interfaces/worker.WorkerOptions#maxconcurrentworkflowtaskexecutions)
  - Golang: [Workflows](/develop/go/core-application#maxconcurrentworkflowtaskpollers)
- Doing some combination of the above

**Temporal Cloud bottleneck**

If the Schedule-To-Start latency is _high_ and the Sync Match Rate is also _low_, Temporal Cloud could very well be the bottleneck and you should reach out via support channels for us to confirm.

:::warning

Setting the [Schedule-To-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout) in your Activity Options can skew your observations.
Avoid setting a Schedule-To-Start Timeout when profiling latency.
You should avoid setting a Schedule-To-Start Timeout when profiling latency.

:::

## Detect greedy Worker resources {#detect-greedy-workers}

**How to detect greedy Worker resources.**

You can have too many Workers.
If you see the Poll Success Rate showing low numbers, you might have too many resources polling Temporal Cloud.

Metrics to monitor:

- **Temporal Cloud metric**: [temporal_cloud_v0_poll_success_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_poll_success_count)
- **Temporal Cloud metric**: [temporal_cloud_v0_poll_success_sync_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_poll_success_sync_count)
- **Temporal Cloud metric**: [temporal_cloud_v0_poll_timeout_count](/production-deployment/cloud/metrics/reference#temporal_cloud_v0_poll_timeout_count)
- **SDK metric**: [temporal_workflow_task_schedule_to_start_latency](/references/sdk-metrics#workflow_task_schedule_to_start_latency)
- **SDK metric**: [temporal_activity_schedule_to_start_latency](/references/sdk-metrics#activity_schedule_to_start_latency)

**Calculate Poll Success Rate**

```
(temporal_cloud_v0_poll_success_count + temporal_cloud_v0_poll_success_sync_count)
/
(temporal_cloud_v0_poll_success_count + temporal_cloud_v0_poll_success_sync_count + temporal_cloud_v0_poll_timeout_count)
```

**Target**

Poll Success Rate should be >90% in most cases of systems with a steady load.
For high volume and low latency, try to target >95%.

**Interpretation**

There may be too many Workers.

If you see the following at the same time then you might have too many Workers:

- Low poll success rate, AND
- Low `schedule_to_start_latency`, AND
- Low Worker hosts resource utilization

**Actions**

Consider sizing down your Workers by either:

- Reducing the number of Workers polling the impacted Task Queue, OR
- Reducing the concurrent pollers per Worker, OR
- Both of the above

#### Prometheus query samples

**poll_success_rate query**

```
(
    (
        sum by(temporal_namespace) (
          rate(
            temporal_cloud_v0_poll_success_count{temporal_namespace=~"$namespace"}[5m]
          )
        )
      +
        sum by(temporal_namespace) (
          rate(
            temporal_cloud_v0_poll_success_sync_count{temporal_namespace=~"$namespace"}[5m]
          )
        )
    )
  /
    (
        (
            sum by(temporal_namespace) (
              rate(
                temporal_cloud_v0_poll_success_count{temporal_namespace=~"$namespace"}[5m]
              )
            )
          +
            sum by(temporal_namespace) (
              rate(
                temporal_cloud_v0_poll_success_sync_count{temporal_namespace=~"$namespace"}[5m]
              )
            )
        )
      +
        sum by(temporal_namespace) (
          rate(
            temporal_cloud_v0_poll_timeout_count{temporal_namespace=~"$namespace"}[5m]
          )
        )
    )
)
```

## Detect misconfigured Workers {#detect-misconfigured-workers}

**How to detect misconfigured Workers.**

Worker configuration can negatively affect Task processing efficiency.

Metrics to monitor:

- **SDK metric**: [temporal_worker_task_slots_available](/references/sdk-metrics#worker_task_slots_available)
- **SDK metric**: [sticky_cache_size](/references/sdk-metrics#sticky_cache_size)
- **SDK metric**: [sticky_cache_total_forced_eviction](/references/sdk-metrics#sticky_cache_total_forced_eviction)

**Execution Size Configuration**

The `maxConcurrentWorkflowTaskExecutionSize` and `maxConcurrentActivityExecutionSize` define the number of total available slots for the Worker.
If this is set too low, the Worker will not be able to keep up processing Tasks.

**Target**

The `temporal_worker_task_slots_available` metric should always be >0.

#### Prometheus query samples

**Over Time**

```
avg_over_time(temporal_worker_task_slots_available{namespace="$namespace",worker_type="WorkflowWorker"}[10m])
```

**Current Time**

```
temporal_worker_task_slots_available{namespace="default", worker_type="WorkflowWorker", task_queue="$task_queue_name"}
```

**Interpretation**

You are likely experiencing a Task backlog if you are seeing inadequate slot counts frequently.
The work is not getting processed as fast as it should/can.

**Action**

Increase the `maxConcurrentWorkflowTaskExecutionSize` and `maxConcurrentActivityExecutionSize` values and keep an eye on your Worker resource metrics (CPU utilization, etc) to make sure you haven't created a new issue.

### Configure Sticky Execution Cache {#configure-sticky-cache}

Sticky Execution means that a Worker caches a Workflow Execution Event History and creates a dedicated Task Queue to listen on.
It significantly improves performance because the Temporal Service only sends new events to the Worker instead of entire Event Histories.

**How to configure your Workflow Sticky cache.**

The `WorkflowCacheSize` should always be greater than the `sticky_cache_size` metric value.
Additionally, you can watch `sticky_cache_total_forced_eviction` for unusually high numbers that are likely an indicator of inefficiency, since Workflows are being evicted from the cache.

**Target**

The `sticky_cache_size` should report less than or equal to your `WorkflowCacheSize` value.
Also, sticky_cache_total_forced_eviction should not be reporting high numbers (relative).

**Action**

If you see a high eviction count, verify there are no other inefficiencies in your Worker configuration or resource provisioning (backlog).
If you see the cache size metric exceed the `WorkflowCacheSize`, increase this value if your Worker resources can accommodate it or provision more Workers.
Finally, take time to review this document and see if it addresses other potential cache issues.

#### Prometheus query samples

**Sticky Cache Size**

```
max_over_time(temporal_sticky_cache_size{namespace="$namespace"}[10m])
```

**Sticky Cache Evictions**

```
rate(temporal_sticky_cache_total_forced_eviction_total{namespace="$namespace"}[5m]))
```

---

## Codec Server - Temporal Platform feature guide

Temporal Server stores and persists the data handled in your Workflow Execution.
Encrypting this data ensures that any sensitive application data is secure when handled by the Temporal Server.

For example, if you have sensitive information passed in the following objects that are persisted in the Workflow Execution Event History, use encryption to secure it:

- Inputs and outputs/results in your [Workflow](/workflow-execution), [Activity](/activity-execution), and [Child Workflow](/child-workflows)
- [Signal](/sending-messages#sending-signals) inputs
- [Memo](/workflow-execution#memo)
- Headers (verify if applicable to your SDK)
- [Query](/sending-messages#sending-queries) inputs and results
- Results of [Local Activities](/local-activity) and [Side Effects](/workflow-execution/event#side-effect)
- [Application errors and failures](/references/failures).
  Failure messages and call stacks are not encoded as codec-capable Payloads by default; you must explicitly enable encoding these common attributes on failures.
  For more details, see [Failure Converter](/failure-converter).

Using encryption ensures that your sensitive data exists unencrypted only on the Client and the Worker Process that is executing the Workflows and Activities, on hosts that you control.

By default, your data is serialized to a [Payload](/dataconversion#payload) by a [Data Converter](/dataconversion).
To encrypt your Payload, configure your custom encryption logic with a [Payload Codec](/payload-codec) and set it with a [custom Data Converter](/default-custom-data-converters#custom-data-converter).

A Payload Codec does byte-to-byte conversion to transform your Payload (for example, by implementing compression and/or encryption and decryption) and is an optional step that happens between the Client and the [Payload Converter](/payload-converter):

<CaptionedImage
    src="/diagrams/remote-data-encoding.svg"
    title="Remote data encoding architecture" />

You can run your Payload Codec with a [Codec Server](/codec-server) and use the Codec Server endpoints in the Web UI and CLI to decode your encrypted Payload locally.
For details on how to set up a Codec Server, see [Codec Server setup](#codec-server-setup).

However, if you plan to set up [remote data encoding](/remote-data-encoding) for your data, ensure that you consider all security implications of running encryption remotely before implementing it.

When implementing a custom codec, it is recommended to perform your compression or encryption on the entire input Payload and store the result in the data field of a new Payload with a different encoding metadata field.
This ensures that the input Payload's metadata is preserved.
When the encoded Payload is sent to be decoded, you can verify the metadata field before applying the decryption.
If your Payload is not encoded, it is recommended to pass the unencoded data to the decode function instead of failing the conversion.

Examples for implementing encryption:

- [Go sample](https://github.com/temporalio/samples-go/tree/main/encryption)
- [Java sample](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/encryptedpayloads)
- [Python sample](https://github.com/temporalio/samples-python/tree/main/encryption)
- [TypeScript sample](https://github.com/temporalio/samples-typescript/tree/main/encryption)
- [.NET sample](https://github.com/temporalio/samples-dotnet/tree/main/src/Encryption)

## Codec Server setup {#codec-server-setup}

Use a Codec Server to programmatically decode your encoded [payloads](/dataconversion#payload).

A Codec Server is an HTTP server that uses your custom Codec logic to decode your data remotely.
The Codec Server is independent of the Temporal Service and decodes your encrypted payloads through predefined endpoints. You create, operate, and manage access to your Codec Server in your own environment.
The Temporal CLI and the Web UI in turn provide built-in hooks to call the Codec Server to decode encrypted payloads on demand.

The Codec Server is independent of the Temporal Server and decodes your encrypted payloads through endpoints.
When you configure a Codec Server endpoint in the Temporal Web UI or CLI, the Web UI and CLI use the remote endpoint to receive decoded payloads from the Codec Server.
See [API contract requirements](#api-contract-specifications).

Decoded payloads can then be displayed in the Workflow Execution Event History on the Web UI. Note that when you use a Codec Server, the decoded payloads are decoded and returned on the client side only; payloads on the Temporal Server (whether on Temporal Cloud or a self-hosted Temporal Service) remain encrypted.

Because you create, operate, and manage access to your Codec Server in your controlled environment, ensure that you consider the following:

- When you register a Codec Server endpoint with your Web UI, expect the Codec Server to receive multiple requests per Workflow Execution.
- Ensure that you secure access to your Codec Server. For details, see [Authorization](#authorization). You might need some form of [Key management infrastructure](/key-management) for sharing your encryption keys between the Workers and your Codec Server.
- You will need to enable [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) on the HTTP/HTTPS endpoints in your Codec Server to receive requests from the Temporal Web UI.
- You may introduce latency in the Web UI when sending and receiving payloads to the Codec Server.

Your Codec Server should share logic with the custom [Payload Codec](/payload-codec) used elsewhere in your application.

### API contract specifications

When you create your Codec Server to handle requests from the Web UI, the following requirements must be met.

#### Endpoints

The Web UI and CLI send a POST to a `/decode` endpoint. In your Codec Server, create a `/decode` path and pass the incoming payload to the decode method in your Payload Codec.

For examples on how to create your Codec Server, see the following Codec Server implementation samples:

- [Go](https://github.com/temporalio/samples-go/tree/main/codec-server)
- [Java](https://github.com/temporalio/sdk-java/tree/master/temporal-remote-data-encoder)
- [Python](https://github.com/temporalio/samples-python/blob/main/encryption/codec_server.py)
- [TypeScript](https://github.com/temporalio/samples-typescript/blob/main/encryption/src/codec-server.ts)
- [.NET](https://github.com/temporalio/samples-dotnet/blob/main/src/Encryption/CodecServer/Program.cs)

You can also add a [verification step](#authorization) to check whether the incoming request has the required authorization to access the decode logic in your Payload Codec.

#### Headers

Each request from the Web UI to your Codec Server includes the following headers:

- `Content-Type: application/json`: Ensure that your Codec Server can accommodate this [MIME type](https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types).

- `X-Namespace: {namespace}`: This is a custom HTTP Header. Ensure that the [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) configuration in your Codec Server includes this header.

- [Optional] `Authorization: <credentials>`: Include this in your CORS configuration when enabling authorization with your Codec Server.

For details on setting up authorization, see [Authorization](#authorization).

#### Request body

The general specification for the `POST` request body contains payloads.
By default, all field values in your payload are base64 encoded, regardless of whether they are encrypted by your custom codec implementation.

The following example shows a sample `POST` request body with base64 encoding.

```json
{
  "payloads": [{
    "metadata": {
      "encoding": <base64EncodedEncodingHint>
    },
    "data": <encryptedPayloadData>
  }, ...]
}
```

#### CORS

By default, in cross-origin Fetch/XHR invocations, browsers will not send credentials.
Enable [Cross-Origin Resource Sharing (CORS)](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) requests on your Codec Server to receive HTTP/HTTPS requests from the Temporal Web UI.

At a minimum, enable the following responses from your Codec Server to allow requests coming from the Temporal Web UI:

- `Access-Control-Allow-Origin`
- `Access-Control-Allow-Methods`
- `Access-Control-Allow-Headers`

For example, for Temporal Cloud Web UI hosted at https://cloud.temporal.io, enable the following in your Codec Server:

- `Access-Control-Allow-Origin: https://cloud.temporal.io`
- `Access-Control-Allow-Methods: POST, GET, OPTIONS`
- `Access-Control-Allow-Headers: X-Namespace, Content-Type`

For details on what a sample request/response looks like from the Temporal Web UI, see [Sample Request/Response](#sample-requestresponse).
If setting authorization, include `Authorization` in your `Access-Control-Allow-Headers`.
For details on setting up authorization, see [Authorization](#authorization).

#### Authorization

It is important to establish how you will provide access to your Codec Server.
Because it is designed to decode potentially sensitive data with a single API call, access to a production Codec Server should be restricted.

Depending on your infrastructure and risk levels, it might be sufficient to restrict HTTP ingress to your Codec Server (such as by using a VPN like [WireGuard](https://www.wireguard.com/)).
The Temporal Web UI can communicate with a Codec Server that is only accessible on `localhost`, so this is a legitimate security pattern.
However, if your Codec Server is exposed to the internet at all, you will likely need an authentication solution.

If you are already using an organization-wide authentication provider, you should integrate it with your Codec Server. Remember, a Codec Server is just a standalone HTTP server, so you can use existing libraries for OAuth, [Auth0](https://auth0.com/), or any other protocol.
[This repository](https://github.com/pvsone/codec-cors-credentials) contains an example of using Auth0 to handle browser-based auth to a Codec Server.

To enable authorization from the Web UI (for both a self-hosted Temporal Service and Temporal Cloud), your Codec Server must be an HTTPS Server.

**Temporal Cloud**

The Temporal Cloud UI provides an option to pass access tokens (JWT) to your Codec Server endpoints.
Use the access tokens to validate access and then return decoded payloads from the Codec Server.

You can enable this by selecting **Pass access token** in your Codec Server endpoint interface where you add your endpoint.
Enabling this option in the Temporal Cloud UI adds an authorization header to each request sent to the Codec Server endpoint that you set.

In your Codec Server implementation, verify the signature on this access token (in your authorization header) against [our JWKS endpoint](https://login.tmprl.cloud/.well-known/jwks.json).

{/* Commenting this for now. _/}
{/_ If you want to unpack the claims in your token to add additional checks on whether the user has valid access to the Namespace and payloads they are trying to access, you can implement it using Auth0 SDKs, middleware, or one of the third-party libraries at JWT.io. */}

The token provided from Temporal Cloud UI contains the email identifier of the person requesting access to the payloads.
Based on the permissions you have provided to the user in your access control systems, set conditions in your Codec Server whether to return decoded payloads or just return the original encoded payloads.

**Self-hosted Temporal Service**

On a self-hosted Temporal Service, configure [authorization in the Web UI configuration](/references/web-ui-configuration#auth) in your Temporal Service setup.

With this enabled, you can pass access tokens to your Codec Server and validate the requests from the Web UI to the Codec Server endpoints that you set.
Note that with a self-hosted Temporal Service, you must explicitly configure authorization specifications for the Web UI and CLI.

#### Sample request/response

Consider the following sample request/response when creating and hosting a Codec Server with the following specifications:

- Scheme: `https`
- Host: `dev.mydomain.com/codec`
- Path: `/decode`

```json
HTTP/1.1 POST /decode
Host: https://dev.mydomain.com/codec
Content-Type: application/json
X-Namespace: myapp-dev.acctid123
Authorization: Bearer <token>

{"payloads":[{"metadata":{"encoding":"anNvbi9wcm90b2J1Zg==","messageType":"dGVtcG9yYWxfc2hvcC5vcmNoZXN0cmF0aW9ucy52MS5TdGFydFNob3BwaW5nQ2FydFJlcXVlc3Q="},"data":"eyJjYXJ0SWQiOiJleGFtcGxlLWNhcnQiLCJzaG9wcGVySWQiOiJ5b3VyLXNob3BwZXItaWQtZXhhbXBsZSIsImVtYWlsIjoieW91ci1lbWFpbEBkb21haW4uY29tIn0"}]}

200 OK
Content-Type: application/json

{
  "payloads": [{
    "metadata":{
      "encoding": "json/protobuf",
      "messageType": "temporal_shop.orchestrations.v1.StartShoppingCartRequest"
    },
    "data":{
      "cartId":"example-cart",
      "shopperId":"your-shopper-id-example",
      "email":"your-email@domain.com"
    }}]
}
```

You can also perform remote encoding on an `/encode` endpoint, which looks the same in reverse:

- Scheme: `https`
- Host: `dev.mydomain.com/codec`
- Path: `/encode`

```json
HTTP/1.1 POST /encode
Host: https://dev.mydomain.com/codec
Content-Type: application/json
X-Namespace: myapp-dev.acctid123
Authorization: Bearer <token>

{"payloads":[{"metadata":{"encoding":"json/protobuf","messageType":"temporal_shop.orchestrations.v1.StartShoppingCartRequest"},"data":{"cartId":"example-cart","shopperId":"your-shopper-id-example","email":"your-email@domain.com"}}]}

200 OK
Content-Type: application/json

{
  "payloads": [
    {
      "metadata": {
        "encoding": "anNvbi9wcm90b2J1Zg==",
        "messageType": "dGVtcG9yYWxfc2hvcC5vcmNoZXN0cmF0aW9ucy52MS5TdGFydFNob3BwaW5nQ2FydFJlcXVlc3Q="
      },
      "data": "eyJjYXJ0SWQiOiJleGFtcGxlLWNhcnQiLCJzaG9wcGVySWQiOiJ5b3VyLXNob3BwZXItaWQtZXhhbXBsZSIsImVtYWlsIjoieW91ci1lbWFpbEBkb21haW4uY29tIn0"
    }
  ]
}
```

### Set your Codec Server endpoints with Web UI and CLI

After you create your Codec Server and expose the requisite endpoints, set the endpoints in your Web UI and CLI.

#### Web UI

On Temporal Cloud and self-hosted Temporal Service, you can configure a Codec Server endpoint to be used for a Namespace in the Web UI.

<CaptionedImage
    src="/img/info/set-codec-endpoint-form.png"
    title="Codec Server endpoint Namespace setting"
/>

To set a Codec Server endpoint on a Namespace, do the following.

1. In the Web UI, go to Namespaces, select the Namespace where you want to configure the Codec Server endpoint, and click **Edit**.
1. In the **Codec Server** section on the Namespace configuration page, enter your Codec Server endpoint and port number.
1. Optional: If your Codec Server is configured to [authenticate requests](#authorization) from Temporal Web UI, enable **Pass access token** to send a JWT access token with the HTTPS requests.
1. Optional: If your Codec Server is configured to [verify origins of requests](#cors), enable **Include cross-origin credentials**.

On Temporal Cloud, you must have [Namespace Admin privileges](/cloud/users#namespace-level-permissions) to add a Codec Server endpoint on the Namespace. Setting a Codec Server endpoint on a Cloud Namespace enables it for all users on the Namespace.

Setting a Codec Server endpoint on a self-hosted Temporal Service enables it for the entire Temporal Service. You can use a single Codec Server to handle different encoding and decoding routes for each namespace.

You can also override the global Codec Server setting at the browser level. This can be useful when developing, testing, or troubleshooting encoding functionality.

<CaptionedImage
    src="/img/info/data-encoder-button.png"
    title="Codec Server endpoint browser setting"
/>

To set a browser override for the Namespace-level endpoint, do the following.

1. Navigate to **Workflows** in your Namespace.
2. In the top-right corner, select **Configure Codec Server**.
3. Select whether you want to use the Namespace-level (or Temporal Service-level for self-hosted Temporal Service) or the browser-level Codec Endpoint setting as the default for your browser.
   In Temporal Cloud:
   - **Use Namespace-level settings, where available. Otherwise, use my browser setting.**
     Uses the Namespace-level Codec Server endpoint by default.
     If no endpoint is set on the Namespace, your browser setting is applied.
   - **Use my browser setting and ignore Namespace-level setting.**
     Applies your browser-level setting by default, overriding the Namespace-level Codec Server endpoint.
4. Enter your Codec Server endpoint and port number.
5. Optional: If your Codec Server is configured to [authenticate requests](#authorization) from Temporal Web UI, enable **Pass access token** to send a JWT access token with the HTTPS requests.
6. Optional: If your Codec Server is configured to [verify origins of requests](#cors), enable **Include cross-origin credentials**.

In a self-hosted Temporal Service with dedicated UI Server configuration, you can also set the codec endpoint in the UI server [configuration file](/references/web-ui-configuration#codec):

```yaml
codec:
    endpoint: {{ default .Env.TEMPORAL_CODEC_ENDPOINT "{namespace}"}}
```

#### CLI

You can configure a Codec Server endpoint with the Temporal CLI using the `--codec-endpoint` flag.

For example, if you are running your Codec Server on `http://localhost:8888`, you can use `env set` to set the endpoint globally:

```bash
temporal env set --codec-endpoint "http://localhost:8888"
```

If your Codec Server endpoint is not set globally, provide the `--codec-endpoint` option with each command.
For example, to see the decoded output of the Workflow Execution "yourWorkflow" in the Namespace "yourNamespace", run:

```bash
temporal --codec-endpoint "http://localhost:8888" --namespace "yourNamespace" workflow show --workflow-id "yourWorkflow"  --run-id "<yourRunId>" --output "table"
```

For details, see the [CLI reference](/cli/).

If your Codec Server requires authentication, the Temporal CLI will also accept a `--codec-auth` parameter to supply an
authorization header:

```shell
temporal workflow show \
   --workflow-id converters_workflowID \
   --codec-endpoint 'http://localhost:8081/{namespace}' \
   --codec-auth 'auth-header'
```

### Working with Large Payloads

Codec Servers can be used for more than encryption and decryption of sensitive data.
Codec Server behavior is left up to implementers -- they can also call external services or perform other tasks, as long as they hook in at the encoding and decoding stages of a Workflow payload.

By default, Temporal limits payload size to 4MB.
If this limitation is problematic for your use case, you could implement a codec that persists your payloads to an object store outside of workflow histories.
An example implementation is available from [DataDog](https://github.com/DataDog/temporal-large-payload-codec).

### Temporal Nexus

The Data Converter works the same for a Nexus Operation as it does for other payloads sent between a Worker and Temporal Cloud.
Both the caller and handler Workers must use compatible Data Converters to pass operation inputs and results between them.

See [Nexus Payload Encryption & Data Converter](/nexus/security#payload-encryption-data-converter) for details.

---

## Temporal Platform production deployments

**Ready to elevate your durable application into production?**

To take your application to production, you deploy your application code, including your Workflows, Activities, and Workers, on your infrastructure using your existing build, test and deploy tools.

Then you need a production-ready Temporal Service to coordinate the execution of your Workflows and Activities.

You can use Temporal Cloud, a fully-managed platform, or you can self-host the service.

## Use Temporal Cloud

You can let us handle the operations of running the Temporal Service, and focus on your application.
Follow the [Temporal Cloud guide](/cloud) to get started.

<CaptionedImage
    src="/diagrams/basic-platform-topology-cloud.svg"
    title="Connect your application instances to Temporal Cloud"
/>

## Run a Self-hosted Temporal Service

Alternatively, you can run your own production level Temporal Service to orchestrate your durable applications.
Follow the [Self-hosted guide](/self-hosted-guide) to get started.

<CaptionedImage
    src="/diagrams/basic-platform-topology-self-hosted.svg"
    title="Connect your application instances to your self-hosted Temporal Service"
/>

## Worker deployments

Whether you're hosting with Temporal Cloud or on your own, you have control over where to run and scale your Workers.
We provide guidance on [Worker Deployments](/production-deployment/worker-deployments).

---

## Migrate to Cloud

Migrating to Temporal Cloud from a self-hosted Temporal Service will have different requirements depending on your usage.
This guide provides some guidance based on our experience helping customers of all sizes successfully migrate.

### What to expect from a migration

Depending on your Workflows' requirements, the migration process may be as simple as changing a few parameters, or may require more extensive code changes.
There are two aspects to consider when migrating: your Temporal Client connection code and your Workflow Executions.
Here's a high-level overview of what you can expect:

- **Introduce another Temporal Client to your Starter and Worker Processes:** Configure and deploy a new Temporal Client so that Temporal Cloud becomes responsible for new Workflow Executions.
- **Migrate Workflow Executions:** There are different approaches for new, running, and completed Workflow Executions.
  - **New Workflow Executions:** When you no longer need to send Signals or Queries to your self-hosted Temporal Service, you can deprecate your old Client code. Until then, your self-hosted Temporal Service can receive relevant traffic, while new Workflow Executions are sent to Temporal Cloud.
  - **Running Workflow Executions:** Short-running Workflows can often be drained and then started again on Temporal Cloud. Long-running Workflows that cannot be drained might require you to implement more code changes to pass the state of the currently running Workflow to Temporal Cloud.
  - **Completed Workflow Executions:** Completed Workflow Execution History cannot be automatically migrated to Temporal Cloud. Refer to [Multi-Cluster Replication](#multi-cluster-replication) for more information.

### Updating Client connection code in your Workers

Whether you're self-hosting Temporal or using Temporal Cloud, you manage runtime of your code.
To migrate your Workflows to Temporal Cloud, you need to change some parameters in the Client connection code, such as updating the namespace and gRPC endpoint.

The changes needed to direct your Workflow to your Temporal Cloud
Namespace are only a few lines of code, including:

- [Add your SSL certificate and private key](/cloud/saml) associated with your Namespace.
- [Copy the Cloud-hosted endpoint](/cloud/namespaces#temporal-cloud-grpc-endpoint) from the Namespace detail Web page.
  The endpoint uses this format: `<namespace_id>.<account_id>.tmprl.cloud:port`.
- [Connect to Temporal Cloud](/cloud/get-started) with your Client.
- [Configure tcld, the Cloud CLI](/cloud/tcld), with the same address, Namespace, and
  certificate used to create a Client through code.

### Migrating your Workflow Executions

A Temporal Service stores the complete Event History for the entire lifecycle of a
Workflow Execution.
To migrate from a self-hosted Temporal Service to Temporal Cloud, take into account the current state, Event History, and any future expectations of your Workflow Executions.

**New Workflows are automatically executed on Temporal Cloud.**
Once you've made the code changes in Step 1, and your new code is deployed, new Workflow Executions will be sent to Temporal Cloud.
Existing Workflows must receive Signals to migrate and re-execute on Cloud.
If you maintain your self-hosted instance, you will still be able to use it to access any execution history from before your migration.
You can also export JSON from your previous execution history, that you can then import into your own analytics system.

**Running Workflows can either be drained or migrated.**
If your Workflow can be completed before any compelling event which drives a move to Temporal Cloud, those Workflows can be automatically restarted on Temporal Cloud.
If your Workflows need to run continuously, you must migrate Workflows while they are running.
To accomplish this migration, cancel your current Workflow and pass the current state to a new Workflow in Temporal Cloud.
Refer to [this repository](https://github.com/temporalio/temporal-migration) for an example of migrating running Workflows in Java.

When performing a live migration, make sure your Worker capacity can support the migration load.
Both a [Signal](/sending-messages#sending-signals) and a [Query](/sending-messages#sending-queries) will be executed during the course of the migration.
Also, the Query API loads the entire history of Workflows into Workers to compute the result (if they are not already cached).
That means that your self-hosted Temporal Service Worker capacity will need to support having those executions in memory to serve those requests.
The volume of these requests might be high to execute against all the matches to a `ListFilter`.

### Considerations when resuming Workflows on a new Temporal Service or Namespace

- **Skipping Steps:** If your Workflow steps cannot guarantee idempotency, determine whether you need to skip those steps when resuming the execution in the target Namespace.
- **Elapsed Time:** If your Workflow is “resuming sleep” when in the target Namespace, determine how you will calculate the delta for the sleep invocation in the new execution.
- **Child Relationships:** If your Workflow has Child Workflow relationships (other than Detached Parent Close Policy children), determine how you can pass the state of those children into the parent to execute the child in a resumed state.
- **Heartbeat state:** If you have long running activities relying on heartbeat state, determine how you can resume these activities in the target Namespace.
- Child Workflows with the same type as their Parent types are returned in List Filters used to gather relevant executions. Unless these are Detached `ParentClosePolicy` children, this is not what you want since the Parent/Child relationship will not be carried over to the target Namespace.
- Long running activities that use heartbeat details will not receive the latest details in the target Namespace.
- Duration between Awaitables inside a Workflow definition needs to be considered for elapsed time accuracy when resuming in the target Namespace.
- When Signaling directly from one Workflow to another, make sure to handle `NotFound` executions in the target Namespace. The Workflows may resume out of order.

### Other considerations when migrating

- Have you added an mTLS certificate to your Temporal Namespace? Review our [documentation for adding a certificate to your Temporal Cloud account](/cloud/certificates) for more information.
- There are differences in how metrics are generated in self-hosted Temporal and Temporal Cloud. Review the [documentation on Temporal Cloud metrics](/cloud/metrics/) for more information.
- Consider the implications for [security and access to your Temporal Service](/cloud/security).
- Review your current load (actions per second) and speak to your Account Executive and Solutions Architect so we can set appropriate [Namespace limits](/cloud/limits).

### Multi-Cluster Replication

[Multi-Cluster Replication](/self-hosted-guide/multi-cluster-replication) is an experimental feature which asynchronously replicates Workflow Executions from active Clusters to other passive Clusters for backup and state reconstruction.
Migrating Execution History from a self-hosted Temporal Service to Temporal Cloud is not currently supported.
However, a migration tool based on Multi-Cluster Replication, which will enable this, is currently in development for Temporal Cloud.
If you have used this feature locally or you are interested in using it to migrate to Temporal Cloud, [create a support ticket](https://docs.temporal.io/cloud/support) or watch this space for more information about public availability.

---

## Self-hosted Archival setup

Archival is a feature that automatically backs up [Event Histories](/workflow-execution/event#event-history) and Visibility records from Temporal Service persistence to a custom blob store.

- [How to create a custom Archiver](#custom-archiver)
- [How to set up Archival](#set-up-archival)

Workflow Execution Event Histories are backed up after the [Retention Period](/temporal-service/temporal-server#retention-period) is reached.
Visibility records are backed up immediately after a Workflow Execution reaches a Closed status.

Archival enables Workflow Execution data to persist as long as needed, while not overwhelming the Temporal Service's persistence store.

This feature is helpful for compliance and debugging.

Temporal's Archival feature is considered **experimental** and not subject to normal [versioning and support policy](/temporal-service/temporal-server#versions-and-support).

Archival is not supported when running Temporal through Docker.
It's disabled by default when installing the system manually and when deploying through [helm charts](https://github.com/temporalio/helm-charts/blob/main/charts/temporal/templates/server-configmap.yaml).
It can be enabled in the [config](https://github.com/temporalio/temporal/blob/main/config/development.yaml).

### How to set up Archival {#set-up-archival}

[Archival](/temporal-service/archival) consists of the following elements:

- **Configuration:** Archival is controlled by the [server configuration](https://github.com/temporalio/temporal/blob/main/config/development.yaml#L81) (i.e. the `config/development.yaml` file).
- **Provider:** Location where the data should be archived. Supported providers are S3, GCloud, and the local file system.
- **URI:** Specifies which provider should be used. The system uses the URI schema and path to make the determination.

Take the following steps to set up Archival:

1. [Set up the provider](#providers) of your choice.
2. [Configure Archival](#configuration).
3. [Create a Namespace](#namespace-creation) that uses a valid URI and has Archival enabled.

#### Providers

Temporal directly supports several providers:

- **Local file system**: The [filestore archiver](https://github.com/temporalio/temporal/tree/main/common/archiver/filestore) is used to archive data in the file system of whatever host the Temporal server is running on. In the case of [temporal helm-charts](https://github.com/temporalio/helm-charts), the archive data is stored in the `history` pod. APIs do not function with the filestore archive. This provider is used mainly for local installations and testing and should not be relied on for production environments.
- **Google Cloud**: The [gcloud archiver](https://github.com/temporalio/temporal/tree/main/common/archiver/gcloud) is used to connect and archive data with [Google Cloud](https://cloud.google.com/storage).
- **S3**: The [s3store archiver](https://github.com/temporalio/temporal/tree/main/common/archiver/s3store) is used to connect and archive data with [S3](https://aws.amazon.com/s3).
- **Custom**: If you want to use a provider that is not currently supported, you can [create your own archiver](#custom-archiver) to support it.

Make sure that you save the provider's storage location URI in a place where you can reference it later, because it is passed as a parameter when you [create a Namespace](#namespace-creation).

#### Configuration

Archival configuration is defined in the [`config/development.yaml`](https://github.com/temporalio/temporal/blob/main/config/development.yaml#L93) file.
Let's look at an example configuration:

```yaml
# Temporal Service level Archival config
archival:
  # Event History configuration
  history:
    # Archival is enabled at the Temporal Service level
    state: 'enabled'
    enableRead: true
    # Namespaces can use either the local filestore provider or the Google Cloud provider
    provider:
      filestore:
        fileMode: '0666'
        dirMode: '0766'
      gstorage:
        credentialsPath: '/tmp/gcloud/keyfile.json'

# Default values for a Namespace if none are provided at creation
namespaceDefaults:
  # Archival defaults
  archival:
    # Event History defaults
    history:
      state: 'enabled'
      # New Namespaces will default to the local provider
      URI: 'file:///tmp/temporal_archival/development'
```

You can disable Archival by setting `archival.history.state` and `namespaceDefaults.archival.history.state` to `"disabled"`.

Example:

```yaml
archival:
  history:
    state: 'disabled'

namespaceDefaults:
  archival:
    history:
      state: 'disabled'
```

The following table showcases acceptable values for each configuration and what purpose they serve.

| Config                                         | Acceptable values                                                                  | Description                                                                                                                  |
| ---------------------------------------------- | ---------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------- |
| `archival.history.state`                       | `enabled`, `disabled`                                                              | Must be `enabled` to use the Archival feature with any Namespace in the Temporal Service.                                    |
| `archival.history.enableRead`                  | `true`, `false`                                                                    | Must be `true` to read from the archived Event History.                                                                      |
| `archival.history.provider`                    | Sub provider configs are `filestore`, `gstorage`, `s3`, or `your_custom_provider`. | Default config specifies `filestore`.                                                                                        |
| `archival.history.provider.filestore.fileMode` | File permission string                                                             | File permissions of the archived files. We recommend using the default value of `"0666"` to avoid read/write issues.         |
| `archival.history.provider.filestore.dirMode`  | File permission string                                                             | Directory permissions of the archive directory. We recommend using the default value of `"0766"` to avoid read/write issues. |
| `namespaceDefaults.archival.history.state`     | `enabled`, `disabled`                                                              | Default state of the Archival feature whenever a new Namespace is created without specifying the Archival state.             |
| `namespaceDefaults.archival.history.URI`       | Valid URI                                                                          | Must be a URI of the file store location and match a schema that correlates to a provider.                                   |

Additional resources: [Temporal Service configuration reference](/references/configuration).

#### Namespace creation

Although Archival is configured at the Temporal Service level, it operates independently within each Namespace.
If an Archival URI is not specified when a Namespace is created, the Namespace uses the value of `defaultNamespace.archival.history.URI` from the `config/development.yaml` file.
The Archival URI cannot be changed after the Namespace is created.
Each Namespace supports only a single Archival URI, but each Namespace can use a different URI.
A Namespace can safely switch Archival between `enabled` and `disabled` states as long as Archival is enabled at the Temporal Service level.

Archival is supported in [Global Namespaces](/global-namespace) (Namespaces that span multiple clusters).
When Archival is running in a Global Namespace, it first runs on the active cluster; later it runs on the standby cluster. Before archiving, a history check is done to see what has been previously archived.

#### Test setup

To test Archival locally, start by running a Temporal server:

```bash
./temporal-server start
```

Then register a new Namespace with Archival enabled.

{/* ./tctl --ns samples-namespace namespace register --gd false --history_archival_state enabled --retention 3 */}

```bash
./temporal operator namespace create --namespace="my-namespace" --global false --history-archival-state="enabled" --retention="4d"
```

:::note

If the retention period isn't set, it defaults to 72h.
The minimum retention period is one day.
The maximum retention period is 30 days.

Setting the retention period to 0 results in the error _A valid retention period is not set on request_.

:::

Next, run a sample Workflow such as the [helloworld temporal sample](https://github.com/temporalio/temporal-go-samples/tree/master/helloworld).

When execution is finished, Archival occurs.

#### Retrieve archives

You can retrieve archived Event Histories by copying the `workflowId` and `runId` of the completed Workflow from the log output and running the following command:

{/* ./tctl --ns samples-namespace wf show --wid <workflowId> --rid <runId> */}

```bash
./temporal workflow show --workflow-id="my-workflow-id" --run-id="my-run-id" --namespace="my-namespace"
```

### How to create a custom Archiver {#custom-archiver}

To archive data with a given provider, using the [Archival](/temporal-service/archival) feature, Temporal must have a corresponding Archiver component installed.
The platform does not limit you to the existing providers.
To use a provider that is not currently supported, you can create your own Archiver.

#### Create a new package

The first step is to create a new package for your implementation in [/common/archiver](https://github.com/temporalio/temporal/tree/main/common/archiver).
Create a directory in the archiver folder and arrange the structure to look like the following:

```
temporal/common/archiver
  - filestore/                      -- Filestore implementation
  - provider/
      - provider.go                 -- Provider of archiver instances
  - yourImplementation/
      - historyArchiver.go          -- HistoryArchiver implementation
      - historyArchiver_test.go     -- Unit tests for HistoryArchiver
      - visibilityArchiver.go       -- VisibilityArchiver implementations
      - visibilityArchiver_test.go  -- Unit tests for VisibilityArchiver
```

#### Archiver interfaces

Next, define objects that implement the [HistoryArchiver](https://github.com/temporalio/temporal/blob/main/common/archiver/interface.go#L80) and the [VisibilityArchiver](https://github.com/temporalio/temporal/blob/main/common/archiver/interface.go#L121) interfaces.

The objects should live in `historyArchiver.go` and `visibilityArchiver.go`, respectively.

#### Update provider

Update the `GetHistoryArchiver` and `GetVisibilityArchiver` methods of the `archiverProvider` object in the [/common/archiver/provider/provider.go](https://github.com/temporalio/temporal/blob/main/common/archiver/provider/provider.go) file so that it knows how to create an instance of your archiver.

#### Add configs

Add configs for your archiver to the `config/development.yaml` file and then modify the [HistoryArchiverProvider](https://github.com/temporalio/temporal/blob/main/common/config/config.go#L376) and [VisibilityArchiverProvider](https://github.com/temporalio/temporal/blob/main/common/config/config.go#L393) structs in `/common/common/config.go` accordingly.

#### Custom archiver FAQ

**If my custom Archive method can automatically be retried by the caller, how can I record and access progress between retries?**

Handle this situation by using `ArchiverOptions`.
Here is an example:

```go
func(a * Archiver) Archive(ctx context.Context, URI string, request * ArchiveRequest, opts...ArchiveOption) error {
    featureCatalog: = GetFeatureCatalog(opts...) // this function is defined in options.go
    var progress progress
    // Check if the feature for recording progress is enabled.
    if featureCatalog.ProgressManager != nil {
        if err: = featureCatalog.ProgressManager.LoadProgress(ctx, & prevProgress);
        err != nil {
            // log some error message and return error if needed.
        }
    }

    // Your archiver implementation...

    // Record current progress
    if featureCatalog.ProgressManager != nil {
        if err: = featureCatalog.ProgressManager.RecordProgress(ctx, progress);
        err != nil {
            // log some error message and return error if needed.
        }
    }
}
```

**If my `Archive` method encounters an error that is non-retryable, how do I indicate to the caller that it should not retry?**

```go
func(a * Archiver) Archive(ctx context.Context, URI string, request * ArchiveRequest, opts...ArchiveOption) error {
    featureCatalog: = GetFeatureCatalog(opts...) // this function is defined in options.go

    err: = youArchiverImpl()

    if nonRetryableErr(err) {
        if featureCatalog.NonRetryableError != nil {
            return featureCatalog.NonRetryableError() // when the caller gets this error type back it will not retry anymore.
        }
    }
}
```

**How does my history archiver implementation read history?**

The archiver package provides a utility called [HistoryIterator](https://github.com/temporalio/temporal/blob/main/common/archiver/historyIterator.go) which is a wrapper of [ExecutionManager](https://github.com/temporalio/temporal/blob/main/common/persistence/data_interfaces.go#L1014).
`HistoryIterator` is more simple than the `HistoryManager`, which is available in the BootstrapContainer, so archiver implementations can choose to use it when reading Workflow histories.
See the [historyIterator.go](https://github.com/temporalio/temporal/blob/main/common/archiver/history_iterator.go) file for more details.
Use the [filestore historyArchiver implementation](https://github.com/temporalio/temporal/tree/main/common/archiver/filestore) as an example.

**Should my archiver define its own error types?**

Each archiver is free to define and return its own errors.
However, many common errors that exist between archivers are already defined in [common/archiver/constants.go](https://github.com/temporalio/temporal/blob/main/common/archiver/constants.go).

**Is there a generic query syntax for the visibility archiver?**

Currently, no.
But this is something we plan to do in the future.
As for now, try to make your syntax similar to the one used by our advanced list Workflow API.

- [s3store](https://github.com/temporalio/temporal/tree/main/common/archiver/s3store#visibility-query-syntax)
- [gcloud](https://github.com/temporalio/temporal/tree/main/common/archiver/gcloud#visibility-query-syntax)

---

## Temporal Platform's production readiness checklist

This page describes common challenges customers face who self-host Temporal and it shares recommendations to mitigate those issues.

Temporal at its core is about durability and reliability.
To ensure this durability and reliability, a Temporal Service must be deployed according to best practices.

This guide provides a path to demonstrate that Temporal consumers can be confident in a Temporal Service and provides a list of key tests you as a user should perform against the service.

## Self-Hosting Challenge Areas

Significant engineering and ongoing effort is required to resolve several potential challenges:

- Scalability with spiky or growing workloads
- Global hosting
- Uptime, availability and reliability
- Management and control plane
- Latency, which must be kept low and consistent
- [Security](/self-hosted-guide/security)
- Maintenance and upgrades
- Expert support to users of the service
- Cost management

Each of these components is an essential part of building a mission critical Temporal Service.
Without demonstrated architectural durability, the value of Temporal's [Durable Execution](https://temporal.io/how-it-works) model is compromised.

## Scalability with Variable or Growing Workloads {#scaling-and-metrics}

Workloads can be highly variable, and you may experience sustained workload spikes.
Temporal recommends scaling your clusters to well above the average throughput.
See [Scaling Temporal: The Basics](https://temporal.io/blog/scaling-temporal-the-basics) for an introduction to the topic.

Temporal server throughput is often limited by the number of [Shards](/temporal-service/temporal-server#history-shard) configured for the Temporal Service.
A Shard is an unit within a Temporal Service by which concurrent Workflow Execution throughput can be scaled.
Shard capacity, and often overall cluster throughput, is set at build time for a cluster and that cluster setting cannot be adjusted later.
Adding more Shards if needed requires a cluster rebuild, and a migration to the new cluster.

The requirements of your Temporal Service will vary widely based on your intended production workload.
You will want to run your own proof of concept tests and watch for key metrics to understand the system health and scaling needs.

**Load testing.** You can use [the Omes benchmarking tool](https://github.com/temporalio/omes/), see how we ourselves [stress test Temporal](https://temporal.io/blog/temporal-deep-dive-stress-testing/), or write your own.

All metrics emitted by the server are [listed in Temporal's source](https://github.com/temporalio/temporal/blob/main/common/metrics/defs.go).
There are also equivalent metrics that you can configure from the client side.
At a high level, you will want to track these 3 categories of metrics:

- **Service metrics**: For each request made by the service handler we emit `service_requests`, `service_errors`, and `service_latency` metrics with `type`, `operation`, and `namespace` tags.
  This gives you basic visibility into service usage and allows you to look at request rates across services, namespaces and even operations.
- **Persistence metrics**: The Server emits `persistence_requests`, `persistence_errors` and `persistence_latency` metrics for each persistence operation.
  These metrics include the `operation` tag such that you can get the request rates, error rates or latencies per operation.
  These are super useful in identifying issues caused by the database.
- **Workflow Execution stats**: The Server also emits counters for when Workflow Executions are complete.
  These are useful in getting overall stats about Workflow Execution completions.
  Use `workflow_success`, `workflow_failed`, `workflow_timeout`, `workflow_terminate` and `workflow_cancel` counters for each type of Workflow Execution completion.
  These include the `namespace` tag.

## Availability

A high level of availability and reliability (99.99%) is a requirement for mission critical deployments.
Temporal recommends testing for this availability level while load testing.
We also recommend validating this level of reliability while doing server upgrades, to ensure no loss of service availability.

Temporal Clusters can be deployed in as many regions as needed to meet various requirements:

- Data Residency
- Latency
- Security / Isolation
  This can multiply the effort to implement and maintain clusters.

[Temporal Cloud is available in various cloud provider regions](/cloud/service-availability).

## Management and Control Plane

Temporal success leads to larger Temporal deployments.
Needs can increase, and can go from having one or two production use cases in a single region to many use cases in many regions.
Running multiple Temporal Services is complex work, as each needs its own setup, tuning, and configuration.

Needing to monitor and manage all your Temporal Services in a unified way leads to operational management pain.
Consider adding a layer on top of Temporal to manage multiple Temporal Services: a control plane.
A control plane manages and directs data flow, deciding where data packets should be sent.
A Temporal Service data plan can streamline operations and improve efficiency.
Since Temporal does not ship its own open source data plane, rolling your own can be complex and take effort to add.

Temporal Cloud provides exactly that support.
With Temporal Cloud, all Namespaces in all regions can be managed from a single view.
[Temporal Cloud](https://temporal.io/cloud) also has RBAC functionality that can delegate responsibilities for individual Namespaces.

Self-hosted Temporal does not support RBAC or audit logging out of the box.
Temporal Cloud provides RBAC and SSO support, audit logging, data encryption, third party penetration test validation, and SOC 2-Type II and HIPAA compliance.

## Maintenance and Upgrades

Temporal recommends keeping up-to-date and not falling behind on your server versions.

Temporal Server is proactively updated, and releases as often as every two weeks.
Temporal recommends [upgrading sequentially](/self-hosted-guide/upgrade-server), not skipping any minor versions, although you can skip patch versions.
No support is guaranteed for Temporal Server, but very old servers will be hard for even the community to support, so we encourage you to keep up to date.
You must create and maintain the infrastructure to host and run your self-hosted Temporal installation, such as Kubernetes, as well as data stores for persistence.

Server upgrades can negatively affect self-hosted Temporal Service availability.
Temporal recommends load and availability testing during the upgrade process to understand the performance implications.

Temporal Cloud updates are managed by the Temporal Cloud team; Cloud upgrades are seamless.

## Expert Support

Temporal recommends that customer platform teams who are building out a Temporal service gain deep experience across the lifecycle and breadth of a Temporal application.

Specific activities include:

- [Worker tuning](/develop/worker-performance)
- [Worker best practices](/workers)
- Code reviews
- Design guidance
- Training
- Code reviews
- Security reviews
- [Metrics](/references/sdk-metrics) and monitoring
- Technical onboarding

[Temporal support](/cloud/support) provides guidance on all of the above.

## Cost Management

Running a mission critical, global Temporal Service can be expensive.
Temporal Server is a complex system to run and scale.
Temporal recommends performance testing and planning scaling as your performance requirements evolve.
Following our guidance can oversize your self-hosted Temporal Server installs, but this is necessary to handle unpredictable spiky workloads.
Performance testing can help you right-size your environments.
Running mission critical Temporal as a Service requires multiple Temporal Clusters for high availability and global coverage.

It is a good practice to have trained, experienced administrators familiar with Temporal Service architecture to maintain your Temporal servers and provide a mission critical service.
Staffing, training and skill development can be significant costs to maintaining a Temporal Service.

[Temporal Cloud](https://temporal.io/cloud) can be significantly less expensive to set up and scale.

---

## Self-hosted Temporal Service defaults

:::info Looking for Temporal Cloud defaults?

See the [Temporal Cloud defaults and limits page](/cloud/limits)

:::

This page details many of the defaults coded into the Temporal Platform that can produce errors and warnings.
Errors are hard limits that fail when reached.
Warnings are soft limits that produce a warning log on the server side.

:::info

These limits might apply specifically to each Workflow Execution and do not pertain to the entire Temporal Platform or individual Namespaces.

:::

- **Identifiers:** By default, the maximum length for identifiers (such as Workflow Id, Workflow Type, and Task Queue name) is 1000 characters.
  - This is configurable with the `limit.maxIDLength` dynamic config variable, set to 255 in [this SQL example](https://github.com/temporalio/docker-compose/blob/93d382ef9133e4cde8ce311de5153cd0cc9fbd0c/dynamicconfig/development-sql.yaml#L1-L2).
  - The character format is UTF-8.
- **gRPC:** gRPC has a limit of 4 MB for [each message received](https://github.com/grpc/grpc/blob/v1.36.2/include/grpc/impl/codegen/grpc_types.h#L466).
- **Event batch size:** The `DefaultTransactionSizeLimit` limit is [4 MB](https://github.com/temporalio/temporal/pull/1363).
  This is the largest transaction size allowed for the persistence of Event Histories.
- **Blob size limit** for Payloads (including Workflow context and each Workflow and Activity argument and return value; _[source](https://github.com/temporalio/temporal/blob/v1.7.0/service/frontend/service.go#L133-L134)_):
  - Temporal warns at 256 KB: `Blob size exceeds limit.`
  - Temporal errors at 2 MB: `ErrBlobSizeExceedsLimit: Blob data size exceeds limit.`
  - Refer to [Troubleshoot blob size limit error](/troubleshooting/blob-size-limit-error).
- **Workflow Execution Update limits**:
  - A single Workflow Execution can have a maximum of 10 in-flight Updates and 2000 total Updates in History.
- **History total size limit** (leading to a terminated Workflow Execution):
  - Temporal warns at 10 MB: [history size exceeds warn limit](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/workflowExecutionContext.go#L1238).
  - Temporal errors at 50 MB: [history size exceeds error limit](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/workflowExecutionContext.go#L1204).
  - This is configurable with [HistorySizeLimitError and HistorySizeLimitWarn](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/configs/config.go#L380-L381).
- **History total count limit** (leading to a terminated Workflow Execution):
  - Temporal warns after 10,240 Events: [history size exceeds warn limit](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/workflowExecutionContext.go#L1238).
  - Temporal errors after 51,200 Events: [history size exceeds error limit](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/workflowExecutionContext.go#L1204).
  - This is configurable with [HistoryCountLimitError and HistoryCountLimitWarn](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/configs/config.go#L382-L383).
- **Concurrent limit**
  - The following Commands are limited:
    - `ScheduleActivityTask`
    - `SignalExternalWorkflowExecution`
    - `RequestCancelExternalWorkflowExecution`
    - `StartChildWorkflowExecution`
  - These will fail if the concurrent pending count exceeds 2,000.
    For optimal performance, limit concurrent operations to 500 or fewer.
    This reduces Workflow's Event History size and decreases the loading time in the Web UI.
  - As of v1.21, the open source Temporal Service has a default limit of 2,000 pending Activities, Child Workflows, Signals, or Workflow cancellation requests, but you can override the limits in the dynamic configuration using these variables:
    - `limit.numPendingActivities.error`
    - `limit.numPendingSignals.error`
    - `limit.numPendingCancelRequests.error`
    - `limit.numPendingChildExecutions.error`
  - By default, [Batch jobs](/cli/batch) are limited to one job at a time.
- [Custom Search Attributes limits](/search-attribute#custom-search-attribute-limits)

For details on dynamic configuration keys, see [Dynamic configuration reference](/references/dynamic-configuration).

---

## Deploying a Temporal Service

There are many ways to self-host a [Temporal Service](/temporal-service).
The right way for you depends entirely on your use case and where you plan to run it.

For step-by-step guides on deploying and configuring Temporal, refer to our [Infrastructure tutorials](https://learn.temporal.io/tutorials/infrastructure/).

### Minimum requirements

The Temporal Server depends on a database.

Supported databases include the following:

- [Apache Cassandra](/self-hosted-guide/visibility#cassandra)
- [MySQL](/self-hosted-guide/visibility#mysql)
- [PostgreSQL](/self-hosted-guide/visibility#postgresql)
- [SQLite](/self-hosted-guide/visibility#sqlite)

### Docker & Docker Compose

You can run a Temporal Service in [Docker](https://docs.docker.com/engine/install) containers using [Docker Compose](https://docs.docker.com/compose/install).

If you have Docker and Docker Compose installed, all you need to do is clone the [temporalio/docker-compose](https://github.com/temporalio/docker-compose) repo and run the `docker compose up` command from its root.

The `temporalio/docker-compose` repo comes loaded with a variety of configuration templates that enable you to try all three databases that the Temporal Platform supports (PostgreSQL, MySQL, Cassandra).
It also enables you to try [Advanced Visibility](/visibility#advanced-visibility) using [Search Attributes](/search-attribute), emit metrics, and even play with the [Archival](/temporal-service/archival) feature.
The Docker images in this repo are produced using the Temporal Server [auto-setup.sh](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) script.
This script defaults to creating images that run all the Temporal Server services in a single process.
You can use this script as a starting point for producing your own images.

The following commands start and run a Temporal Service in Docker using the default configuration:

```bash
git clone https://github.com/temporalio/docker-compose.git
cd docker-compose
docker compose up
```

Local [Temporal Clients](/encyclopedia/temporal-sdks#temporal-client) and [Workers](/workers) can connect to the Temporal Service running in Docker at 127.0.0.1:7233 (default connection for most SDKs) and the Temporal Web UI at 127.0.0.1:8080.

To try other configurations (different dependencies and databases), or to try a custom Docker image, follow the [temporalio/docker-compose README](https://github.com/temporalio/docker-compose/blob/main/README.md).

### Temporal Server binaries

You can run a complete Temporal Server by deploying just two Go binaries -- the [core Temporal Server](https://github.com/temporalio/temporal/releases/), and the [Temporal UI Server](https://github.com/temporalio/ui-server/releases).
Refer to our [tutorial site](https://learn.temporal.io/) to learn how to deploy Temporal binaries behind an [Nginx reverse proxy](https://learn.temporal.io/tutorials/infrastructure/nginx-sqlite-binary/) or an [Envoy edge proxy](https://learn.temporal.io/tutorials/infrastructure/envoy-sqlite-binary/).

Each service can also be deployed separately.
For example, if you are using Kubernetes, you could have one service per pod, so they can scale independently in the future.

In Docker, you could run each service in its own container, using the `SERVICES` flag to specify the service:

```bash
docker run
    # persistence/schema setup flags omitted
    -e SERVICES=history \                      -- Spin up one or more: history, matching, worker, frontend
    -e LOG_LEVEL=debug,info \                           -- Logging level
    -e DYNAMIC_CONFIG_FILE_PATH=config/foo.yaml         -- Dynamic config file to be watched
    temporalio/server:<tag>
```

The environment variables supported by the Temporal Docker images are documented [on Docker Hub](https://hub.docker.com/r/temporalio/auto-setup).

Each Temporal Server release ships an [Auto Setup](https://temporal.io/blog/auto-setup) Docker image that includes an [auto-setup.sh](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) script.
We recommend using this script for initial schema setup of each supported database.

### Importing the Server package

The Temporal Server is a standalone Go application that can be [imported](/references/server-options) into another project.

You might want to do this to pass custom plugins or any other customizations through the [Server Options](/references/server-options).
Then you can build and run a binary that contains your customizations.

This requires Go v1.19 or later, as specified in the Temporal Server [Build prerequisites](https://github.com/temporalio/temporal/blob/main/CONTRIBUTING.md#build-prerequisites).

### Helm charts

[Temporal Helm charts](https://github.com/temporalio/helm-charts) enable you to get a Temporal Service running on [Kubernetes](https://kubernetes.io/) by deploying the Temporal Server services to individual pods and connecting them to your existing database and Elasticsearch instances.

The Temporal Helm charts repo contains [extensive documentation](https://github.com/temporalio/helm-charts/blob/main/README.md) about Kubernetes deployments.

---

## Self-hosted Temporal Service guide

Welcome to the self-hosted Temporal Service guide.
This guide shows you how to self-host open source infrastructure software that orchestrates your durable applications.

:::info Sign up for Temporal Cloud!

Instead of self-hosting, you can use [Temporal Cloud](/cloud).

:::

:::info Getting started with Temporal?

If you are just getting started with Temporal, we recommend our [introductory tutorials and courses](https://learn.temporal.io)

:::

:::info Building an app?

If you are building a new Temporal Application, you might only need a [development server](/cli#start-dev-server) available through the [Temporal CLI](/cli).
Check out the [dev guide](/develop) for application development best practices.

:::

- [Deployment](/self-hosted-guide/deployment)
- [Defaults](/self-hosted-guide/defaults)
- [Production checklist](/self-hosted-guide/production-checklist)
- [Security](/self-hosted-guide/security)
- [Monitoring](/self-hosted-guide/monitoring)
- [Visibility](/self-hosted-guide/visibility)
- [Data encryption](/production-deployment/data-encryption)
- [Upgrading server](/self-hosted-guide/upgrade-server#upgrade-server)
- [Archival](/self-hosted-guide/archival)
- [Multi-Cluster Replication](/self-hosted-guide/multi-cluster-replication)
- [Temporal Nexus](/production-deployment/self-hosted-guide/nexus)

---

## Monitor Temporal Platform metrics

Learn how to monitor metrics and health check a self-hosted Temporal Platform.

The Temporal Service and SDKs emit metrics that can be used to monitor performance and troubleshoot issues. To collect and aggregate these metrics, you can use one of the following tools:

- Prometheus
- StatsD
- M3

After you enable your monitoring tool, you can relay these metrics to any monitoring and observability platform.

## Prometheus

This article discusses setting up Prometheus and Grafana to view metrics data on Temporal Service, Temporal Client, and Temporal Worker performance.

Each section includes an example on how you can do this in your local docker-compose Temporal Service setup and with the Java SDK.
If you implement the examples, ensure that your local docker-compose is set up, install your SDK, and have a sample application to work with.
(To get started, you can clone the SDK samples repositories.)

- See [Docker Compose](https://github.com/temporalio/docker-compose) for details on how to set up your local Temporal docker-compose.
- See the [Dev guide](/develop) for details on how to install your SDK and get started with samples.

To set up Prometheus and Grafana:

1. Set up Prometheus endpoints for your [Temporal Service metrics](#temporal-service-metrics-setup) and [SDK metrics](#sdk-metrics-setup).
2. [Configure Prometheus](#prometheus-configuration) to receive metrics data from your Temporal Service and SDK Clients.
   Make sure to test whether you are receiving metrics data on your Prometheus endpoint.
3. [Set up Grafana](#grafana) to use Prometheus as a data source.
4. Set up your [Grafana dashboard](#dashboard-setup) with Prometheus queries to display relevant data.

The Temporal Service and SDKs emit all metrics by default.
However, you must enable Prometheus in your application code (using the Temporal SDKs) and your Temporal Service configuration to collect the metrics emitted from your SDK and Temporal Service.

### Temporal Service metrics setup {#temporal-service-metrics-setup}

To enable Prometheus to receive metrics data, set listen addresses in the Server configuration for Prometheus to scrape from.

The [docker-compose setup](https://github.com/temporalio/docker-compose/blob/0bca458992ef5135700dcd9369a53fcda30356b0/docker-compose.yml) provided for local development sets up most Temporal Services in one Docker container.

Here's an example of how to expose a Prometheus endpoint on your local docker-compose Temporal Service configuration:

```yaml {20,26}
version: '3.5'
services:
  #...

  temporal:
    container_name: temporal
    depends_on:
      - postgresql
      - elasticsearch
    environment:
      - DB=postgresql
      - DB_PORT=5432
      - POSTGRES_USER=temporal
      - POSTGRES_PWD=temporal
      - POSTGRES_SEEDS=postgresql
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - ENABLE_ES=true
      - ES_SEEDS=elasticsearch
      - ES_VERSION=v7
      - PROMETHEUS_ENDPOINT=0.0.0.0:8000 #expose a port for Prometheus
    image: temporalio/auto-setup:${TEMPORAL_VERSION}
    networks:
      - temporal-network
    ports:
      - 7233:7233
      - 8000:8000 #add your port
    volumes:
      - ./dynamicconfig:/etc/temporal/config/dynamicconfig
#...
```

Depending on how you deploy your Temporal Service, you can set different ports for each Temporal Service, as done in [this example](https://github.com/tsurdilo/my-temporal-dockercompose.git), where each Temporal Service is deployed as a separate container.

### SDK metrics setup

SDK metrics are emitted by Clients and must be set up in your application code.
The Metrics section in the Observability guide details how to set this up for all the supported SDKs.

- [Go](/develop/go/observability#metrics)
- [Java](/develop/java/observability#metrics)
- [PHP](/develop/php/observability)
- [Python](/develop/python/observability#metrics)
- [TypeScript](/develop/typescript/observability#metrics)
- [.NET](/develop/dotnet/observability#metrics)

For example, with the Java SDK, you can set up the Prometheus registry and Micrometer stats reporter, set the scope, and expose an endpoint from which Prometheus can scrape the SDK Client metrics in the following way.

```java
//...
// You need to import the following packages to set up metrics in Java.
// See the Developer's guide for packages required for the other SDKs.

  // See the Micrometer documentation for configuration details on other supported monitoring systems.
  // This example shows how to set up the Prometheus registry and stats reported.

  PrometheusMeterRegistry registry = new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
  StatsReporter reporter = new MicrometerClientStatsReporter(registry);

   // set up a new scope, report every 10 seconds
    Scope scope = new RootScopeBuilder()
            .tags(ImmutableMap.of(
                         "workerCustomTag1",
                         "workerCustomTag1Value",
                         "workerCustomTag2",
                         "workerCustomTag2Value"))
            .reporter(reporter)
            .reportEvery(com.uber.m3.util.Duration.ofSeconds(10));

  // For Prometheus collection, expose the scrape endpoint at port 8077. See Micrometer documentation for details on starting the Prometheus scrape endpoint. For example,
  HttpServer scrapeEndpoint = MetricsUtils.startPrometheusScrapeEndpoint(registry, 8077); //note: MetricsUtils is a utility file with the scrape endpoint configuration. See Micrometer docs for details on this configuration.
  // Stopping the starter stops the HTTP server that exposes the scrape endpoint.
  //Runtime.getRuntime().addShutdownHook(new Thread(() -> scrapeEndpoint.stop(1)));

  //Create Workflow service stubs to connect to the Frontend Service.
  WorkflowServiceStubs service = WorkflowServiceStubs.newServiceStubs(
         WorkflowServiceStubsOptions.newBuilder()
                 .setMetricsScope(scope) //set the metrics scope for the WorkflowServiceStubs
                 .build());

  //Create a Workflow service client, which can be used to start, signal, and query Workflow Executions.
  WorkflowClient yourClient = WorkflowClient.newInstance(service,
         WorkflowClientOptions.newBuilder().build());

  //...
```

You can set up separate scrape endpoints in your Clients that you use to start your Workers and Workflow Executions.
To use this example, add the example code with the Prometheus endpoint on port 8077 to your Worker program, and use `yourClient` to start your Workers.
Similarly, in your starter code, add the example code and set the Prometheus endpoint to port 8078, create a Workflow Client (as described in the code example), and use it to start your Workflow Execution.

For more examples on how to set up SDK metrics in other SDKs, see the metrics samples:

- [Java SDK Samples](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/metrics)
- [Go SDK Samples](https://github.com/temporalio/samples-go/tree/main/metrics)

In your Workers, you can set specific `WorkerOptions` for performance tuning, as described in the [Worker Performance Guide](/develop/worker-performance).

With the scrape endpoints set, define your Prometheus scrape configuration and targets to receive the metrics data from the Temporal Service and Temporal SDKs.

### Prometheus configuration

Enable Prometheus to scrape metrics from the endpoints defined in the Temporal Service and SDK configurations.

For example with the local docker-compose Temporal Service, create a separate container for Prometheus with a [Prometheus docker image](https://hub.docker.com/r/prom/prometheus/tags) for v2.37.0 set with the default ports.

```
version: "3.5"
services:
#...
  prometheus:
   container_name: prometheus
   image: prom/prometheus:v2.37.0
   ports:
     - 9090:9090
   volumes:
     - type: bind
       source:./deployment/prometheus/config.yml
       target: /etc/prometheus/prometheus.yml
   depends_on:
     - temporal
#...
```

The Prometheus container configuration will be read from `./deployment/prometheus/config.yml`, so for this example, create a Prometheus configuration YAML file config.yml at `./deployment/prometheus` in your docker-compose Temporal Service project.

For other ways to set your Prometheus configuration, see the [Prometheus Configuration documentation](https://prometheus.io/docs/prometheus/latest/configuration/configuration/).

Next, add your Prometheus setup configuration to scrape metrics data from the Temporal Service and SDK Client target endpoints.

For example, open the Prometheus configuration YAML file, created in the previous example at `./deployment/prometheus/config.yml`, and add the following configuration to scrape metrics from targets set on the docker-compose Temporal Service and SDK Clients in the previous sections.

```
global:
 scrape_interval: 10s
scrape_configs:
 - job_name: 'temporalmetrics'
   metrics_path: /metrics
   scheme: http
   static_configs:
     # Temporal Service metrics target
     - targets:
         - 'host.docker.internal:8000'
       labels:
         group: 'server-metrics'

     # Local app targets (if configured)
     - targets:
         - 'host.docker.internal:8077'
         - 'host.docker.internal:8078'
       labels:
         group: 'sdk-metrics'
```

In this example, Prometheus is configured to scrape at 10-second intervals and to listen for Temporal Service metrics on `host.docker.internal:8000` and SDK metrics on two targets, `host.docker.internal:8077` and `host.docker.internal:8078`.
The `8077` and `8078` ports must be set on `WorkflowServiceStubs` in your application code with your preferred SDK.
You can use these ports to create Workers and make Client API calls to start Workflow Executions and send Signals and Queries.
See the [SDK Metrics](#sdk-metrics-setup) section for details.
You can set up as many targets as required.

For more details on how to configure Prometheus, refer the [Prometheus documentation](https://prometheus.io/docs/prometheus/latest/configuration/configuration/).

To check whether you're receiving your metrics data, restart your local docker-compose Temporal Service (with the configuration provided in the examples here) and check the following ports:

- [localhost:8000/metrics](http://localhost:8000/metrics) - The port for exposing your Temporal Service metrics.
  You should see all the Temporal Service metrics emitted when you start your local docker-compose Temporal Service.
- [localhost:8078/metrics](http://localhost:8078/metrics) - The port for exposing your SDK metrics.
  Depending on whether you have set this port on the Client that is starting your Worker or your Workflow Executions, the related metrics should show when you start your Worker or Workflow Execution.
- [localhost:9090/](http://localhost:9090/) - The port for Prometheus detail.
  Go to **Status > Targets** to check the statuses of your Prometheus target endpoints.

## Datadog

Datadog has a Temporal integration for collecting Temporal Service metrics.
Once you've [configured Prometheus](#prometheus), configure the Datadog Agent according to their guide:

[docs.datadoghq.com/integrations/temporal/](https://docs.datadoghq.com/integrations/temporal/)

## Grafana

With [Prometheus](#prometheus) configured, set up Grafana to use Prometheus as a data source.

For example, in the modified local docker-compose Temporal Service setup described in the previous section, create a separate container with port 8085 for Grafana.

```
version: "3.5"
services:
#...
  grafana:
   container_name: grafana
   image: grafana/grafana:7.5.16
   environment:
     - GF_AUTH_DISABLE_LOGIN_FORM=true
     - GF_AUTH_ANONYMOUS_ENABLED=true
     - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
   ports:
     - 8085:3000
   volumes:
     - type: bind
       source: ./deployment/grafana/provisioning/datasources
       target: /etc/grafana/provisioning/datasources
   depends_on:
     - prometheus
#...
```

Note that in this example, Grafana is set up to start without authorizations; this is not a good practice and is not recommended.
For more information on how to customize your Grafana setup, see the [Grafana documentation](https://grafana.com/docs/grafana/latest/setup-grafana/).

Next, configure Grafana to use Prometheus as the data source.
You can do this either on the UI or in your Grafana deployment configuration.

For the preceding example, create a configuration file (for example, config.yml) at `./deployment/grafana/provisioning/datasource` in your docker-compose Temporal Service project and configure the Prometheus data source for Grafana, as shown:

```
apiVersion: 1

datasources:
 - name: 'Temporal Prometheus'
   type: 'prometheus'
   org_id: 1
   url: 'http://prometheus:9090'
   is_default: true
   version: 1
   editable: true
```

In this example, Grafana is set to pull metrics from Prometheus at the port 9090, as defined in the Prometheus configuration.
After you update this configuration, restart your local docker-compose Temporal Service, and go to [localhost:8085](http://localhost:8085) to access Grafana.

### Dashboard setup

To set up your dashboards in Grafana, either use the UI or configure them in your Grafana deployment on the Temporal Service, as done in this [dashboards](https://github.com/tsurdilo/my-temporal-dockercompose/tree/main/deployment/grafana/dashboards) example.

In your Grafana dashboard, add your Prometheus query to call specific metrics.
The [Temporal Service Metrics reference](/references/cluster-metrics) describes a few metrics and queries that you can get started with.

For example, to create a dashboard in your local Grafana UI at [localhost:8085](http://localhost:8085):

1. Go to **Create > Dashboard**, and add an empty panel.
2. On the **Panel configuration** page, in the **Query** tab, select **Temporal Prometheus** as the data source.
3. In the **Metrics** field, use any of the queries listed in the [Temporal Service Metrics reference](/references/cluster-metrics).
   For example, add `sum by (operation) (rate(service_requests{service_name="frontend"}[2m]))` to see all the Frontend Service requests on your local docker-compose Temporal Service.
4. You should see the graph show metrics data for the Frontend Service from the docker-compose Temporal Service.
5. When you start your Workflows (after setting up your SDK Metrics), you will see your SDK metrics in the graph as well.
6. Optional: In the Legend field, add "`{{operation}}`" to clean the legend on the graph to show operations.

You can add multiple queries in your dashboard to report relevant data.
For more details on configuring Grafana dashboards, see the [Grafana Dashboards documentation](https://grafana.com/docs/grafana/latest/dashboards/).

After you set up your dashboard, you can start experimenting with different samples provided in the Temporal samples repositories.

Temporal also has a repository of community-driven [Grafana dashboards](https://github.com/temporalio/dashboards) that you can get started with.
You can set these up in your Grafana configuration to show the dashboards by default when you start your Temporal Service.
If you are following the examples provided here and importing a dashboard from the community-driven dashboards repository, update the data source for each panel to "Temporal Prometheus" (which is the name set for the Prometheus data source in the [Grafana configuration](#grafana) section).

## How to set up health checks for a Temporal Service {#health-checks}

The [Frontend Service](/temporal-service/temporal-server#frontend-service) supports TCP or [gRPC](https://github.com/grpc/grpc/blob/875066b61e3b57af4bb1d6e36aabe95a4f6ba4f7/src/proto/grpc/health/v1/health.proto#L45) health checks on port 7233.

If you use [Nomad](https://www.nomadproject.io/) to manage your containers, the [check stanza](https://developer.hashicorp.com/nomad/docs/job-specification/check) would look like this for TCP:

```
service {
  check {
    type     = "tcp"
    port     = 7233
    interval = "10s"
    timeout  = "2s"
  }
```

or like this for gRPC (requires Consul ≥ `1.0.5`):

```
service {
  check {
    type         = "grpc"
    port         = 7233
    interval     = "10s"
    timeout      = "2s"
  }
```

---

## Self-hosted Multi-Cluster Replication

Multi-Cluster Replication is a feature which asynchronously replicates Workflow Executions from active Clusters to other passive Clusters, for backup and state reconstruction.
When necessary, for higher availability, Cluster operators can failover to any of the backup Clusters.

Temporal's Multi-Cluster Replication feature is considered **experimental** and not subject to normal [versioning and support policy](/temporal-service/temporal-server#versions-and-support).

Temporal automatically forwards Start, Signal, and Query requests to the active Cluster.
This feature must be enabled through a Dynamic Config flag per [Global Namespace](/global-namespace).

When the feature is enabled, Tasks are sent to the Parent Task Queue partition that matches that Namespace, if it exists.

All Visibility APIs can be used against active and standby Clusters.
This enables [Temporal UI](https://docs.temporal.io/web-ui) to work seamlessly for Global Namespaces.
Applications making API calls directly to the Temporal Visibility API continue to work even if a Global Namespace is in standby mode.
However, they might see a lag due to replication delay when querying the Workflow Execution state from a standby Cluster.

#### Namespace Versions

A _version_ is a concept in Multi-Cluster Replication that describes the chronological order of events per Namespace.

With Multi-Cluster Replication, all Namespace change events and Workflow Execution History events are replicated asynchronously for high throughput.
This means that data across clusters is **not** strongly consistent.
To guarantee that Namespace data and Workflow Execution data will achieve eventual consistency (especially when there is a data conflict during a failover), a **version** is introduced and attached to Namespaces.
All Workflow Execution History entries generated in a Namespace will also come with the version attached to that Namespace.

All participating Clusters are pre-configured with a unique initial version and a shared version increment:

- `initial version < shared version increment`

When performing failover for a Namespace from one Cluster to another Cluster, the version attached to the Namespace will be changed by the following rule:

- for all versions which follow `version % (shared version increment) == (active cluster's initial version)`, find the smallest version which has `version >= old version in namespace`

When there is a data conflict, a comparison will be made and Workflow Execution History entries with the highest version will be considered the source of truth.

When a cluster is trying to mutate a Workflow Execution History, the version will be checked.
A cluster can mutate a Workflow Execution History only if the following is true:

- The version in the Namespace belongs to this cluster, i.e.
  `(version in namespace) % (shared version increment) == (this cluster's initial version)`
- The version of this Workflow Execution History's last entry (event) is equal or less than the version in the Namespace, i.e.
  `(last event's version) <= (version in namespace)`

<details>
    <summary>
    Namespace version change example
    </summary>

Assuming the following scenario:

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: Namespace α is registered, with active Cluster set to Cluster A

```
namespace α's version is 1
all workflows events generated within this namespace, will come with version 1
```

T = 1: namespace β is registered, with active Cluster set to Cluster B

```
namespace β's version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 2: Namespace α is updated to with active Cluster set to Cluster B

```
namespace α's version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 3: Namespace β is updated to with active Cluster set to Cluster A

```
namespace β's version is 11
all workflows events generated within this namespace, will come with version 11
```

</details>

#### Version history

Version history is a concept which provides a high level summary of version information in regards to Workflow Execution History.

Whenever there is a new Workflow Execution History entry generated, the version from Namespace will be attached.
The Workflow Executions's mutable state will keep track of all history entries (events) and the corresponding version.

<details>
    <summary>
        Version history example (without data conflict)
    </summary>

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: adding event with event ID == 1 & version == 1

View in both Cluster A & B

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 1               | 1       |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 2 & version == 1

View in both Cluster A & B

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: adding event with event ID == 3 & version == 1

View in both Cluster A & B

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               |                 |         |
| 3        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 3: Namespace failover triggered, Namespace version is now 2
adding event with event ID == 4 & version == 2

View in both Cluster A & B

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 4: adding event with event ID == 5 & version == 2

View in both Cluster A & B

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 5               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| 5        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

</details>

Since Temporal is AP, during failover (change of active Temporal Cluster Namespace), there can exist cases where more than one Cluster can modify a Workflow Execution, causing divergence of Workflow Execution History. Below shows how the version history will look like under such conditions.

<details>
    <summary>
    Version history example (with data conflict)
    </summary>

Below, shows version history of the same Workflow Execution in 2 different Clusters.

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Cluster C comes with initial version: 3
- Shared version increment: 10

T = 0:

View in both Cluster B & C

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 4 & version == 2 in Cluster B

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 2               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: namespace failover to Cluster C, adding event with event ID == 4 & version == 3 in Cluster C

```
| -------- | --------------- | --------------- | ------- |
| Events   | Version History |                 |         |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               | 4               | 3       |
| 4        | 3               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: replication task from Cluster C arrives in Cluster B

Note: below is a tree structures

```
| ------------- | ------------- |
| Events         |               |
| -------------- | ------------- |
| Event ID       | Event Version |
| -------------  | ------------- |
| 1              | 1             |
| 2              | 1             |
| 3              | 2             |
| -------------  | ------------- |
|                |               |
| -------------  | ------------- |
|                |               |
| -------------- | ------------- |  | -------- | ------------- |
| Event ID       | Event Version |  | Event ID | Event Version |
| -------------  | ------------- |  | -------- | ------------- |
| 4              | 2             |  | 4        | 3             |
| -------------- | ------------- |  | -------- | ------------- |

| --------------- | ----------- |
| Version History |              |
| --------------- | ------------ |
| Event ID        | Version      |
| --------------- | ------------ |
| 2               | 1            |
| 3               | 2            |
| --------------- | ------------ |

| --------------- | ----------- |  | --------------- | ------- |
| Event ID | Version |  | Event ID | Version |
| -------- | ------- || --------------- | ------- |
| 4   | 2   |  | 4 | 3 |
| --- | --- || --------------- | ------- |
```

T = 2: replication task from Cluster B arrives in Cluster C, same as above

</details>

#### Conflict resolution

When a Workflow Execution History diverges, proper conflict resolution is applied.

In Multi-cluster Replication, Workflow Execution History Events are modeled as a tree, as shown in the second example in [Version History](#version-history).

Workflow Execution Histories that diverge will have more than one history branch.
Among all history branches, the history branch with the highest version is considered the `current branch` and the Workflow Execution's mutable state is a summary of the current branch.
Whenever there is a switch between Workflow Execution History branches, a complete rebuild of the Workflow Execution's mutable state will occur.

Temporal Multi-Cluster Replication relies on asynchronous replication of Events across Clusters, so in the case of a failover it is possible to have an Activity Task dispatched again to the newly active Cluster due to a replication task lag.
This also means that whenever a Workflow Execution is updated after a failover by the new Cluster, any previous replication tasks for that Execution cannot be applied.
This results in loss of some progress made by the Workflow Execution in the previous active Cluster.
During such conflict resolution, Temporal re-injects any external Events like Signals in the new Event History before discarding replication tasks.
Even though some progress could roll back during failovers, Temporal provides the guarantee that Workflow Executions won't get stuck and will continue to make forward progress.

Activity Execution completions are not forwarded across Clusters.
Any outstanding Activities will eventually time out based on the configuration.
Your application should have retry logic in place so that the Activity gets retried and dispatched again to a Worker after the failover to the new Cluster.
Handling this is similar to handling an Activity Task timeout caused by a Worker restarting.

#### Zombie Workflows

There is an existing contract that for any Namespace and Workflow Id combination, there can be at most one run (Namespace + Workflow Id + Run Id) open / executing.

Multi-cluster Replication aims to keep the Workflow Execution History as up-to-date as possible among all participating Clusters.

Due to the nature of Multi-cluster Replication (for example, Workflow Execution History events are replicated asynchronously) different Runs (same Namespace and Workflow Id) can arrive at the target Cluster at different times, sometimes out of order, as shown below:

```
| ------------- |          | ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
        |                          |                          |
        | Run 1 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        | Run 2 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        |                          |                          |
        |                          |                          |
        |                          | Run 2 Replication Events |
        |                          | -----------------------> |
        |                          |                          |
        |                          | Run 1 Replication Events |
        |                          | -----------------------> |
        |     |  |
        | --- || ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
```

Because Run 2 appears in Cluster B first, Run 1 cannot be replicated as "runnable" due to the rule `at most one Run open` (see above), thus the "zombie" Workflow Execution state is introduced.
A "zombie" state is one in which a Workflow Execution which cannot be actively mutated by a Cluster (assuming the corresponding Namespace is active in this Cluster). A zombie Workflow Execution can only be changed by a replication Task.

Run 1 will be replicated similar to Run 2, except when Run 1's execution will become a "zombie" before Run 1 reaches completion.

#### Workflow Task processing

In the context of Multi-cluster Replication, a Workflow Execution's mutable state is an entity which tracks all pending tasks.
Prior to the introduction of Multi-cluster Replication, Workflow Execution History entries (events) are from a single branch, and the Temporal Server will only append new entries (events) to the Workflow Execution History.

After the introduction of Multi-cluster Replication, it is possible that a Workflow Execution can have multiple Workflow Execution History branches.
Tasks generated according to one history branch may become invalidated by switching history branches during conflict resolution.

Example:

T = 0: task A is generated according to Event Id: 4, version: 2

```
| -------- | ------------- |
| Events   |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 1        | 1             |
| 2        | 1             |
| 3        | 2             |
| -------- | ------------- |
|          |
|          |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 4        | 2             | <-- task A belongs to this event |
| -------- | ------------- |
```

T = 1: conflict resolution happens, Workflow Execution's mutable state is rebuilt and history Event Id: 4, version: 3 is written down to persistence

```
| ------------- | -------------- |
| Events        |
| ------------- | -------------- |
| Event ID      | Event Version  |
| ------------- | -------------- |
| 1             | 1              |
| 2             | 1              |
| 3             | 2              |
| ------------- | -------------- |

| --------------| -------------- |                                  |----------| ----------------- |
| Event ID | Event Version |  | Event ID | Event Version |
| -------- | ------------- || -------- | ----------------- |
| 4   | 2   | <-- task A belongs to this event | 4 | 3 | <-- current branch / mutable state |
| --- | --- || -------- | ----------------- |
```

T = 2: task A is loaded.

At this time, due to the rebuild of a Workflow Execution's mutable state (conflict resolution), Task A is no longer relevant (Task A's corresponding Event belongs to non-current branch).
Task processing logic will verify both the Event Id and version of the Task against a corresponding Workflow Execution's mutable state, then discard task A.

## How to set up Multi-Cluster Replication {#set-up-multi-cluster-replication}

The [Multi-Cluster Replication](/self-hosted-guide/multi-cluster-replication) feature asynchronously replicates Workflow Execution Event Histories from active Clusters to other passive Clusters, and can be enabled by setting the appropriate values in the `clusterMetadata` section of your configuration file.

1. `enableGlobalNamespace` must be set to `true`.
2. `failoverVersionIncrement` has to be equal across connected Clusters.
3. `initialFailoverVersion` in each Cluster has to assign a different value.
   No equal value is allowed across connected Clusters.

After the above conditions are satisfied, you can start to configure a multi-cluster setup.

#### Set up Multi-Cluster Replication prior to v1.14

You can set this up with [`clusterMetadata` configuration](/references/configuration#clustermetadata); however, this is meant to be only a conceptual guide rather than a detailed tutorial.

:::tip

If you need help when setting up, please reach out to our [community Slack](https://temporalio.slack.com).
Good places to start include the **\#support-community** channel, searching through previous conversations, and asking our unusually excellent Temporal-trained large language model (visit **\#ask-ai**).

Need a Slack invitation?
Here's an [invitation link](https://temporal.io/slack).

:::

For example:

```yaml
# cluster A
clusterMetadata:
  enableGlobalNamespace: true
  failoverVersionIncrement: 100
  masterClusterName: "clusterA"
  currentClusterName: "clusterA"
  clusterInformation:
    clusterA:
      enabled: true
      initialFailoverVersion: 1
      rpcAddress: "127.0.0.1:7233"
    clusterB:
      enabled: true
      initialFailoverVersion: 2
      rpcAddress: "127.0.0.1:8233"

# cluster B
clusterMetadata:
  enableGlobalNamespace: true
  failoverVersionIncrement: 100
  masterClusterName: "clusterA"
  currentClusterName: "clusterB"
  clusterInformation:
    clusterA:
      enabled: true
      initialFailoverVersion: 1
      rpcAddress: "127.0.0.1:7233"
    clusterB:
      enabled: true
      initialFailoverVersion: 2
      rpcAddress: "127.0.0.1:8233"
```

#### Set up Multi-Cluster Replication in v1.14 and later

You still need to set up local cluster [`clusterMetadata` configuration](/references/configuration#clustermetadata)

For example:

```yaml
# cluster A
clusterMetadata:
  enableGlobalNamespace: true
  failoverVersionIncrement: 100
  masterClusterName: "clusterA"
  currentClusterName: "clusterA"
  clusterInformation:
    clusterA:
      enabled: true
      initialFailoverVersion: 1
      rpcAddress: "127.0.0.1:7233"

# cluster B
clusterMetadata:
  enableGlobalNamespace: true
  failoverVersionIncrement: 100
  masterClusterName: "clusterB"
  currentClusterName: "clusterB"
  clusterInformation:
    clusterB:
      enabled: true
      initialFailoverVersion: 2
      rpcAddress: "127.0.0.1:8233"
```

Then you can use the Temporal CLI tool to add cluster connections. All operations should be executed in both Clusters.

{/* tctl -address 127.0.0.1:7233 admin cluster upsert-remote-cluster --frontend_address "localhost:8233" */}

{/* tctl -address 127.0.0.1:8233 admin cluster upsert-remote-cluster --frontend_address "localhost:7233" */}

{/* tctl -address 127.0.0.1:7233 admin cluster upsert-remote-cluster --frontend_address "localhost:8233" --enable_connection false
tctl -address 127.0.0.1:8233 admin cluster upsert-remote-cluster --frontend_address "localhost:7233" --enable_connection false */}

{/* tctl -address 127.0.0.1:7233 admin cluster remove-remote-cluster --cluster "clusterB"
tctl -address 127.0.0.1:8233 admin cluster remove-remote-cluster --cluster "clusterA" */}

{/* THIS MUST BE CHECKED FOR ACCURACY */}

```shell
# Add a cluster
temporal operator cluster upsert --frontend_address="127.0.2.1:8233"

# Disable connections
temporal operator cluster upsert --frontend_address="localhost:8233" --enable_connection false

# Delete connections
temporal operator cluster remove --name="someClusterName"
```

---

## Temporal Platform security features

:::info General company security

For information about the general security habits of Temporal Technologies, see our [trust page](https://trust.temporal.io).

:::

:::info Cloud security

For information about Temporal Cloud security features, see our [Cloud security page](/cloud/security)
:::

The Temporal Platform is designed with security in mind, and there are many features that you can use to keep both the Platform itself and your user's data secure.

A secured Temporal Server has its network communication encrypted and has authentication and authorization protocols set up for API calls made to it.
Without these, your server could be accessed by unwanted entities.

What is documented on this page are the built-in opt-in security measures that come with Temporal.
However users may also choose to design their own security architecture with reverse proxies or run unsecured instances inside of a VPC environment.

### Server Samples

The https://github.com/temporalio/samples-server repo offers two examples, which are further explained below:

- **TLS:** how to configure Transport Layer Security (TLS) to secure network communication with and within a Temporal Service.
- **Authorizer:** how to inject a low-level authorizer component that can control access to all API calls.

### Encryption in transit with mTLS

Temporal supports Mutual Transport Layer Security (mTLS) as a way of encrypting network traffic between the services of a Temporal Service and also between application processes and a Temporal Service.
Self-signed or properly minted certificates can be used for mTLS.
mTLS is set in Temporal's [TLS configuration](/references/configuration#tls).
The configuration includes two sections such that intra-Temporal Service and external traffic can be encrypted with different sets of certificates and settings:

- `internode`: Configuration for encrypting communication between nodes in the Temporal Service.
- `frontend`: Configuration for encrypting the Frontend's public endpoints.

A customized configuration can be passed using either the [WithConfig](/references/server-options#withconfig) or [WithConfigLoader](/references/server-options#withconfigloader) Server options.

See [TLS configuration reference](/references/configuration#tls) for more details.

### Authentication

There are a few authentication protocols available to prevent unwanted access such as authentication of servers, clients, and users.

### Servers

To prevent spoofing and [MITM attacks](https://en.wikipedia.org/wiki/Man-in-the-middle_attack) you can specify the `serverName` in the `client` section of your respective mTLS configuration.
This enables established connections to authenticate the endpoint, ensuring that the server certificate presented to any connecting Client has the appropriate server name in its CN property.
It can be used for both `internode` and `frontend` endpoints.

More guidance on mTLS setup can be found in [the `samples-server` repo](https://github.com/temporalio/samples-server/tree/main/tls) and you can reach out to us for further guidance.

### Client connections

To restrict a client's network access to Temporal Service endpoints you can limit it to clients with certificates issued by a specific Certificate Authority (CA).
Use the `clientCAFiles`/ `clientCAData` and `requireClientAuth` properties in both the `internode` and `frontend` sections of the [mTLS configuration](/references/configuration#tls).

### Users

To restrict access to specific users, authentication and authorization is performed through extensibility points and plugins as described in the [Authorization](#authorization) section below.

#### Authorization

:::note
Information regarding [`Authorizer`](#authorizer-plugin) and [`ClaimMapper`](#claim-mapper) has been moved to another location.
:::

Temporal offers two plugin interfaces for implementing API call authorization:

- [`ClaimMapper`](#claim-mapper)
- [`Authorizer`](#authorizer-plugin)

The authorization and claim mapping logic is customizable, making it available to a variety of use cases and identity schemes.
When these are provided the frontend invokes the implementation of these interfaces before executing the requested operation.

See https://github.com/temporalio/samples-server/blob/main/extensibility/authorizer for a sample implementation.

<CaptionedImage
    src="/diagrams/frontend-authorization-order-of-operations.png"
    title="Front-end authorization order of operations"
/>

### Single sign-on integration

Temporal can be integrated with a single sign-on (SSO) experience by utilizing the `ClaimMapper` and `Authorizer` plugins.
The default JWT `ClaimMapper` implementation can be used as is or as a base for a custom implementation of a similar plugin.

### Temporal UI

To enable SSO authentication in the Temporal UI using environment credentials, you need to configure the UI container with specific environment variables that define your identity provider and OAuth settings.
In your docker-compose.yaml, set `TEMPORAL_AUTH_ENABLED=true` to activate authentication.
Next, specify the required OAuth credentials and endpoints using environment variables such as:

- `TEMPORAL_AUTH_CLIENT_ID`
- `TEMPORAL_AUTH_CLIENT_SECRET`
- `TEMPORAL_AUTH_PROVIDER_URL`
- `TEMPORAL_AUTH_CALLBACK_URL`

These values correspond to the client credentials and endpoints provided by your OAuth identity provider (such as Google, Auth0, Okta).
When properly configured, Temporal UI will redirect users to your SSO login page and enforce authentication on access.
This approach does not require any additional configuration files, making it ideal for containerized environments using secure environment variable injection.

```yaml
temporal-ui:
  container_name: temporal-ui
  depends_on:
    - temporal
  environment:
    - TEMPORAL_GRPC_ENDPOINT=temporal:7233
    - TEMPORAL_ADDRESS=temporal:7233
    - TEMPORAL_AUTH_ENABLED=true
    - TEMPORAL_AUTH_PROVIDER_URL=https://example.com
    - TEMPORAL_AUTH_CLIENT_ID=xxxxxxxxxxxxxx
    - TEMPORAL_AUTH_CLIENT_SECRET=xxxxxxxxxxxxxx
    - TEMPORAL_AUTH_CALLBACK_URL=https://your-domain/auth/sso/callback
    - TEMPORAL_AUTH_SCOPES=openid profile email
  image: temporalio/ui:latest
  networks:
    - temporal-network
  ports:
    - 8080:8080
```

For more general guidance for configuration, refer to the [Temporal UI README](https://github.com/temporalio/web?tab=readme-ov-file#configuration).
For more details on configuration with Docker, refer to [Temporal UI Config](https://github.com/temporalio/ui/blob/c95265ee6431fd0f6cf78ae06373885d66a8ee0c/server/docker/config-template.yaml).

## Temporal Service plugins {#plugins}

The Temporal Service supports some pluggable components.

### What is a ClaimMapper Plugin? {#claim-mapper}

The Claim Mapper component is a pluggable component that extracts Claims from JSON Web Tokens (JWTs).

This process is achieved with the method `GetClaims`, which translates `AuthInfo` structs from the caller into `Claims` about the caller's roles within Temporal.

A `Role` (within Temporal) is a bit mask that combines one or more of the role constants.
In the following example, the role is assigned constants that allow the caller to read and write information.

```go
role := authorization.RoleReader | authorization.RoleWriter
```

`GetClaims` is customizable and can be modified with the `temporal.WithClaimMapper` server option.
Temporal also offers a default JWT `ClaimMapper` for your use.

A typical approach is for `ClaimMapper` to interpret custom `Claims` from a caller's JWT, such as membership in groups, and map them to Temporal roles for the user.
The subject information from the caller's mTLS certificate can also be a parameter in determining roles.

#### `AuthInfo`

`AuthInfo` is a struct that is passed to `GetClaims`. `AuthInfo` contains an authorization token extracted from the `authorization` header of the gRPC request.

`AuthInfo` includes a pointer to the `pkix.Name` struct.
This struct contains an [x.509](https://www.ibm.com/docs/en/ibm-mq/7.5?topic=certificates-distinguished-names) Distinguished Name from the caller's mTLS certificate.

#### `Claims`

`Claims` is a struct that contains information about permission claims granted to the caller.

`Authorizer` assumes that the caller has been properly authenticated, and trusts the `Claims` when making an authorization decision.

#### Default JWT ClaimMapper

Temporal offers a default JWT `ClaimMapper` that extracts the information needed to form Temporal `Claims`.
This plugin requires a public key to validate digital signatures.

To get an instance of the default JWT `ClaimMapper`, call `NewDefaultJWTClaimMapper` and provide it with the following:

- a `TokenKeyProvider` instance
- a `config.Authorization` pointer
- a logger

The code for the default `ClaimMapper` can also be used to build a custom `ClaimMapper`.

#### Token key provider

A `TokenKeyProvider` obtains public keys from specified issuers' URIs that adhere to a specific format.
The default JWT `ClaimMapper` uses this component to obtain and refresh public keys over time.

Temporal provides a `defaultTokenKeyProvider`.
This component dynamically obtains public keys that follow the [JWKS format](https://tools.ietf.org/html/rfc7517).
It supports formats such as `RSA` and `ECDSA`.

```go
provider := authorization.NewDefaultTokenKeyProvider(cfg, logger)
```

:::note

`KeySourceURIs` are the HTTP endpoints that return public keys of token issuers in the [JWKS format](https://tools.ietf.org/html/rfc7517).
`RefreshInterval` defines how frequently keys should be refreshed.
For example, [Auth0](https://auth0.com/) exposes endpoints such as `https://YOUR_DOMAIN/.well-known/jwks.json`.

:::

By default, "permissions" is used to name the `permissionsClaimName` value.

Configure the plugin with `config.Config.Global.Authorization.JWTKeyProvider`.

#### JSON Web Token format

The default JWT `ClaimMapper` expects authorization tokens to be formatted as follows:

```
Bearer <token>
```

The Permissions Claim in the JWT Token is expected to be a collection of Individual Permission Claims.
Each Individual Permission Claim must be formatted as follows:

```
<namespace> : <permission>
```

These permissions are then converted into Temporal roles for the caller.
This can be one of Temporal's four values:

- read
- write
- worker
- admin

Multiple permissions for the same Namespace are overridden by the `ClaimMapper`.

##### Example of a payload for the default JWT ClaimMapper

```
{
   "permissions":[
      "temporal-system:read",
      "namespace1:write"
   ],
   "aud":[
      "audience"
   ],
   "exp":1630295722,
   "iss":"Issuer"
}
```

### What is an Authorizer Plugin? {#authorizer-plugin}

The `Authorizer` plugin contains a single `Authorize` method, which is invoked for each incoming API call.
`Authorize` receives information about the API call, along with the role and permission claims of the caller.

`Authorizer` allows for a wide range of authorization logic, including call target, role/permissions claims, and other data available to the system.

#### Configuration

The following arguments must be passed to `Authorizer`:

- `context.Context`: General context of the call.
- `authorization.Claims`: Claims about the roles assigned to the caller. Its intended use is described in the [`Claims`](#claims) section earlier on this page.
- `authorization.CallTarget`: Target of the API call.

`Authorizer` then returns one of two decisions:

- `DecisionDeny`: the requested API call is not invoked and an error is returned to the caller.
- `DecisionAllow`: the requested API call is invoked.

:::warning Security Warning

If you do **not** explicitly configure an `Authorizer`, Temporal uses the default `noopAuthorizer`. This default allows **every** API request,
with no authentication or access control. Anyone who can reach your Temporal Server can invoke any API, including sensitive administrative operations.
This is **not secure** for production or for any environment that is accessible to untrusted clients (such as over the internet).

**To protect your Temporal Server, you must configure an `Authorizer` plugin with a corresponding `ClaimMapper`.** Without this, your deployment is
effectively open to anyone with network access.

:::

Configure your `Authorizer` with the [`temporal.WithAuthorizer`](/references/server-options#withauthorizer) server option, and your `ClaimMapper` with
the [`temporal.WithClaimMapper`](/references/server-options#withclaimmapper) server option.

```go
temporalServer, err := temporal.NewServer(
	temporal.WithAuthorizer(newCustomAuthorizer()),
	temporal.WithClaimMapper(func(cfg *config.Config) authorization.ClaimMapper {
		return newCustomClaimMapper(cfg)
	}),
)
```

#### How to authorize SDK API calls {#authorize-api-calls}

When authentication is enabled, you can authorize API calls made to the Frontend Service.

The Temporal Server [expects](#authentication) an `authorization` gRPC header with an authorization token to be passed with API calls if [requests authorization](#authorization) is configured.

Authorization Tokens may be provided to the Temporal Java SDK by implementing a `io.temporal.authorization.AuthorizationTokenSupplier` interface.
The implementation should be used to create `io.temporal.authorization.AuthorizationGrpcMetadataProvider` that may be configured on ServiceStub gRPC interceptors list.

The implementation is called for each SDK gRPC request and may supply dynamic tokens.

**JWT**

One of the token types that may be passed this way are JWT tokens.
Temporal Server provides a [default implementation of JWT authentication](#default-jwt-claimmapper).

**Example**

```java
AuthorizationTokenSupplier tokenSupplier =
  //your implementation of token supplier
  () -> "Bearer <Base64 url-encoded value of the token for default JWT ClaimMapper>";
WorkflowServiceStubsOptions serviceStubOptions =
  WorkflowServiceStubsOptions.newBuilder()
    //other service stub options
    .addGrpcMetadataProvider(new AuthorizationGrpcMetadataProvider(tokenSupplier))
    .build();
WorkflowServiceStubs service = WorkflowServiceStubs.newServiceStubs(serviceStubOptions);
WorkflowClient client = WorkflowClient.newInstance(service);
```

Related read:

- [How to secure a Temporal Service](/security)

## Data Converter {#data-converter}

Each Temporal SDK provides a [Data Converter](/dataconversion) that can be customized with a custom [Payload Codec](/payload-codec) to encode and secure your data.

For details on what data can be encoded, how to secure it, and what to consider when using encryption, see [Data encryption](/production-deployment/data-encryption).

#### Codec Server

You can use a [Codec Server](/codec-server) with your custom Payload Codec to decode the data you see on your Web UI and CLI locally through remote endpoints.
However, ensure that you consider all security implications of [remote data encoding](/remote-data-encoding) before using a Codec Server.

For details on how to set up a Codec Server, see [Codec Server setup](/production-deployment/data-encryption#codec-server-setup).

---

## Server Frontend API Reference

While it's usually easiest to interact with [Temporal Server](/temporal-service/temporal-server) via a [Client SDK](/encyclopedia/temporal-sdks#temporal-client) or the [Temporal CLI](https://docs.temporal.io/cli), you can also use its gRPC API.

## gRPC API

Our Client and Worker SDKs use the gRPC API. The API reference is located here:

[`api-docs.temporal.io`](https://api-docs.temporal.io/)

### Use with code

Usually you interact with the API via high-level methods like `client.workflow.start()`. However, Client SDKs also expose the underlying gRPC services. For instance, the TypeScript SDK has:

- WorkflowService: [`Client.connection.workflowService`](https://typescript.temporal.io/api/classes/client.Connection#workflowservice)
- OperatorService: [`Client.connection.operatorService`](https://typescript.temporal.io/api/classes/client.Connection/#operatorservice)
- HealthService: [`Client.connection.healthService`](https://typescript.temporal.io/api/classes/client.Connection/#healthservice)

If you're not using an SDK Client (rare), you can generate gRPC client stubs by:

- Cloning [`temporalio/api`](https://github.com/temporalio/api) (repo with the protobuf files)
- Generating code in [your language](https://grpc.io/docs/languages/)

### Use manually

To query the API manually via command line or a GUI, first:

- If you don't already have a Server to connect to, run [`temporal server start-dev`](/cli/server#start-dev)
- Clone this repo:

```shell
git clone https://github.com/temporalio/api.git
cd api
```

#### With command line

Install [`evans`](https://github.com/ktr0731/evans#installation).

```shell
cd /path/to/api
evans --proto temporal/api/workflowservice/v1/service.proto --port 7233
```

To connect to Temporal Cloud, set the host, cert, cert key, and TLS flag:

```shell
evans --proto temporal/api/workflowservice/v1/service.proto --host devrel.a2dd6.tmprl.cloud --port 7233 --tls --cert /Users/me/certs/temporal.pem --certkey /Users/me/certs/temporal.key
```

Once inside the evans prompt, you can run commands like `help`, `show service` to list available methods, and `call ListWorkflowExecutions`.

#### With a GUI

- Install [BloomRPC](https://github.com/bloomrpc/bloomrpc#installation).
- Open the app
- Select "Import Paths" button on the top-left and enter the path to the cloned repo: `/path/to/api`
- Select the "Import protos" + button and select this file:

```shell
/path/to/api/temporal/api/workflowservice/v1/service.proto
```

- A list of methods should appear in the sidebar. Select one.
- Edit the JSON in the left pane.
- Hit `Cmd/Ctrl-Enter` or click the play button to get a response from the server on the right.

<CaptionedImage
    src="/img/proto/ListWorkflowExecutions.png"
    title="ListWorkflowExecutions"
/>

One downside compared to [command line](#with-command-line) is it doesn't show enum names, just numbers like `"task_queue_type": 1`.

<CaptionedImage
    src="/img/proto/DescribeTaskQueue.png"
    title="DescribeTaskQueue"
/>

## HTTP API

The Web UI uses [`temporalio/ui-server`](https://github.com/temporalio/ui-server), an HTTP proxy for the gRPC API.

:::caution

As soon as [this HTTP API proposal](https://github.com/temporalio/proposals/pull/79) is implemented, it will be the recommended HTTP API, at which point the `ui-server` API may be discontinued. Further, `ui-server` was designed for use in the UI, and may make breaking changes.

:::

To view the API docs, run [`temporal server start-dev`](/cli#start-dev-server) and open:

[`localhost:8233/openapi/`](http://localhost:8233/openapi/)

To make a request, run:

````sh
$ curl localhost:8233/api/v1/namespaces/default/workflows

{
  "executions": [
    {
      "execution": {
        "workflowId": "workflow-_homozdkzYWLRpX6Rfou5",
        "runId": "c981cb26-baa4-4af8-ac5f-866451d3f83c"
      },
      "type": {
        "name": "example"
      },
      "startTime": ...
    },
    ...
  ],
  "nextPageToken": null
}
```

*/}
````

---

## Self-hosted Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability).
Learn why you should use Nexus in the [evaluation guide](/evaluate/nexus).

:::

[Temporal Nexus](/nexus) allows you to reliably connect Temporal Applications.
It was designed with Durable Execution in mind and enables each team to have their own Namespace for improved modularity, security, debugging, and fault isolation.

<CaptionedImage
    src="/img/cloud/nexus/nexus-overview-short.png"
    title="Nexus Overview"
/>

## Enable Nexus

Enable Nexus in your self-hosted Temporal Service by updating the server's static configuration file and enabling Nexus through dynamic config, then setting the public callback URL and allowed callback addresses.
Nexus is only supported in single cluster setups at this time.
For additional information on operating Nexus workloads in your self-hosted cluster, see [Nexus Architecture](https://github.com/temporalio/temporal/blob/main/docs/architecture/nexus.md).

:::note
Replace `$PUBLIC_URL` with a URL value that's accessible to external callers or internally within the cluster.
Currently, external Nexus calls are considered experimental so it should be safe to use the address of an internal load balancer for the Frontend Service.
:::

To enable Nexus in your deployment:

1. Ensure that the server's static configuration file enables the HTTP API.

   ```yaml
   services:
     frontend:
       rpc:
         # NOTE: keep other fields as they were
         httpPort: 7243

   clusterMetadata:
     # NOTE: keep other fields as they were
     clusterInformation:
       active:
         # NOTE: keep other fields as they were
         httpAddress: $PUBLIC_URL:7243
   ```

2. Enable Nexus through dynamic config, set the public callback URL, and set the allowed callback addresses.

   ```yaml
   system.enableNexus:
     - value: true
   component.nexusoperations.callback.endpoint.template:
     # The URL must be publicly accessible if the callback is meant to be called by external services.
     # When using Nexus for cross namespace calls, the URL's host is irrelevant as the address is resolved using
     # membership. The URL is a Go template that interpolates the `NamepaceName` and `NamespaceID` variables.
     - value: https://$PUBLIC_URL:7243/namespaces/{{.NamespaceName}}/nexus/callback
   component.callbacks.allowedAddresses:
     # This list is a security mechanism for limiting which callback URLs are accepted by the server.
     # Attackers may leverage the callback mechanism to force the server to call arbitrary URLs.
     # The config below is only recommended for development, tune this to your requirements.
     - value:
         - Pattern: "*"
           AllowInsecure: true
   ```

## Build and use Nexus Services

Nexus has a familiar programming model to build and use Nexus Services using the Temporal SDK.
The [Nexus Operation lifecycle](/nexus/operations#operation-lifecycle) supports both synchronous and asynchronous Operations.
Nexus Operations can be implemented with Temporal primitives, like a Workflow, or execute arbitrary code.

:::tip RESOURCES

- [Go SDK - Nexus quick start and code sample](/develop/go/nexus)
- [Java SDK - Nexus quick start and code sample](/develop/java/nexus)

:::

## Learn more

- [Evaluate](/evaluate/nexus) why you should use Nexus and watch the [Nexus keynote and demo](https://youtu.be/qqc2vsv1mrU?feature=shared&t=2082).
- [Learn key Nexus concepts](/nexus) and how Nexus works in the [Nexus deep dive talk](https://www.youtube.com/watch?v=izR9dQ_eIe4&t=934s)
- Explore [additional resources](/evaluate/nexus#learn-more) to learn more about Nexus.

---

## Upgrade the Temporal Server

## How to upgrade the Temporal Server version {#upgrade-server}

If a newer version of the [Temporal Server](/temporal-service/temporal-server) is available, a notification appears in the Temporal Web UI.

:::info

If you are using a version that is older than 1.0.0, reach out to us at [community.temporal.io](http://community.temporal.io) to ask how to upgrade.

:::

First check to see if an upgrade to the database schema is required for the version you wish to upgrade to.
If a database schema upgrade is required, it will be called out directly in the [release notes](https://github.com/temporalio/temporal/releases).
Some releases require changes to the schema, and some do not.
We ensure that any consecutive versions are compatible in terms of database schema upgrades, features, and system behavior; however there is no guarantee that there is compatibility between _any_ two non-consecutive versions.

### Key considerations

When upgrading the Temporal Server, there are two key considerations to keep in mind:

1. **Sequential Upgrades:** Temporal Server should be upgraded sequentially.
   That is, if you're on version \(v1.n.x\), your next upgrade should be to \(v1.n+1.x\) or the closest available subsequent version.
   This sequence should be repeated until your desired version is reached.

2. **Data Compatibility:** During an upgrade, the Temporal Server either updates or restructures the existing version data to match the data format of the newer version.
   Temporal Server ensures backward compatibility only between two successive minor versions.
   Consequently, skipping versions during an upgrade may lead to older data formats becoming unreadable.
   If the previous data format cannot be interpreted and converted to the newer format, the upgrade process will be unsuccessful.

### Step-by-Step Upgrade Procedure:

Upgrading the Temporal Server requires a methodical approach to ensure data integrity, compatibility, and seamless transition between versions.
The following documentation outlines the step-by-step process to successfully upgrade your Temporal Server.

When upgrading your Temporal Server version, ensure that you upgrade sequentially.

1. **Upgrade Database Schema:** Before initiating the Temporal Server upgrade, use one of the recommended upgrade tools to update your database schema.
   This ensures it is aligned with the version of Temporal Server you aim to upgrade to.
2. **Upgrade Temporal Server:** Once the database schema is updated, proceed to upgrade the Temporal Server deployment to the next sequential version.
3. **Iterative Upgrades** (optional): Continue this process (steps 1 and 2) iteratively until you reach the desired Temporal Server version.

By adhering to the above guidelines and following the step-by-step procedure, you can ensure a smooth and successful upgrade of your Temporal Server.

The Temporal Server upgrade updates or rewrites the old version data with the format introduced in the newer version.
Because Temporal Server guarantees backward compatibility between two consecutive minor versions, and because older versions of the code are eventually removed from the code base, skipping versions when upgrading might cause older formats to become unrecognizable.
If the old format of the data can't be read to be rewritten to the new format, the upgrades fail.

Check the [Temporal Server releases](https://github.com/temporalio/temporal/releases) and follow these releases in order.
You can skip patch versions; use the latest patch of a minor version when upgrading.

Also, be aware that each upgrade requires the History Service to load all Shards and update the Shard metadata, so allow approximately 10 minutes on each version for these processes to complete before upgrading to the next version.

Use one of the upgrade tools to upgrade your database schema to be compatible with the Temporal Server version being upgraded to.

If you are using a schema tools version prior to Temporal Server v1.8.0, we strongly recommend _never_ using the "dryrun" (`-y`, or `--dryrun`) options in any of your schema update commands.
Using this option might lead to potential loss of data, as when using it will create a new database and drop your
existing one.
This flag was removed in the 1.8.0 release.

### Upgrade Cassandra schema

If you are using Cassandra for your Temporal Service's persistence, use the `temporal-cassandra-tool` to upgrade both the default Persistence and Visibility schemas.

**Example default schema upgrade:**

```bash
temporal_v1.2.1 $ temporal-cassandra-tool \
   --tls \
   --tls-ca-file <...> \
   --user <cassandra-user> \
   --password <cassandra-password> \
   --endpoint <cassandra.example.com> \
   --keyspace temporal \
   --timeout 120 \
   update \
   --schema-dir ./schema/cassandra/temporal/versioned
```

**Example visibility schema upgrade:**

```bash
temporal_v1.2.1 $ temporal-cassandra-tool \
   --tls \
   --tls-ca-file <...> \
   --user <cassandra-user> \
   --password <cassandra-password> \
   --endpoint <cassandra.example.com> \
   --keyspace temporal_visibility \
   --timeout 120 \
   update \
   --schema-dir ./schema/cassandra/visibility/versioned
```

### Upgrade PostgreSQL or MySQL schema

If you are using MySQL or PostgreSQL use the `temporal-sql-tool`, which works similarly to the `temporal-cassandra-tool`.

Refer to this [Makefile](https://github.com/temporalio/temporal/blob/v1.4.1/Makefile#L367-L383) for context.

#### PostgreSQL

**Example default schema upgrade:**

```bash
./temporal-sql-tool \
	--tls \
	--tls-enable-host-verification \
	--tls-cert-file <path to your client cert> \
	--tls-key-file <path to your client key> \
	--tls-ca-file <path to your CA> \
	--ep localhost -p 5432 -u temporal -pw temporal --pl postgres --db temporal update-schema -d ./schema/postgresql/v96/temporal/versioned
```

**Example visibility schema upgrade:**

```bash
./temporal-sql-tool \
	--tls \
	--tls-enable-host-verification \
	--tls-cert-file <path to your client cert> \
	--tls-key-file <path to your client key> \
	--tls-ca-file <path to your CA> \
	--ep localhost -p 5432 -u temporal -pw temporal --pl postgres --db temporal_visibility update-schema -d ./schema/postgresql/v96/visibility/versioned
```

If you're upgrading PostgreSQL to v12 or later to enable advanced Visibility features with Temporal Server v1.20, upgrade your PostgreSQL version first, and then run `temporal-sql-tool` with the `postgres12` plugin, as shown in the following example:

```bash
./temporal-sql-tool \
	--tls \
	--tls-enable-host-verification \
	--tls-cert-file <path to your client cert> \
	--tls-key-file <path to your client key> \
	--tls-ca-file <path to your CA> \
	--ep localhost -p 5432 -u temporal -pw temporal --pl postgres12 --db temporal_visibility update-schema -d ./schema/postgresql/v12/visibility/versioned
```

#### MySQL

**Example default schema upgrade:**

```bash
./temporal-sql-tool \
	--tls \
	--tls-enable-host-verification \
	--tls-cert-file <path to your client cert> \
	--tls-key-file <path to your client key> \
	--tls-ca-file <path to your CA> \
	--ep localhost -p 3036 -u root -pw root --pl mysql --db temporal update-schema -d ./schema/mysql/v57/temporal/versioned/
```

**Example visibility schema upgrade:**

```bash
./temporal-sql-tool \
	--tls \
	--tls-enable-host-verification \
	--tls-cert-file <path to your client cert> \
	--tls-key-file <path to your client key> \
	--tls-ca-file <path to your CA> \
	--ep localhost -p 3036 -u root -pw root --pl mysql --db temporal_visibility update-schema -d ./schema/mysql/v57/visibility/versioned/
```

If you're upgrading MySQL to v8.0.17 or later to enable advanced Visibility features with Temporal Server v1.20, upgrade your MySQL version first, and then run `temporal-sql-tool` with the `mysql8` plugin, as shown in the following example:

```bash
./temporal-sql-tool \
	--tls \
	--tls-enable-host-verification \
	--tls-cert-file <path to your client cert> \
	--tls-key-file <path to your client key> \
	--tls-ca-file <path to your CA> \
	--ep localhost -p 5432 -u temporal -pw temporal --pl mysql8 --db temporal_visibility update-schema -d ./schema/mysql/v8/visibility/versioned.
```

### Roll-out technique

We recommend preparing a staging Temporal Service and then do the following to verify the upgrade is successful:

1. Create some simulation load on the staging Temporal Service.
2. Upgrade the database schema in the staging Temporal Service.
3. Wait and observe for a few minutes to verify that there is no unstable behavior from both the server and the simulation load logic.
4. Upgrade the server.
5. Now do the same to the live environment Temporal Service.

---

## Self-hosted Visibility feature setup

A [Visibility](/temporal-service/visibility) store is set up as a part of your [Persistence store](/temporal-service/persistence) to enable listing and filtering details about Workflow Executions that exist on your Temporal Service.

A Visibility store is required in a Temporal Service setup because it is used by Temporal Web UI and CLI to pull Workflow Execution data and enables features like batch operations on a group of Workflow Executions.

With the Visibility store, you can use [List Filters](/list-filter) with [Search Attributes](/search-attribute) to list and filter Workflow Executions that you want to review.

Setting up [advanced Visibility](/visibility#advanced-visibility) enables access to creating and using multiple custom Search Attributes with your List Filters.

For details, see [Search Attributes](/search-attribute).

Note that if you use MySQL, PostgreSQL, or SQLite as your Visibility store, Temporal Server version 1.20 and later supports advanced Visibility features on MySQL (version 8.0.17 and later), PostgreSQL (version 12 and later) and SQLite (v3.31.0 and later), in addition to Elasticsearch.

To enable advanced Visibility on your SQL databases, ensure that you do the following:

- [Upgrade your Temporal Server](/self-hosted-guide/upgrade-server#upgrade-server) to version 1.20 or later.
- [Update your database schemas](/self-hosted-guide/upgrade-server#upgrade-server) for MySQL to version 8.0.17 (or later), PostgreSQL to version 12 (or later), or SQLite to v3.31.0 (or later).

Beginning with Temporal Server v1.21, you can set up a secondary Visibility store in your Temporal Service to enable [Dual Visibility](/dual-visibility).
This is useful for migrating your Visibility store database.

#### Supported databases

The following databases are supported as Visibility stores:

- [MySQL](#mysql) v5.7 and later.
  Use v8.0.17 (or later) with Temporal Server v1.20 or later for advanced Visibility capabilities.
  Because standard Visibility is deprecated beginning with Temporal Server v1.21, support for older versions of MySQL will be dropped.
- [PostgreSQL](#postgresql) v9.6 and later.
  Use v12 (or later) with Temporal Server v1.20 or later for advanced Visibility capabilities.
  Because standard Visibility is deprecated beginning with Temporal Server v1.21, support for older versions of PostgreSQL will be dropped.
- [SQLite](#sqlite) v3.31.0 and later for advanced Visibility capabilities.
- [Cassandra](#cassandra).
  Support for Cassandra as a Visibility database is deprecated beginning with Temporal Server v1.21.
  For information on migrating from Cassandra to any of the supported databases, see [Migrating Visibility database](#migrating-visibility-database).
- [Elasticsearch](#elasticsearch) supported versions.
  We recommend operating a Temporal Service with Elasticsearch as your Visibility store for any use case that spawns more than a few Workflow Executions.

You can use any combination of the supported databases for your Persistence and Visibility stores.
For updates, check [Server release notes](https://github.com/temporalio/temporal/releases).

## How to set up MySQL Visibility store {#mysql}

:::tip Support, stability, and dependency info

- MySQL v5.7 and later.
- Support for MySQL v5.7 will be deprecated for all Temporal Server versions after v1.20.
- With Temporal Server version 1.20 and later, advanced Visibility is available on MySQL v8.0.17 and later.

:::

You can set MySQL as your [Visibility store](/temporal-service/visibility).
Verify [supported versions](/self-hosted-guide/visibility) before you proceed.

If using MySQL v8.0.17 or later as your Visibility store with Temporal Server v1.20 and later, any [custom Search Attributes](/search-attribute#custom-search-attribute) that you create must be associated with a Namespace in that Temporal Service.

**Persistence configuration**

Set your MySQL Visibility store name in the `visibilityStore` parameter in your Persistence configuration, and then define the Visibility store configuration under `datastores`.

The following example shows how to set a Visibility store `mysql-visibility` and define the datastore configuration in your Temporal Service configuration YAML.

```yaml
#...
persistence:
  #...
  visibilityStore: mysql-visibility
  #...
  datastores:
    default:
      #...
    mysql-visibility:
      sql:
        pluginName: 'mysql8' # For MySQL v8.0.17 and later. For earlier versions, use "mysql" plugin.
        databaseName: 'temporal_visibility'
        connectAddr: ' ' # Remote address of this database; for example, 127.0.0.0:3306
        connectProtocol: ' ' # Protocol example: tcp
        user: 'username_for_auth'
        password: 'password_for_auth'
        maxConns: 2
        maxIdleConns: 2
        maxConnLifetime: '1h'
#...
```

For details on the configuration parameters and values, see [Temporal Service configuration](/references/configuration#sql).

To enable advanced Visibility features on your MySQL Visibility store, upgrade to MySQL v8.0.17 or later with Temporal Server v1.20 or later.
See [Upgrade Server](/self-hosted-guide/upgrade-server#upgrade-server) on how to upgrade your Temporal Server and database schemas.

For example configuration templates, see [MySQL Visibility store configuration](https://github.com/temporalio/temporal/blob/main/config/development-mysql8.yaml).

**Database schema and setup**

Visibility data is stored in a database table called `executions_visibility` that must be set up according to the schemas defined (by supported versions):

- [MySQL v8.0.17 and later](https://github.com/temporalio/temporal/tree/main/schema/mysql/v8/visibility)

The following example shows how the [auto-setup.sh](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) script sets up your Visibility store.

```bash
#...
# set your MySQL environment variables
: "${DBNAME:=temporal}"
: "${VISIBILITY_DBNAME:=temporal_visibility}"
: "${DB_PORT:=}"
: "${MYSQL_SEEDS:=}"
: "${MYSQL_USER:=}"
: "${MYSQL_PWD:=}"
: "${MYSQL_TX_ISOLATION_COMPAT:=false}"

#...
# set connection details
#...
# set up MySQL schema
setup_mysql_schema() {
    #...
    # use valid schema for the version of the database you want to set up for Visibility
    VISIBILITY_SCHEMA_DIR=${TEMPORAL_HOME}/schema/mysql/${MYSQL_VERSION_DIR}/visibility/versioned
    if [[ ${SKIP_DB_CREATE} != true ]]; then
        temporal-sql-tool --ep "${MYSQL_SEEDS}" -u "${MYSQL_USER}" -p "${DB_PORT}" "${MYSQL_CONNECT_ATTR[@]}" --db "${VISIBILITY_DBNAME}" create
    fi
    temporal-sql-tool --ep "${MYSQL_SEEDS}" -u "${MYSQL_USER}" -p "${DB_PORT}" "${MYSQL_CONNECT_ATTR[@]}" --db "${VISIBILITY_DBNAME}" setup-schema -v 0.0
    temporal-sql-tool --ep "${MYSQL_SEEDS}" -u "${MYSQL_USER}" -p "${DB_PORT}" "${MYSQL_CONNECT_ATTR[@]}" --db "${VISIBILITY_DBNAME}" update-schema -d "${VISIBILITY_SCHEMA_DIR}"
#...
}
```

Note that the script uses [temporal-sql-tool](https://github.com/temporalio/temporal/blob/3b982585bf0124839e697952df4bba01fe4d9543/tools/sql/main.go) to run the setup.

## How to set up PostgreSQL Visibility store {#postgresql}

:::tip Support, stability, and dependency info

- PostgreSQL v9.6 and later.
- With Temporal Service version 1.20 and later, advanced Visibility is available on PostgreSQL v12 and later.
- Support for PostgreSQL v9.6 through v11 will be deprecated for all Temporal Server versions after v1.20; we recommend upgrading to PostgreSQL 12 or later.

:::

You can set PostgreSQL as your [Visibility store](/temporal-service/visibility).
Verify [supported versions](/self-hosted-guide/visibility) before you proceed.

If using PostgreSQL v12 or later as your Visibility store with Temporal Server v1.20 and later, any [custom Search Attributes](/search-attribute#custom-search-attribute) that you create must be associated with a Namespace in that Temporal Service.

**Persistence configuration**

Set your PostgreSQL Visibility store name in the `visibilityStore` parameter in your Persistence configuration, and then define the Visibility store configuration under `datastores`.

The following example shows how to set a Visibility store `postgres-visibility` and define the datastore configuration in your Temporal Service configuration YAML.

```yaml
#...
persistence:
  #...
  visibilityStore: postgres-visibility
  #...
  datastores:
    default:
    #...
    postgres-visibility:
      sql:
        pluginName: 'postgres12' # For PostgreSQL v12 and later. For earlier versions, use "postgres" plugin.
        databaseName: 'temporal_visibility'
        connectAddr: ' ' # remote address of this database; for example, 127.0.0.0:5432
        connectProtocol: ' ' # protocol example: tcp
        user: 'username_for_auth'
        password: 'password_for_auth'
        maxConns: 2
        maxIdleConns: 2
        maxConnLifetime: '1h'
#...
```

To enable advanced Visibility features on your PostgreSQL Visibility store, upgrade to PostgreSQL v12 or later with Temporal Server v1.20 or later.
See [Upgrade Server](/self-hosted-guide/upgrade-server#upgrade-server) for details on how to upgrade your Temporal Server and database schemas.

**Database schema and setup**

Visibility data is stored in a database table called `executions_visibility` that must be set up according to the schemas defined (by supported versions):

- [PostgreSQL v12 and later](https://github.com/temporalio/temporal/tree/main/schema/postgresql/v12/visibility)

The following example shows how the [auto-setup.sh](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) script sets up your PostgreSQL Visibility store.

```bash
#...
# set your PostgreSQL environment variables
: "${DBNAME:=temporal}"
: "${VISIBILITY_DBNAME:=temporal_visibility}"
: "${DB_PORT:=}"
: "${POSTGRES_SEEDS:=}"
: "${POSTGRES_USER:=}"
: "${POSTGRES_PWD:=}"

#... set connection details
# set up PostgreSQL schema
setup_postgres_schema() {
    #...

    # use valid schema for the version of the database you want to set up for Visibility
    VISIBILITY_SCHEMA_DIR=${TEMPORAL_HOME}/schema/postgresql/${POSTGRES_VERSION_DIR}/visibility/versioned
    if [[ ${VISIBILITY_DBNAME} != "${POSTGRES_USER}" && ${SKIP_DB_CREATE} != true ]]; then
        temporal-sql-tool --plugin postgres --ep "${POSTGRES_SEEDS}" -u "${POSTGRES_USER}" -p "${DB_PORT}" --db "${VISIBILITY_DBNAME}" create
    fi
    temporal-sql-tool --plugin postgres --ep "${POSTGRES_SEEDS}" -u "${POSTGRES_USER}" -p "${DB_PORT}" --db "${VISIBILITY_DBNAME}" update-schema -d "${VISIBILITY_SCHEMA_DIR}"
  #...
}
```

Note that the script uses [temporal-sql-tool](https://github.com/temporalio/temporal/blob/3b982585bf0124839e697952df4bba01fe4d9543/tools/sql/main.go) to run the setup.

## How to set up SQLite Visibility store {#sqlite}

:::tip Support, stability, and dependency info

- SQLite v3.31.0 and later.

:::

You can set SQLite as your [Visibility store](/temporal-service/visibility).
Verify [supported versions](/self-hosted-guide/visibility) before you proceed.

Temporal supports only an in-memory database with SQLite; this means that the database is automatically created when Temporal Server starts and is destroyed when Temporal Server stops.

You can change the configuration to use a file-based database so that it is preserved when Temporal Server stops.
However, if you use a file-based SQLite database, upgrading your database schema to enable advanced Visibility features is not supported; in this case, you must delete the database and create it again to upgrade.

If using SQLite v3.31.0 and later as your Visibility store with Temporal Server v1.20 and later, any [custom Search Attributes](/search-attribute#custom-search-attribute) that you create must be associated with a Namespace in that Temporal Service.

**Persistence configuration**

Set your SQLite Visibility store name in the `visibilityStore` parameter in your Persistence configuration, and then define the Visibility store configuration under `datastores`.

The following example shows how to set a Visibility store `sqlite-visibility` and define the datastore configuration in your Temporal Service configuration YAML.

```yaml
persistence:
  # ...
  visibilityStore: sqlite-visibility
  # ...
  datastores:
    # ...
    sqlite-visibility:
      sql:
        user: 'username_for_auth'
        password: 'password_for_auth'
        pluginName: 'sqlite'
        databaseName: 'default'
        connectAddr: 'localhost'
        connectProtocol: 'tcp'
        connectAttributes:
          mode: 'memory'
          cache: 'private'
        maxConns: 1
        maxIdleConns: 1
        maxConnLifetime: '1h'
        tls:
          enabled: false
          caFile: ''
          certFile: ''
          keyFile: ''
          enableHostVerification: false
          serverName: ''
```

SQLite (v3.31.0 and later) has advanced Visibility enabled by default.

**Database schema and setup**

Visibility data is stored in a database table called `executions_visibility` that must be set up according to the schemas defined (by supported versions) in https://github.com/temporalio/temporal/blob/main/schema/sqlite/v3/visibility/schema.sql.

For an example of setting up the SQLite schema, see [Temporalite](https://github.com/temporalio/temporalite/blob/main/server.go) setup.

## How to set up Cassandra Visibility store {#cassandra}

:::tip Support, stability, and dependency info

- Support for Cassandra as a Visibility database is deprecated beginning with Temporal Server v1.21. For updates, check the [Temporal Server release notes](https://github.com/temporalio/temporal/releases).
- We recommend migrating from Cassandra to any of the other supported databases for Visibility.

:::

You can set Cassandra as your [Visibility store](/temporal-service/visibility).
Verify [supported versions](/self-hosted-guide/visibility) before you proceed.

Advanced Visibility is not supported with Cassandra.

To enable advanced Visibility features, use any of the supported databases, such as MySQL, PostgreSQL, SQLite, or Elasticsearch, as your Visibility store.
We recommend using Elasticsearch for any Temporal Service setup that handles more than a few Workflow Executions because it supports the request load on the Visibility store and helps optimize performance.

To migrate from Cassandra to a supported SQL database, see [Migrating Visibility database](#migrating-visibility-database).

**Persistence configuration**

Set your Cassandra Visibility store name in the `visibilityStore` parameter in your Persistence configuration, and then define the Visibility store configuration under `datastores`.

The following example shows how to set a Visibility store `cass-visibility` and define the datastore configuration in your Temporal Service configuration YAML.

```yaml
#...
persistence:
  #...
  visibilityStore: cass-visibility
  #...
  datastores:
    default:
    #...
    cass-visibility:
      cassandra:
        hosts: '127.0.0.1'
        keyspace: 'temporal_visibility'
#...
```

**Database schema and setup**

Visibility data is stored in a database table called `executions_visibility` that must be set up according to the schemas defined (by supported versions) in https://github.com/temporalio/temporal/tree/main/schema/cassandra/visibility.

The following example shows how the [auto-setup.sh](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) script sets up your Visibility store.

```bash
#...
# set your Cassandra environment variables
: "${KEYSPACE:=temporal}"
: "${VISIBILITY_KEYSPACE:=temporal_visibility}"

: "${CASSANDRA_SEEDS:=}"
: "${CASSANDRA_PORT:=9042}"
: "${CASSANDRA_USER:=}"
: "${CASSANDRA_PASSWORD:=}"
: "${CASSANDRA_TLS_ENABLED:=}"
: "${CASSANDRA_CERT:=}"
: "${CASSANDRA_CERT_KEY:=}"
: "${CASSANDRA_CA:=}"
: "${CASSANDRA_REPLICATION_FACTOR:=1}"
#...
# set connection details
#...
# set up Cassandra schema
setup_cassandra_schema() {
  #...
  # use valid schema for the version of the database you want to set up for Visibility
    VISIBILITY_SCHEMA_DIR=${TEMPORAL_HOME}/schema/cassandra/visibility/versioned
    if [[ ${SKIP_DB_CREATE} != true ]]; then
        temporal-cassandra-tool --ep "${CASSANDRA_SEEDS}" create -k "${VISIBILITY_KEYSPACE}" --rf "${CASSANDRA_REPLICATION_FACTOR}"
    fi
    temporal-cassandra-tool --ep "${CASSANDRA_SEEDS}" -k "${VISIBILITY_KEYSPACE}" setup-schema -v 0.0
    temporal-cassandra-tool --ep "${CASSANDRA_SEEDS}" -k "${VISIBILITY_KEYSPACE}" update-schema -d "${VISIBILITY_SCHEMA_DIR}"
  #...
}
```

## How to integrate Elasticsearch into a Temporal Service {#elasticsearch}

You can integrate Elasticsearch with your Temporal Service as your Visibility store.
We recommend using Elasticsearch for large-scale operations on the Temporal Service.

To integrate Elasticsearch with your Temporal Service, edit the `persistence` section of your `development.yaml` configuration file to add Elasticsearch as the `visibilityStore`, and run the index schema setup commands.

**Persistence configuration**

Set your Elasticsearch Visibility store name in the `visibilityStore` parameter in your Persistence configuration, and then define the Visibility store configuration under `datastores`.

The following example shows how to set a Visibility store named `es-visibility` and define the datastore configuration in your Temporal Service configuration YAML.

```yaml
persistence:
  ...
  visibilityStore: es-visibility
  datastores:
    ...
    es-visibility: # Define the Elasticsearch datastore connection information under the `es-visibility` key
      elasticsearch:
        version: "v7"
        url:
          scheme: "http"
          host: "127.0.0.1:9200"
        indices:
          visibility: temporal_visibility_v1_dev
```

**Index schema and index**

The following example shows how the [auto-setup.sh](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) script sets up an Elasticsearch Visibility store.

```bash
#...
# Elasticsearch
: "${ENABLE_ES:=false}"
: "${ES_SCHEME:=http}"
: "${ES_SEEDS:=}"
: "${ES_PORT:=9200}"
: "${ES_USER:=}"
: "${ES_PWD:=}"
: "${ES_VERSION:=v7}"
: "${ES_VIS_INDEX:=temporal_visibility_v1}"
: "${ES_SEC_VIS_INDEX:=}"
: "${ES_SCHEMA_SETUP_TIMEOUT_IN_SECONDS:=0}"
#...
# Validate your ES environment
#...
# Wait for ES to start
#...
# ES_SERVER is the URL of Elasticsearch server; for example, "http://localhost:9200".
SETTINGS_URL="${ES_SERVER}/_cluster/settings"
SETTINGS_FILE=${TEMPORAL_HOME}/schema/elasticsearch/visibility/cluster_settings_${ES_VERSION}.json
TEMPLATE_URL="${ES_SERVER}/_template/temporal_visibility_v1_template"
SCHEMA_FILE=${TEMPORAL_HOME}/schema/elasticsearch/visibility/index_template_${ES_VERSION}.json
INDEX_URL="${ES_SERVER}/${ES_VIS_INDEX}"
curl --fail --user "${ES_USER}":"${ES_PWD}" -X PUT "${SETTINGS_URL}" -H "Content-Type: application/json" --data-binary "@${SETTINGS_FILE}" --write-out "\n"
curl --fail --user "${ES_USER}":"${ES_PWD}" -X PUT "${TEMPLATE_URL}" -H 'Content-Type: application/json' --data-binary "@${SCHEMA_FILE}" --write-out "\n"
curl --user "${ES_USER}":"${ES_PWD}" -X PUT "${INDEX_URL}" --write-out "\n"
```

**Elasticsearch privileges**

Ensure that the following privileges are granted for the Elasticsearch Temporal index:

- **Read**
  - [index privileges](https://www.elastic.co/guide/en/elasticsearch/reference/current/security-privileges.html#privileges-list-indices): `create`, `index`, `delete`, `read`
- **Write**
  - [index privileges](https://www.elastic.co/guide/en/elasticsearch/reference/current/security-privileges.html#privileges-list-indices): `write`
- **Custom Search Attributes**
  - [index privileges](https://www.elastic.co/guide/en/elasticsearch/reference/current/security-privileges.html#privileges-list-indices): `manage`
  - [cluster privileges](https://www.elastic.co/guide/en/elasticsearch/reference/current/security-privileges.html#privileges-list-cluster): `monitor` or `manage`.

## How to set up Dual Visibility {#dual-visibility}

To enable [Dual Visibility](/dual-visibility), set up a secondary Visibility store with your primary Visibility store, and configure your Temporal Service to enable read and/or write operations on the secondary Visibility store.

With Dual Visibility, you can read from only one Visibility store at a time, but can configure your Temporal Service to write to primary only, secondary only, or to both primary and secondary stores.

#### Set up secondary Visibility store

Set the secondary store with the `secondaryVisibilityStore` configuration key in your Persistence configuration, and then define the secondary Visibility store configuration under `datastores`.

You can configure any of the [supported databases](/self-hosted-guide/visibility) as your secondary store.

Examples:

To configure MySQL as a secondary store with Cassandra as your primary store, do the following.

```yaml
persistence:
  visibilityStore: cass-visibility # This is your primary Visibility store
  secondaryVisibilityStore: mysql-visibility # This is your secondary Visibility store
  datastores:
    cass-visibility:
      cassandra:
        hosts: '127.0.0.1'
        keyspace: 'temporal_primary_visibility'
    mysql-visibility:
      sql:
        pluginName: 'mysql8' # Verify supported versions. Use a version of SQL that supports advanced Visibility.
        databaseName: 'temporal_secondary_visibility'
        connectAddr: '127.0.0.1:3306'
        connectProtocol: 'tcp'
        user: 'temporal'
        password: 'temporal'
```

To configure Elasticsearch as both your primary and secondary store, use the configuration key `elasticsearch.indices.secondary_visibility`, as shown in the following example.

```yaml
persistence:
  visibilityStore: es-visibility
  datastores:
    es-visibility:
      elasticsearch:
        version: 'v7'
        logLevel: 'error'
        url:
          scheme: 'http'
          host: '127.0.0.1:9200'
        indices:
          visibility: temporal_visibility_v1
          secondary_visibility: temporal_visibility_v1_new
        closeIdleConnectionsInterval: 15s
```

#### Database schema and setup

The database schema and setup for a secondary store depends on the database you plan to use.

- [MySQL](#mysql)
- [PostgresSQL](#postgresql)
- [SQLite](#sqlite)
- [Elasticsearch](#elasticsearch)

For the Cassandra and MySQL configuration in the previous example, an example setup script would be as follows.

```bash
#...
# set your Cassandra environment variables
: "${KEYSPACE:=temporal}"
: "${VISIBILITY_KEYSPACE:=temporal_primary_visibility}"

: "${CASSANDRA_SEEDS:=}"
: "${CASSANDRA_PORT:=9042}"
: "${CASSANDRA_USER:=}"
: "${CASSANDRA_PASSWORD:=}"
: "${CASSANDRA_TLS_ENABLED:=}"
: "${CASSANDRA_CERT:=}"
: "${CASSANDRA_CERT_KEY:=}"
: "${CASSANDRA_CA:=}"
: "${CASSANDRA_REPLICATION_FACTOR:=1}"
#...
# set connection details
#...
# set up Cassandra schema
setup_cassandra_schema() {
  #...
  # use valid schema for the version of the database you want to set up for Visibility
    VISIBILITY_SCHEMA_DIR=${TEMPORAL_HOME}/schema/cassandra/visibility/versioned
    if [[ ${SKIP_DB_CREATE} != true ]]; then
        temporal-cassandra-tool --ep "${CASSANDRA_SEEDS}" create -k "${VISIBILITY_KEYSPACE}" --rf "${CASSANDRA_REPLICATION_FACTOR}"
    fi
    temporal-cassandra-tool --ep "${CASSANDRA_SEEDS}" -k "${VISIBILITY_KEYSPACE}" setup-schema -v 0.0
    temporal-cassandra-tool --ep "${CASSANDRA_SEEDS}" -k "${VISIBILITY_KEYSPACE}" update-schema -d "${VISIBILITY_SCHEMA_DIR}"
  #...
}
#...
# set your MySQL environment variables
: "${DBNAME:=temporal}"
: "${VISIBILITY_DBNAME:=temporal_secondary_visibility}"
: "${DB_PORT:=}"
: "${MYSQL_SEEDS:=}"
: "${MYSQL_USER:=}"
: "${MYSQL_PWD:=}"
: "${MYSQL_TX_ISOLATION_COMPAT:=false}"

#...
# set connection details
#...
# set up MySQL schema
setup_mysql_schema() {
    #...
    # use valid schema for the version of the database you want to set up for Visibility
    VISIBILITY_SCHEMA_DIR=${TEMPORAL_HOME}/schema/mysql/${MYSQL_VERSION_DIR}/visibility/versioned
    if [[ ${SKIP_DB_CREATE} != true ]]; then
        temporal-sql-tool --ep "${MYSQL_SEEDS}" -u "${MYSQL_USER}" -p "${DB_PORT}" "${MYSQL_CONNECT_ATTR[@]}" --db "${VISIBILITY_DBNAME}" create
    fi
    temporal-sql-tool --ep "${MYSQL_SEEDS}" -u "${MYSQL_USER}" -p "${DB_PORT}" "${MYSQL_CONNECT_ATTR[@]}" --db "${VISIBILITY_DBNAME}" setup-schema -v 0.0
    temporal-sql-tool --ep "${MYSQL_SEEDS}" -u "${MYSQL_USER}" -p "${DB_PORT}" "${MYSQL_CONNECT_ATTR[@]}" --db "${VISIBILITY_DBNAME}" update-schema -d "${VISIBILITY_SCHEMA_DIR}"
#...
}
```

For Elasticsearch as both primary and secondary Visibility store configuration in the previous example, an example setup script would be as follows.

```bash
#...
# Elasticsearch
: "${ENABLE_ES:=false}"
: "${ES_SCHEME:=http}"
: "${ES_SEEDS:=}"
: "${ES_PORT:=9200}"
: "${ES_USER:=}"
: "${ES_PWD:=}"
: "${ES_VERSION:=v7}"
: "${ES_VIS_INDEX:=temporal_visibility_v1_dev}"
: "${ES_SEC_VIS_INDEX:=temporal_visibility_v1_new}"
: "${ES_SCHEMA_SETUP_TIMEOUT_IN_SECONDS:=0}"

#...

# Validate your ES environment
#...
# Wait for ES to start
#...
# Set up Elasticsearch index
setup_es_index() {
    ES_SERVER="${ES_SCHEME}://${ES_SEEDS%%,*}:${ES_PORT}"
    # ES_SERVER is the URL of Elasticsearch server i.e. "http://localhost:9200".
    SETTINGS_URL="${ES_SERVER}/_cluster/settings"
    SETTINGS_FILE=${TEMPORAL_HOME}/schema/elasticsearch/visibility/cluster_settings_${ES_VERSION}.json
    TEMPLATE_URL="${ES_SERVER}/_template/temporal_visibility_v1_template"
    SCHEMA_FILE=${TEMPORAL_HOME}/schema/elasticsearch/visibility/index_template_${ES_VERSION}.json
    INDEX_URL="${ES_SERVER}/${ES_VIS_INDEX}"
    curl --fail --user "${ES_USER}":"${ES_PWD}" -X PUT "${SETTINGS_URL}" -H "Content-Type: application/json" --data-binary "@${SETTINGS_FILE}" --write-out "\n"
    curl --fail --user "${ES_USER}":"${ES_PWD}" -X PUT "${TEMPLATE_URL}" -H 'Content-Type: application/json' --data-binary "@${SCHEMA_FILE}" --write-out "\n"
    curl --user "${ES_USER}":"${ES_PWD}" -X PUT "${INDEX_URL}" --write-out "\n"

    # Checks for and sets up Elasticsearch as a secondary Visibility store
    if [[ ! -z "${ES_SEC_VIS_INDEX}" ]]; then
      SEC_INDEX_URL="${ES_SERVER}/${ES_SEC_VIS_INDEX}"
      curl --user "${ES_USER}":"${ES_PWD}" -X PUT "${SEC_INDEX_URL}" --write-out "\n"
    fi
}
```

#### Update Temporal Service configuration

With the primary and secondary stores set, update the `system.secondaryVisibilityWritingMode` and `system.enableReadFromSecondaryVisibility` configuration keys in your self-hosted Temporal Service's dynamic configuration YAML file to enable read and/or write operations to the secondary Visibility store.

For example, to enable write operations to both primary and secondary stores, but disable reading from the secondary store, use the following.

```yaml
system.secondaryVisibilityWritingMode:
  - value: 'dual'
    constraints: {}
system.enableReadFromSecondaryVisibility:
  - value: false
    constraints: {}
```

For details on the configuration options, see:

- [Secondary Visibility dynamic configuration reference](/references/dynamic-configuration#secondary-visibility-settings)
- [Migrating Visibility databases](#migrating-visibility-database)

## How to migrate Visibility database {#migrating-visibility-database}

To migrate your Visibility database, [set up a secondary Visibility store](#dual-visibility) to enable [Dual Visibility](/dual-visibility), and update the dynamic configuration in your Temporal Service to update the read and write operations for the Visibility store.

Dual Visibility setup is optional but useful in gradually migrating your Visibility data to another database.

Before you begin, verify [supported databases and versions](/self-hosted-guide/visibility) for a Visibility store.

The following steps describe how to migrate your Visibility database.

After you make any changes to your [Temporal Service configuration](/temporal-service/configuration), ensure that you restart your services.

#### Set up secondary Visibility store

1. In your Temporal Service configuration, [add a secondary Visibility store](/references/configuration#secondaryvisibilitystore) to your Visibility setup under the Persistence configuration.

   Example: To migrate from Cassandra to Elasticsearch, add Elasticsearch as your secondary database and set it up.
   For details, see [secondary Visibility database schema and setup](#dual-visibility).

   ```yaml
   persistence:
   visibilityStore: cass-visibility
   secondaryVisibilityStore: es-visibility
   datastores:
     cass-visibility:
     cassandra:
       hosts: '127.0.0.1'
       keyspace: 'temporal_visibility'
     es-visibility:
     elasticsearch:
       version: 'v7'
       logLevel: 'error'
       url:
       scheme: 'http'
       host: '127.0.0.1:9200'
       indices:
       visibility: temporal_visibility_v1_dev
       closeIdleConnectionsInterval: 15s
   ```

1. Update the [dynamic configuration](/temporal-service/configuration#dynamic-configuration) keys on your self-hosted Temporal Service to enable write operations to the secondary store and disable read operations.
   Example:

   ```yaml
   system.secondaryVisibilityWritingMode:
   - value: "dual"
   constraints: {}
   system.enableReadFromSecondaryVisibility:
   - value: false
   constraints: {}
   ```

At this point, Visibility data is read from the primary store, and all Visibility data is written to both the primary and secondary store.
This setting applies only to new Visibility data generated after Dual Visibility is enabled.
It does not migrate any existing data in the primary store to the secondary store.

For details on write options to the secondary store, see [Secondary Visibility dynamic configuration reference](/references/dynamic-configuration#secondary-visibility-settings).

#### Run in dual mode

When you enable a secondary store, only new Visibility data is written to both primary and secondary stores.
The primary store still holds the Workflow Execution data from before the secondary store was set up.

Running in dual mode lets you plan for closed and open Workflow Executions data from before the secondary store was set up in your self-hosted Temporal Service.

Example:

- To manage closed Workflow Executions data, run in dual mode until the Namespace [Retention Period](/temporal-service/temporal-server#retention-period) is reached.
  After the Retention Period, Workflow Execution data is removed from the Persistence and Visibility stores.
  If you want to keep the closed Workflow Executions data after the set Retention Period, you must set up [Archival](/self-hosted-guide/archival).
- To manage data for all open Workflow Executions, run in dual mode until all the Workflow Executions started before enabling Dual Visibility mode are closed.
  After the Workflow Executions are closed, verify the Retention Period and set up Archival if you need to keep the data beyond the Retention Period.

You can run your Visibility setup in dual mode for an indefinite period, or until you are ready to deprecate the primary store and move completely to the secondary store without losing data.

#### Deprecate primary Visibility store

When you are ready to deprecate your primary store, follow these steps.

1. Update the dynamic configuration YAML to enable read operations from the secondary store.
   Example:

   ```yaml
   system.secondaryVisibilityWritingMode:
   - value: "dual"
   constraints: {}
   system.enableReadFromSecondaryVisibility:
   - value: true
   constraints: {}
   ```

   At this point, Visibility data is read from the secondary store only.
   Verify whether data on the secondary store is correct.

1. When the secondary store is vetted and ready to replace your current primary store, change your Temporal Service configuration to set the secondary store as your primary, and remove the dynamic configuration set in the previous steps.
   Example:

   ```yaml
   persistence:
   visibilityStore: es-visibility
   datastores:
     es-visibility:
     elasticsearch:
       version: 'v7'
       logLevel: 'error'
       url:
       scheme: 'http'
       host: '127.0.0.1:9200'
       indices:
       visibility: temporal_visibility_v1_dev
       closeIdleConnectionsInterval: 15s
   ```

## Managing custom Search Attributes {#custom-search-attributes}

To manage your custom Search Attributes on Temporal Cloud, use `tcld`.
With Temporal Cloud, you can create and rename custom Search Attributes.

To manage your custom Search Attributes on self-hosted Temporal Clusters, use Temporal CLI. With self-hosted Temporal Service, you can create and remove custom Search Attributes.
Note that if you use [SQL databases](/self-hosted-guide/visibility) with Temporal Server v1.20 and later, creating a custom Search Attribute creates a mapping with a database field name in the Visibility store `custom_search_attributes` table.
Removing a custom Search Attribute removes this mapping with the database field name but does not remove the data.
If you remove a custom Search Attribute and add a new one, the new custom Search Attribute might be mapped to the database field of the one that was recently removed.
This might cause unexpected results when you use the List API to retrieve results using the new custom Search Attribute.
These constraints do not apply if you use Elasticsearch.

### How to create custom Search Attributes {#create-custom-search-attributes}

Add custom Search Attributes to your Visibility store using the Temporal CLI for a self-hosted Temporal Service and `tcld` for Temporal Cloud.

Creating a custom Search Attribute in your Visibility store makes it available to use in your Workflow metadata and [List Filters](/list-filter).

**On Temporal Cloud**

To create custom Search Attributes on Temporal Cloud, use [`tcld namespace search-attributes add`](/cloud/tcld/namespace/#search-attributes).
For example, to add a custom Search Attributes "CustomSA" to your Temporal Cloud Namespace "YourNamespace", run the following command.
`tcld namespace search-attributes add --namespace YourNamespace --search-attribute "CustomSA"`

**On self-hosted Temporal Service**

If you're self-hosting your Temporal Service, verify whether your [Visibility database](/self-hosted-guide/visibility) version supports advanced Visibility features.

To create custom Search Attributes in your self-hosted Temporal Service Visibility store, use `temporal operator search-attribute create` with `--name` and `--type` command options.

For example, to create a Search Attribute called `CustomSA` of type `Keyword`, run the following command:

```
temporal operator search-attribute create --name="CustomSA" --type="Keyword"
```

Note that if you use a SQL database with advanced Visibility capabilities, you are required to specify a Namespace when creating a custom Search Attribute.
For example:

```
temporal operator search-attribute create --name="CustomSA" --type="Keyword" --namespace="yournamespace"
```

You can also create multiple custom Search Attributes when you set up your Visibility store.

For example, the [auto-setup.sh](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) script that is used to set up your local [docker-compose Temporal Service](https://github.com/temporalio/docker-compose) creates custom Search Attributes in the Visibility store, as shown in the following code snippet from the script (for SQL databases).

```bash
add_custom_search_attributes() {
    until temporal operator search-attribute list --namespace "${DEFAULT_NAMESPACE}"; do
      echo "Waiting for namespace cache to refresh..."
      sleep 1
    done
    echo "Namespace cache refreshed."

    echo "Adding Custom*Field search attributes."

    temporal operator search-attribute create --namespace "${DEFAULT_NAMESPACE}" --yes \
        --name="CustomKeywordField" --type="Keyword" \
        --name="CustomStringField" --type="Text" \
        --name="CustomTextField" --type="Text" \
        --name="CustomIntField" --type="Int" \
        --name="CustomDatetimeField" --type="Datetime" \
        --name="CustomDoubleField" --type="Double" \
        --name="CustomBoolField" --type="Bool"
}
```

Note that this script has been updated for Temporal Server v1.20, which requires associating every custom Search Attribute with a Namespace when using a SQL database.

For Temporal Server v1.19 and earlier, or if using Elasticsearch for advanced Visibility, you can create custom Search Attributes without a Namespace association, as shown in the following example.

{/* CHECK FOR ACCURACY */}

```bash
add_custom_search_attributes() {
       echo "Adding Custom*Field search attributes."
       temporal operator search-attribute create \
        --name="CustomKeywordField" --type="Keyword" \
        --name="CustomStringField" --type="Text" \
        --name="CustomTextField" --type="Text" \
        --name="CustomIntField" --type="Int" \
        --name="CustomDatetimeField" --type="Datetime" \
        --name="CustomDoubleField" --type="Double" \
        --name="CustomBoolField" --type="Bool"
}
```

When your Visibility store is set up and running, these custom Search Attributes are available to use in your Workflow code.

### How to remove custom Search Attributes {#remove-custom-search-attributes}

To remove a Search Attribute key from your self-hosted Temporal Service Visibility store, use the command `temporal operator search-attribute remove`.
Removing Search Attributes is not supported on Temporal Cloud.

For example, if using Elasticsearch for advanced Visibility, to remove a custom Search Attribute called `CustomSA` of type Keyword use the following command:

```
temporal operator search-attribute remove \
    --name="your_custom_attribute"
```

With Temporal Server v1.20, if using a SQL database for advanced Visibility, you need to specify the Namespace in your command, as shown in the following command:

```
temporal operator search-attribute remove \
    --name="your_custom_attribute" \
    --namespace="your_namespace"
```

To check whether the Search Attribute was removed, run

```
temporal operator search-attribute list
```

and check the list.

If you're on Temporal Server v1.20 and later, specify the Namespace from which you removed the Search Attribute.
For example,

```
temporal search-attribute list --namespace="yournamespace"
```

Note that if you use [SQL databases](/self-hosted-guide/visibility) with Temporal Server v1.20 and later, a new custom Search Attribute is mapped to a database field name in the Visibility store `custom_search_attributes` table.
Removing this custom Search Attribute removes the mapping with the database field name but does not remove the data.
If you remove a custom Search Attribute and add a new one, the new custom Search Attribute might be mapped to the database field of the one that was recently removed.
This might cause unexpected results when you use the List API to retrieve results using the new custom Search Attribute.
These constraints do not apply if you use Elasticsearch.

---

## Quick Launch - Deploying your Workers on Amazon EKS

Temporal Workers run in [Kubernetes](https://kubernetes.io)-based deployments deliver scale, resilience, and flexible resource management.
Amazon EKS (Elastic Kubernetes Service) offers one of the most popular choices for running Temporal Workers.
It integrates smoothly with AWS services and supports auto-scaling and fault tolerance—key features for many Temporal users.

Follow this guide to deploy and manage your Temporal Workers in EKS.
This guide walks you through writing Temporal Worker code, containerizing and publishing the Worker to the Amazon Elastic Container Registry (ECR), and deploying the worker to Amazon EKS.
The example on this page uses Temporal’s Python SDK and Temporal Cloud.

:::tip

This guide applies to running Workers for both Temporal OSS and Temporal Cloud.
However, there are some differences when working with Temporal OSS.
For example, you'll need to use mTLS certificates instead of API keys.
You must modify your Kubernetes deployments to handle and mount the TLS certificates for your use case.
The specifics will vary depending on your deployment.

:::

## Before you begin

To get started deploying your Workers to EKS, you’ll need:

- Your Temporal Cloud account, including:
  - A Namespace using [API key authentication](/cloud/api-keys#namespace-authentication)
  - Your API Key for a [Service Account](/cloud/api-keys#generate-an-api-key-for-a-service-account)
- An Amazon Web Services (AWS) account, including:
  - A deployed EKS cluster within your AWS Account
- An installed version of the [`aws` CLI](https://aws.amazon.com/cli/)
- [`docker`](https://www.docker.com/get-started/)
- The [`kubectl`](https://kubernetes.io/docs/reference/kubectl/) command line tool, configured with your deployed EKS cluster

## Write your Worker code

In Temporal applications, business logic lives within your main Workflow code.
Your Worker code runs separately, and is responsible for executing your Workflows and Activities.
Make sure to configure your Worker to use environment variables so you can dynamically route your Worker to different Temporal Instances, Namespaces, and Task Queues on the fly:

```python
TEMPORAL_ADDRESS = os.environ.get("TEMPORAL_ADDRESS", "localhost:7233")
TEMPORAL_NAMESPACE = os.environ.get("TEMPORAL_NAMESPACE", "default")
TEMPORAL_TASK_QUEUE = os.environ.get("TEMPORAL_TASK_QUEUE", "test-task-queue")
TEMPORAL_API_KEY = os.environ.get("TEMPORAL_API_KEY", "")
```

After configuration, instantiate your Temporal client:

```
client = await Client.connect(
    TEMPORAL_ADDRESS,
    namespace=TEMPORAL_NAMESPACE,
    rpc_metadata={"temporal-namespace": TEMPORAL_NAMESPACE},
    api_key=TEMPORAL_API_KEY,
    tls=True
)
```

Here is a complete Python boilerplate that showcases how to instantiate a Client and pass it to the Worker before starting the Worker execution:

```python

from temporalio.worker import Worker
from temporalio.client import Client

from workflows import your_workflow
from activities import your_first_activity, your_second_activity, your_third_activity

TEMPORAL_ADDRESS = os.environ.get("TEMPORAL_ADDRESS", "localhost:7233")
TEMPORAL_NAMESPACE = os.environ.get("TEMPORAL_NAMESPACE", "default")
TEMPORAL_TASK_QUEUE = os.environ.get("TEMPORAL_TASK_QUEUE", "test-task-queue")
TEMPORAL_API_KEY = os.environ.get("TEMPORAL_API_KEY", "your-api-key")

async def main():
  client = await Client.connect(
    TEMPORAL_ADDRESS,
    namespace=TEMPORAL_NAMESPACE,
    rpc_metadata={"temporal-namespace": TEMPORAL_NAMESPACE},
    api_key=TEMPORAL_API_KEY,
    tls=True
  )

  print("Initializing worker...")

  # Run the worker
  worker = Worker(
    client,
    task_queue=TEMPORAL_TASK_QUEUE,
    workflows=[your_workflow],
    activities=[
      your_first_activity,
      your_second_activity,
      your_third_activity
    ]
  )

  print("Starting worker... Waiting for tasks.")
  await worker.run()

if __name__ == "__main__":
  asyncio.run(main())
```

## Containerize the Worker for Kubernetes

You need to containerize your Worker code to run it with Kubernetes.
Here is a sample Python Dockerfile, complete with the Temporal Python SDK installed:

```docker
# Use Python 3.11 slim image as base
FROM python:3.11-slim

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Install the Temporal Python SDK dependency
RUN pip install --no-cache-dir temporalio

# Copy application code
COPY . .

# Set Python to run in unbuffered mode
ENV PYTHONUNBUFFERED=1

# Run the worker
CMD ["python", "worker.py"]
```

Build the Docker image and target the `linux/amd64` architecture:

```bash
docker buildx build \
    --platform linux/amd64 \
    -t your-app .
```

## Publish the Worker Image to Amazon ECR

After building the Docker image, you’re ready to publish it to Amazon ECR.
Make sure that you’re authenticated with AWS, and that you’ve set your `AWS_REGION` and `AWS_ACCOUNT_ID` environment variables:

```bash
export AWS_ACCOUNT_ID=<your_aws_account_id>
export AWS_REGION=<your_aws_region>
```

Create an ECR repository and authenticate ECR with the Docker container client:

```bash
aws ecr create-repository \
    --repository-name your-app
aws ecr get-login-password --region $AWS_REGION | \
    docker login --username AWS --password-stdin \
            $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com
```

After authenticating Docker with ECR, tag your container and publish it:

```bash
docker tag your-app $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/your-app:latest
docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/your-app:latest
```

## Deploy the Workers to EKS

With your Worker containerized, you’re ready to deploy it to EKS. Create a namespace in your EKS cluster. You’ll use the namespace to run your Temporal Workers:

```bash
kubectl create namespace your-namespace
```

Create a `ConfigMap` to hold non-sensitive values that Kubernetes will inject into your Worker deployment.
These enable dynamic routing for instances, Namespaces, and Task Queues.
To set these values, build a config-map.yaml file like the following example:

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: temporal-worker-config
  namespace: temporal-system
data:
  TEMPORAL_HOST_URL: “<your-temporal-address>“
  TEMPORAL_NAMESPACE: “<your-temporal-cloud-namespace>”
  TEMPORAL_TASK_QUEUE: “<your-task-queue>”
```

Apply the `ConfigMap` to your namespace:

```bash
kubectl apply -f config-map.yaml \
    --namespace your-namespace
```

For sensitive values, use Kubernetes Secrets.
Create a secret to hold your Temporal API key:

```bash
kubectl create secret generic temporal-secret \
    --from-literal=TEMPORAL_API_KEY=$TEMPORAL_API_KEY \
    --namespace your-namespace
```

With your configuration in place, you can deploy the Worker.
Create a deployment.yaml file configuring your Worker image, resources, and secret values.
For common deployments, tune the resources you specify so they match your production workloads.
Note that the spun-up container reads your Temporal API key from the Kubernetes secret you just created:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
   name: your-app
   namespace: your-namespace
   labels:
      app: your-app
spec:
   selector:
      matchLabels:
         app: your-app
   replicas: 1
   template:
      metadata:
         labels:
            app: your-app
      spec:
         serviceAccountName: your-app
         containers:
            - name: your-app
              image: <your-ecr-image-name>
              env:
                - name: TEMPORAL_ADDRESS
                  valueFrom:
                    configMapKeyRef:
                      name: temporal-worker-config
                      key: TEMPORAL_ADDRESS
                - name: TEMPORAL_NAMESPACE
                  valueFrom:
                    configMapKeyRef:
                      name: temporal-worker-config
                      key: TEMPORAL_NAMESPACE
                - name: TEMPORAL_TASK_QUEUE
                  valueFrom:
                    configMapKeyRef:
                      name: temporal-worker-config
                      key: TEMPORAL_TASK_QUEUE
                - name: TEMPORAL_API_KEY
                  valueFrom:
                    secretKeyRef:
                      name: temporal-secret
                      key: TEMPORAL_API_KEY
              resources:
                limits:
                  cpu: "0.5"
                  memory: "512Mi"
                requests:
                  cpu: "0.2"
                  memory: "256Mi"
```

Apply the deployment.yaml file to the EKS cluster:

```bash
kubectl apply -f deployment.yaml \
    --namespace your-namespace
```

## Verify that the Workers are Connected

After deploying your Workers to EKS, confirm that they have connected to Temporal Cloud.
Retrieve the pod listing for the Kubernetes/EKS namespace that you created:

```
kubectl get pods -n temporal-system
```

After listing the pods, access the Worker logs to confirm you’re properly connected to Temporal Cloud:

```
kubectl logs <pod-name> -n temporal-system
```

You confirm connection when you see:

```
Initializing worker...
Starting worker... Waiting for tasks.
```

You have now successfully deployed your Temporal Worker to EKS.

---

## Temporal Worker Deployments

A core feature of Temporal is that you are able to deploy your Workers to any infrastructure where your Workflow and Activity code will actually run.
This way, you have total control over your runtime environment, and can be responsive to any security or scaling needs that may arise over time, whether you are using Temporal Cloud or self-hosting a Temporal Service.

However, if you do not already have some expertise in site reliability engineering, or do not know how to migrate from a Docker deployment to (for example) a Kubernetes pod of Temporal Workers, you may want more direct guidance here.
For example, most of our [Tutorials and Courses](https://learn.temporal.io/) use only one or two Temporal Workers to demonstrate core functionality.
The content in this section will provide clarity on real-world deployments that grow far beyond those examples.

Our Worker Deployments guide provides documentation of Temporal product features that make it easier to scale and revise your Workflows.

[Worker Versioning](/production-deployment/worker-deployments/worker-versioning) allows you to pin Workflows to individual versions of your workers, which are called Worker Deployment Versions.

This section also covers specific Worker Deployment examples:

- [**Deploy Workers to Amazon EKS**](/production-deployment/worker-deployments/deploy-workers-to-aws-eks)
  Containerize your Worker, publish it to Amazon Elastic Container Registry (ECR), and deploy it to Amazon Elastic Kubernetes Service (EKS) using the Temporal Python SDK.
  This guide covers the full deployment lifecycle and shows how to configure your Worker to connect to Temporal Cloud using Kubernetes-native tools like ConfigMaps and Secrets.
  Running Workers on EKS gives you fine-grained control over scaling, resource allocation, and availability—ideal for production systems that need reliability and flexibility in the cloud.

You can also refer to our [Code Exchange](https://temporal.io/code-exchange) for community-contributed strategies for deploying versioned workers.

---

## Worker Versioning

Worker Versioning is a Temporal feature that allows you to confidently deploy new changes to the Workflows running on your Workers without breaking them.
Temporal enables this by helping you manage different builds or versions, formally called [Worker Deployment Versions](/worker-versioning#deployment-versions).

Worker Versioning unlocks important benefits for users of [blue-green or rainbow deployments](#deployment-systems).

- Ramping traffic gradually to a new Worker Deployment Version.
- Verifying a new Deployment Version with tests before sending production traffic to it.
- Instant rollback when you detect that a new Deployment Version is broken.

In addition, Worker Versioning introduces **Workflow Pinning**.
For pinned Workflow Types, each execution runs entirely on the Worker Deployment Version where it started.
You need not worry about making breaking code changes to running, pinned Workflows.

To use Workflow Pinning, we recommend using [rainbow deployments](#deployment-systems).

:::tip
Watch this Temporal Replay 2025 talk to learn more about Worker Versioning and see a demo.

    <iframe width="560" height="315"
        src="https://www.youtube.com/embed/rm4BlD9WXqc"
        title="YouTube video player"
        frameBorder="0"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        referrerPolicy="strict-origin-when-cross-origin" allowFullScreen></iframe>

:::

:::note
Worker Versioning is currently available in Public Preview.

Minimum versions:

- Go SDK version [v1.35.0](https://github.com/temporalio/sdk-go/releases/tag/v1.35.0)
- Python [v1.11](https://github.com/temporalio/sdk-python/releases/tag/1.11.0)
- Java [v1.29](https://github.com/temporalio/sdk-java/releases/tag/v1.29.0)
- Typescript [v1.12](https://github.com/temporalio/sdk-typescript/releases/tag/v1.12.0)
- .NET [v1.7.0](https://github.com/temporalio/sdk-dotnet/releases/tag/1.7.0)
- Ruby [v0.5.0](https://github.com/temporalio/sdk-ruby/releases/tag/v0.5.0)
- Other SDKs: coming soon!

Self-hosted users:

- Minimum Temporal CLI version [v1.4.1](https://github.com/temporalio/cli/releases/tag/v1.4.1)
- Minimum Temporal Server version: [v1.28.0](https://github.com/temporalio/temporal/releases/tag/v1.28.0)
- Minimum Temporal UI Version [v2.38.0](https://github.com/temporalio/ui/releases/tag/v2.38.0)
  :::

## Getting Started with Worker Versioning {#definition}

To get started with Worker Versioning, you should understand some concepts around versioning and deployments.

- A **Worker Deployment** is a deployment or service across multiple versions. In a rainbow deployment, more than two active Deployment Versions can run at once.
- A **Worker Deployment Version** is a version of a deployment or service. It can have multiple Workers polling on multiple Task Queues, but they all run the same build.
- A **Build ID**, in combination with a Worker Deployment name, identifies a single Worker Deployment Version.
- When a versioned worker polls on a task queue, that task queue becomes part of that Worker's version. That version's Worker Deployment controls how the task queue matches Workflow Tasks with Workers.
- Using **Workflow Pinning**, you can declare each Workflow type to have a **Versioning Behavior**, either Pinned or Auto-Upgrade.
  - A **Pinned** Workflow is guaranteed to complete on a single Worker Deployment Version.
  - An **Auto-Upgrade** Workflow will move to the latest Worker Deployment Version automatically whenever you change the current version. Auto-upgrade Workflows are not restricted to a single Deployment Version and need to be kept replay-safe manually, i.e. with [patching](/workflow-definition#workflow-versioning).
  - Both Pinned and Auto-Upgrade Workflows are guaranteed to start only on the Current or Ramping Version of their Worker Deployment.
  - Workflow Pinning is designed for use with rainbow deployments. See [Deployment Systems](#deployment-systems).
- Each Worker Deployment has a single **Current Version** which is where workflows are routed to unless they were previously pinned on a different version. Other versions can continue polling to allow pinned Workflows to finish executing, or in case you need to roll back. If no current version is specified, the default is unversioned.
- Each Worker Deployment can have a **Ramping Version** which is where a configurable percentage of Workflows are routed to unless they were previously pinned on a different version. The ramp percentage can be in the range [0, 100]. Workflows that don't go to the Ramping Version will go to the Current Version. If no Ramping Version is specified, 100% of new Workflows and auto-upgrade Workflows will go to the Current Version.

## Setting up your deployment system {#deployment-systems}

If you haven't already, you'll want to pick a container deployment solution for your Workers.

You also need to pick among three common deployment strategies:

- A **rolling deployment** strategy upgrades Workers in place with little control over how quickly they cut over and only a slow ability to roll Workers back. Rolling deploys have minimal footprint but tend to provide lower availability than the other strategies and are incompatible with Worker Versioning.
- A **blue-green deployment** strategy maintains two "colors," or Worker Deployment Versions simultaneously and can control how traffic is routed between them. This allows you to maximize your uptime with features like instant rollback and ramping. Worker Versioning enables the routing control that blue-green deployments need.
- A **rainbow deployment** strategy is like blue-green but with more colors, allowing Workflow Pinning. You can deploy new revisions of your Workflows freely while older versions drain. Using Worker Versioning, Temporal lets you know when all the Workflows of a given version are drained so that you can sunset it.

## Configuring a Worker for Versioning

You'll need to add a few additional configuration parameters to your Workers to toggle on Worker Versioning.
There are three new parameters, with different names depending on the language:

- `UseVersioning`: This enables the Versioning functionality for this Worker.
- A `Version` to identify the revision that this Worker will be allowed to execute. This is a combination of a deployment name and a build ID number.
- (Optional) The [Default Versioning Behavior](#definition). If unset, you'll be required to specify the behavior on each Workflow. Or you can default to Pinned or Auto-Upgrade.

Follow the example for your SDK below:

<SdkTabs>
<SdkTabs.Go>
```go
buildID:= mustGetEnv("MY_BUILD_ID")
w := worker.New(c, myTaskQueue, worker.Options{
      DeploymentOptions: worker.DeploymentOptions{
          UseVersioning: true,
          Version: worker.WorkerDeploymentVersion{
              DeploymentName: "llm_srv",
              BuildId:        buildID,
          },
          DefaultVersioningBehavior: workflow.VersioningBehaviorUnspecified,
},
})
```
</SdkTabs.Go>
<SdkTabs.Java>
```java

    WorkerOptions.newBuilder()
    .setDeploymentOptions(
        WorkerDeploymentOptions.newBuilder()
        .setVersion(new WorkerDeploymentVersion("llm_srv", "1.0"))
        .setUseVersioning(true)
        .setDefaultVersioningBehavior(VersioningBehavior.AUTO_UPGRADE)
        .build())
    .build();
```

</SdkTabs.Java>
<SdkTabs.Python>
```python
from temporalio.common import WorkerDeploymentVersion, VersioningBehavior
from temporalio.worker import Worker, WorkerDeploymentConfig

Worker(
    client,
    task_queue="mytaskqueue",
    workflows=workflows,
    activities=activities,
    deployment_config=WorkerDeploymentConfig(
        version=WorkerDeploymentVersion(
            deployment_name="llm_srv",
            build_id=my_env.build_id),
        use_worker_versioning=True,
        default_versioning_behavior=VersioningBehavior.UNSPECIFIED
    ),
)
```

</SdkTabs.Python>
<SdkTabs.TypeScript>

```ts
const myWorker = await Worker.create({
  workflowsPath: require.resolve('./workflows'),
  taskQueue,
  workerDeploymentOptions: {
    useWorkerVersioning: true,
    version: { buildId: '1.0', deploymentName: 'llm_srv' },

    defaultVersioningBehavior: 'UNSPECIFIED',
  },
  connection: nativeConnection,
});
```

</SdkTabs.TypeScript>
<SdkTabs.DotNet>

```csharp
var myWorker = new TemporalWorker(
    Client,
    new TemporalWorkerOptions(taskQueue)
    {DeploymentOptions = new(new("llm_srv", "1.0"), true)
      { DefaultVersioningBehavior = VersioningBehavior.Unspecified },
    }.AddWorkflow<MyWorkflow>());
```

</SdkTabs.DotNet>
<SdkTabs.Ruby>

```ruby
worker = Temporalio::Worker.new(
  client: client,
  task_queue: task_queue,
  workflows: [MyWorkflow],
  deployment_options: Temporalio::Worker::DeploymentOptions.new(
      version: Temporalio::WorkerDeploymentVersion.new(
          deployment_name: 'llm_srv',
          build_id: '1.0'
      ),
      use_worker_versioning: true,
      default_versioning_behavior: Temporalio::VersioningBehavior::UNSPECIFIED
  )
)
```

</SdkTabs.Ruby>
</SdkTabs>

### Which Default Versioning Behavior should you choose?

If you are using blue-green deployments, you should default to Auto-Upgrade and should not use Workflow Pinning.

Otherwise, if your Worker and Workflows are new, we suggest not providing a `DefaultVersioningBehavior`.
In general, each Workflow Type should be annotated as Auto-Upgrade or Pinned.
If all of your Workflows will be short-running for the foreseeable future, you can default to Pinned.

Many users who are migrating to Worker Versioning will start by defaulting to Auto-Upgrade until they have had time to annotate their Workflows.
This default is the most similar to the legacy behavior.
Once each Workflow Type is annotated, you can remove the `DefaultVersioningBehavior`.

## Rolling out changes with the CLI

Next, deploy your Worker with the additional configuration parameters.
Before making any Workflow revisions, you can use the `temporal` CLI to check which of your Worker versions are currently polling:

You can view the Versions that are part of a Deployment with `temporal worker deployment describe`:

```bash
temporal worker deployment describe --name="$MY_DEPLOYMENT"
```

To activate a Deployment Version, use `temporal worker deployment set-current-version`, specifying the deployment name and a Build ID:

```bash
temporal worker deployment set-current-version \
    --deployment-name "YourDeploymentName" \
    --build-id "YourBuildID"
```

To ramp a Deployment Version up to some percentage of your overall Worker fleet, use `set-ramping version`, with the same parameters and a ramping percentage:

```bash
temporal worker deployment set-ramping-version \
    --deployment-name "YourDeploymentName" \
    --build-id "YourBuildID" \
    --percentage=5
```

You can verify that Workflows are cutting over to that version with `describe -w YourWorkflowID`:

```bash
temporal workflow describe -w YourWorkflowID
```

That returns the new Version that the workflow is running on:

```
Versioning Info:

  Behavior               AutoUpgrade
  Version                llm_srv.2.0
  OverrideBehavior       Unspecified
```

## Marking a Workflow Type as Pinned

You can mark a Workflow Type as pinned when you register it by adding an additional Pinned parameter.
This will cause it to remain on its original deployed version:

<SdkTabs>
<SdkTabs.Go>
```go
// w is the Worker configured as in the previous example
w.RegisterWorkflowWithOptions(HelloWorld, workflow.RegisterOptions{
	// or workflow.VersioningBehaviorAutoUpgrade
    VersioningBehavior: workflow.VersioningBehaviorPinned,
})
```
</SdkTabs.Go>
<SdkTabs.Java>
```java
@WorkflowInterface
public interface HelloWorld {
    @WorkflowMethod
    String hello();
}

public static class HelloWorldImpl implements HelloWorld {
    @Override
    @WorkflowVersioningBehavior(VersioningBehavior.PINNED)
    public String hello() {
        return "Hello, World!";
    }
}

```
</SdkTabs.Java>
<SdkTabs.Python>
```python
@workflow.defn(versioning_behavior=VersioningBehavior.PINNED)
class HelloWorld:
    @workflow.run
    async def run(self):
        return "hello world!"
```

</SdkTabs.Python>
<SdkTabs.TypeScript>

```ts
setWorkflowOptions({ versioningBehavior: 'PINNED' }, helloWorld);
export async function helloWorld(): Promise<string> {
  return 'hello world!';
}
```

</SdkTabs.TypeScript>
<SdkTabs.DotNet>

```csharp
[Workflow(VersioningBehavior = VersioningBehavior.Pinned)]
public class HelloWorld
{
    [WorkflowRun]
    public async Task<string> RunAsync()
    {
        return "hello world!";
    }
}
```

</SdkTabs.DotNet>
<SdkTabs.Ruby>

```ruby
class HelloWorld < Temporalio::Workflow::Definition
  workflow_versioning_behavior Temporalio::VersioningBehavior::PINNED

  def execute
    'hello world!'
  end
end
```

</SdkTabs.Ruby>
</SdkTabs>

You can check your set of Deployment Versions with `temporal worker deployment describe`:

```bash
temporal worker deployment describe --name="$MY_DEPLOYMENT"
```

## Moving a pinned Workflow

Sometimes you'll need to manually move a set of pinned workflows off of a version that has a bug to a version with the fix.

If you need to move a pinned Workflow to a new version, use `temporal workflow update-options`:

```bash
temporal workflow update-options \
    --workflow-id "$WORKFLOW_ID" \
    --versioning-override-behavior pinned \
    --versioning-override-deployment-name "$TARGET_DEPLOYMENT" \
    --versioning-override-build-id "$TARGET_BUILD_ID"
```

You can move several Workflows at once matching a `--query` parameter:

```bash
temporal workflow update-options \
  --query="TemporalWorkerDeploymentVersion=$TARGET_DEPLOYMENT:$BAD_BUILD_ID" \
  --versioning-override-behavior pinned \
  --versioning-override-deployment-name "$TARGET_DEPLOYMENT" \
  --versioning-override-build-id "$FIXED_BUILD_ID"
```

In this scenario, you may also need to use the other [Versioning APIs](/workflow-definition#workflow-versioning) to patch
your Workflow in the "fixed" build, so that your target Worker can handle the moved Workflows correctly.
If you made a [version-incompatible change](/workflow-definition#deterministic-constraints) to your Workflow, and you
want to roll back to an earlier version, it's not possible to patch it. Considering using [Workflow Reset](/workflow-execution/event#reset)
along with your move.

"Reset-with-Move" allows you to atomically Reset your Workflow and set a Versioning Override on the newly reset Workflow,
so when it resumes execution, all new Workflow Tasks will be executed on your new Worker.

```bash
temporal workflow reset with-workflow-update-options \
    --workflow-id "$WORKFLOW_ID" \
    --event-id "$EVENT_ID" \
    --reason "$REASON" \
    --versioning-override-behavior pinned \
    --versioning-override-deployment-name "$TARGET_DEPLOYMENT" \
    --versioning-override-build-id "$TARGET_BUILD_ID"
```

## Sunsetting an old Deployment Version

A Worker Deployment Version moves through the following states:

1. **Inactive**: The version exists because a Worker with that version has polled the server. If this version never becomes Active, it will never be Draining or Drained.
2. **Active**: The version is either Current or Ramping, so it is accepting new Workflows and existing auto-upgrade Workflows.
3. **Draining**: The version stopped being Current or Ramping, and it has open pinned Workflows running on it. It is possible to be Draining and have no open pinned Workflows for a short time, since the drainage status is updated periodically.
4. **Drained**: The version was draining and now all the pinned Workflows that were running on it are closed.

You can see these statuses when you describe a Worker Deployment in the `WorkerDeploymentVersionStatus` of each `VersionSummary`, or by describing the version directly.
When a version is Draining or Drained, that is displayed in a value called `DrainageStatus`.
Periodically, the Temporal Service will refresh this status by counting any open pinned workflows using that version.
On each refresh, `DrainageInfo.last_checked_time` is updated.
Eventually, `DrainageInfo` will report that the version is fully drained.
At this point, no Workflows are still running on that version and no more will be automatically routed to it, so you can consider shutting down the running Workers.

You can monitor this by checking `WorkerDeploymentInfo.VersionSummaries` or with `temporal worker deployment describe-version`:

```bash
temporal worker deployment describe-version \
    --deployment-name "YourDeploymentName" \
    --build-id "YourBuildID"
```

```
Worker Deployment Version:
  Version                  llm_srv.1.0
  CreateTime               5 hours ago
  RoutingChangedTime       32 seconds ago
  RampPercentage           0
  DrainageStatus           draining
  DrainageLastChangedTime  31 seconds ago
  DrainageLastCheckedTime  31 seconds ago

Task Queues:
     Name        Type  
  hello-world  activity
  hello-world  workflow
```

If you have implemented [Queries](/sending-messages#sending-queries) on closed pinned Workflows, you may need to keep some Workers running to handle them.

### Adding a pre-deployment test

Before deploying a new Workflow revision, you can test it with synthetic traffic.

To do this, utilize pinning in your tests, following the examples below:

<SdkTabs>
<SdkTabs.Go>
```go
workflowOptions := client.StartWorkflowOptions{
	ID:        "MyWorkflowId",
	TaskQueue: "MyTaskQueue",
	VersioningOverride: &client.PinnedVersioningOverride{
        Version: worker.WorkerDeploymentVersion{
            DeploymentName: "DeployName",
            BuildId:        "1.0",
        },
    },
}
// c is an initialized Client
we, err := c.ExecuteWorkflow(context.Background(), workflowOptions, HelloWorld, "Hello")
```
</SdkTabs.Go>
<SdkTabs.TypeScript>
```ts
const handle = await client.workflow.start('helloWorld', {
taskQueue: 'MyTaskQueue',
workflowId: 'MyWorkflowId',
versioningOverride: {
      pinnedTo: { buildId: '1.0', deploymentName: 'deploy-name' },
},
});
```
</SdkTabs.TypeScript>
<SdkTabs.DotNet>
```csharp
var workerV1 = new WorkerDeploymentVersion("deploy-name", "1.0");
var handle = await Client.StartWorkflowAsync(
    (HelloWorld wf) => wf.RunAsync(),
      	new(id: "MyWorkflowId", taskQueue: "MyTaskQueue")
      	{
           VersioningOverride = new VersioningOverride.Pinned(workerV1),
        }
);
```
</SdkTabs.DotNet>
<SdkTabs.Ruby>
```ruby
worker_v1 = Temporalio::WorkerDeploymentVersion.new(
  deployment_name: 'deploy-name',
  build_id: '1.0'
)
handle = env.client.start_workflow(
  HelloWorld,
  id: 'MyWorkflowId',
  task_queue: 'MyTaskQueue',
  versioning_override: Temporalio::VersioningOverride.pinned(worker_v1)
)
```
</SdkTabs.Ruby>
</SdkTabs>

This covers the complete lifecycle of working with Worker Versioning.
We are continuing to improve this feature, and we welcome any feedback or feature requests using the sidebar link!

---

## OSS Temporal Service metrics reference

:::info OSS Temporal Service metrics

The information on this page is relevant to open source [Temporal Service deployments](/temporal-service).

See [Cloud metrics](/cloud/metrics/) for metrics emitted by [Temporal Cloud](/cloud/overview).

See [SDK metrics](/references/sdk-metrics) for metrics emitted by the [SDKs](/encyclopedia/temporal-sdks).

:::

A Temporal Service emits a range of metrics to help operators get visibility into the Temporal Service's performance and to set up alerts.

All metrics emitted by the Temporal Service are listed in [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go).

For details on setting up metrics in your Temporal Service configuration, see the [Temporal Service configuration reference](/references/configuration#global).

The [dashboards repository](https://github.com/temporalio/dashboards) contains community-driven Grafana dashboard templates that can be used as a starting point for monitoring the Temporal Service and SDK metrics.
You can use these templates as references to build your own dashboards.
For any metrics that are missing in the dashboards, use [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go) as a reference.

Note that, apart from these metrics emitted by the Temporal Service, you should also monitor infrastructure-specific metrics like CPU, memory, and network for all hosts that are running Temporal Service services.

## Common metrics

Temporal emits metrics for each gRPC service request.
These metrics are emitted with `type`, `operation`, and `namespace` tags, which provide visibility into Service usage and show the request rates across Services, Namespaces, and Operations.

- Use the `operation` tag in your query to get request rates, error rates, or latencies per operation.
- Use the `service_name` tag with the [service role tag values](https://github.com/temporalio/temporal/blob/bba148cf1e1642fd39fa0174423b183d5fc62d95/common/metrics/defs.go#L108) to get details for the specific service.

All common tags that you can add in your query are defined in the [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go) file.

For example, to see service requests by operation on the Frontend Service, use the following:

`sum by (operation) (rate(service_requests{service_name="frontend"}[2m]))`

Note: All metrics queries in this topic are [Prometheus queries](https://prometheus.io/docs/prometheus/latest/querying/basics/).

The following list describes some metrics you can get started with.

### `service_requests`

Shows service requests received per Task Queue.
Example: Service requests by operation
`sum(rate(service_requests{operation=\"AddWorkflowTask\"}[2m]))`

### `service_latency`

Shows latencies for all Client request operations.
Usually these are the starting point to investigate which operation is experiencing high-latency issues.
Example: P95 service latency by operation for the Frontend Service
`histogram_quantile(0.95, sum(rate(service_latency_bucket{service_name="frontend"}[5m])) by (operation, le))`

### `service_error_with_type`

(Available only in v1.17.0+) Identifies errors encountered by the service.
Example: Service errors by type for the Frontend Service
`sum(rate(service_errors_with_type{service_name="frontend"}[5m])) by (error_type)`

### `client_errors`

An indicator for connection issues between different Server roles.
Example: Client errors
`sum(rate(client_errors{service_name="frontend",service_role="history"}[5m]))`

In addition to these, you can define some service-specific metrics to get performance details for each service.
Start with the following list, and use [metric_defs.go](https://github.com/temporalio/temporal/blob/main/common/metrics/metric_defs.go) to define additional metrics as required.

## Matching Service metrics

### `poll_success`

Shows for Tasks that are successfully matched to a poller.
Example: `sum(rate(poll_success{}[5m]))`

### `poll_timeouts`

Shows when no Tasks are available for the poller within the poll timeout.
Example: `sum(rate(poll_timeouts{}[5m]))`

### `asyncmatch_latency`

Measures the time from creation to delivery for async matched Tasks.
The larger this latency, the longer Tasks are sitting in the queue waiting for your Workers to pick them up.
Example: `histogram_quantile(0.95, sum(rate(asyncmatch_latency_bucket{service_name=~"matching"}[5m])) by (operation, le))`

### `no_poller_tasks`

Emitted whenever a task is added to a task queue that has no poller, and is a counter metric.
This is usually an indicator that either the Worker or the starter programs are using the wrong Task Queue.

## History Service metrics

A History Task is an internal Task in Temporal that is created as part of a transaction to update Workflow state and is processed by the Temporal History service.
It is critical to ensure that the History Task processing system is healthy.
The following key metrics can be used to monitor the History Service health:

### `task_requests`

Emitted on every Task process request.
Example: `sum(rate(task_requests{service="$service",operation=~"TransferActive.*"}[1m]))`

### `task_errors`

Emitted on every Task process error.
Example: `sum(rate(task_errors{operation=~"TransferActive.*"}[1m]))`

### `task_attempt`

Number of attempts on each Task Execution.
A Task is retried forever, and each retry increases the attempt count.
Example: `histogram_quantile($percentile, sum(rate(task_attempt_bucket{service="$service",operation=~"TransferActive.*"}[1m])) by (operation, le))`

### `task_latency_processing`

Shows the processing latency per attempt.
Example: `histogram_quantile($percentile, sum(rate(task_latency_processing_bucket{operation=~"TransferActive.*",service="$service", service_name="history"}[1m])) by (operation, le))`

### `task_latency`

Measures the in-memory latency across multiple attempts.

### `task_latency_queue`

Measures the duration, end-to-end, from when the Task should be executed (from the time it was fired) to when the Task is done.

### `task_latency_load`

(Available only in v1.18.0+) Measures the duration from Task generation to Task loading (Task schedule to start latency for persistence queue).

### `task_latency_schedule`

(Available only in v1.18.0+) Measures the duration from Task submission (to the Task scheduler) to processing (Task schedule to start latency for in-memory queue).

### `queue_latency_schedule`

(Available only in v1.18.0+) Measures the time to schedule 100 Tasks in one Task channel in the host-level Task scheduler.
If fewer than 100 Tasks are in the Task channel for 30 seconds, the latency is scaled to 100 Tasks upon emission.
Note: This is still an experimental metric and is subject to change.

### `task_latency_userlatency`

Shows the latency introduced because of Workflow logic.
For example, if you have one Workflow scheduling many Activities or Child Workflows at the same time, it can cause a per-Workflow lock contention.
The wait period for the per-Workflow lock is counted as `userlatency`.

The `operation` tag contains details about Task type and Active versus Standby statuses, and can be used to get request rates, error rates, or latencies per operation, which can help identify issues caused by database problems.

## Persistence metrics

Temporal Server emits metrics for every persistence database read and write.
Some of the most important ones are the following:

### `persistence_requests`

Emitted on every persistence request.
Examples:

- Prometheus query for getting the total number of persistence requests by operation for the History Service:
  `sum by (operation) (rate(persistence_requests{service="$service",service_name="history"}[1m]))`
- Prometheus query for getting the total number of persistence requests by operation for the Matching Service:
  `sum by (operation) (rate(persistence_requests{cluster="$cluster",service_name="matching"}[5m]))`

### `persistence_errors`

Shows all persistence errors.
This metric is a good indicator for connection issues between the Temporal Service and the persistence store.
Example:

- Prometheus query for getting all persistence errors by service (history)
  `sum (rate(persistence_errors{service="$service",service_name="history"}[1m]))`

### `persistence_error_with_type`

Shows all errors related to the persistence store with type, and contain an `error_type` tag.

- Prometheus query for getting persistence errors with type by (history) and by error type:
  `sum(rate(persistence_error_with_type{service="$service",service_name="history"}[1m])) by (error_type)`

### `persistence_latency`

Shows the latency on persistence operations.
Example:

- Prometheus query for getting latency by percentile:
  `histogram_quantile($percentile, sum(rate(persistence_latency_bucket{service="$service" service_name="history"}[1m])) by (operation, le))`

## Schedule metrics

Temporal emits metrics that track the performance and outcomes of these Scheduled Executions.

Below are additional metrics that can help you monitor and optimize your Scheduled Workflow Executions.

### `schedule_buffer_overruns`

Indicates instances where the buffer for holding Scheduled Workflows exceeds its maximum capacity.
This scenario typically occurs when schedules with a `buffer_all` overlap policy have their average run length exceeding the average schedule interval.

Example: To monitor buffer overruns.

`sum(rate(schedule_buffer_overruns{namespace="$namespace"}[5m]))`

### `schedule_missed_catchup_window`

Tracks occurrences when the system fails to execute a Scheduled Action within the defined catchup window.
Missed catchup windows can result from extended outages beyond the configured catchup period.

Example: To identify missed catchup opportunities.

`sum(rate(schedule_missed_catchup_window{namespace="$namespace"}[5m]))`

### `schedule_rate_limited`

Reflects instances where the creation of Workflows by a Schedule is throttled due to rate limiting policies within a Namespace.
This metric is crucial for identifying scheduling patterns that frequently hit rate limits, potentially causing missed catchup windows.

Example: To assess the impact of rate limiting on Scheduled Executions.

`sum(rate(schedule_rate_limited{namespace="$namespace"}[5m]))`

### `schedule_action_success`

Measures the successful execution of Workflows as per their schedules or through manual triggers.
This metric is confirms that Workflows are running as expected without delays or errors.

Example: To track the success rate of Scheduled Workflow Executions.

`sum(rate(schedule_action_success{namespace="$namespace"}[5m]))`

## Workflow metrics

These metrics pertain to Workflow statistics.

### `workflow_cancel`

Number of Workflows canceled before completing execution.

### `workflow_continued_as_new`

Number of Workflow Executions that were Continued-As-New from a past execution.

### `workflow_failed`

Number of Workflows that failed before completion.

### `workflow_success`

Number of Workflows that successfully completed.

### `workflow_timeout`

Number of Workflows that timed out before completing execution.

## Nexus metrics

These metrics pertain to Nexus Operations.

### Nexus Machinery in the History Service

See [architecture document](https://github.com/temporalio/temporal/blob/5d55d6c707bd68d8f3274c57ae702331adf05e6e/docs/architecture/nexus.md#scheduler)
for more info.

#### In-Memory Buffer

`dynamic_worker_pool_scheduler_enqueued_tasks`: A counter that is incremented when a task is enqueued to the buffer.

`dynamic_worker_pool_scheduler_dequeued_tasks`: A counter that is incremented when a task is dequeued from the buffer.

`dynamic_worker_pool_scheduler_rejected_tasks`: A counter that is incremented when the buffer is full and adding the
task is rejected.

`dynamic_worker_pool_scheduler_buffer_size`: A gauge that periodically samples the size of the buffer.

### Concurrency Limiter

`dynamic_worker_pool_scheduler_active_workers`: A gauge that periodically samples the number of running goroutines.

#### Rate Limiter

`rate_limited_task_runnable_wait_time`: A histogram representing the time a task spends waiting for the rate limiter.

#### Circuit Breaker

`circuit_breaker_executable_blocked`: A counter that is incremented every time a task execution is blocked by the
circuit breaker.

#### Task Executors

`nexus_outbound_requests`: A counter representing the number of Nexus outbound requests made by the history service.

`nexus_outbound_latency`: A histogram representing the latency of outbound Nexus requests made by the history service.

`callback_outbound_requests`: A counter representing the number of callback outbound requests made by the history
service.

`callback_outbound_latency`: A histogram representing the latency histogram of outbound callback requests made by the
history service.

### Nexus Machinery on the Frontend Service

#### `nexus_requests`

The number of Nexus requests received by the service.

Type: Counter

#### `nexus_latency`

Latency of Nexus requests.

Type: Histogram

#### `nexus_request_preprocess_errors`

The number of Nexus requests for which pre-processing failed.

Type: Counter

#### `nexus_completion_requests`

The number of Nexus completion (callback) requests received by the service.

Type: Counter

#### `nexus_completion_latency`

Latency histogram of Nexus completion (callback) requests.

Type: Histogram

#### `nexus_completion_request_preprocess_errors`

The number of Nexus completion requests for which pre-processing failed.

Type: Counter

---

## Temporal Commands reference

A [Command](/workflow-execution#command) is a requested action issued by a [Worker](/workers#worker) to the [Temporal Service](/temporal-service) after a [Workflow Task Execution](/tasks#workflow-task-execution) completes.

The following is a complete list of possible Commands.

### CompleteWorkflowExecution

This Command is triggered when the Workflow Function Execution returns.
It indicates to the Temporal Service that the [Workflow Execution](/workflow-execution) is complete.
The corresponding [Event](/workflow-execution/event#event) for this Command is one of the few Events that will be the last in a Workflow Execution [Event History](/workflow-execution/event#event-history).

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionCompleted](/references/events#workflowexecutioncompleted)

### ContinueAsNewWorkflowExecution

This Command is triggered when there is a call to [Continue-As-New](/workflow-execution/continue-as-new) from within the [Workflow](/workflows).
The corresponding Event for this Command is one of the few Events that will be the last in a Workflow Execution Event History.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionContinuedAsNew](/references/events#workflowexecutioncontinuedasnew)

### FailWorkflowExecution

This Command is triggered when the Workflow Execution returns an error or an exception is thrown.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionFailed](/references/events#workflowexecutionfailed)

### CancelWorkflowExecution

This Command is triggered when the Workflow has successfully cleaned up after receiving a Cancellation Request (which will be present as [WorkflowExecutionCancelRequestedEvent](/references/events#workflowexecutioncancelrequested) in the Event History).
The Corresponding Event for this Command is one of the few Events that will be the last in a Workflow Execution Event History.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [WorkflowExecutionCanceled](/references/events#workflowexecutioncanceled)

### StartChildWorkflowExecution

This Command is triggered by a call to spawn a [Child Workflow Execution](/child-workflows).

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [ChildWorkflowExecutionStarted](/references/events#childworkflowexecutionstarted)

By default, you cannot have more than 2,000 pending Child Workflows.

### SignalExternalWorkflowExecution

This Command is triggered by a call to [Signal](/sending-messages#sending-signals) another Workflow Execution.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [SignalExternalWorkflowExecutionInitiated](/references/events#signalexternalworkflowexecutioninitiated)

By default, you cannot have more than 2,000 pending Signals to other Workflows.

### RequestCancelExternalWorkflowExecution

This Command is triggered by a call to request cancellation of another Workflow Execution.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [RequestCancelExternalWorkflowExecutionInitiated](/references/events#requestcancelexternalworkflowexecutioninitiated)

By default, you cannot have more than 2,000 pending Signals to other Workflows.

### ScheduleActivityTask

This Command is triggered by a call to execute an [Activity](/activities).

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [ActivityTaskScheduled](/references/events#activitytaskscheduled)

By default, you cannot schedule more than 2,000 Activities concurrently.

### RequestCancelActivityTask

This Command is triggered by a call to request the cancellation of an [Activity Task](/tasks#activity-task).

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [ActivityTaskCancelRequested](/references/events#activitytaskcancelrequested)

### StartTimer

This Command is triggered by a call to start a Timer.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [TimerStarted](/references/events#timerstarted)

### CancelTimer

This Command is triggered by a call to cancel a Timer.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [TimerCanceled](/references/events#timercanceled)

### RecordMarker

This Command is triggered by the SDK.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [MarkerRecorded](/references/events#markerrecorded)

### UpsertWorkflowSearchAttributes

This Command is triggered by a call to "upsert" Workflow [Search Attributes](/search-attribute).

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [UpsertWorkflowSearchAttributes](/references/events#upsertworkflowsearchattributes)

### ProtocolMessageCommand

This Command helps guarantee ordering constraints for features such as Updates.

This Command points at the message from which the Event is created.
Therefore, just from the Command, you can't predict the resulting Event type.

### ScheduleNexusOperation

This Command is triggered by a call to execute an Nexus Operation in the caller Workflow.

- Awaitable: Yes, a Workflow Execution can await on the action resulting from this Command.
- Corresponding Event: [NexusOperationScheduled](/references/events#nexusoperationscheduled)

By default, you can't schedule more than 30 Nexus Operations concurrently, see [Limits](/workflow-execution/limits#workflow-execution-nexus-operation-limits) for details.

### CancelNexusOperation

This Command is triggered by a call to request the cancellation of a Nexus Operation.

- Awaitable: No, a Workflow Execution can not await on the action resulting from this Command.
- Corresponding Event: [NexusOperationCancelRequested](/references/events#nexusoperationcancelrequested)

---

## Temporal Cluster configuration reference

Much of the behavior of a Temporal Cluster is configured using the `development.yaml` file and may contain the following top-level sections:

- [`global`](#global)
- [`persistence`](#persistence)
- [`log`](#log)
- [`clusterMetadata`](#clustermetadata)
- [`services`](#services)
- [`publicClient`](#publicclient)
- [`archival`](#archival)
- [`namespaceDefaults`](#namespacedefaults)
- [`dcRedirectionPolicy`](#dcredirectionpolicy)
- [`dynamicConfigClient`](#dynamicconfigclient)

Changing any properties in the `development.yaml` file requires a process restart for changes to take effect.
Configuration parsing code is available [here](https://github.com/temporalio/temporal/blob/main/common/config/config.go).

## global

The `global` section contains process-wide configuration. See below for a minimal configuration (optional parameters are commented out.)

```yaml
global:
  membership:
    broadcastAddress: '127.0.0.1'
  metrics:
    prometheus:
      framework: 'tally'
      listenAddress: '127.0.0.1:8000'
```

### membership

The `membership` section controls the following membership layer parameters.

#### maxJoinDuration

The amount of time the service will attempt to join the gossip layer before failing.

Default is 10s.

#### broadcastAddress

Used by gossip protocol to communicate with other hosts in the same Cluster for membership info.
Use IP address that is reachable by other hosts in the same Cluster.
If there is only one host in the Cluster, you can use 127.0.0.1.
Check `net.ParseIP` for supported syntax, only IPv4 is supported.

### metrics

Configures the Cluster's metric subsystem.
Specific provides are configured using provider names as the keys.

- [`statsd`](#statsd)
- `prometheus`
- `m3`

#### prefix

The prefix to be applied to all outgoing metrics.

#### tags

The set of key-value pairs to be reported as part of every metric.

#### excludeTags

A map from tag name string to tag values string list.
This is useful to exclude some tags that might have unbounded cardinality.
The value string list can be used to whitelist values of that excluded tag to continue to be included.
For example, if you want to exclude `task_queue` because it has unbounded cardinality, but you still want to see a whitelisted value for `task_queue`.

#### statsd

:::caution

`statsd` is not supported natively by Temporal.

:::

The `statsd` sections supports the following settings:

- `hostPort`: The host:port of the statsd server.
- `prefix`: Specific prefix in reporting to `statsd`.
- `flushInterval`: Maximum interval for sending packets. (_Default_ 300ms).
- `flushBytes`: Specifies the maximum UDP packet size you wish to send. (_Default_ 1432 bytes).

#### prometheus

The `prometheus` sections supports the following settings:

- `framework`: The framework to use, currently supports `opentelemetry` and `tally`, default is `tally`. We plan to switch default to `opentelemetry` once its API become stable.
- `listenAddress`: Address for Prometheus to scrape metrics from.
  The Temporal Server uses the Prometheus client API, and the `listenAddress` configuration is used to listen for metrics.
- `handlerPath`: Metrics handler path for scraper; default is `/metrics`.

#### m3

The `m3` sections supports the following settings:

- `hostPort`: The host:port of the M3 server.
- `service`: The service tag to that this client emits.
- `queue`: M3 reporter queue size, default is 4k.
- `packetSize`: M3 reporter max packet size, default is 32k.

### pprof

- `port`: If specified, this will initialize pprof upon process start on the listed port.

### tls

The `tls` section controls the SSL/TLS settings for network communication and contains two subsections, `internode` and `frontend`.
The `internode` section governs internal service communication among roles where the `frontend` governs SDK client communication to the Frontend Service role.

Each of these subsections contain a `server` section and a `client` section.
The `server` contains the following parameters:

- `certFile`: The path to the file containing the PEM-encoded public key of the certificate to use.
- `keyFile`: The path to the file containing the PEM-encoded private key of the certificate to use.
- `requireClientAuth`: _boolean_ - Requires clients to authenticate with a certificate when connecting, otherwise known as mutual TLS.
- `clientCaFiles`: A list of paths to files containing the PEM-encoded public key of the Certificate Authorities you wish to trust for client authentication. This value is ignored if `requireClientAuth` is not enabled.

:::tip

See the [server samples repo](https://github.com/temporalio/samples-server/tree/master/tls) for sample TLS configurations.

:::

Below is an example enabling Server TLS (https) between SDKs and the Frontend APIs:

```yaml
global:
  tls:
    frontend:
      server:
        certFile: /path/to/cert/file
        keyFile: /path/to/key/file
      client:
        serverName: dnsSanInFrontendCertificate
```

Note, the `client` section generally needs to be provided to specify an expected DNS SubjectName contained in the presented server certificate via the `serverName` field; this is needed as Temporal uses IP to IP communication.
You can avoid specifying this if your server certificates contain the appropriate IP Subject Alternative Names.

Additionally, the `rootCaFiles` field needs to be provided when the client's host does not trust the Root CA used by the server.
The example below extends the above example to manually specify the Root CA used by the Frontend Services:

```yaml
global:
  tls:
    frontend:
      server:
        certFile: /path/to/cert/file
        keyFile: /path/to/key/file
      client:
        serverName: dnsSanInFrontendCertificate
        rootCaFiles:
          - /path/to/frontend/server/CA/files
```

Below is an additional example of a fully secured cluster using mutual TLS for both frontend and internode communication with manually specified CAs:

```yaml
global:
  tls:
    internode:
      server:
        certFile: /path/to/internode/cert/file
        keyFile: /path/to/internode/key/file
        requireClientAuth: true
        clientCaFiles:
          - /path/to/internode/serverCa
      client:
        serverName: dnsSanInInternodeCertificate
        rootCaFiles:
          - /path/to/internode/serverCa
    frontend:
      server:
        certFile: /path/to/frontend/cert/file
        keyFile: /path/to/frontend/key/file
        requireClientAuth: true
        clientCaFiles:
          - /path/to/internode/serverCa
          - /path/to/sdkClientPool1/ca
          - /path/to/sdkClientPool2/ca
      client:
        serverName: dnsSanInFrontendCertificate
        rootCaFiles:
          - /path/to/frontend/serverCa
```

**Note:** In the case that client authentication is enabled, the `internode.server` certificate is used as the client certificate among services. This adds the following requirements:

- The `internode.server` certificate must be specified on all roles, even for a frontend-only configuration.
- Internode server certificates must be minted with either **no** Extended Key Usages or **both** ServerAuth and ClientAuth EKUs.
- If your Certificate Authorities are untrusted, such as in the previous example, the internode server Ca will need to be specified in the following places:

  - `internode.server.clientCaFiles`
  - `internode.client.rootCaFiles`
  - `frontend.server.clientCaFiles`

## persistence

The `persistence` section holds configuration for the data store/persistence layer.
The following example shows a minimal specification for a password-secured Cluster using Cassandra.

```yaml
persistence:
  defaultStore: default
  visibilityStore: cass-visibility # The primary Visibility store.
  secondaryVisibilityStore: es-visibility # A secondary Visibility store added to enable Dual Visibility.
  numHistoryShards: 512
  datastores:
    default:
      cassandra:
        hosts: '127.0.0.1'
        keyspace: 'temporal'
        user: 'username'
        password: 'password'
    cass-visibility:
      cassandra:
        hosts: '127.0.0.1'
        keyspace: 'temporal_visibility'
    es-visibility:
      elasticsearch:
        version: 'v7'
        logLevel: 'error'
        url:
          scheme: 'http'
          host: '127.0.0.1:9200'
        indices:
          visibility: temporal_visibility_v1_dev
        closeIdleConnectionsInterval: 15s
```

The following top level configuration items are required:

### numHistoryShards

_Required_ - The number of history shards to create when initializing the Cluster.

**Warning:** This value is immutable and will be ignored after the first run.
Please ensure you set this value appropriately high enough to scale with the worst case peak load for this Cluster.

### defaultStore

_Required_ - The name of the data store definition that should be used by the Temporal server.

### visibilityStore

_Required_ - The name of the primary data store definition that should be used to set up [Visibility](/temporal-service/visibility) on the Temporal Cluster.

### secondaryVisibilityStore

_Optional_ - The name of the secondary data store definition that should be used to set up [Dual Visibility](/dual-visibility) on the Temporal Cluster.

### datastores

_Required_ - contains named data store definitions to be referenced.

Each definition is defined with a heading declaring a name (ie: `default:` and `visibility:` above), which contains a data store definition.

Data store definitions must be either `cassandra` or `sql`.

#### cassandra

A `cassandra` data store definition can contain the following values:

- `hosts`: _Required_ - "," separated Cassandra endpoints, e.g. "192.168.1.2,192.168.1.3,192.168.1.4".
- `port`: Default: 9042 - Cassandra port used for connection by `gocql` client.
- `user`: Cassandra username used for authentication by `gocql` client.
- `password`: Cassandra password used for authentication by `gocql` client.
- `keyspace`: _Required_ - the Cassandra keyspace.
- `datacenter`: The data center filter arg for Cassandra.
- `maxConns`: The max number of connections to this data store for a single TLS configuration.
- `tls`: See TLS below.

#### sql

A `sql` data store definition can contain the following values:

- `user`: Username used for authentication.
- `password`: Password used for authentication.
- `pluginName`: _Required_ - SQL database type.
  - _Valid values_: `mysql` or `postgres`.
- `databaseName` - _required_ - the name of SQL database to connect to.
- `connectAddr` - _required_ - the remote address of the database, e.g. "192.168.1.2".
- `connectProtocol` - _required_ - the protocol that goes with the `connectAddr`
  - _Valid values_: `tcp` or `unix`
- `connectAttributes` - a map of key-value attributes to be sent as part of connect `data_source_name` url.
- `maxConns` - the max number of connections to this data store.
- `maxIdleConns` - the max number of idle connections to this data store
- `maxConnLifetime` - is the maximum time a connection can be alive.
- `tls` - See below.

#### tls

The `tls` and `mtls` sections can contain the following values:

- `enabled` - _boolean_.
- `serverName` - name of the server hosting the data store.
- `certFile` - path to the cert file.
- `keyFile` - path to the key file.
- `caFile` - path to the ca file.
- `enableHostVerification` - _boolean_ - `true` to verify the hostname and server cert (like a wildcard for Cassandra cluster). This option is basically the inverse of `InSecureSkipVerify`. See `InSecureSkipVerify` in http://golang.org/pkg/crypto/tls/ for more info.

Note: `certFile` and `keyFile` are optional depending on server config, but both fields must be omitted to avoid using a client certificate.

## log

The `log` section is optional and contains the following possible values:

- `stdout` - _boolean_ - `true` if the output needs to go to standard out.
- `level` - sets the logging level.
  - _Valid values_ - debug, info, warn, error or fatal, default to info.
- `outputFile` - path to output log file.

## clusterMetadata

`clusterMetadata` contains the local cluster information. The information is used in [Multi-Cluster Replication](/temporal-service/multi-cluster-replication).

An example `clusterMetadata` section:

```yaml
clusterMetadata:
  enableGlobalNamespace: true
  failoverVersionIncrement: 10
  masterClusterName: 'active'
  currentClusterName: 'active'
  clusterInformation:
    active:
      enabled: true
      initialFailoverVersion: 0
      rpcAddress: '127.0.0.1:7233'
  #replicationConsumer:
  #type: kafka
```

- `currentClusterName` - _required_ - the name of the current cluster. **Warning:** This value is immutable and will be ignored after the first run.
- `enableGlobalNamespace` - _Default:_ `false`.
- `replicationConsumer` - determines which method to use to consume replication tasks. The type may be either `kafka` or `rpc`.
- `failoverVersionIncrement` - the increment of each cluster version when failover happens.
- `masterClusterName` - the master cluster name, only the master cluster can register/update namespace. All clusters can do namespace failover.
- `clusterInformation` - contains the local cluster name to `ClusterInformation` definition. The local cluster name should be consistent with `currentClusterName`. `ClusterInformation` sections consist of:
  - `enabled` - _boolean_ - whether a remote cluster is enabled for replication.
  - `initialFailoverVersion`
  - `rpcAddress` - indicate the remote service address (host:port). Host can be DNS name. Use `dns:///` prefix to enable round-robin between IP address for DNS name.

## services

The `services` section contains configuration keyed by service role type.
There are four supported service roles:

- `frontend`
- `matching`
- `worker`
- `history`

Below is a minimal example of a `frontend` service definition under `services`:

```yaml
services:
  frontend:
    rpc:
      grpcPort: 8233
      membershipPort: 8933
      bindOnIP: '0.0.0.0'
```

There are two sections defined under each service heading:

### rpc

_Required_

`rpc` contains settings related to the way a service interacts with other services. The following values are supported:

- `grpcPort`: Port on which gRPC will listen.
- `membershipPort`: Port used to communicate with other hosts in the same Cluster for membership info.
  Each service should use different port.
  If there are multiple Temporal Clusters in your environment (Kubernetes for example), and they have network access to each other, each Cluster should use a different membership port.
- `bindOnLocalHost`: Determines whether uses `127.0.0.1` as the listener address.
- `bindOnIP`: Used to bind service on specific IP, or `0.0.0.0`.
  Check `net.ParseIP` for supported syntax, only IPv4 is supported, mutually exclusive with `BindOnLocalHost` option.

**Note:** Port values are currently expected to be consistent among role types across all hosts.

## publicClient

The `publicClient` a required section describing the configuration needed to for worker to connect to Temporal server for background server maintenance.

- `hostPort` IPv4 host port or DNS name to reach Temporal frontend, [reference](https://github.com/grpc/grpc/blob/master/doc/naming.md)

Example:

```yaml
publicClient:
  hostPort: 'localhost:8933'
```

Use `dns:///` prefix to enable round-robin between IP address for DNS name.

## archival

_Optional_

Archival is an optional configuration needed to set up the [Archival store](/temporal-service/archival).
It can be enabled on `history` and `visibility` data.

The following list describes supported values for each configuration on the `history` and `visibility` data.

- `state`: State for Archival setting. Supported values are `enabled`, `disabled`. This value must be `enabled` to use Archival with any Namespace in your Cluster.
  - `enabled`: Enables Archival in your Cluster setup. When set to `enabled`, `URI` and `namespaceDefaults` values must be provided.
  - `disabled`: Disables Archival in your Cluster setup. When set to `disabled`, the `enableRead` value must be set to `false`, and under `namespaceDefaults`, `state` must be set to `disabled`, with no values set for `provider` and `URI` fields.
- `enableRead`: Supported values are `true` or `false`. Set to `true` to allow read operations from the archived Event History data.
- `provider`: Location where data should be archived. Subprovider configs are `filestore`, `gstorage`, `s3`, or `your_custom_provider`. Default configuration specifies `filestore`.

Example:

- To enable Archival in your Cluster configuration:

  ```yaml
  # Cluster-level Archival config enabled
  archival:
    # Event History configuration
    history:
      # Archival is enabled for the History Service data.
      state: 'enabled'
      enableRead: true
      # Namespaces can use either the local filestore provider or the Google Cloud provider.
      provider:
        filestore:
          fileMode: '0666'
          dirMode: '0766'
        gstorage:
          credentialsPath: '/tmp/gcloud/keyfile.json'
    # Configuration for archiving Visibility data.
    visibility:
      # Archival is enabled for Visibility data.
      state: 'enabled'
      enableRead: true
      provider:
        filestore:
          fileMode: '0666'
          dirMode: '0766'
  ```

- To disable Archival in your Cluster configuration:

  ```yaml
  # Cluster-level Archival config disabled
  archival:
    history:
      state: 'disabled'
      enableRead: false
    visibility:
      state: 'disabled'
      enableRead: false

  namespaceDefaults:
    archival:
      history:
        state: 'disabled'
      visibility:
        state: 'disabled'
  ```

For more details on Archival setup, see [Set up Archival](/self-hosted-guide/archival#set-up-archival).

## namespaceDefaults

_Optional_

Sets default Archival configuration for each Namespace using `namespaceDefaults` for `history` and `visibility` data.

- `state`: Default state of the Archival for the Namespace. Supported values are `enabled` or `disabled`.
- `URI`: Default URI for the Namespace.

For more details on setting Namespace defaults on Archival, see [Namespace creation in Archival setup](/self-hosted-guide/archival#namespace-creation)

Example:

```yaml
# Default values for a Namespace if none are provided at creation.
namespaceDefaults:
  # Archival defaults.
  archival:
    # Event History defaults.
    history:
      state: 'enabled'
      # New Namespaces will default to the local provider.
      URI: 'file:///tmp/temporal_archival/development'
    visibility:
      state: 'disabled'
      URI: 'file:///tmp/temporal_vis_archival/development'
```

## dcRedirectionPolicy

_Optional_

Contains the Frontend datacenter API redirection policy that you can use for cross-DC replication.

Supported values:

- `policy`: Supported values are `noop`, `selected-apis-forwarding`, and `all-apis-forwarding`.
  - `noop`: Not setting a value or setting `noop` means no redirection. This is the default value.
  - `selected-apis-forwarding`: Sets up forwarding for the following APIs to the active Cluster based on the Namespace.
    - `StartWorkflowExecution`
    - `SignalWithStartWorkflowExecution`
    - `SignalWorkflowExecution`
    - `RequestCancelWorkflowExecution`
    - `TerminateWorkflowExecution`
    - `QueryWorkflow`
  - `all-apis-forwarding`: Sets up forwarding for all APIs on the Namespace in the active Cluster.

Example:

```yaml
#...
dcRedirectionPolicy:
  policy: 'selected-apis-forwarding'
#...
```

## dynamicConfigClient

_Optional_

Configuration for setting up file-based [dynamic configuration](/temporal-service/configuration#dynamic-configuration) client for the Cluster.

This setting is required if specifying dynamic configuration. Supported configuration values are as follows:

- `filepath`: Specifies the path where the dynamic configuration YAML file is stored. The path should be relative to the root directory.
- `pollInterval`: Interval between the file-based client polls to check for dynamic configuration updates. The minimum period you can set is 5 seconds.

Example:

```yaml
dynamicConfigClient:
  filepath: 'config/dynamicconfig/development-cass.yaml'
  pollInterval: '10s'
```

---

## Temporal Cluster dynamic configuration reference

Temporal Cluster provides [dynamic configuration](/temporal-service/configuration#dynamic-configuration) keys that you can update and apply to a running Cluster without restarting your services.

The dynamic configuration keys are set with default values when you create your Cluster configuration.
You can override these values as you test your Cluster setup for optimal performance according to your workload requirements.

For the complete list of dynamic configuration keys, see [https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go).
Ensure that you check server release notes for any changes to these keys and values.

For the default values of dynamic configuration keys, check the following links:

- [Frontend Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/frontend/service.go#L176)
- [History Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/history/configs/config.go#L309)
- [Matching Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/matching/config.go#L125)
- [Worker Service](https://github.com/temporalio/temporal/blob/5783e781504d8ffac59f9848b830868f3139b980/service/worker/service.go#L193)

Setting dynamic configuration is optional.
Change these values only if you need to override the default values to achieve better performance on your Temporal Cluster.
Also, ensure that you test your changes before setting these in production.

## Format

To override the default dynamic configuration values, specify your custom values and constraints for the dynamic configuration keys that you want to change in a YAML configuration file.
Use the following format when creating your dynamic configuration file.

```yaml
testGetBoolPropertyKey:
  - value: false
  - value: true
    constraints:
      namespace: 'your-namespace'
  - value: false
    constraints:
      namespace: 'your-other-namespace'
testGetDurationPropertyKey:
  - value: '1m'
    constraints:
      namespace: 'your-namespace'
      taskQueueName: 'longIdleTimeTaskqueue'
testGetFloat64PropertyKey:
  - value: 12.0
    constraints:
      namespace: 'your-namespace'
testGetMapPropertyKey:
  - value:
      key1: 1
      key2: 'value 2'
      key3:
        - false
        - key4: true
          key5: 2.0
```

### Constraints

You can define constraints on some dynamic configuration keys to set specific values that apply on a Namespace or Task Queue level.
Not defining constraints on a dynamic configuration key sets the values across the Cluster.

- To set global values for the configuration key with no constraints, use the following:

  ```yaml
  frontend.globalNamespaceRPS: # Total per-Namespace RPC rate limit applied across the Cluster.
    - value: 5000
  ```

- For keys that can be customized at Namespace level, you can specify multiple values for different Namespaces in addition to one default value that applies globally to all Namespaces.
  To set values at a Namespace level, use `namespace` (String) as shown in the following example.

  ```yaml
  frontend.persistenceNamespaceMaxQPS: # Rate limit on the number of queries the Frontend sends to the Persistence store.
    - constraints: {} # Sets default value that applies to all Namespaces
      value: 2000 # The default value for this key is 0.
    - constraints: { namespace: 'namespace1' } # Sets limit on number of queries that can be sent from "namespace1" Namespace to the Persistence store.
      value: 4000
    - constraints: { namespace: 'namespace2' }
      value: 1000
  ```

- For keys that can be customized at a Task Queue level, you can specify Task Queue name and Task type in addition to Namespace.
  To set values at a Task Queue level, use `taskQueueName` (String) with `taskType` (optional; supported values: `Workflow` and `Activity`).

  For example if you have Workflow Executions creating a large number of Workflow and Activity tasks per second, you can add more partitions to your Task Queues (default is 4) to handle the high throughput of tasks.
  To do this, add the following to your dynamic configuration file.
  Note that if changing the number of partitions, you must set the same count for both read and write operations on Task Queues.

  ```yaml
  matching.numTaskqueueReadPartitions: # Number of Task Queue partitions for read operations.
    - constraints: { namespace: 'namespace1', taskQueueName: 'tq' } # Applies to the "tq" Task Queue for both Workflows and Activities.
      value: 8 # The default value for this key is 4. Task Queues that need to support high traffic require higher number of partitions. Set these values in accordance to your poller count.
    - constraints: {
          namespace: 'namespace1',
          taskQueueName: 'other-tq',
          taskType: 'Activity',
        } # Applies to the "other_tq" Task Queue for Activities specifically.
      value: 20
    - constraints: { namespace: 'namespace2' } # Applies to all task queues in "namespace2".
      value: 10
    - constraints: {} # Applies to all other task queues in "namespace1" and all other Namespaces.
      value: 16
  matching.numTaskqueueWritePartitions: # Number of Task Queue partitions for write operations.
    - constraints: { namespace: 'namespace1', taskQueueName: 'tq' } # Applies to the "tq" Task Queue for both Workflows and Activities.
      value: 8 # The default value for this key is 4. Task Queues that need to support high traffic require higher number of partitions. Set these values in accordance to your poller count.
    - constraints: {
          namespace: 'namespace1',
          taskQueueName: 'other-tq',
          taskType: 'Activity',
        } # Applies to the "other_tq" Task Queue for Activities specifically.
      value: 20
    - constraints: { namespace: 'namespace2' } # Applies to all task queues in "namespace2".
      value: 10
    - constraints: {} # Applies to all other task queues in "namespace1" and all other Namespaces.
      value: 16
  ```

{/* Note that the values set with most constraints take priority over values that are set with fewer constraints, regardless of the order in which they are set in the dynamic configuration key. */}

For more examples on how dynamic configuration is set, see:

- [docker-compose](https://github.com/temporalio/docker-compose/tree/main/dynamicconfig)
- [samples-server](https://github.com/temporalio/samples-server/blob/main/tls/config/dynamicconfig/development.yaml)

## Commonly used dynamic configuration keys

The following table lists commonly used dynamic configuration keys that can be used for rate limiting requests to the Temporal Cluster.

Setting dynamic configuration keys is optional.
If you choose to update these values for your Temporal Cluster, ensure that you are provisioning enough resources to handle the load.

All values listed here are for Temporal server v1.21.
Check [server release notes](https://github.com/temporalio/temporal/releases) to verify any potential breaking changes when upgrading your versions.

### Service-level RPS limits

The Requests Per Second (RPS) dynamic configuration keys set the rate at which requests can be made to each service in your Cluster.

When scaling your services, tune the RPS to test your workload and set acceptable provisioning benchmarks.
Exceeding these limits results in `ResourceExhaustedError`.

| Dynamic configuration key              | Type | Description                                                                                                                                                                                                                                          | Default value |
| -------------------------------------- | ---- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| Frontend                               |      |                                                                                                                                                                                                                                                      |               |
| `frontend.rps`                         | Int  | Rate limit (requests/second) for requests accepted by each Frontend Service host.                                                                                                                                                                    | 2400          |
| `frontend.namespaceRPS`                | Int  | Rate limit (requests/second) for requests accepted by each Namespace on the Frontend Service.                                                                                                                                                        | 2400          |
| `frontend.namespaceCount`              | Int  | Limit on the number of concurrent Task Queue polls per Namespace per Frontend Service host.                                                                                                                                                          | 1200          |
| `frontend.globalNamespaceRPS`          | Int  | Rate limit (requests/second) for requests accepted per Namespace, applied across Cluster. The limit is evenly distributed among available Frontend Service instances. If this is set, it overrides the per-instance limit (`frontend.namespaceRPS`). | 0             |
| `internal-frontend.globalNamespaceRPS` | Int  | Rate limit (requests/second) for requests accepted on each Internal-Frontend Service host applied across the Cluster.                                                                                                                                | 0             |
| History                                |      |                                                                                                                                                                                                                                                      |               |
| `history.rps`                          | Int  | Rate limit (requests/second) for requests accepted by each History Service host.                                                                                                                                                                     | 3000          |
| Matching                               |      |                                                                                                                                                                                                                                                      |               |
| `matching.rps`                         | Int  | Rate limit (requests/second) for requests accepted by each Matching Service host.                                                                                                                                                                    | 1200          |
| `matching.numTaskqueueReadPartitions`  | Int  | Number of read partitions for a Task Queue. Must be set with `matching.numTaskqueueWritePartitions`.                                                                                                                                                 | 4             |
| `matching.numTaskqueueWritePartitions` | Int  | Number of write partitions for a Task Queue.                                                                                                                                                                                                         | 4             |

### QPS limits for Persistence store

The Queries Per Second (QPS) dynamic configuration keys set the maximum number of queries a service can make per second to the Persistence store.

Persistence store rate limits are evaluated synchronously.
Adjust these keys according to your database capacity and workload.
If the number of queries made to the Persistence store exceeds the dynamic configuration value, you will see latencies and timeouts on your tasks.

| Dynamic configuration key                 | Type | Description                                                                                                                                                                                                                                             | Default value |
| ----------------------------------------- | ---- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| Frontend                                  |      |                                                                                                                                                                                                                                                         |               |
| `frontend.persistenceMaxQPS`              | Int  | Maximum number queries per second that the Frontend Service host can send to the Persistence store.                                                                                                                                                     | 2000          |
| `frontend.persistenceNamespaceMaxQPS`     | Int  | Maximum number of queries per second that each Namespace on the Frontend Service host can send to the Persistence store.  If the value set for this config is less than or equal to 0, the value set for `frontend.persistenceMaxQPS` will apply. | 0             |
| History                                   |      |                                                                                                                                                                                                                                                         |               |
| `history.persistenceMaxQPS`               | Int  | Maximum number of queries per second that the History host can send to the Persistence store.                                                                                                                                                           | 9000          |
| `history.persistenceNamespaceMaxQPS`      | Int  | Maximum number of queries per second for each Namespace that the History host can send to the Persistence store.  If the value set for this config is less than or equal to 0, then the value set for `history.persistenceMaxQPS` will apply.     | 0             |
| Matching                                  |      |                                                                                                                                                                                                                                                         |               |
| `matching.persistenceMaxQPS`              | Int  | Maximum number of queries per second that the Matching Service host can send to the Persistence store.                                                                                                                                                  | 9000          |
| `matching.persistenceNamespaceMaxQPS`     | Int  | Maximum number of queries per second that the Matching host can send to the Persistence store for each Namespace. If the value set for this config is less than or equal to 0, the value set for `matching.persistenceMaxQPS` will apply.         | 0             |
| Worker                                    |      |                                                                                                                                                                                                                                                         |               |
| `worker.persistenceMaxQPS`                | Int  | Maximum number of queries per second that the Worker Service host can send to the Persistence store.                                                                                                                                                    | 100           |
| `worker.persistenceNamespaceMaxQPS`       | Int  | Maximum number of queries per second that the Worker host can send to the Persistence store for each Namespace.  If the value set for this config is less than or equal to 0, the value set for `worker.persistenceMaxQPS` will apply.            | 0             |
| Visibility                                |      |                                                                                                                                                                                                                                                         |               |
| `system.visibilityPersistenceMaxReadQPS`  | Int  | Maximum number queries per second that Visibility database can receive for read operations.                                                                                                                                                             | 9000          |
| `system.visibilityPersistenceMaxWriteQPS` | Int  | Maximum number of queries per second that Visibility database can receive for write operations.                                                                                                                                                         | 9000          |

### Activity and Workflow default policy setting

You can define default values for Activity and Workflow [Retry Policies](/encyclopedia/retry-policies) at the Cluster level with the following dynamic configuration keys.

| Dynamic configuration key            | Type                          | Description                                                                                                       | Default value                                                                                   |
| ------------------------------------ | ----------------------------- | ----------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| `history.defaultActivityRetryPolicy` | Map (key-value pair elements) | Server configuration for an Activity Retry Policy when it is not explicitly set for the Activity in your code.    | [Default values for retry Policy](/encyclopedia/retry-policies#default-values-for-retry-policy) |
| `history.defaultWorkflowRetryPolicy` | Map (key-value pair elements) | Retry Policy for unset fields where the user has set an explicit `RetryPolicy`, but not specified all the fields. | [Default values for retry Policy](/encyclopedia/retry-policies#default-values-for-retry-policy) |

### Size limit settings

The Persistence store in the Cluster has default size limits set for optimal performance. The dynamic configuration keys relating to some of these are listed below.

The default values on these keys are based on extensive testing.
You can change these values, but ensure that you are provisioning enough database resources to handle the changed values.

For details on platform limits, see the [Temporal Platform limits sheet](/self-hosted-guide/defaults).

| Dynamic configuration key               | Type | Description                                                                                                                                                                                                                                     | Default value            |
| --------------------------------------- | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------ |
| `limit.maxIDLength`                     | Int  | Length limit for various Ids, including: `Namespace`, `TaskQueue`, `WorkflowID`, `ActivityID`, `TimerID`, `WorkflowType`, `ActivityType`, `SignalName`, `MarkerName`, `ErrorReason`/`FailureReason`/`CancelCause`, `Identity`, and `RequestID`. | 1000                     |
| `limit.blobSize.warn`                   | Int  | Limit, in bytes, for BLOBs size in an Event when a warning is thrown in the server logs.                                                                                                                                                        | 512 KB (512 × 1024)      |
| `limit.blobSize.error`                  | Int  | Limit, in bytes, for BLOBs size in an Event when an error occurs in the transaction.                                                                                                                                                            | 2 MB (2 × 1024 × 1024)   |
| `limit.historySize.warn`                | Int  | Limit, in bytes, at which a warning is thrown for the Workflow Execution Event History size.                                                                                                                                                    | 10 MB (10 × 1024 × 1024) |
| `limit.historySize.error`               | Int  | Limit, in bytes, at which an error occurs in the Workflow Execution for exceeding allowed size.                                                                                                                                                 | 50 MB (50 × 1024 × 1024) |
| `limit.historyCount.warn`               | Int  | Limit, in count, at which a warning is thrown for the Workflow Execution Event History size.                                                                                                                                                    | 10,240 Events            |
| `limit.historyCount.error`              | Int  | Limit, in count, at which an error occurs in the Workflow Execution for exceeding allowed number of Events.                                                                                                                                     | 51,200 events            |
| `limit.numPendingActivities.error`      | Int  | Maximum number of pending Activities that a Workflow Execution can have before the `ScheduleActivityTask` fails with an error.                                                                                                                  | 2000                     |
| `limit.numPendingSignals.error`         | Int  | Maximum number of pending Signals that a Workflow Execution can have before the `SignalExternalWorkflowExecution` commands from this Workflow fail with an error.                                                                               | 2000                     |
| `history.maximumSignalsPerExecution`    | Int  | Maximum number of Signals that a Workflow Execution can receive before it throws an `Invalid Argument` error.                                                                                                                                   | 10000                    |
| `limit.numPendingCancelRequests.error`  | Int  | Maximum number of pending requests to cancel other Workflows that a Workflow Execution can have before the `RequestCancelExternalWorkflowExecution` commands fail with an error.                                                                | 2000                     |
| `limit.numPendingChildExecutions.error` | Int  | Maximum number of pending Child Workflows that a Workflow Execution can have before the `StartChildWorkflowExecution` commands fail with an error.                                                                                              | 2000                     |
| `frontend.visibilityMaxPageSize`        | Int  | Maximum number of Workflow Executions shown from the ListWorkflowExecutions API in one page.                                                                                                                                                    | 1000                     |

### Secondary visibility settings

Secondary visibility configuration keys enable Dual Visibility on your Temporal Cluster.
This can be useful when migrating a Visibility database or creating a backup Visibility store.

| Dynamic configuration key                  | Type    | Description                                                                                                                                                                                                                                                                                                                                                                                                          | Default value |
| ------------------------------------------ | ------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| `system.enableReadFromSecondaryVisibility` | Boolean | Enables reading from the [secondary visibility store](/dual-visibility), and can be set per Namespace. Allowed values are `true` or `false`.                                                                                                                                                                                                                                                                         | `false`       |
| `system.secondaryVisibilityWritingMode`    |         | Enables writing Visibility data to the secondary Visibility store and can be set per Namespace. Setting this value to `on` disables write operations to the primary Visibility store. Allowed values: `off`: Enables writing to primary Visibility store only.  `on`: Enables writing to secondary Visibility store only. `dual`: Enables writing to both primary and secondary Visibility stores. | `off`         |

### Server version check settings

The Temporal server reports the server version and the version of the SDK that it is connected to in order to determine if the Web UI should show a banner that states a new version is available to install. This can be disabled by defining the following value or by setting the `TEMPORAL_VERSION_CHECK_DISABLED` environment variable to `1`.

| Dynamic configuration key           | Type    | Description                                                                                                                       | Default value |
| ----------------------------------- | ------- | --------------------------------------------------------------------------------------------------------------------------------- | ------------- |
| `frontend.enableServerVersionCheck` | Boolean | Enables the Temporal server to report version information about the current server and SDK. Allowed values are `true` or `false`. | `true`        |

---

## Errors

This reference lists possible [Workflow Task](/tasks#workflow-task) errors and how to resolve them.

> For other types of errors, see [Temporal Failures](https://docs.temporal.io/kb/failures).

Each of the below errors corresponds with a [WorkflowTaskFailedCause](https://api-docs.temporal.io/#temporal.api.enums.v1.WorkflowTaskFailedCause), which appears in [Events](/workflow-execution/event#event) under `workflow_task_failed_event_attributes`.

## Bad Cancel Timer Attributes {#bad-cancel-timer-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed while attempting to cancel a Timer.

{/* TODO add Timer term definition and link to it */}

Check your Timer attributes for a missing Timer Id value.
Add a valid Timer Id and redeploy the code.

## Bad Cancel Workflow Execution Attributes {#bad-cancel-workflow-execution-attributes}

The [Workflow Task](/tasks#workflow-task) failed due to unset [CancelWorkflowExecution](/references/commands#cancelworkflowexecution) attributes.

Reset any missing attributes and redeploy the Workflow Task.

## Bad Complete Workflow Execution Attributes {#bad-complete-workflow-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to unset attributes on [CompleteWorkflowExecution](/references/commands#completeworkflowexecution).

Reset any missing attributes.
Adjust the size of your Payload if it exceeds size limits.

## Bad Continue as New Attributes {#bad-continue-as-new-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate a [ContinueAsNew](/references/commands#continueasnewworkflowexecution) attribute.
The attribute could be unset or invalid.

Reset any missing attributes.
If the payload or memo exceeded size limits, adjust the input size.

Check that the [Workflow](/workflows) is validating search attributes after unaliasing keys.

## Bad Fail Workflow Execution Attributes {#bad-fail-workflow-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to unset [FailWorkflowExecution](/references/commands#failworkflowexecution) attributes.

If you encounter this error, make sure that `StartToClostTimeout` or `ScheduleToCloseTimeout` are set.
Restart the [Worker](/workers) that the [Workflow](/workflows) and [Activity](/activities) are registered to.

## Bad Modify Workflow Properties Attributes {#bad-modify-workflow-properties-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate attributes on a property in the Upsert Memo or in a payload.
These attributes are either unset or exceeding size limits.

Reset any unset and empty attributes.
Adjust the size of the [Memo](/workflow-execution#memo) or payload to fit within the system's limits.

## Bad Record Marker Attributes {#bad-record-marker-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to an unset or incorrect [Marker](/references/events#markerrecorded) name.

Enter a valid Marker name and redeploy the Task.

## Bad Request Cancel Activity Attributes {#bad-request-cancel-activity-attributes}

This error either indicates the possibility of unset attributes for [RequestCancelActivity](/references/commands#requestcancelactivitytask), or an invalid History Builder state.

Update the [Temporal SDK](/encyclopedia/temporal-sdks) to the most recent release.
Reset any unset attributes before retrying the [Workflow Task](/tasks#workflow-task).

If you continue to see this error, review your code for [nondeterministic causes](/workflow-definition#non-deterministic-change).

## Bad Request Cancel External Workflow Execution Attributes {#bad-request-cancel-external-workflow-execution}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed while trying to cancel an external Workflow.
Unset or invalid attributes can cause this to occur.

Reset any missing attributes, such as Workflow Id or Run Id.
Adjust any fields that exceed length limits.

If [Child Workflow](/child-workflows) is set to `Start` and `RequestCancel`, remove one of these attributes.
A Child Workflow cannot perform both actions in the same Workflow Task.

## Bad Schedule Activity Attributes {#bad-schedule-activity-attributes}

This error indicates unset or invalid attributes for [`ScheduleActivityTask`](/references/commands#scheduleactivitytask) or [`CompleteWorkflowExecution`](/references/commands#completeworkflowexecution).

Reset any unset or empty attributes.
Adjust the size of the received payload to stay within the given size limit.

## Bad Schedule Nexus Operation Attributes

This error indicates unset or invalid attributes for ScheduleNexusOperation, for example if the Nexus Endpoint name used in the caller Workflow doesn't exist.

Inspect the reason given in the error for mitigation when possible.

## Bad Search Attributes {#bad-search-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) has unset or invalid [Search Attributes](/search-attribute).
This can cause Workflow Tasks to continue to retry without success.

Make sure that all attributes are defined before retrying the Task.
Adjust the size of the Payload to fit within the system's size limits.

## Bad Signal Input Size {#bad-signal-input-size}

This error indicates that the Payload has exceeded the [Signal's](/sending-messages#sending-signals) available input size.

Adjust the size of the Payload, and redeploy the [Workflow Task](/tasks#workflow-task).

## Bad Signal Workflow Execution Attributes {#bad-signal-workflow-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate attributes for [SignalExternalWorkflowExecution](/references/commands#signalexternalworkflowexecution).

Reset any unset, missing, nil, or invalid attributes.
Adjust the input to fit within the system's size limits.

## Bad Start Child Execution Attributes {#bad-start-child-execution-attributes}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed to validate attributes for [`StartChildWorkflowExecution`](/references/commands#startchildworkflowexecution)

Adjust the input size of the attributes to fall within the system's size limits.

Make sure that [Search Attribute](/search-attribute) validation is performed after unaliasing keys.

## Bad Start Timer Attributes {#bad-start-timer-attributes}

This error indicates that the scheduled [Event](/workflow-execution/event#event) is missing a Timer Id.

{/* TODO add Timer Id as anchor for term and link to it */}

Set a valid Timer Id and retry the [Workflow Task](/tasks#workflow-task).

## Cause Bad Binary {#cause-bad-binary}

This error indicates that the [Worker](/workers) deployment returned a bad binary checksum.

{/* TODO: get more information about binary */}

## Cause Bad Update {#cause-bad-update}

{/* TODO: add link to Workflow Update page when written */}

This error indicates that a [Workflow Execution](/workflow-execution) tried to complete before receiving an Update.

`BadUpdate` can happen when a [Worker](/workers#worker) generates a [Workflow Task Completed](/references/events#workflowtaskcompleted) message with missing fields or an invalid Update response format.

This error might indicate usage of an unsupported SDK.
Make sure you're using a [supported SDK](/encyclopedia/temporal-sdks).

## Cause Reset Workflow {#cause-reset-workflow}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed due to a request to reset the [Workflow](/workflows).

If the system hasn't started a new Workflow, manually reset the Workflow.

## Cause Unhandled Update {#cause-unhandled-update}

`UnhandledUpdate` occurs when a Workflow Update is received by the Temporal Server while a Workflow Task being processed on a Worker produces a Command that would cause the Workflow to transition to a closed state.

Temporal rejects the Workflow Task completion to guarantee that the Update is eventually handled by Workflow code and rewinds the Workflow so it can handle the pending Update.

This error can happen when the Workflow receives frequent Updates.

## Cause Unspecified {#cause-unspecified}

This error indicates that the [Workflow Task](/tasks#workflow-task) has failed for an unknown reason.

If you see this error, examine your Workflow Definition.

## Failover Close Command {#failover-close-command}

This error indicates that a [Namespace](/namespaces) failover forced the [Workflow Task](/tasks#workflow-task) to close.
The system automatically schedules a retry when this error occurs.

{/* TODO: troubleshooting */}

## Force Close Command {#force-close-command}

This error indicates that the [Workflow Task](/tasks#workflow-task) was forced to close.
A retry will be scheduled if the error is recoverable.

{/* TODO: more info */}

## Nondeterminism Error {#non-deterministic-error}

The [Workflow Task](/tasks#workflow-task) failed due to a [nondeterminism error](/workflow-definition#non-deterministic-change).

{/* TODO: info */}

## Pending Activities Limit Exceeded {#pending-activities-limit-exceeded}

The [Workflow](/workflows) has reached capacity for pending [Activities](/activities).
Therefore, the [Workflow Task](/tasks#workflow-task) was failed to prevent the creation of another Activity.

Let the Workflow complete any current Activities before redeploying the code.

## Pending Child Workflows Limit Exceeded {#pending-child-workflows-limit-exceeded}

This error indicates that the [Workflow](/workflows) has reached capacity for pending [Child Workflows](/child-workflows).
Therefore, the [Workflow Task](/tasks#workflow-task) was failed to prevent additional Child Workflows from being added.

Wait for the system to finish any currently running Child Workflows before redeploying this Task.

## Pending Nexus Operations Limit Exceeded {#pending-nexus-operations-limit-exceeded}

The Workflow has reached capacity for pending Nexus Operations. Therefore, the Workflow Task was failed to prevent the creation of another Nexus Operation.

Let the Workflow complete any current Nexus Operation before retrying the Task.

See [Per Workflow Nexus Operation Limits](/cloud/limits#per-workflow-nexus-operation-limits) for details.

## Pending Request Cancel Limit Exceeded {#pending-request-cancel-limit-exceeded}

This error indicates that the [Workflow Task](/tasks#workflow-task) failed after attempting to add more cancel requests.
The [Workflow](/workflows) has reached capacity for pending requests to cancel other Workflows, and cannot accept more requests.

If you see this error, give the system time to process pending requests before retrying the Task.

## Pending Signals Limit Exceeded {#pending-signals-limit-exceeded}

The Workflow has reached capacity for pending Signals.
Therefore, the [Workflow Task](/tasks#workflow-task) was failed after attempting to add more [Signals](/sending-messages#sending-signals) to an external Workflow.

Wait for Signals to be processed by the Workflow before retrying the Task.

## Reset Sticky Task Queue {#reset-sticky-task-queue}

This error indicates that the Sticky [Task Queue](/task-queue) needs to be reset.

If you see this error, reset the Sticky Task Queue.
The system will retry automatically.

## Resource Exhausted Cause Concurrent Limit {#resource-exhausted-cause-concurrent-limit}

This error indicates that the concurrent [poller count](/develop/worker-performance#poller-count) has been exhausted.

{/* TODO: more info needed */}

Adjust the poller count per [Worker](/workers).

## Resource Exhausted Cause Persistence Limit {#resource-exhausted-cause-persistence-limit}

This error indicates that the persistence rate limit has been reached.

{/* TODO: more info needed */}

## Resource Exhausted Cause RPS Limit {#resource-exhausted-cause-rps-limit}

This error indicates that the [Workflow](/workflows) has exhausted its RPS limit.

{/* TODO: more info needed */}

## Resource Exhausted Cause System Overload {#resource-exhausted-cause-system-overload}

This error indicates that the system is overloaded and cannot allocate further resources to [Workflow Tasks](/tasks#workflow-task).

{/* TODO: more info needed */}

## Resource Exhausted Cause Unspecified {#resource-exhausted-cause-unspecified}

This error indicates that an unknown cause is preventing resources from being allocated to further [Workflow Tasks](/tasks#workflow-task).

{/* TODO: more info needed */}

## Schedule Activity Duplicate Id {#schedule-activity-duplicate-id}

The [Workflow Task](/tasks#workflow-task) failed because the [Activity](/activities) Id is already in use.

Check your code to see if you've already specified the same Activity Id in your [Workflow](/workflows).
Enter another Activity Id, and try running the Workflow Task again.

## Start Timer Duplicate Id {#start-timer-duplicate-id}

This error indicates that a Timer with the given Timer Id has already started.

{/* TODO link to Timer term when exists */}

Try entering a different Timer Id, and retry the [Workflow Task](/tasks#workflow-task).

## Unhandled Command {#unhandled-command}

This error indicates new available [Events](/references/events) since the last [Workflow Task](/tasks#workflow-task) started.
The Workflow Task was failed because the [Workflow](/workflows) attempted to close itself without handling the new Events.

`UnhandledCommand` can happen when the Workflow is receiving a high number of [Signals](/sending-messages#sending-signals).
If the Workflow doesn't have enough time to handle these Signals, a RetryWorkflow Task is scheduled to handle these new Events.

To prevent this error, drain the Signal Channel with the ReceiveAsync function.

If you continue to see this error, check your logs for failing Workflow Tasks.
The Workflow may have been picked up by a different [Worker](/workers#worker).

## Workflow Worker Unhandled Failure {#workflow-worker-unhandled-failure}

This error indicates that the [Workflow Task](/tasks#workflow-task) encountered an unhandled failure from the [Workflow Definition](/workflow-definition).

{/* TODO: more info needed */}

---

## Temporal Events reference

[Events](/workflow-execution/event#event) are created by the [Temporal Service](/temporal-service) in response to external occurrences and [Commands](/workflow-execution#command) generated by a [Workflow Execution](/workflow-execution).
All possible Events that could appear in a Workflow Execution [Event History](/workflow-execution/event#event-history) are listed below.

### WorkflowExecutionStarted

This is always the first [Event](/workflow-execution/event#event) in a Workflow Execution Event History.
It indicates that the Temporal Service received a request to spawn the Workflow Execution.

| Field                              | Description                                                                                                                                                    |
| ---------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| workflow_type                      | The [Name](/workflow-definition#workflow-type) of [Workflow](/workflows) that was initiated.                                                                   |
| parent_workflow_namespace          | The [Namespace](/namespaces) of the Parent [Workflow Execution](/workflow-execution), if applicable.                                                           |
| parent_workflow_execution          | Identifies the parent Workflow and the execution run.                                                                                                          |
| parent_initiated_event_id          | Id of the [StartWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to.                                            |
| task_queue                         | The [Task Queue](/task-queue) that this [Workflow Task](/tasks#workflow-task) was enqueued in.                                                                 |
| input                              | Information that is deserialized by the SDK to provide arguments to the Workflow.                                                                              |
| workflow_execution_timeout         | The total timeout period for a [Workflow Execution](/workflow-execution), including retries and continue-as-new.                                               |
| workflow_run_timeout               | Timeout of a single Workflow run.                                                                                                                              |
| workflow_task_timeout              | Timeout of a single Workflow Task.                                                                                                                             |
| continued_execution_run_id         | [Run Id](/workflow-execution/workflowid-runid#run-id) of the previous Workflow which continued-as-new, retried or was executed by Cron into this Workflow.     |
| initiator                          | Allows the Workflow to continue as a new Workflow Execution.                                                                                                   |
| continued_failure                  | Serialized result of a failure.                                                                                                                                |
| last_completion_result             | Information from the previously completed [Task](/tasks#task), if applicable.                                                                                  |
| original_execution_run_id          | The [Run Id](/workflow-execution/workflowid-runid#run-id) of the original Workflow started.                                                                    |
| identity                           | The Id of the [Client](/self-hosted-guide/security#client-connections) or parent Workflow [Worker](/workers#worker) that requested the start of this Workflow. |
| first_execution_run_id             | The first [Run Id](/workflow-execution/workflowid-runid#run-id), along the chain of [Continue-As-New](/workflow-execution/continue-as-new) Runs and Reset.     |
| retry_policy                       | The amount of retries as determined by the service's dynamic configuration. Retries will happen until 'schedule_to_close_timeout' is reached.                  |
| attempt                            | The number of attempts that have been made to complete this Task.                                                                                              |
| workflow_execution_expiration_time | The absolute time at which the Workflow Execution will [time out](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout).                       |
| cron_schedule                      | Displays the Workflow's [Cron Schedule](/cron-job), if applicable.                                                                                             |
| first_workflow_task_backoff        | Contains the amount of time between when this iteration of the Workflow was scheduled, and when it should run next. Applies to Cron Scheduling.                |
| memo                               | Non-indexed information to show in the Workflow.                                                                                                               |
| search_attributes                  | Provides data for setting up a Workflow's [Search Attributes](/search-attribute).                                                                              |
| prev_auto_reset_points             |                                                                                                                                                                |
| header                             | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the [Workflow Task](/tasks#workflow-task).             |
| completion_callbacks               | Completion callbacks attached when this workflow was started.                                                                                                  |

### WorkflowExecutionCompleted

This indicates that the [Workflow Execution](/workflow-execution) has successfully completed. The [Event](/workflow-execution/event#event) contains Workflow Execution results.

| Field                            | Description                                                                                                                                  |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| result                           | Serialized result of completed [Workflow](/workflows).                                                                                       |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                                              |
| new_execution_run_id             | The [Run Id](/workflow-execution/workflowid-runid#run-id) of the new Workflow Execution started as a result of a [Cron Schedule](/cron-job). |

### WorkflowExecutionFailed

This [Event](/workflow-execution/event#event) indicates that the [Workflow Execution](/workflow-execution) has unsuccessfully completed and contains the Workflow Execution error.

| Field                            | Description                                                                                                                                        |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| failure                          | Serialized result of a [Workflow](/workflows) failure.                                                                                             |
| retry_state                      | The reason provided for whether the [Task](/tasks#task) should or shouldn't be retried.                                                            |
| workflow_task_completed_event_id | The [Run Id](/workflow-execution/workflowid-runid#run-id) of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| new_execution_run_id             | The [Run Id](/workflow-execution/workflowid-runid#run-id) of the new Workflow started by Cron or [Retry](/encyclopedia/retry-policies).            |

### WorkflowExecutionTimedOut

This [Event](/workflow-execution/event#event) type indicates that the [Workflow Execution](/workflow-execution) has timed out by the [Temporal Server](/temporal-service/temporal-server) due to the [Workflow](/workflows) having not been completed within [timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) settings.

| Field                | Description                                                                                                                             |
| -------------------- | --------------------------------------------------------------------------------------------------------------------------------------- |
| retry_state          | The reason provided for whether the [Task](/tasks#task) should or shouldn't be retried.                                                 |
| new_execution_run_id | The [Run Id](/workflow-execution/workflowid-runid#run-id) of the new Workflow started by Cron or [Retry](/encyclopedia/retry-policies). |

### WorkflowExecutionCancelRequested

This [Event](/workflow-execution/event#event) type indicates that a request has been made to cancel the [Workflow Execution](/workflow-execution).

| Field                       | Description                                                                                                                                     |
| --------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| cause                       | The user-provided reason for the cancelation request.                                                                                           |
| external_initiated_event_id | The [Run Id](/workflow-execution/workflowid-runid#run-id) of the Event in the [Workflow](/workflows) that requested cancelation, if applicable. |
| external_workflow_execution | Identifies the external Workflow and the run of the its execution.                                                                              |
| identity                    | Id of the [Worker](/workers#worker) that requested cancelation.                                                                                 |

### WorkflowExecutionCanceled

This [Event](/workflow-execution/event#event) type indicates that the client has confirmed the cancelation request and the [Workflow Execution](/workflow-execution) has been canceled.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| details                          | Additional information reported by the [Workflow](/workflows) upon cancelation.                 |

### WorkflowExecutionSignaled

This [Event](/workflow-execution/event#event) type indicates the [Workflow](/workflows) has received a [Signal](/sending-messages#sending-signals) Event.
The Event type contains the Signal name and a Signal payload.

| Field       | Description                                                                                                   |
| ----------- | ------------------------------------------------------------------------------------------------------------- |
| signal_name | The name/type of Signal to be fired.                                                                          |
| input       | Information that is deserialized by the SDK to provide arguments to the Workflow function.                    |
| identity    | Identifies the [Worker](/workers#worker) that signaled to the Workflow.                                       |
| header      | Information passed by the sender of the Signal that is copied into the [Workflow Task](/tasks#workflow-task). |

### WorkflowExecutionTerminated

This [Event](/workflow-execution/event#event) type indicates that the [Workflow Execution](/workflow-execution) has been forcefully terminated and that likely the terminate Workflow API was called.

| Field    | Description                                                          |
| -------- | -------------------------------------------------------------------- |
| reason   | Information provided by the user or client for Workflow termination. |
| details  | Additional information reported by the Workflow upon termination.    |
| identity | Identifies the Worker that requested termination.                    |

### WorkflowExecutionContinuedAsNew

This [Event](/workflow-execution/event#event) type indicates that the Workflow has successfully completed, and a new Workflow has been started within the same transaction.
This Event type contains last [Workflow Execution](/workflow-execution) results as well as new Workflow Execution inputs.

| Field                            | Description                                                                                                          |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------- |
| new_execution_run_id             | The [Run Id](/workflow-execution/workflowid-runid#run-id) of the new Workflow started by this Continue-As-New Event. |
| workflow_type                    | The name/type of Workflow that was started by this Event.                                                            |
| task_queue                       | The [Task Queue](/task-queue) that this [Workflow Task](/tasks#workflow-task) was enqueued in.                       |
| input                            | Information that is deserialized by the SDK to provide arguments to the Workflow.                                    |
| workflow_run_timeout             | Timeout of a single Workflow run.                                                                                    |
| workflow_task_timeout            | Timeout of a single Workflow Task.                                                                                   |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event command was reported with.              |
| backoff_start_interval           | The amount of time to delay the beginning of the [ContinuedAsNew](#workflowexecutioncontinuedasnew) Workflow.        |
| initiator                        | Allows the Workflow to continue as a new execution.                                                                  |
| last_completion_result           | Information passed by the previously completed Task to the ongoing execution.                                        |
| header                           | Information passed by the sender of the Signal that is copied into the Workflow Task.                                |
| memo                             | Non-indexed information to show in the Workflow.                                                                     |
| search_attributes                | Provides data for setting up a Workflow's [Search Attributes](/search-attribute).                                    |

### WorkflowExecutionOptionsUpdated

This [Event](/workflow-execution/event#event) type indicates that the Workflow options have been updated.
The Event type contains updated options such as a versioning override or attached completion callbacks.

| Field                         | Description                                                                                                            |
| ----------------------------- | ---------------------------------------------------------------------------------------------------------------------- |
| versioning_override           | Versioning override upserted in this event. Ignored if nil or if unset_versioning_override is true.                    |
| unset_versioning_override     | Versioning override removed in this event.                                                                             |
| attached_request_id           | Request ID attached to the running workflow execution so subsequent requests with the same request ID will be deduped. |
| attached_completion_callbacks | Completion callbacks attached to the running workflow execution.                                                       |

### WorkflowTaskScheduled

This [Event](/workflow-execution/event#event) type indicates that the [Workflow Task](/tasks#workflow-task) has been scheduled.
The SDK client should now be able to process any new history events.

| Field                  | Description                                                                                |
| ---------------------- | ------------------------------------------------------------------------------------------ |
| task_queue             | The [Task Queue](/task-queue) that this Workflow Task was enqueued in.                     |
| start_to_close_timeout | The time that the [Worker](/workers#worker) takes to process this Task once it's received. |
| attempt                | The number of attempts that have been made to complete this Task.                          |

### WorkflowTaskStarted

This [Event](/workflow-execution/event#event) type indicates that the [Workflow Task](/tasks#workflow-task) has started.
The SDK client has picked up the Workflow Task and is processing new history events.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to. |
| identity           | Identifies the [Worker](/workers#worker) that started this Task.                                            |
| request_id         | Identifies the Workflow Task request.                                                                       |

### WorkflowTaskCompleted

This [Event](/workflow-execution/event#event) type indicates that the [Workflow Task](/tasks#workflow-task) completed.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to. |
| started_event_id   | The Id of the [WorkflowTaskStarted](#workflowtaskstarted) Event that this Task corresponds to.              |
| identity           | Identity of the [Worker](/workers#worker) that completed this Task.                                         |
| binary_checksum    | Binary Id of the Worker that completed this Task.                                                           |

The SDK client picked up the Workflow Task, processed new history events, and may or may not ask the [Temporal Server](/temporal-service/temporal-server) to do additional work.
It is possible for the following events to still occur:

- [ActivityTaskScheduled](#activitytaskscheduled)
- [TimerStarted](#timerstarted)
- [UpsertWorkflowSearchAttributes](#upsertworkflowsearchattributes)
- [MarkerRecorded](#markerrecorded)
- [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated)
- [RequestCancelExternalWorkflowExecutionInitiated](#requestcancelexternalworkflowexecutioninitiated)
- [SignalExternalWorkflowExecutionInitiated](#signalexternalworkflowexecutioninitiated)
- [WorkflowExecutionCompleted](#workflowexecutioncompleted)
- [WorkflowExecutionFailed](#workflowexecutionfailed)
- [WorkflowExecutionCanceled](#workflowexecutioncanceled)
- [WorkflowExecutionContinuedAsNew](#workflowexecutioncontinuedasnew)

### WorkflowTaskTimedOut

This [Event](/workflow-execution/event#event) type indicates that the [Workflow Task](/tasks#workflow-task) encountered a [timeout](/encyclopedia/detecting-workflow-failures#workflow-task-timeout).
Either an SDK client with a local cache was not available at the time, or it took too long for the SDK client to process the Task.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to. |
| started_event_id   | The Id of the [WorkflowTaskStarted](#workflowtaskstarted) Event that this Task corresponds to.              |
| timeout_type       | The type of timeout that has occurred.                                                                      |

### WorkflowTaskFailed

This [Event](/workflow-execution/event#event) type indicates that the [Workflow Task](/tasks#workflow-task) encountered a failure.
Usually this means that the Workflow was non-deterministic.
However, the Workflow reset functionality also uses this Event.

| Field              | Description                                                                                                                                  |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [WorkflowTaskScheduled](#workflowtaskscheduled) Event that this Workflow Task corresponds to.                                  |
| started_event_id   | The Id of the [WorkflowTaskStarted](#workflowtaskstarted) Event that this Workflow Task corresponds to.                                      |
| failure            | Details for the Workflow Task's failure.                                                                                                     |
| identity           | The identity of the [Worker](/workers#worker) that failed this Task. The Worker must be explicitly defined to return a value for this field. |
| base_run_id        | The original [Run Id](/workflow-execution/workflowid-runid#run-id) of the Workflow.                                                          |
| new_run_id         | The Run Id of the reset Workflow.                                                                                                            |
| fork_event_version | Identifies the Event version that was forked off to the reset Workflow.                                                                      |
| binary_checksum    | The Binary Id of the Worker that failed this Task. The Worker must be explicitly defined to return a value for this field.                   |

### ActivityTaskScheduled

This [Event](/workflow-execution/event#event) type indicates that an [Activity Task](/tasks#activity-task) was scheduled.
The SDK client should pick up this Activity Task and execute.
This Event type contains Activity inputs, as well as Activity Timeout configurations.

| Field                            | Description                                                                                                                                        |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| activity_id                      | The identifier assigned to this Activity by a [Worker](/workers#worker) or user.                                                                   |
| activity_type                    | The [type of Activity](/activity-definition#activity-type) that was scheduled.                                                                     |
| namespace                        | Namespace of the Workflow that the [Activity](/activities) resides in.                                                                             |
| task_queue                       | The [Task Queue](/task-queue) that this Activity Task was enqueued in.                                                                             |
| header                           | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the [Workflow Task](/tasks#workflow-task). |
| input                            | Information that is deserialized by the SDK to provide arguments to the [Workflow](/workflows) function.                                           |
| schedule_to_close_timeout        | The amount of time that a caller will wait for Activity completion. Limits the amount of time that retries will be attempted for this Activity.    |
| schedule_to_start_timeout        | Limits the time that an Activity Task can stay in a Task Queue. This timeout cannot be retried.                                                    |
| start_to_close_timeout           | Maximum amount of execution time that an Activity is allowed after being picked up by a Worker. This timeout is retryable.                         |
| heartbeat_timeout                | Maximum amount of time allowed between successful Worker heartbeats.                                                                               |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                                                    |
| retry_policy                     | The amount of retries as determined by the service's dynamic configuration. Retries will happen until `schedule_to_close_timeout` is reached.      |

### ActivityTaskStarted

This [Event](/workflow-execution/event#event) type indicates that an [Activity Task Execution](/tasks#activity-task-execution) was started.
The SDK Worker picked up the Activity Task and started processing the [Activity](/activities) invocation.
Note, however, that this Event is not written to History until the terminal Event (like [ActivityTaskCompleted](#activitytaskcompleted) or [ActivityTaskFailed](#activitytaskfailed)) occurs.

| Field              | Description                                                                                                          |
| ------------------ | -------------------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this Task corresponds to.                   |
| identity           | Identifies the [Worker](/workers#worker) that started the Task.                                                      |
| request_id         | Identifies the Activity Task request.                                                                                |
| attempt            | The number of attempts that have been made to complete this Task.                                                    |
| last_failure       | Details from the most recent failure Event. Only assigned values if the Task has previously failed and been retried. |

### ActivityTaskCompleted

This [Event](/workflow-execution/event#event) type indicates that the [Activity Task](/tasks#activity-task) has completed.
The SDK client has picked up and successfully completed the Activity Task.
This Event type contains [Activity Execution](/activity-execution) results.

| Field              | Description                                                                                                    |
| ------------------ | -------------------------------------------------------------------------------------------------------------- |
| result             | Serialized result of a completed [Activity](/activities).                                                      |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this completion Event corresponds to. |
| started_event_id   | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this Task corresponds to.                 |
| identity           | Identity of the [Worker](/workers#worker) that completed this Task.                                            |

### ActivityTaskFailed

This [Event](/workflow-execution/event#event) type indicates that the [Activity Task](/tasks#activity-task) has failed.
The SDK client picked up the Activity Task but unsuccessfully completed it.
This Event type contains [Activity Execution](/activity-execution) errors.

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| failure            | Serialized result of a [Workflow](/workflows) failure.                                                      |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this failure Event corresponds to. |
| started_event_id   | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this failure corresponds to.           |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                    |

### ActivityTaskTimedOut

This [Event](/workflow-execution/event#event) type indicates that the Activity has timed out according to the [Temporal Server](/temporal-service/temporal-server), due to one of these [Activity](/activities) timeouts: [Schedule-to-Close Timeout](/encyclopedia/detecting-activity-failures#schedule-to-close-timeout) and [Schedule-to-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout).

| Field              | Description                                                                                                 |
| ------------------ | ----------------------------------------------------------------------------------------------------------- |
| failure            | Serialized result of a [Workflow](/workflows) failure.                                                      |
| scheduled_event_id | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this timeout Event corresponds to. |
| started_event_id   | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this timeout corresponds to.           |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                    |
| timeout_type       | The type of timeout that led to this Event, e.g., Start-to-Close, Schedule-to-Close, Schedule-to-Start.     |

You can run a Workflow containing an Activity Execution that takes longer than the Start-to-Close Timeout you set and use a RetryPolicy that sets MaxAttempts to 1 so it does not retry indefinitely.
When the Activity times out, you will observe that the `ActivityTaskTimedOut` Event contains other attributes missing from the documentation, including the type of timeout that led to the Event.

### ActivityTaskCancelRequested

This [Event](/workflow-execution/event#event) type indicates that a request to [cancel](/activity-execution#cancellation) the [Activity](/activities) has occurred.

| Field                            | Description                                                                                                |
| -------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| scheduled_event_id               | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this cancel Event corresponds to. |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.            |

### ActivityTaskCanceled

This [Event](/workflow-execution/event#event) type indicates that the [Activity](/activities) has been [canceled](/activity-execution#cancellation).

| Field                            | Description                                                                                                                |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------- |
| details                          | Additional information reported by the Activity upon confirming cancelation.                                               |
| latest_cancel_requested_event_id | Id of the most recent [ActivityTaskCancelRequested](#activitytaskcancelrequested) Event which refers to the same Activity. |
| scheduled_event_id               | The Id of the [ActivityTaskScheduled](#activitytaskscheduled) Event that this cancelation corresponds to.                  |
| started_event_id                 | The Id of the [ActivityTaskStarted](#activitytaskstarted) Event that this cancelation corresponds to.                      |
| identity                         | Identifies the [Worker](/workers#worker) that requested cancelation.                                                       |

### TimerStarted

This [Event](/workflow-execution/event#event) type indicates a timer has started.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| timer_id                         | The Id assigned for the timer by a [Worker](/workers#worker) or user.                           |
| start_to_fire_timeout            | Amount of time to elapse before the timer fires.                                                |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |

### TimerFired

This [Event](/workflow-execution/event#event) type indicates a timer has fired.

| Field            | Description                                                           |
| ---------------- | --------------------------------------------------------------------- |
| timer_id         | The Id assigned for the timer by a [Worker](/workers#worker) or user. |
| started_event_id | The Id of the [TimerStarted](#timerstarted) Event itself.             |

### TimerCanceled

This [Event](/workflow-execution/event#event) type indicates a Timer has been canceled.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| timer_id                         | The Id assigned for the timer by a [Worker](/workers#worker) or user.                           |
| started_event_id                 | The Id of the [TimerStarted](#timerstarted) Event itself.                                       |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |

### RequestCancelExternalWorkflowExecutionInitiated

This [Event](/workflow-execution/event#event) type indicates that a [Workflow](/workflows) has requested that the [Temporal Server](/temporal-service/temporal-server) try to cancel another Workflow.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| namespace                        | [Namespace](/namespaces) of the Workflow that`s going to be signaled for execution.             |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).           |
| child_workflow_only              | Set to true if this Workflow is a child of the Workflow which issued the cancelation request.   |
| reason                           | Information provided by the user or client for Workflow cancelation.                            |

### RequestCancelExternalWorkflowExecutionFailed

This [Event](/workflow-execution/event#event) type indicates that [Temporal Server](/temporal-service/temporal-server) could not cancel the targeted [Workflow](/workflows).
This is usually because the target Workflow could not be found.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| namespace                        | [Namespace](/namespaces) of the Workflow that failed to cancel.                                 |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).           |
| initiated_event_id               | Id of the [RequestCancelExternalWorkflowExecutionInitiated] Event this failure corresponds to.  |

### ExternalWorkflowExecutionCancelRequested

This [Event](/workflow-execution/event#event) type indicates that the [Temporal Server](/temporal-service/temporal-server) has successfully requested the cancelation of the target [Workflow](/workflows).

| Field              | Description                                                                                                                                                       |
| ------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| initiated_event_id | Id of the [RequestCancelExternalWorkflowExecutionInitiated](#requestcancelexternalworkflowexecutioninitiated) Event that this cancelation request corresponds to. |
| namespace          | [Namespace](/namespaces) of the Workflow that was requested to cancel.                                                                                            |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).                                                                             |

### ExternalWorkflowExecutionSignaled

This [Event](/workflow-execution/event#event) type indicates that the [Temporal Server](/temporal-service/temporal-server) has successfully [Signaled](/sending-messages#sending-signals) the targeted [Workflow](/workflows).

| Field              | Description                                                                                                                      |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------- |
| initiated_event_id | Id of the [SignalExternalWorkflowExecutionInitiated](#signalexternalworkflowexecutioninitiated) Event this Event corresponds to. |
| namespace          | [Namespace](/namespaces) of the Workflow that was signaled to.                                                                   |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).                                            |

### MarkerRecorded

This [Event](/workflow-execution/event#event) type is transparent to the [Temporal Server](/temporal-service/temporal-server).
The Server will only store it and will not try to understand it.
The SDK client may use it for local activities or side effects.

| Field                            | Description                                                                                                         |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| marker_name                      | Identifies various markers.                                                                                         |
| details                          | Serialized information recorded in the marker.                                                                      |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                     |
| header                           | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the marker. |
| failure                          | Serialized result of a [Workflow](/workflows) failure.                                                              |

### StartChildWorkflowExecutionInitiated

This [Event](/workflow-execution/event#event) type indicates that the [Temporal Server](/temporal-service/temporal-server) will try to start a Child Workflow.

| Field         | Description                                     |
| ------------- | ----------------------------------------------- |
| namespace     | [Namespace](/namespaces) of the Child Workflow. |
| workflow_id   | Identifies the Child Workflow.                  |
| workflow_type | The name/type of Workflow that was initiated.   |

### StartChildWorkflowExecutionFailed

This [Event](/workflow-execution/event#event) type indicates a [Child Workflow Execution](/child-workflows) cannot be started / triggered.
It is usually due to a Child Workflow Id collision.

| Field                            | Description                                                                                                              |
| -------------------------------- | ------------------------------------------------------------------------------------------------------------------------ |
| namespace                        | [Namespace](/namespaces) of the Child Workflow.                                                                          |
| workflow_id                      | Identifies the Child Workflow.                                                                                           |
| workflow_type                    | The name/type of Workflow that has failed.                                                                               |
| initiated_event_id               | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                          |

### ChildWorkflowExecutionStarted

This [Event](/workflow-execution/event#event) type indicates a [Child Workflow Execution](/child-workflows) has successfully started / triggered.
This would also cause the [WorkflowExecutionStarted](#workflowexecutionstarted) to be recorded for the Workflow that has started.

| Field              | Description                                                                                                                      |
| ------------------ | -------------------------------------------------------------------------------------------------------------------------------- |
| namespace          | [Namespace](/namespaces) of the Child Workflow.                                                                                  |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to.         |
| workflow_execution | Identifies the Workflow and the run of the Workflow Execution.                                                                   |
| workflow_type      | The name/type of Workflow that has started execution.                                                                            |
| header             | Information passed by the sender of the [Signal](/sending-messages#sending-signals) that is copied into the Child Workflow Task. |

### ChildWorkflowExecutionCompleted

This [Event](/workflow-execution/event#event) type indicates that the [Child Workflow Execution](/child-workflows) has successfully completed.
This would also cause the [WorkflowExecutionCompleted](#workflowexecutioncompleted) to be recorded for the [Workflow](/workflows) that has completed.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| result             | Serialized result of the completed Child Workflow.                                                                       |
| namespace          | [Namespace](/namespaces) of the completed Child Workflow.                                                                |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).                                    |
| workflow_type      | The name/type of Workflow that was completed.                                                                            |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event this Event corresponds to.               |

### ChildWorkflowExecutionFailed

This [Event](/workflow-execution/event#event) type indicates that the [Child Workflow Execution](/child-workflows) has unsuccessfully completed.
This would also cause the [WorkflowExecutionFailed](#workflowexecutionfailed) to be recorded for the Workflow that has failed.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| failure            | Serialized result of a [Workflow](/workflows) failure.                                                                   |
| namespace          | [Namespace](/namespaces) of the Child Workflow that failed.                                                              |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).                                    |
| workflow_type      | The name/type of Workflow that has failed.                                                                               |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event this failure corresponds to.             |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                                 |

### ChildWorkflowExecutionCanceled

This [Event](/workflow-execution/event#event) type indicates that the Child Workflow Execution has been canceled.
This would also cause the [WorkflowExecutionCanceled](#workflowexecutioncanceled) to be recorded for the Workflow that was canceled.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| details            | Additional information reported by the Child Workflow upon cancelation.                                                  |
| namespace          | [Namespace](/namespaces) of the Child Workflow that was canceled.                                                        |
| workflow_execution | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).                                    |
| workflow_type      | The name/type of Workflow that was canceled.                                                                             |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event this cancelation corresponds to.         |

### ChildWorkflowExecutionTimedOut

This Event type indicates that the [Child Workflow Execution](/child-workflows) has timed out by the [Temporal Server](/temporal-service/temporal-server).
This would also cause the [WorkflowExecutionTimeOut](#workflowexecutiontimedout) to be recorded for the Workflow that timed out.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| namespace          | [Namespace](/namespaces) of the Child Workflow.                                                                          |
| workflow_execution | Identifies the Workflow and the run of the Workflow Execution.                                                           |
| workflow_type      | The name/type of Workflow that has timed out.                                                                            |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event that this timeout corresponds to.        |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                                 |

### ChildWorkflowExecutionTerminated

This [Event](/workflow-execution/event#event) type indicates that the Child Workflow Execution has been terminated.
This would also cause the [WorkflowExecutionTerminated](#workflowexecutionterminated) to be recorded for the Workflow that was terminated.

| Field              | Description                                                                                                              |
| ------------------ | ------------------------------------------------------------------------------------------------------------------------ |
| namespace          | [Namespace](/namespaces) of the Child Workflow.                                                                          |
| workflow_execution | Identifies the Workflow and the run of the Workflow Execution.                                                           |
| workflow_type      | The name/type of Workflow that was terminated.                                                                           |
| initiated_event_id | Id of the [StartChildWorkflowExecutionInitiated](#startchildworkflowexecutioninitiated) Event this Event corresponds to. |
| started_event_id   | Id of the [ChildWorkflowExecutionStarted](#childworkflowexecutionstarted) Event that this termination corresponds to.    |
| retry_state        | The reason provided for whether the Task should or shouldn't be retried.                                                 |

### SignalExternalWorkflowExecutionInitiated

This [Event](/workflow-execution/event#event) type indicates that the [Temporal Server](/temporal-service/temporal-server) will try to [Signal](/sending-messages#sending-signals) the targeted [Workflow](/workflows).
This Event type contains the Signal name, as well as a Signal payload.

| Field                            | Description                                                                                     |
| -------------------------------- | ----------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with. |
| namespace                        | [Namespace](/namespaces) of the Workflow that's to be signaled.                                 |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).           |
| signal_name                      | The name/type of Signal to be fired.                                                            |
| input                            | Information that is deserialized by the SDK to provide arguments to the Workflow Function.      |
| child_workflow_only              | Set to true if this Workflow is a child of the Workflow which issued the cancelation request.   |
| header                           | Information to be passed from the Signal to the targeted Workflow.                              |

### SignalExternalWorkflowExecutionFailed

This [Event](/workflow-execution/event#event) type indicates that the [Temporal Server](/temporal-service/temporal-server) cannot Signal the targeted [Workflow](/workflows), usually because the Workflow could not be found.

| Field                            | Description                                                                                                                                                                                  |
| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| workflow_task_completed_event_id | The Id of the [WorkflowTaskCompleted](#workflowtaskcompleted) that the Event was reported with.                                                                                              |
| namespace                        | [Namespace](/namespaces) of the Workflow that failed to execute.                                                                                                                             |
| workflow_execution               | Identifies the Workflow and the run of the [Workflow Execution](/workflow-execution).                                                                                                        |
| initiated_event_id               | Id of the [RequestCancelExternalWorkflowExecutionInitiated](#requestcancelexternalworkflowexecutioninitiated) Event this failure [signal](/sending-messages#sending-signals) corresponds to. |

### UpsertWorkflowSearchAttributes

This [Event](/workflow-execution/event#event) type indicates that the Workflow [Search Attributes](/search-attribute) should be updated and synchronized with the visibility store.

| Field                            | Description                                                                                |
| -------------------------------- | ------------------------------------------------------------------------------------------ |
| workflow_task_completed_event_id | The [WorkflowTaskCompleted](#workflowtaskcompleted) Event reported the Event with this Id. |
| search_attributes                | Provides data for setting up a Workflow's [Search Attributes](/search-attribute).          |

### WorkflowExecutionUpdateAcceptedEvent

This [Event](/workflow-execution/event#event) type indicates that a [Workflow Execution](/workflow-execution) has accepted an [Update](/sending-messages#sending-updates) for execution.
The original request input payload is both indicated and stored by this Event, as it generates no Event when initially requesting an Update.

| Field                                | Description                                                                                                                                                            |
| ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| protocol_instance_id                 | The instance of the Update protocol with this Id is executing this Update.                                                                                             |
| accepted_request_message_id          | The Id of the request message sent by [Temporal Server](/temporal-service/temporal-server) to the [Worker](/workers#worker).                                           |
| accepted_request_sequencing_event_id | Execute this Update after the Event with this Id.                                                                                                                      |
| accepted_request                     | The request input and metadata initially provided by the invoker of the Update and subsequently relayed by Temporal Server to the Worker for acceptance and execution. |

### WorkflowExecutionUpdateCompletedEvent

This [Event](/workflow-execution/event#event) type indicates that a [Workflow Execution](/workflow-execution) has executed an [Update](/sending-messages#sending-updates) to completion.

| Field             | Description                                                                                                                                  |
| ----------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| meta              | The metadata associated with this Update, sourced from the initial request.                                                                  |
| accepted_event_id | The Id of the [WorkflowExecutionUpdateAcceptedEvent](#workflowexecutionupdateacceptedevent) The Platform accepted this Update for execution. |
| outcome           | The outcome of execution of this Update whether the execution resulted in a success or a failure.                                            |

### NexusOperationScheduled

This Event type indicates that a Nexus Operation scheduled by a caller Workflow.
The caller's [Nexus Machinery](/glossary#nexus-machinery) will attempt to start the Nexus Operation.
This Event type contains Nexus Operation input and the Operation request ID.

| Field                            | Description                                                                                                                                                                                                                                                                                               |
| :------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| endpoint                         | Endpoint name, must exist in the endpoint registry.                                                                                                                                                                                                                                                       |
| service                          | Service name.                                                                                                                                                                                                                                                                                             |
| operation                        | Operation name.                                                                                                                                                                                                                                                                                           |
| input                            | Input for the operation. The server converts this into Nexus request content and the appropriate content headers internally when sending the StartOperation request. On the handler side, if it is also backed by Temporal, the content is transformed back to the original Payload stored in this event. |
| schedule_to_close_timeout        | Schedule-to-close timeout for this operation. Indicates how long the caller is willing to wait for operation completion. Calls are retried internally by the server.                                                                                                                                      |
| nexus_header                     | Header to attach to the Nexus request. Note these headers are not the same as Temporal headers on internal activities and child Workflows, these are transmitted to Nexus operations that may be external and are not traditional payloads.                                                               |
| workflow_task_completed_event_id | The ID of the [WorkflowTaskCompleted](#workflowtaskcompleted) event that the corresponding ScheduleNexusOperation command was reported with.                                                                                                                                                              |
| request_id                       | A unique ID generated by the History Service upon creation of this event. The ID will be transmitted with all Nexus StartOperation requests and is used as an idempotency key.                                                                                                                            |
| endpoint_id                      | Endpoint ID as resolved in the endpoint registry at the time this event was generated. This is stored on the event and used internally by the server in case the endpoint is renamed from the time the event was originally scheduled.                                                                    |

### NexusOperationStarted

This Event type indicates that a Nexus Operation Execution was started.
This Event is added to the caller's Workflow History for Asynchronous Nexus Operations, for example those that are backed by a Workflow.
The Event is not added to the caller's Workflow History for Synchronous Nexus Operations, since they transition directly to [NexusOperationCompleted](#nexusoperationcompleted) or another final state such as [NexusOperationFailed](#nexusoperationfailed) when the response is provided synchronously by the Nexus handler.

| Field              | Description                                                                                                                                       |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------------ |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled) event this task corresponds to.                                                 |
| operation_token    | The operation token returned by the Nexus handler in the response to the StartOperation request. This token is used when canceling the operation. |
| request_id         | The request ID allocated at schedule time.                                                                                                        |

### NexusOperationCompleted

This Event type indicates that a Nexus Operation has completed successfully.
The caller's Workflow History records the result of a successful Nexus Operation with this event for synchronous and asynchronous Nexus Operations.
This Event type contains Nexus Operation results.

| Field              | Description                                                                                                                                                          |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled) event. Uniquely identifies this operation.                                                         |
| result             | Serialized result of the Nexus operation. The response of the Nexus handler. Delivered either via a completion callback or as a response to a synchronous operation. |
| request_id         | The request ID allocated at schedule time.                                                                                                                           |

### NexusOperationFailed

This Event type indicates that a Nexus Operation has failed.
The caller's Workflow History records a failed Nexus Operation with this event both for synchronous and asynchronous Nexus Operations.
For example, when a Nexus Handler responds synchronously with a non-retryable error or when a Workflow that backs an Operation fails, resulting in a [WorkflowExecutionFailed](#workflowexecutionfailed) Event.
When an SDK client picks up a Nexus Operation, the Nexus handler asynchronously starts an underlying Workflow, which subsequently results in [WorkflowExecutionFailed](#workflowexecutionfailed).
This Event type contains a Nexus Operation failure.

| Field              | Description                                                                                                   |
| :----------------- | :------------------------------------------------------------------------------------------------------------ |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled)` event. Uniquely identifies this operation. |
| failure            | Failure details. A NexusOperationFailureInfo wrapping an ApplicationFailureInfo.                              |
| request_id         | The request ID allocated at schedule time.                                                                    |

### NexusOperationTimedOut

This Event type indicates that a Nexus Operation has timed out according to the Temporal Server, due to one of these Nexus Operation timeouts: Schedule-to-Close Timeout.
| Field | Description |
| :---- | :---- |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled)` event. Uniquely identifies this operation. |
| failure | Failure details. A NexusOperationFailureInfo wrapping a CanceledFailureInfo. |
| request_id | The request ID allocated at schedule time. |

### NexusOperationCancelRequested

This Event type indicates that the Workflow that scheduled a Nexus Operation requested to cancel it.
| Field | Description |
| :---- | :---- |
| scheduled_event_id | The id of the [NexusOperationScheduled](#nexusoperationscheduled)` event this cancel request corresponds to. |
| workflow_task_completed_event_id | The [WorkflowTaskCompleted](#workflowtaskcompleted) event that the corresponding RequestCancelNexusOperation command was reported with. |

### NexusOperationCanceled

This Event type indicates that a Nexus Operation has resolved as canceled.
| Field | Description |
| :---- | :---- |
| scheduled_event_id | The ID of the [NexusOperationScheduled](#nexusoperationscheduled)` event. Uniquely identifies this operation. |
| failure | Cancellation details. |
| request_id | The request ID allocated at schedule time. |

---

## Temporal Failures reference

A Failure is Temporal's representation of various types of errors that occur in the system.

There are different types of Failures, and each has a different type in the SDKs and different information in the protobuf messages (which are used to communicate with the Temporal Service and appear in [Event History](/workflow-execution/event#event-history)).

## Temporal Failure

Most SDKs have a base class that the other Failures extend:

- TypeScript: [TemporalFailure](https://typescript.temporal.io/api/classes/common.TemporalFailure)
- Java: [TemporalFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/TemporalFailure.html)
- Python: [FailureError](https://python.temporal.io/temporalio.exceptions.FailureError.html)
- PHP: [TemporalFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-TemporalFailure.html)

The base [Failure proto message](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure) has these fields:

- `string message`
- `string stack_trace`
- `string source`: The SDK this Failure originated in (for example, `"TypeScriptSDK"`). In some SDKs, this field is used to rehydrate the call stack into an exception object.
- `Failure cause`: The `Failure` message of the cause of this Failure (if applicable).
- `Payload encoded_attributes`: Contains the encoded `message` and `stack_trace` fields when using a [Failure Converter](/failure-converter).

## Application Failure

Workflow, and Activity, and Nexus Operation code use Application Failures to communicate application-specific failures that happen.
This is the only type of Temporal Failure created and thrown by user code.

- TypeScript: [ApplicationFailure](https://typescript.temporal.io/api/classes/common.ApplicationFailure)
- Java: [ApplicationFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ApplicationFailure.html)
- Go: [ApplicationError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ApplicationError)
- Python: [ApplicationError](https://python.temporal.io/temporalio.exceptions.ApplicationError.html)
- PHP: [ApplicationFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ApplicationFailure.html)
- Proto: [ApplicationFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ApplicationFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

### Errors in Workflows

An error in a Workflow can cause either a **Workflow Task Failure** (the Task will be retried) or a **Workflow Execution Failure** (the Workflow is marked as failed).

Only Workflow exceptions that are Temporal Failures cause the Workflow Execution to fail; all other exceptions cause the Workflow Task to fail and be retried (in Go, any error returned from the Workflow fails the Workflow Execution, and a panic fails the Workflow Task).
Most types of Temporal Failures are raised by the Temporal Service, like a [Cancelled Failure](#cancelled-failure) when the Workflow is Cancelled or an [Activity Failure](#activity-failure) when an Activity fails.
In contrast, you can explicitly fail the Workflow Execution by throwing an Application Failure (returning any error in Go) in Workflow Definition code.

#### Workflow Task Failures

A **Workflow Task Failure** is an unexpected situation failing to process a Workflow Task.
This could be triggered by a non-Temporal exception being raised (panicking in Go) in your Workflow code.
Any exception that does not extend Temporal's `FailureError` exception is considered a Workflow Task Failure.
These types of failures will cause the Workflow Task to be retried until the
Workflow Execution Timeout, which is unlimited by default.

#### Workflow Execution Failures

An `ApplicationError`, an extension of `FailureError`, can be raised in a Workflow to fail the Workflow Execution.
Workflow Execution Failures put the Workflow Execution into the "Failed" state and no more attempts will be made in progressing this execution.
If you are creating custom exceptions you would need to extend the [`ApplicationError`](https://docs.temporal.io/references/failures#application-failure) class—a child class of [`FailureError`](https://docs.temporal.io/references/failures#temporal-failure).

### Errors in Activities

In Activities, you can either throw an Application Failure or another Error to fail the Activity Task.
In the latter case, the error is converted to an Application Failure.
During conversion, the following Application Failure fields are set:

- `type` is set to the error's type name.
- `message` is set to the error message.
- `non_retryable` is set to false.
- `details` are left unset.
- `cause` is a Failure converted from the error's `cause` property.
- `next_retry_delay` is left unset.
- call stack is copied.

When an [Activity Execution](/activity-execution) fails, the Application Failure from the last Activity Task is the `cause` field of the [ActivityFailure](#activity-failure).
This ActivityFailure is thrown by the Workflow's call to the Activity, and it can be handled in the Workflow Definition.

### Errors in Nexus Operations

Nexus Operations can end up in completed, failed, canceled, and timed out states.

Under the hood, the Nexus Operation machinery breaks up the lifecycle of an Operation into one or more StartOperation requests and completion callbacks, and automatically retries these requests as long they fail with retryable errors.

The Workflow-specified schedule-to-close timeout is enforced by the caller's machinery and is the only way for an Operation to transition to the timed out state.

Operations can end up in the other three states either when the operation handler returns a synchronous response or error, or when an asynchronous Operation (for example, one backed by a workflow) eventually reaches a terminal state.

A Nexus Operation handler can return either retryable or non-retryable errors to indicate to the caller's Nexus machinery whether to retry a given request.
Requests that time out before a response is sent to the caller are automatically retried.

By default, errors are considered retryable, unless specified below:

- Non retryable Application Failures
- Unsuccessful Operation errors that can resolve an operation as either failed or canceled
- [Handler errors](https://github.com/nexus-rpc/api/blob/main/SPEC.md#predefined-handler-errors) with the following types: `BAD_REQUEST`, `UNAUTHENTICATED`, `UNAUTHORIZED`, `NOT_FOUND`, and `RESOURCE_EXHAUSTED`

#### Nexus Operation Task Failures

A Nexus Operation Task Failure is an unexpected situation failing to process a Nexus Operation Task in a handler.
This could be triggered by throwing an unknown error in your Nexus handler code.
These types of failures will cause the Nexus Operation Task to be retried.

#### Nexus Operation Execution Failures

A non-retryable Application Failure can be thrown by a Nexus Operation handler to fail the overall Nexus Operation Execution.
Nexus Operation Execution Failures put the Nexus Operation Execution into the "Failed" state and no more attempts will be made to complete the Nexus Operation.

#### Propagation of Workflow errors

Application Errors thrown from a Workflow created by a Nexus NewWorkflowRunOperation handler will be automatically propagated to the caller as a non-retryable error and result in a Nexus Operation Execution Failure.

#### Using Failures in a Nexus handler

In a Nexus Operation handler, you can throw an Application Failure, a Nexus Error or another Error to fail the individual Nexus Operation Task or fail the overall Nexus Operation Execution.

Unknown errors are converted to a retryable Application Failure. During conversion, the following fields are set on the Application Failure:

- `non_retryable` is set to false.
- `type` is set to the error's type name.
- `message` is set to the error message.

#### Retryable failures

Retryable Nexus Operation Task failures, such as an unknown error, are automatically retried with a built-in Retry Policy.
When a Nexus Task fails, the caller Workflow records an event attempt failure on the pending Nexus Operation and sets the following fields:

- `state` is set to the new state, for example BackingOff.
- `attempt` is set to an incremented count.
- `next_attempt_schedule_time` is set when the Nexus Task will be retried.
- `last_attempt_failure` is set with the following fields:
  - `message` is set to the error message.
  - `failure_info` is set to the Application Failure.

For example, an unknown error thrown in a Nexus handler will surface as:

```
temporal workflow describe -w my-workflow-id
...
Pending Nexus Operations: 1

  Endpoint                 myendpoint
  Service                  my-hello-service
  Operation                echo
  OperationToken
  State                    BackingOff
  Attempt                  6
  ScheduleToCloseTimeout   0s
  NextAttemptScheduleTime  20 seconds from now
  LastAttemptCompleteTime  11 seconds ago
  LastAttemptFailure       {"message":"unexpected response status: "500 Internal Server Error": internal error","applicationFailureInfo":{}}
```

### Non-retryable

When an Activity or Workflow throws an Application Failure, the Failure's `type` field is matched against a Retry Policy's list of [non-retryable errors](/encyclopedia/retry-policies#non-retryable-errors) to determine whether to retry the Activity or Workflow.
Activities and Workflow can also avoid retrying by setting an Application Failure's `non_retryable` flag to `true`.

When a Nexus Operation handler throws an Application Failure, it is retried by default using a built-in Retry Policy that cannot be customized.
Nexus Operation handlers can avoid retrying by setting an Application Failure's `non_retryable` flag to true.
When a non-retryable error is returned from a Nexus handler, the overall Nexus Operation Execution is failed and the error is returned to the caller’s Workflow Execution as a Nexus Operation Failure.

### Setting the Next Retry Delay {#activity-next-retry-delay}

By setting the Next Retry Delay for a given Application Failure, you can tell the server to wait that amount of time before trying the Activity or Workflow again.
This will override whatever the Retry Policy would have computed for your specific exception.

Java: [NextRetryDelay](/develop/java/failure-detection#activity-next-retry-delay)
TypeScript: [nextRetryDelay](/develop/typescript/failure-detection#activity-next-retry-delay)
PHP: [NextRetryDelay](/develop/php/failure-detection#activity-next-retry-delay)

### Nexus errors {#nexus-errors}

#### Default mapping

By default, Application Failures thrown from a Nexus Operation handler will be mapped to the following underlying Nexus Failures, based on what `non_retryable` is set to:

| `non_retryable` | Nexus error                | HTTP status code          |
| :-------------- | :------------------------- | :------------------------ |
| false (default) | HandlerErrorTypeInternal   | 500 Internal Server Error |
| true            | UnsuccessfulOperationError | 424 Failed Dependency     |

#### Use Nexus Errors directly

For improved semantics and mapping to HTTP status codes for external Nexus callers (when supported), we recommend that Nexus Operation handlers throw a Nexus Error directly, which includes the list below with associated retry semantics.

For example the Nexus Go SDK provides

- `nexus.HandlerError(nexus.HandlerErrorType, msg)`
- `nexus.UnsuccessfulOperationError{state, failure}`

#### Retryable Nexus errors

| Nexus error type                  | `non_retryable` |
| :-------------------------------- | :-------------- |
| HandlerErrorTypeResourceExhausted | false           |
| HandlerErrorTypeInternal          | false           |
| HandlerErrorTypeNotImplemented    | false           |
| HandlerErrorTypeUnavailable       | false           |

#### Non-retryable Nexus errors

| Nexus error type                | `non_retryable` |
| :------------------------------ | :-------------- |
| HandlerErrorTypeBadRequest      | true            |
| HandlerErrorTypeUnauthenticated | true            |
| HandlerErrorTypeUnauthorized    | true            |
| HandlerErrorTypeNotFound        | true            |
| UnsuccessfulOperationError      | true            |

## Cancelled Failure

When [Cancellation](/activity-execution#cancellation) of a Workflow, Activity or Nexus Operation is requested, SDKs represent the cancellation to the user in language-specific ways.
For example, in TypeScript, in some cases a Cancelled Failure is thrown directly by a Workflow API function, and in other cases the Cancelled Failure is wrapped in a different Failure.
To check both types of cases, TypeScript has the [isCancellation](https://typescript.temporal.io/api/namespaces/workflow#iscancellation) helper.

When a Workflow, Activity or Nexus Operation is successfully Cancelled, a Cancelled Failure is the `cause` field of the Activity Failure, Nexus Operation Failure or "Workflow failed" error.

- TypeScript: [CancelledFailure](https://typescript.temporal.io/api/classes/common.CancelledFailure)
- Java: [CanceledFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/CanceledFailure.html)
- Go: [CanceledError](https://pkg.go.dev/go.temporal.io/sdk/temporal#CanceledError)
- Python: [CancelledError](https://python.temporal.io/temporalio.exceptions.CancelledError.html)
- PHP: [CanceledFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-CanceledFailure.html)
- Proto: [CanceledFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.CanceledFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Activity Failure

An Activity Failure is delivered to the Workflow Execution when an Activity fails.
It contains information about the failure and the Activity Execution; for example, the Activity Type and Activity Id.
The reason for the failure is in the `cause` field.
For example, if an Activity Execution times out, the `cause` is a [Timeout Failure](#timeout-failure).

- TypeScript: [ActivityFailure](https://typescript.temporal.io/api/classes/common.ActivityFailure)
- Java: [ActivityFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ActivityFailure.html)
- Go: [ActivityError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ActivityError)
- Python: [ActivityError](https://python.temporal.io/temporalio.exceptions.ActivityError.html)
- PHP: [ActivityFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ActivityFailure.html)
- Proto: [ActivityFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ActivityFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Nexus Operation Failure

A Nexus Operation Failure is delivered to the Workflow Execution when a Nexus Operation fails.
It contains information about the failure and the Nexus Operation Execution; for example, the Nexus Operation name and Nexus Operation token.
The reason for the failure is in the message and cause (typically an Application Error or a Canceled Error).

- Go: NexusOperationError
- Proto: NexusOperationFailureInfo

A Nexus Operation Failure includes the following fields:

- Endpoint is set to the name of the endpoint.
- Service is set to the name of the service.
- Operation is set to the name of the operation.
- Operation_token is set if this is an async operation, which can be used to perform additional actions like cancelling the operation.
- Scheduled_event_id is set to the caller’s event id that scheduled the operation.
- Message is set to a generic unsuccessful error message.
- Cause is set to the underlying Application Failure with the following fields:
  - Non-retryable is set to true.
  - Type is set to the error's type name.
  - Message is set to the error message.
- Nexus_error_code is set the the underlying Nexus error code.

## Child Workflow Failure

A Child Workflow Failure is delivered to the Workflow Execution when a Child Workflow Execution fails.
It contains information about the failure and the Child Workflow Execution; for example, the Workflow Type and Workflow Id.
The reason for the failure is in the `cause` field.

- TypeScript: [ChildWorkflowFailure](https://typescript.temporal.io/api/classes/common.ChildWorkflowFailure)
- Java: [ChildWorkflowFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ChildWorkflowFailure.html)
- Go: [ChildWorkflowExecutionError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ChildWorkflowExecutionError)
- Python: [ChildWorkflowError](https://python.temporal.io/temporalio.exceptions.ChildWorkflowError.html)
- PHP: [ChildWorkflowFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ChildWorkflowFailure.html)
- Proto: [ChildWorkflowExecutionFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ChildWorkflowExecutionFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Timeout Failure

A Timeout Failure represents the timeout of an Activity or Workflow.

When an Activity times out, the last Heartbeat details it emitted is attached.

- TypeScript: [TimeoutFailure](https://typescript.temporal.io/api/classes/common.TimeoutFailure)
- Java: [TimeoutFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/TimeoutFailure.html)
- Go: [TimeoutError](https://pkg.go.dev/go.temporal.io/sdk/temporal#TimeoutError)
- Python: [TimeoutError](https://python.temporal.io/temporalio.exceptions.TimeoutError.html)
- PHP: [TimeoutFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-TimeoutFailure.html)
- Proto: [TimeoutFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.TimeoutFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Terminated Failure

A Terminated Failure is used as the `cause` of an error when a Workflow is terminated, and you receive the error in one of the following locations:

- Inside a Workflow that's waiting for the result of a Child Workflow.
- When waiting for the result of a Workflow on the Client.

In the SDKs:

- TypeScript: [TerminatedFailure](https://typescript.temporal.io/api/classes/common.TerminatedFailure)
- Java: [TerminatedFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/TerminatedFailure.html)
- Go: [TerminatedError](https://pkg.go.dev/go.temporal.io/sdk/temporal#TerminatedError)
- Python: [TerminatedError](https://python.temporal.io/temporalio.exceptions.TerminatedError.html)
- PHP: [TerminatedFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-TerminatedFailure.html)
- Proto: [TerminatedFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.TerminatedFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

## Server Failure

A Server Failure is used for errors that originate in the Temporal Service.

- TypeScript: [ServerFailure](https://typescript.temporal.io/api/classes/common.ServerFailure)
- Java: [ServerFailure](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/failure/ServerFailure.html)
- Go: [ServerError](https://pkg.go.dev/go.temporal.io/sdk/temporal#ServerError)
- Python: [ServerError](https://python.temporal.io/temporalio.exceptions.ServerError.html)
- PHP: [ServerFailure](https://php.temporal.io/classes/Temporal-Exception-Failure-ServerFailure.html)
- Proto: [ServerFailureInfo](https://api-docs.temporal.io/#temporal.api.failure.v1.ServerFailureInfo) and [Failure](https://api-docs.temporal.io/#temporal.api.failure.v1.Failure)

---

## Temporal Platform references

- [SDK metrics reference](/references/sdk-metrics)
- [Commands reference](/references/commands)
- [Events reference](/references/events)
- [Web UI environmental variables reference](/references/web-ui-environment-variables)
- [Temporal Service configuration reference](/references/configuration)
- [Temporal Web UI configuration reference](/references/web-ui-configuration)
- [Temporal Cloud Operation reference](/references/operation-list)
- [Go SDK API reference](https://pkg.go.dev/go.temporal.io/sdk)
- [Java SDK API reference](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/index.html)
- [Python SDK API reference](https://python.temporal.io/)
- [TypeScript SDK API reference](https://typescript.temporal.io)
- [.NET SDK API reference](https://dotnet.temporal.io/api/)
- [PHP SDK API reference](https://php.temporal.io/namespaces/temporal.html)
- [Glossary](/glossary)

---

## Operations


Temporal Cloud [rate limits operations per second (OPS)](/cloud/limits#operations-per-second) per namespace. An operation is anything 1. a user does directly, or 2. Temporal does on behalf of the user in the background that results in load on Temporal Server. The exception is visibility queries: they do hit the Server (the query is passed from the server to the visibility store), but primarily the load is on the visibility system. Visibility rate limits are separate from OPS rate limits.

Below is the list of operations, including:
- operation name
- description
- priority (foreground is higher priority, background is lower priority)
- effect of that operation being throttled

<OperationsTable />

---

## Temporal SDK metrics reference

:::info SDK metrics

The information on this page is relevant to [Temporal SDKs](/encyclopedia/temporal-sdks).

See [Cloud metrics](/cloud/metrics/) for metrics emitted by [Temporal Cloud](/cloud/overview).

See [Cluster metrics](/references/cluster-metrics) for metrics emitted by the [OSS Cluster](/temporal-service).

Some SDKs may emit metrics beyond what is listed in this SDK Metrics reference.
Only metrics included in this Metrics reference have guaranteed, defined behavior.
Other metrics are considered deprecated, inconsistent or experimental.

:::

The Temporal SDKs emit a set of metrics from Temporal Client usage and Worker Processes.

- [How to emit metrics using the Go SDK](/develop/go/observability#metrics)
- [How to emit metrics using the Java SDK](/develop/java/observability#metrics)
- [How to emit metrics using the Python SDK](/develop/python/observability#metrics)
- [How to emit metrics using the TypeScript SDK](/develop/typescript/observability#metrics)
- [How to emit metrics using the .NET SDK](/develop/dotnet/observability#metrics)

- [How to tune Worker performance based on metrics](/develop/worker-performance)

All metrics are prefixed with `temporal_` before being exported to their configured destination.
(The prefix has been removed in parts of this reference.)
Currently, some metrics are specific to certain SDKs.

TypeScript, Python, .NET, and Ruby SDK metrics are defined in the Core SDK.

PHP and Go metrics are defined in the Go SDK.

Java metrics are defined in the Java SDK.
Metrics are defined in the following locations.

- [Core SDK Worker metrics](https://github.com/temporalio/sdk-core/blob/master/core/src/telemetry/metrics.rs)
- [Core SDK Client metrics](https://github.com/temporalio/sdk-core/blob/master/client/src/metrics.rs)
- [Java SDK Worker metrics](https://github.com/temporalio/sdk-java/blob/master/temporal-sdk/src/main/java/io/temporal/worker/MetricsType.java)
- [Java SDK Client metrics](https://github.com/temporalio/sdk-java/blob/master/temporal-serviceclient/src/main/java/io/temporal/serviceclient/MetricsType.java)
- [Go SDK Worker and Client metrics](https://github.com/temporalio/sdk-go/blob/c32b04729cc7691f80c16f80eed7f323ee5ce24f/internal/common/metrics/constants.go)

:::note Metric units across SDKs

The unit of measurement for metrics can vary based on which SDK they are being reported from:

**Core-based SDKs:** Metrics of the type Histogram are measured in _milliseconds_ by default.
This can be customized to use seconds for SDKs using [Core SDK](/glossary#core-sdk).
The Core SDK is a shared common core library used by several Temporal SDKs, including TypeScript, Python, and .NET.

**Java and Go SDKs:** Metrics of the type Histogram are measured in _seconds_.

:::

Each metric may have some combination of the following keys attached to them:

- `task-queue`: Task Queue that the Worker Entity is polling
- `namespace`: Namespace the Worker is bound to
- `poller_type`: One of the following:
  - `workflow_task`
  - `activity_task`
  - `nexus_task` (Go and Java only)
  - `sticky_workflow_task`
- `worker_type`: One of the following:
  - `ActivityWorker`
  - `WorkflowWorker`
  - `LocalActivityWorker` (Go and Java only)
  - `NexusWorker` (Go and Java only)
- `activity_type`: The name of the Activity Function the metric is associated with
- `workflow_type`: The name of the Workflow Function the metric is associated with
- `operation`: RPC method name; available for metrics related to Temporal Client gRPC requests

Some keys may not be available in every SDK, and Histogram metrics may have different buckets in each SDK.

| Metric name                                                                                      | Emitted by     | Metric type | Availability   |
| ------------------------------------------------------------------------------------------------ | -------------- | ----------- | -------------- |
| [temporal_activity_execution_cancelled](#activity_execution_cancelled)                           | Worker         | Counter     | Java           |
| [temporal_activity_execution_failed](#activity_execution_failed)                                 | Worker         | Counter     | Core, Go, Java |
| [temporal_activity_execution_latency](#activity_execution_latency)                               | Worker         | Histogram   | Core, Go, Java |
| [temporal_activity_poll_no_task](#activity_poll_no_task)                                         | Worker         | Counter     | Core, Go, Java |
| [temporal_activity_schedule_to_start_latency](#activity_schedule_to_start_latency)               | Worker         | Histogram   | Core, Go, Java |
| [temporal_activity_succeed_endtoend_latency](#activity_succeed_endtoend_latency)                 | Worker         | Histogram   | Core, Go, Java |
| [temporal_activity_task_error](#activity_task_error)                                             | Worker         | Counter     | Go             |
| [temporal_corrupted_signals](#corrupted_signals)                                                 | Worker         | Counter     | Go, Java       |
| [temporal_local_activity_execution_cancelled](#local_activity_execution_cancelled)               | Worker         | Counter     | Core, Go, Java |
| [temporal_local_activity_execution_failed](#local_activity_execution_failed)                     | Worker         | Counter     | Core, Go, Java |
| [temporal_local_activity_execution_latency](#local_activity_execution_latency)                   | Worker         | Histogram   | Core, Go, Java |
| [temporal_local_activity_succeeded_endtoend_latency](#local_activity_succeeded_endtoend_latency) | Worker         | Histogram   | Core, Go, Java |
| [temporal_local_activity_total](#local_activity_total)                                           | Worker         | Counter     | Core, Go, Java |
| [temporal_long_request](#long_request)                                                           | Service Client | Counter     | Core, Go, Java |
| [temporal_long_request_failure](#long_request_failure)                                           | Service Client | Counter     | Core, Go, Java |
| [temporal_long_request_latency](#long_request_latency)                                           | Service Client | Histogram   | Core, Go, Java |
| [temporal_num_pollers](#num_pollers)                                                             | Worker         | Gauge       | Core, Go       |
| [temporal_poller_start](#poller_start)                                                           | Worker         | Counter     | Go, Java       |
| [temporal_request](#request)                                                                     | Service Client | Counter     | Core, Go, Java |
| [temporal_request_failure](#request_failure)                                                     | Service Client | Counter     | Core, Go, Java |
| [temporal_request_latency](#request_latency)                                                     | Service Client | Histogram   | Core, Go, Java |
| [temporal_sticky_cache_hit](#sticky_cache_hit)                                                   | Worker         | Counter     | Core, Go, Java |
| [temporal_sticky_cache_miss](#sticky_cache_miss)                                                 | Worker         | Counter     | Core, Go, Java |
| [temporal_sticky_cache_size](#sticky_cache_size)                                                 | Worker         | Gauge       | Core, Go, Java |
| [temporal_sticky_cache_total_forced_eviction](#sticky_cache_total_forced_eviction)               | Worker         | Counter     | Go, Java       |
| [temporal_unregistered_activity_invocation](#unregistered_activity_invocation)                   | Worker         | Counter     | Go             |
| [temporal_worker_start](#worker_start)                                                           | Worker         | Counter     | Core, Go, Java |
| [temporal_worker_task_slots_available](#worker_task_slots_available)                             | Worker         | Gauge       | Core, Go, Java |
| [temporal_worker_task_slots_used](#worker_task_slots_used)                                       | Worker         | Gauge       | Core, Go, Java |
| [temporal_workflow_active_thread_count](#workflow_active_thread_count)                           | Worker         | Gauge       | Java           |
| [temporal_workflow_cancelled](#workflow_cancelled)                                               | Worker         | Counter     | Core, Go, Java |
| [temporal_workflow_completed](#workflow_completed)                                               | Worker         | Counter     | Core, Go, Java |
| [temporal_workflow_continue_as_new](#workflow_continue_as_new)                                   | Worker         | Counter     | Core, Go, Java |
| [temporal_workflow_endtoend_latency](#workflow_endtoend_latency)                                 | Worker         | Histogram   | Core, Go, Java |
| [temporal_workflow_failed](#workflow_failed)                                                     | Worker         | Counter     | Core, Go, Java |
| [temporal_workflow_task_execution_failed](#workflow_task_execution_failed)                       | Worker         | Counter     | Core, Go, Java |
| [temporal_workflow_task_execution_latency](#workflow_task_execution_latency)                     | Worker         | Histogram   | Core, Go, Java |
| [temporal_workflow_task_queue_poll_empty](#workflow_task_queue_poll_empty)                       | Worker         | Counter     | Core, Go, Java |
| [temporal_workflow_task_queue_poll_succeed](#workflow_task_queue_poll_succeed)                   | Worker         | Counter     | Core, Go, Java |
| [temporal_workflow_task_replay_latency](#workflow_task_replay_latency)                           | Worker         | Histogram   | Core, Go, Java |
| [temporal_workflow_task_schedule_to_start_latency](#workflow_task_schedule_to_start_latency)     | Worker         | Histogram   | Core, Go, Java |
| [temporal_nexus_poll_no_task](#nexus_poll_no_task)                                               | Worker         | Counter     | Go, Java       |
| [temporal_nexus_task_schedule_to_start_latency](#nexus_task_schedule_to_start_latency)           | Worker         | Histogram   | Go, Java       |
| [temporal_nexus_task_execution_failed](#nexus_task_execution_failed)                             | Worker         | Counter     | Go, Java       |
| [temporal_nexus_task_execution_latency](#nexus_task_execution_latency)                           | Worker         | Histogram   | Go, Java       |
| [temporal_nexus_task_endtoend_latency](#nexus_task_endtoend_latency)                             | Worker         | Histogram   | Go, Java       |

### activity_execution_cancelled

An Activity Execution was canceled.

- Type: Counter
- Available in: Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_execution_failed

An Activity Execution failed.
This does not include local Activity Failures in the Go and Java SDKs (see [local_activity_execution_failed](#local_activity_execution_failed)).

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_execution_latency

Time to complete an Activity Execution, from the time the Activity Task is generated to the time the language SDK responded with a completion (failure or success).

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_poll_no_task

An Activity Worker poll for an Activity Task timed out, and no Activity Task is available to pick from the Task Queue.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### activity_schedule_to_start_latency

The Schedule-To-Start time of an Activity Task in seconds.
A [Schedule-To-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout) can be set when an Activity Execution is spawned.
This metric is useful for ensuring Activity Tasks are being processed from the queue in a timely manner. Some SDKs may include
the `activity_type` label, but the metric should not vary by type, as it does not influence the rate at which tasks are pulled
from the queue.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### activity_succeed_endtoend_latency

Total latency of successfully finished Activity Executions from the time they are scheduled to the time they are completed.
This metric is not recorded for async Activity completion.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### activity_task_error

An internal error or panic occurred during Activity Task handling or execution.

- Type: Counter
- Available in: Go,
- Tags: `activity_type`, `namespace`, `task_queue`, `workflow_type`

### corrupted_signals

Number of Signals whose payload could not be deserialized.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### local_activity_execution_cancelled

A Local Activity Execution was canceled.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_execution_failed

A Local Activity Execution failed.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_execution_latency

Time to complete a Local Activity Execution, from the time the first Activity Task is generated to the time the SDK responds that the execution is complete.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_succeeded_endtoend_latency

Total latency of successfully finished Local Activity Executions (from schedule to completion).

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### local_activity_total

Total number of [Local Activity Executions](/local-activity).

- Type: Counter
- Available in: Core, Go, Java
- Tags: `activity_type`, `namespace`, `task_queue`

### long_request

Temporal Client made an RPC long poll request.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### long_request_failure

Temporal Client made an RPC long poll request that failed.
This number is included into the total `long_request` counter for long poll RPC requests.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### long_request_latency

Latency of a Temporal Client gRPC long poll request.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### num_pollers

Current number of Worker Entities that are polling.

- Type: Gauge
- Available in: Core, Go, Java
- Tags: `namespace`, `poller_type`, `task_queue`

### poller_start

A Worker Entity poller was started.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`

### request

Temporal Client made an RPC request.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### request_failure

Temporal Client made an RPC request that failed.
This number is included into the total `request` counter for RPC requests.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### request_latency

Latency of a Temporal Client gRPC request.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `operation`

### sticky_cache_hit

A Workflow Task found a cached Workflow Execution to run against.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### sticky_cache_miss

A Workflow Task did not find a cached Workflow execution to run against.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### sticky_cache_size

Current cache size, expressed in number of Workflow Executions.

- Type: Gauge
- Available in: Core, Go, Java
- Tags: `namespace` (TypeScript, Java), `task_queue` (TypeScript)

### sticky_cache_total_forced_eviction

A Workflow Execution has been forced from the cache intentionally.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`

### unregistered_activity_invocation

A request to spawn an Activity Execution is not registered with the Worker.

- Type: Counter
- Available in: Go,
- Tags: `activity_type`, `namespace`, `task_queue`, `workflow_type`

### worker_start

A Worker Entity has been registered, created, or started.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `worker_type`

### worker_task_slots_available

The total number of Workflow, Activity, Local Activity, or Nexus Task execution slots that are currently available.
Use the `worker_type` key to differentiate execution slots.
The Worker type specifies an ability to perform certain tasks.
For example, Workflow Workers execute Workflow Tasks, Activity Workers execute Activity Tasks, and so forth.

- Type: Gauge
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `worker_type`

### worker_task_slots_used

The total number of Workflow, Activity, Local Activity, or Nexus Tasks execution slots in current use.
Use the `worker_type` key to differentiate execution slots.
The Worker type specifies an ability to perform certain tasks.
For example, Workflow Workers execute Workflow Tasks, Activity Workers execute Activity Tasks, and so forth.

- Type: Gauge
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `worker_type`

### workflow_active_thread_count

Total amount of Workflow threads in the Worker Process.

- Type: Gauge
- Available in: Java

### workflow_cancelled

Workflow Execution ended because of a cancellation request.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_completed

A Workflow Execution completed successfully.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_continue_as_new

A Workflow ended with Continue-As-New.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_endtoend_latency

Total Workflow Execution time from schedule to completion for a single Workflow Run. (A retried Workflow Execution is a separate Run.)

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_failed

A Workflow Execution failed.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_task_execution_failed

A Workflow Task Execution failed.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`, `failure_reason`

Valid values for the `failure_reason` tag:

- `NonDeterminismError`: The Workflow Task failed due to a non-determinim error.
- `WorkflowError`: The Workflow Task failed for any other reason.

### workflow_task_execution_latency

Workflow Task Execution time.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_task_queue_poll_empty

A Workflow Worker polled a Task Queue and timed out without picking up a Workflow Task.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### workflow_task_queue_poll_succeed

A Workflow Worker polled a Task Queue and successfully picked up a Workflow Task.

- Type: Counter
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### workflow_task_replay_latency

Time to catch up on replaying a Workflow Task.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`, `workflow_type`

### workflow_task_schedule_to_start_latency

The Schedule-To-Start time of a Workflow Task.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### nexus_poll_no_task

A Nexus Worker poll for a Nexus Task timed out, and no Nexus Task is available to pick from the Task Queue.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`

### nexus_task_schedule_to_start_latency

The Schedule-To-Start time of a Nexus Task in seconds. The schedule time is taken from when the corresponding request
hit the Frontend service to when the SDK started processing the task.

This time is limited by the `Request-Timeout` header given to the Frontend when handling this request.

- Type: Histogram
- Available in: Core, Go, Java
- Tags: `namespace`, `task_queue`

### nexus_task_execution_failed

Handling of a Nexus Task resulted in an error. This includes any error returned from a user handler and unexpected
internal errors in the SDK.

- Type: Counter
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `nexus_service`, `nexus_operation`, `failure_reason`

Valid values for the `failure_reason` tag:

- `internal_sdk_error`: There was an unexpected internal error within the SDK while handling the Nexus task. Indicates a
  bug in the SDK.
- `handler_error_{TYPE}`: The user handler code returned a predefined error, as specified in the [Nexus spec](https://github.com/nexus-rpc/api/blob/main/SPEC.md#predefined-handler-errors).
  If the handler returns an unexpected error, the TYPE is set to `INTERNAL`.
- `timeout`: The user handler code did not return within the request timeout.
- `operation_failed`: The user handler code has indicated that the operation has failed. In Go, this maps to an
  `UnsuccessfulOperationError` with a `failed` state.
- `operation_canceled`: The user handler code has indicated that the operation has completed as canceled. In Go, this maps
  to an `UnsuccessfulOperationError` with a `canceled` state.

### nexus_task_execution_latency

Time to complete a Nexus Task, from the time the Nexus Task processing starts in the SDK to the time the user handler
completes.

- Type: Histogram
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `nexus_service`, `nexus_operation`

### nexus_task_endtoend_latency

Total latency of Nexus Tasks from the time the corresponding request hit the Frontend to after the SDK gets
acknowledgment from the server for task completion.

- Type: Histogram
- Available in: Go, Java
- Tags: `namespace`, `task_queue`, `nexus_service`, `nexus_operation`

---

## Temporal Server options reference

You can run the [Temporal Server](/temporal-service/temporal-server) as a Go application by including the server package `go.temporal.io/server/temporal` and using it to create and start a Temporal Server.

The Temporal Server services can be run in various ways.
We recommend this approach for a limited number of situations.

```go
s, err := temporal.NewServer()
if err != nil {
	log.Fatal(err)
}
err = s.Start()
if err != nil{
	log.Fatal(err)
}
```

`NewServer()` accepts functions as parameters.
Each function returns a `ServerOption` that is applied to the instance.
Source code for parameter reference is here: https://github.com/temporalio/temporal/blob/main/temporal/server_option.go

### WithConfig

To launch a Temporal server, a configuration file is required. The server automatically searches for this configuration
in the default location ./config/development.yaml when starting. If you need to use a custom configuration, you can
specify it through the server's configuration option. For comprehensive details about configuration parameters and
structure, refer to the [official configuration documentation](https://pkg.go.dev/go.temporal.io/server/common/config).

```go
s, err := temporal.NewServer(
	temporal.WithConfig(cfg),
)
```

### WithConfigLoader

Load a custom configuration from a file.

```go
s, err := temporal.NewServer(
	temporal.WithConfigLoader(configDir, env, zone),
)
```

### ForServices

Sets the list of all valid temporal services.
The default can be used from the `go.temporal.io/server/temporal` package.

```go
s, err := temporal.NewServer(
	temporal.ForServices(temporal.Services),
)
```

### InterruptOn

This option provides a channel that interrupts the server on the signal from that channel.

- If `temporal.InterruptOn()` is not passed, `server.Start()` is never blocked and you need to call `server.Stop()` somewhere.
- If `temporal.InterruptOn(nil)` is passed, `server.Start()` blocks forever until the process is killed.
- If `temporal.InterruptOn(temporal.InterruptCh())` is passed, `server.Start()` blocks until you use Ctrl+C, which then gracefully shuts the server down.
- If `temporal.Interrupt(someCustomChan)` is passed, `server.Start()` blocks until a signal is sent to `someCustomChan`.

```go
s, err := temporal.NewServer(
	temporal.InterruptOn(temporal.InterruptCh()),
)
```

### WithAuthorizer

Sets a low level [authorization mechanism](/self-hosted-guide/security#authorizer-plugin) that determines whether to allow or deny inbound API calls.

```go
s, err := temporal.NewServer(
	temporal.WithAuthorizer(myAuthorizer),
)
```

### WithTLSConfigFactory

Overrides the default TLS configuration provider.
`TLSConfigProvider` is defined in the `go.temporal.io/server/common/rpc/encryption` package.

```go
s, err := temporal.NewServer(
	temporal.WithTLSConfigFactory(yourTLSConfigProvider),
)
```

### WithClaimMapper

Configures a [mechanism to map roles](/self-hosted-guide/security#claim-mapper) to `Claims` for authorization.

```go
s, err := temporal.NewServer(
  temporal.WithClaimMapper(func(cfg *config.Config) authorization.ClaimMapper {
  		logger := getYourLogger() // Replace with how you retrieve or initialize your logger
		return authorization.NewDefaultJWTClaimMapper(
			authorization.NewDefaultTokenKeyProvider(cfg, logger),
			cfg
		)
	}),
)
```

### WithCustomMetricsReporter

Sets a custom tally metric reporter.

```go
s, err := temporal.NewServer(
	temporal.WithCustomMetricsReporter(myReporter),
)
```

You can see the [Uber tally docs on custom reporter](https://github.com/uber-go/tally#report-your-metrics) and see a community implementation of [a reporter for Datadog's `dogstatsd` format](https://github.com/temporalio/temporal/pull/998#issuecomment-857884983).

---

## Temporal Web UI configuration reference

The Temporal Web UI Server uses a configuration file for many of the UI's settings.

An example development.yaml file can be found in the [temporalio/ui-server repo](https://github.com/temporalio/ui-server/blob/main/config/development.yaml).

Multiple configuration files can be created for configuring specific areas of the UI, such as Auth or TLS.

## auth

Configures authorization for the Temporal Server.
Settings apply when Auth is enabled.

```yaml
auth:
  enabled: true
  providers:
    label: sso # for internal use; in future may expose as button text
    type: oidc
    providerUrl: https://accounts.google.com
    issuerUrl:
    clientId: xxxxx-xxxx.apps.googleusercontent.com
    clientSecret: xxxxxxxxxxxxxxxxxxxx
    callbackUrl: https://xxxx.com:8080/auth/sso/callback
    scopes:
      - openid
      - profile
      - email
```

## batchActionsDisabled

Prevents the execution of Batch actions.

```yaml
batchActionsDisabled: false
```

## cloudUi

Enables the Cloud UI.

```yaml
cloudUi: false
```

## codec

Codec Server configuration.

```yaml
codec:
  endpoint: http://your-codec-server-endpoint
  passAccessToken: false
  includeCredentials: false
  decodeEventHistoryDownload: false
```

## cors

The name of the `cors` field stands for Cross-Origin Resource Sharing.
Use this field to provide a list of domains that are authorized to access the UI Server APIs.

```yaml
cors:
  cookieInsecure: false
  allowOrigins:
    - http://localhost:3000 # used at development by https://github.com/temporalio/ui
```

## defaultNamespace

The default Namespace that the UI loads data for.
Defaults to `default`.

```yaml
defaultNamespace: default
```

## disableWriteActions

Prevents the user from executing Workflow Actions on the Web UI.

This option affects Bulk Actions for Recent Workflows as well as Workflow Actions on the Workflow Details page.

```yaml
disableWriteActions: false
```

:::note
`disableWriteActions` overrides the configuration values of each individual Workflow Action.
Setting this variable to `true` disables all Workflow Actions on the Web UI.
:::

## enableUi

Enables the browser UI.
This configuration can be set dynamically with the [TEMPORAL_UI_ENABLED](/references/web-ui-environment-variables#temporal_ui_enabled) environment variable.
If disabled—that is, set to `false`—the UI server APIs remain available.

```yaml
enableUi: true
```

## feedbackUrl

The URL to direct users to when they click on the Feedback button in the UI.
If not specified, it defaults to the UI's GitHub Issue page.

```yaml
feedbackUrl: https://github.com/temporalio/ui/issues/new/choose
```

## forwardHeaders

Configures headers for forwarding.

```yaml
forwardHeaders:
  -
```

## hideLogs

If enabled, disables any server logs from being printed to the console.

```yaml
hideLogs: true
```

## hideWorkflowQueryErrors

Hides any errors resulting from a Query to the Workflow.

```yaml
hideWorkflowQueryErrors: false
```

## notifyOnNewVersion

When enabled—that is, when set to `true`—a notification appears in the UI when a newer version of the [Temporal Server](/temporal-service/temporal-server) is available.

```yaml
notifyOnNewVersion: true
```

## port

The port used by the Temporal Web UI Server and any APIs.

```yaml
port: 8080
```

## publicPath

The path used by the Temporal Web UI Server and any APIs.

```yaml
publicPath: ''
```

## refreshInterval

How often the configuration UI Server reads the configuration file for new values.
Currently, only [tls](#tls) configuration values are propagated during a refresh.

```yaml
refreshInterval: 1m
```

## showTemporalSystemNamespace

When enabled—that is, when set to `true`—the Temporal System Namespace becomes visible in the UI.
The Temporal System Namespace lists Workflow Executions used by the Temporal Platform.

```yaml
showTemporalSystemNamespace: false
```

## temporalGrpcAddress

The frontend address for the Temporal Cluster.

The default address is localhost (127.0.0.1:7233).

```yaml
temporalGrpcAddress: default
```

## tls

Transport Layer Security (TLS) configuration for the Temporal Server.
Settings apply when TLS is enabled.

```yaml
tls:
  caFile: ../ca.cert
  certFile: ../cluster.pem
  keyFile: ../cluster.key
  caData:
  certData:
  keyData:
  enableHostVerification: true
  serverName: tls-server
```

## workflowCancelDisabled

Prevents the user from canceling Workflow Executions from the Web UI.

```yaml
workflowCancelDisabled: false
```

## workflowResetDisabled

Prevents the user from resetting Workflows from the Web UI.

```yaml
workflowResetDisabled: false
```

## workflowSignalDisabled

Prevents the user from signaling Workflow Executions from the Web UI.

```yaml
workflowSignalDisabled: false
```

## workflowTerminateDisabled

Prevents the user from terminating Workflow Executions from the Web UI.

```yaml
workflowTerminateDisabled: false
```

---

## Temporal Web UI environment variables reference

You can use environment variables to dynamically alter the configuration of your Temporal Web UI.

These can be used in many environments, such as with Docker.
For example:

```
docker run\
-e TEMPORAL_ADDRESS=127.0.0.1:7233\
-e TEMPORAL_UI_PORT=8080\
-e TEMPORAL_UI_PUBLIC_PATH=path/to/webui\
-e TEMPORAL_UI_ENABLED=true\
-e TEMPORAL_BANNER_TEXT="Some banner text"\
-e TEMPORAL_CLOUD_UI=false\
-e TEMPORAL_DEFAULT_NAMESPACE=default\
-e TEMPORAL_FEEDBACK_URL=https://feedback.here\
-e TEMPORAL_NOTIFY_ON_NEW_VERSION=true\
-e TEMPORAL_CONFIG_REFRESH_INTERVAL=0s\
-e TEMPORAL_SHOW_TEMPORAL_SYSTEM_NAMESPACE=false\
-e TEMPORAL_DISABLE_WRITE_ACTIONS=false\
-e TEMPORAL_AUTH_ENABLED=true\
-e TEMPORAL_AUTH_TYPE=oidc\
-e TEMPORAL_AUTH_PROVIDER_URL=https://accounts.google.com\
-e TEMPORAL_AUTH_ISSUER_URL=https://accounts.google.com\
-e TEMPORAL_AUTH_CLIENT_ID=xxxxx-xxxx.apps.googleusercontent.com\
-e TEMPORAL_AUTH_CLIENT_SECRET=xxxxxxxxxxxxxxx\
-e TEMPORAL_AUTH_CALLBACK_URL=https://xxxx.com:8080/auth/sso/callback\
-e TEMPORAL_AUTH_SCOPES=openid,email,profile\
-e TEMPORAL_TLS_CA=../ca.cert\
-e TEMPORAL_TLS_CERT=../cluster.pem\
-e TEMPORAL_TLS_KEY=../cluster.key\
-e TEMPORAL_TLS_ENABLE_HOST_VERIFICATION=true\
-e TEMPORAL_TLS_SERVER_NAME=tls-server\
-e TEMPORAL_CODEC_ENDPOINT=https://codec.server\
-e TEMPORAL_CODEC_PASS_ACCESS_TOKEN=false\
-e TEMPORAL_CODEC_INCLUDE_CREDENTIALS=false\
-e TEMPORAL_HIDE_LOGS=false\
temporalio/ui:<tag>
```

The environment variables are defined in the [UI server configuration template file](https://github.com/temporalio/ui-server/blob/main/docker/config-template.yaml) and described in more detail below.

## `TEMPORAL_ADDRESS`

The [Frontend Service](/temporal-service/temporal-server#frontend-service) address for the Temporal Cluster.
This environmental variable can be set [in the base configuration file](/references/web-ui-configuration#temporalgrpcaddress) using `temporalGrpcAddress`.

This variable is required for setting other environmental variables.

## `TEMPORAL_UI_PORT`

The port used by the Temporal WebUI Server and the HTTP API.

This variable is needed for `TEMPORAL_OPENAPI_ENABLED` and all auth-related settings to work properly.

## `TEMPORAL_UI_PUBLIC_PATH`

Stores a value such as "" or "/custom-path" that allows the UI to be served from a subpath.

## `TEMPORAL_UI_ENABLED`

Enables or disables the [browser UI](/references/web-ui-configuration#enableui) for the Temporal Cluster.

Enabling the browser UI allows the Server to be accessed from your web browser.
If disabled, the server cannot be viewed on the web, but the UI server APIs remain available for use.

## `TEMPORAL_BANNER_TEXT`

Provides banner text to display on the Web UI.

## `TEMPORAL_CLOUD_UI`

If enabled, use the alternate UI from Temporal Cloud.

## `TEMPORAL_DEFAULT_NAMESPACE`

The default [Namespace](/namespaces) that the Web UI opens first.

## `TEMPORAL_FEEDBACK_URL`

The URL that users are directed to when they click the Feedback button in the UI.

If not specified, this variable defaults to the UI's GitHub Issue page.

## `TEMPORAL_NOTIFY_ON_NEW_VERSION`

Enables or disables notifications that appear in the UI whenever a newer version of the Temporal Cluster is available.

## `TEMPORAL_CONFIG_REFRESH_INTERVAL`

Determines how often the UI Server reads the configuration file for new values.

## `TEMPORAL_SHOW_TEMPORAL_SYSTEM_NAMESPACE`

If enabled, shows the System Namespace that handles internal Temporal Workflows in the Web UI.

## `TEMPORAL_DISABLE_WRITE_ACTIONS`

Disables any button in the UI that allows the user to modify Workflows or Activities.

## `TEMPORAL_AUTH_ENABLED`

Enables or disables Web UI authentication and authorization methods.

When enabled, the Web UI will use the provider information in the [UI configuration file](/references/web-ui-configuration#auth) to verify the identity of users.

All auth-related variables can be defined when `TEMPORAL_AUTH_ENABLED` is set to "true".
Disabling the variable will retain given values.

## `TEMPORAL_AUTH_TYPE`

Specifies the type of authentication. Defaults to `oidc`.

## `TEMPORAL_AUTH_PROVIDER_URL`

The .well-known IDP discovery URL for authentication and authorization.

This can be set as in the UI server configuration with [auth](/references/web-ui-configuration#auth).

## `TEMPORAL_AUTH_ISSUER_URL`

The URL for the authentication or authorization issuer.

This value is only needed when the issuer differes from the auth provider URL.

## `TEMPORAL_AUTH_CLIENT_ID`

The client ID used for authentication or authorization.

This value is a required parameter.

## `TEMPORAL_AUTH_CLIENT_SECRET`

The client secret used for authentication and authorization.

Client Secrets are used by the oAuth Client for authentication.

## `TEMPORAL_AUTH_CALLBACK_URL`

The callback URL used by Temporal for authentication and authorization.

Callback URLs are invoked by IDP after user has finished authenticating in IDP.

## `TEMPORAL_AUTH_SCOPES`

Specifies a set of scopes for auth. Typically, this is `openid`, `profile`, `email`.

## `TEMPORAL_TLS_CA`

The path for the Transport Layer Security (TLS) Certificate Authority file.

In order to [configure TLS for your server](/references/web-ui-configuration#tls), you'll need a CA certificate issued by a trusted Certificate Authority.
Set this variable to properly locate and use the file.

## `TEMPORAL_TLS_CERT`

The path for the Transport Layer Security (TLS) Certificate.

In order to [configure TLS for your server](/references/web-ui-configuration#tls), you'll need a self-signed certificate.
Set the path to allow the environment to locate and use the certificate.

## `TEMPORAL_TLS_KEY`

The path for the Transport Layer Security (TLS) [key file](/references/web-ui-configuration#tls).

A key file is used to create private and public keys for encryption and signing.
Together, these keys are used to create certificates.

## `TEMPORAL_TLS_CA_DATA`

Stores the data for a TLS CA file.

This variable can be used instead of providing a path for `TEMPORAL_TLS_CA`.

## `TEMPORAL_TLS_CERT_DATA`

Stores the data for a TLS cert file.

This variable can be used instead of providing a path for `TEMPORAL_TLS_CERT`.

## `TEMPORAL_TLS_KEY_DATA`

Stores the data for a TLS key file.

This variable can be used instead of providing a path for `TEMPORAL_TLS_KEY`.

## `TEMPORAL_TLS_ENABLE_HOST_VERIFICATION`

Enables or disables [Transport Layer Security (TLS) host verification](/references/web-ui-configuration#tls).

When enabled, TLS checks the Host Server to ensure that files are being sent to and from the correct URL.

## `TEMPORAL_TLS_SERVER_NAME`

The server on which to operate [Transport Layer Security (TLS) protocols](/references/web-ui-configuration#tls).

TLS allows the current server to transmit encrypted files to other URLs without having to reveal itself.
Because of this, TLS operates a go-between server.

## `TEMPORAL_CODEC_ENDPOINT`

The endpoint for the [Codec Server](/codec-server), if configured.

## `TEMPORAL_CODEC_PASS_ACCESS_TOKEN`

Specifies whether to send a JWT access token as ‘authorization' header in requests with the Codec Server.

## `TEMPORAL_CODEC_INCLUDE_CREDENTIALS`

Specifies whether to include credentials along with requests to the Codec Server.

## `TEMPORAL_FORWARD_HEADERS`

Forward-specified HTTP headers to direct from HTTP API requests to the Temporal gRPC backend.

## `TEMPORAL_HIDE_LOGS`

If enabled, does not print logs from the Temporal Service.

---

## Temporal Platform security

:::info Temporal Technologies' general company security

For information about the general security habits of Temporal Technologies, see our [trust page](https://trust.temporal.io).

:::

:::info Temporal Cloud (SaaS) security

For information about the security features of our SaaS offering, Temporal Cloud, see our [Cloud security page](/cloud/security).

:::

:::info Self-hosted security

For information about how to self-host a secure Temporal Platform, see the [Self-hosted security page](/self-hosted-guide/security).

:::

---

## Troubleshoot the blob size limit error

The `BlobSizeLimitError` is an error that occurs when the size of a blob (payloads including Workflow context and each Workflow and Activity argument and return value) exceeds the set limit in Temporal.

- The max payload for a single request is 2 MB.
- The max size limit for any given [Event History](/workflow-execution/event#event-history) transaction is 4 MB.

## Why does this error occur?

This error occurs when the size of the blob exceeds the maximum size allowed by Temporal.

This limit helps ensure that the Temporal Service prevents excessive resource usage and potential performance issues when handling large payloads.

## How do I resolve this error?

To resolve this error, reduce the size of the blob so that it is within the 4 MB limit.

There are multiple strategies you can use to avoid this error:

1. Use compression with a [custom payload codec](/payload-codec) for large payloads.

   - This addresses the immediate issue of the blob size limit; however, if blob sizes continue to grow this problem can arise again.

2. Break larger batches of commands into smaller batch sizes:

   - Workflow-level batching:
     1. Modify the Workflow to process Activities or Child Workflows into smaller batches.
     2. Iterate through each batch, waiting for completion before moving to the next.
   - Workflow Task-level batching:
     1. Execute Activities in smaller batches within a single Workflow Task.
     2. Introduce brief pauses or sleeps (for example, 1ms) between batches.

3. Consider offloading large payloads to an object store to reduce the risk of exceeding blob size limits:
   1. Pass references to the stored payloads within the Workflow instead of the actual data.
   2. Retrieve the payloads from the object store when needed during execution.

---

## Troubleshoot the deadline-exceeded error

All requests made to the [Temporal Service](/temporal-service) by the Client or Worker are [gRPC requests](https://grpc.io/docs/what-is-grpc/core-concepts/#deadlines).
Sometimes, when these frontend requests can't be completed, you'll see this particular error message: `Context: deadline exceeded`.
Network interruptions, timeouts, server overload, and Query errors are some of the causes of this error.

The following sections discuss the nature of this error and how to troubleshoot it.

### Check system clocks

Timing skew can cause the system clock on a Worker to drift behind the system clock of the Temporal Service.
If the difference between the two clocks exceeds an Activity's Start-To-Close Timeout, an `Activity complete after timeout` error occurs.

If you receive an `Activity complete after timeout` error alongside `Context: deadline exceeded`, check the clocks on the Temporal Service's system and the system of the Worker sending that error.
If the Worker's clock doesn't match the Temporal Service, synchronize all clocks to an NTP server.

### Check Frontend Service logs

:::note

Cloud users cannot access some of the logs needed to diagnose the source of the error.

If you're using Temporal Cloud, create a [support ticket](/cloud/support#support-ticket) with as much information as possible, including the Namespace Name and the Workflow Ids of some Workflow Executions in which the issue occurs.

:::

[Frontend Service](/temporal-service/temporal-server#frontend-service) logs can show which parts of the Temporal Service aren't working.
For the error to appear, a service pod or container must be up and running.

OSS users can verify that the Frontend Service is connected and running by using the Temporal CLI.

```
temporal operator cluster health --address 127.0.0.1:7233
```

Use [`grpc-health-probe`](https://github.com/grpc-ecosystem/grpc-health-probe) to check the Frontend Service, [Matching Service](/temporal-service/temporal-server#matching-service), and [History Service](/temporal-service/temporal-server#history-service).

```
./grpc-health-probe -addr=frontendAddress:frontendPort -service=temporal.api.workflowservice.v1.WorkflowService

./grpc-health-probe -addr=matchingAddress:matchingPort -service=temporal.api.workflowservice.v1.MatchingService

./grpc-health-probe -addr=historyAddress:historyPort -service=temporal.api.workflowservice.v1.HistoryService
```

Logs can also be used to find failed Client [Query](/sending-messages#sending-queries) requests.

### Check your Temporal Service metrics

Temporal Service metrics can be used to detect issues (such as `resource exhausted`) that impact Temporal Service health.
A `resource exhausted` error can cause your client request to fail, which prompts the `deadline exceeded` error.

Use the following query to check for errors in `RpsLimit`, `ConcurrentLimit` and `SystemOverloaded` on your metrics dashboard.

```
sum(rate(service_errors_resource_exhausted{}[1m])) by (resource_exhausted_cause)
```

Look for high latencies, short timeouts, and other abnormal [Temporal Service metrics](/references/cluster-metrics).
If the metrics come from a specific service (such as History Service), check the service's health and performance.

### Check Workflow logic

Check your [Client and Worker configuration](/references/configuration) files for missing or invalid target values, such as the following:

- Server names
- Network or host addresses
- Certificates

Invalid targets also cause `connection refused` errors alongside `deadline exceeded`.
Check that the Client connects after updating your files.

### Advanced troubleshooting

In addition to the steps listed in the previous sections, check the areas mentioned in each of the following scenarios.

### After enabling mTLS

Check the health of the Temporal Service with `temporal operator cluster health`.

```
temporal operator cluster health --address [SERVER_ADDRESS]
```

Add any missing [environment variables](/references/web-ui-environment-variables) to the configuration files, and correct any incorrect values.
Server names and certificates must match between Frontend and internode.

### After restarting the Temporal Service

You might not be giving the Temporal Service enough time to respond and reconnect.
Restart the Server, wait, and then check all services for connectivity and further errors.

If the error persists, review your Workflow Execution History and server logs for more specific causes before continuing to troubleshoot.

### When executing or scheduling Workflows

One or more services might be unable to connect to the [Frontend Service](/temporal-service/temporal-server#frontend-service).
The Workflow might be unable to complete requests within the given connection time.

Increase the value of `frontend.keepAliveMaxConnectionAge` so that requests can be finished before the connection terminates.

:::note

If you increase `frontend.keepAliveMaxConnectionAge` values, consider monitoring your server performance for load.

:::

---

Still unable to resolve your issue?

- If you use Temporal Cloud, create a [support ticket](/cloud/support#support-ticket).
- If you use our open source software or Temporal Cloud, check for similar questions and possible solutions in our [community forum](https://community.temporal.io) or [community Slack](https://temporal.io/slack).

---

## Error Handling and Troubleshooting

Even the most reliable systems can encounter issues.
Our troubleshooting guides are designed to help you quickly identify and resolve potential errors, ensuring your Temporal applications run smoothly and efficiently.

- [Troubleshoot the BlobSizeLimitError](/troubleshooting/blob-size-limit-error): The `BlobSizeLimitError` happens when the size of a blob (payloads including Workflow context and each Workflow and Activity argument and return value) is too large.
  The maximum payload for a single request is 2 MB, and the maximum size for any Event History transaction is 4 MB.
- [Troubleshoot the Deadline-Exceeded Error](/troubleshooting/deadline-exceeded-error):
  The "Context: deadline exceeded" error occurs when requests to the Temporal Service by the Client or Worker cannot be completed.
  This can be due to network issues, timeouts, server overload, or Query errors.
- [Troubleshoot the Failed Reaching Server Error](/troubleshooting/last-connection-error): The message "Failed reaching server: last connection error" often happens due to an expired TLS certificate or during the Server startup process when Client requests reach the Server before roles are fully initialized.

---

## Troubleshoot the failed reaching server error

The message `Failed reaching server: last connection error` can often result from an expired TLS certificate or during the Server startup process, in which the Client requests reach the Server before the roles are fully initialized.

This troubleshooting guide shows you how to do the following:

- Verify the certification expiration date
- Renew the certification
- Update the server configuration

### Verify TLS certification expiration date

The first step in troubleshooting this error is to verify the expiration date of the TLS certification.
Then you can renew the certification and update the server configuration.

Choose one of the following methods to verify the expiration date of the TLS certification:

**Verify the expiration date of the TLS certification**

List the expiration date with the following command:

```command
tcld namespace accepted-client-ca list \
    --namespace <namespace_id>.<account_id> | \
    jq -r '.[0].notAfter'
```

If the returned date is in the past, the certificate has expired.

**Existing certificate management infrastructure**

If you are using an existing certificate management infrastructure, use it to verify the TLS connection.
For example, if you are using OpenSSL, run the following command:

```command
openssl s_client -connect <namespace_grpc_endpoint> -showcerts -cert ~/certs/path.pem -key .~/certs/path.key -tls1_2
```

**Self-signed certificate**

If you are using a self-signed certificate, run the following Temporal CLI command:

```command
temporal namespace describe \
    --namespace <namespace_id>.<account_id> \
    --address <namespace_grpc_endpoint> \
    --tls-cert-path <path-to-mTLS-pem-file> \
    --tls-key-path <path-to-mTLS-key-file>
```

Your Namespace gRPC endpoint is available on the details page for your [Temporal Cloud Namespace](https://cloud.temporal.io/namespaces).

### Renew TLS certification

If the certificate has expired or is about to expire, the next step is to renew it.

You can do this by contacting the certificate authority (CA) that issued the certificate and requesting a renewal.

**Existing certificate management infrastructure**

If you are using an existing certificate management infrastructure, contact the administrator of the infrastructure to renew the certificate.

**Self-signed certificate**

If you are using a self-signed certificate or don't have an existing infrastructure, you can generate a new certificate using OpenSSL or [certstrap](https://github.com/square/certstrap).

For information on generating a self-signed certificate, see [Control authorization](/cloud/certificates#control-authorization).

### Update the CA certification in the server configuration

Update the new CA certificate in the Temporal Cloud server configuration.

You can update certificates using any of the following methods:

- [Update certificates using Temporal Cloud UI](/cloud/certificates#update-certificates-using-temporal-cloud-ui)
- [Update certificates using tcld](/cloud/certificates#update-certificates-using-tcld)

After you update the TLS certification in the server configuration, retry your connection.

### Set reminders

Don't let your certificates expire.
Add reminders to your calendar to issue new CA certificates well before the expiration dates of the existing ones.

### Additional resources

The preceding steps should help you troubleshoot the `failed reaching server: last connection error` error caused by an expired TLS certificate.

If this issue persists, verify that the Client you are using to connect to the server is using the correct TLS certification and that the Client requests reach the server after the roles are fully initialized.
If you still need help, [create a support ticket](/cloud/support#support-ticket).

---

## Performance bottlenecks troubleshooting guide

This guide outlines common performance bottlenecks in Temporal Workers and Clients.
It covers key latency metrics and root causes of high values, and provides diagnostic steps and troubleshooting strategies.
These metrics can help you optimize Temporal deployments and Workflow execution.

To get the most out of this guide, you should be familiar with [Temporal architecture](/temporal), [Workflows](/workflows), [Activities](/activities), and [Task Queues](/task-queue).
You should also know how to use key metrics like latency, counter, rate, CPU utilization, and memory usage.

## Task processing metrics

These metrics provide insights into various stages of the [Task](/tasks) lifecycle, from scheduling to completion.
The following sections detail common metrics, their potential causes for high latency or resource depletion, and strategies for diagnosing and resolving performance issues.

### `temporal_workflow_task_schedule_to_start_latency` spike

High [`temporal_workflow_task_schedule_to_start_latency`](/references/sdk-metrics#workflow_task_schedule_to_start_latency) (P95 higher than one second) can be caused by several factors.
This metric represents the time between when a [Workflow Task](/tasks#workflow-task) is scheduled (enqueued) and when it is picked up by a Worker for processing. Here are some potential causes:

- Insufficient Worker capacity: If there aren't enough Workers or if the Workers are overloaded, they may not be able to pick up Tasks quickly enough. This can lead to Tasks waiting longer in the queue ([Detect Task Backlog](https://docs.temporal.io/production-deployment/cloud/worker-health#detect-task-backlog)).
- Worker configuration issues: Improperly configured Workers, such as having too few pollers or Task slots, can lead to increased latency ([Detect Task Backlog](https://docs.temporal.io/production-deployment/cloud/worker-health#detect-task-backlog)).
- High Workflow lock latency: If many updates are made to a single execution, this can cause Workflow lock latency, which in turn affects the Schedule-to-start latency. Reduce the rate of Signals.
- Network latency: Workers in a different region from the Temporal cluster, or large payload size, can introduce additional latency.

To diagnose and address high `temporal_workflow_task_schedule_to_start_latency`, you should:

1. Check Worker CPU and memory usage.
1. Review Worker configuration (number of pollers, Task slots, etc.).
1. Look for any spikes in Workflow or Activity starts that might be overwhelming the system.
1. Ensure Workers are in the same region as the Temporal cluster if possible.

### `temporal_activity_schedule_to_start_latency` spike

High [`temporal_activity_schedule_to_start_latency`](/references/sdk-metrics#activity_schedule_to_start_latency) (P95 higher than one second) can be caused by several factors.
This metric represents the time between when an [Activity Task](/tasks#activity-task) is scheduled (enqueued) and when it is picked up by a Worker for processing.
Here are some potential causes:

- Insufficient Worker capacity: If there aren't enough Workers or if the Workers are overloaded, they may not be able to pick up Tasks quickly enough. This can lead to Tasks waiting longer in the queue ([Detect Task Backlog](https://docs.temporal.io/production-deployment/cloud/worker-health#detect-task-backlog)).
- Worker configuration issues: Improperly configured Workers, such as having too few pollers or Task slots, can lead to increased latency ([Detect Task Backlog](https://docs.temporal.io/production-deployment/cloud/worker-health#detect-task-backlog)).
- Task Queue configuration: Setting `TaskQueueActivitiesPerSecond` too low can limit the rate at which Activities are started, leading to increased Schedule-to-start latency.
- Network latency: Workers in a different region from the Temporal cluster, or large payload size can introduce additional latency.

To diagnose and address high `temporal_activity_schedule_to_start_latency`:

1. Check Worker CPU and memory usage.
1. Review Worker configuration (number of pollers, Task slots, etc.).
1. Look for any spikes in Workflow or Activity starts that might be overwhelming the system.
1. Ensure Workers are in the same region as the Temporal cluster if possible.

### `temporal_workflow_endtoend_latency` spike

The [`temporal_workflow_endtoend_latency`](/references/sdk-metrics#workflow_endtoend_latency) metric represents the total Workflow Execution time from Schedule to the closure for a single Workflow Run.
Normal ranges for this metric depend on the use case, but here are some potential causes for the unexpected spikes:

- Complex Workflows: If the Workflows have many Activities or if the Activities take a long time to execute.
- Workflow and Activity retries: If Workflows or Activities are configured to retry upon failure and they fail often, this can increase the end-to-end latency as the system will wait for the retry delay before reattempting the failed operation.
- Worker capacity and configuration: If there aren't enough Workers or if the Workers are overloaded, they may not be able to pick up and process Tasks quickly enough. This can lead to Tasks waiting longer in the queue, thereby increasing the end-to-end latency ([Detect Task Backlog](https://docs.temporal.io/production-deployment/cloud/worker-health#detect-task-backlog)).
- External dependencies: If your Workflows or Activities depend on external systems or services (such as databases or APIs) and these systems are slow or unreliable, they can increase the end-to-end latency.
- Network latency: Workers in a different region from the Temporal cluster can introduce additional latency.

To diagnose and address high `temporal_workflow_endtoend_latency`:

1. Review your Workflow and Activity designs to ensure they are as efficient as possible.
2. Monitor your Workers to ensure they have sufficient capacity (CPU and memory) and are not overloaded.
3. Monitor your external dependencies to ensure they are performing well.
4. Ensure Workers are in the same region as the Temporal cluster if possible.

### High `temporal_workflow_task_execution_latency`

The [`temporal_workflow_task_execution_latency`](/references/sdk-metrics#workflow_task_execution_latency) metric represents the time taken by a Worker to execute a Workflow Task.
The Temporal SDK raises a “Deadlock detected during Workflow run” error or [TMPRL1101](https://github.com/temporalio/rules/blob/main/rules/TMPRL1101.md) when a Workflow Task takes more than one or two seconds to complete.
Here are some potential causes:

- CPU-intensive work: Performing CPU-intensive operations in your Workflow Task can lead to slow execution.
- Slow local Activities: Workflow Task execution time includes the Local Activity execution time.
- Slow Workflow replay: Workflow Task execution time includes the Workflow Replay time. Refer to `workflow_task_replay_latency` for more details.
- Worker resource constraints: High CPU usage on Worker pods can lead to slower Workflow Task execution. Workers with insufficient CPU resources can cause delays.
- Infinite loops or blocking calls: Workflow code with infinite loops or blocking external API calls can cause the Workflow Task to execute slowly or time out.
- Slow data conversion: Your custom Data Converter is taking too long to encode/decode payloads, for example, when talking to a remote encryption service.

To diagnose and address slow Workflow Task execution, you can:

1. Monitor Worker CPU and memory utilization.
2. Ensure that your Workers have adequate resources and are properly scaled for your workload.
3. Consider running your Workflow code in a profiler using a replayer to see where CPU cycles are spent.
4. Review your Workflow code for potential optimizations or to remove blocking operations.
5. Disable deadlock detection for Data Converter: It does not reduce Task execution latency but does remove the “Deadlock detected during Workflow run” or TMPRL1101 error. In Go, wrap it with `workflow.DataConverterWithoutDeadlockDetection`. In Java, surround your Data Converter code with `WorkflowUnsafe.deadlockDetectorOff`.

### High `workflow_task_replay_latency`

Workflow Task replay is the process of reconstructing the Workflow's state by re-executing the Workflow code from the beginning, using the recorded Event History.
This process ensures that the Workflow can continue from where it left off, even after interruptions or failures.
[`workflow_task_replay_latency`](/references/sdk-metrics#workflow_task_replay_latency) is high if it exceeds a few milliseconds.
Here are the main causes:

- Large Event Histories: Workflows with long histories take more time to replay, as the Worker needs to process all events to reconstruct the Workflow state.
- Data Converter performance: Slow Data Converters, especially those that perform encryption or interact with external services, can impact replay.
- Large payloads: Activities or Signals with large payloads can slow down the replay process, especially if the Data Converter needs to process these payloads.
- Complex Workflow logic: Workflow code with complex logic or computationally intensive operations, such as scheduling many concurrent child Workflows or Activities, can increase replay latency.
- Frequent cache evictions: If workers often evict Workflow Executions from their cache (due to memory constraints or frequent restarts), it leads to more replays and higher latency.
- Worker resource constraints: High CPU utilization or memory pressure on Worker nodes can slow down the replay.

To diagnose and address slow Workflow Task replay, you can:

1. Monitor SDK Metrics: Keep a close eye on the `temporal_workflow_task_replay_latency` metric. This histogram metric measures the time it takes to replay a Workflow Task.
1. Analyze Workflow History Size: Check the number of events in your Workflow histories and consider using the "Continue-As-New" feature for long-running Workflows.
1. Optimize Data Converters: If you're using custom Data Converters, especially for encryption or complex serialization, look for opportunities to optimize their performance.
1. Review Payload Sizes: Large Activity or Signal payloads can slow down replay. Consider optimizing the size of data being passed in your Workflows.
1. Profile Workflow Code: Use a profiler to identify CPU-intensive parts of your Workflow code that might be slowing down replay.
1. Manage Worker Cache: Frequent cache evictions can lead to more replays. Tune your Worker's cache size and eviction policies.

### `temporal_activity_execution_latency` spike

The [`temporal_activity_execution_latency`](/references/sdk-metrics#activity_execution_latency) metric measures the time from when a Worker starts processing an Activity Task until it reports to the service that the Task is complete or failed.
There are several potential causes for high `temporal_activity_execution_latency`:

- Activity implementation: The most common cause of high Activity Execution latency is the actual implementation of the Activity itself. If the Activity is performing time-consuming operations or making slow external API calls, it will take longer to execute.
- External dependencies: If your Activity is constrained by an external resource or service that all Activities access, it could cause increased latency.
- Worker resource constraints: Under-resourced Worker nodes or experiencing high CPU utilization can lead to slower Activity Execution.
- Network latency: High latency between your Workers and external services or the Temporal service itself can contribute to increased Activity Execution time.

To diagnose and address high Activity Execution latency:

1. Monitor the `activity_execution_latency` metric, which you can filter by Activity type and Activity Task queue.
2. Optimize your Activity implementation to reduce latency, especially with external services or database interactions.
3. Check your Worker CPU and memory utilization to make sure they have adequate resources.
4. Examine your Worker configuration, particularly `(Max)ConcurrentActivityExecutionSize` and `(Max)WorkerActivitiesPerSecond`, to ensure they are not limiting your activity execution.

### Depletion of `temporal_worker_task_slots_available` for `WorkflowWorker`

The [`temporal_worker_task_slots_available{worker_type=”WorkflowWorker”}`](/references/sdk-metrics#worker_task_slots_available) metric indicates the number of available slots for executing Workflow Tasks on a Worker.
This metric may go to zero for several reasons:

- High Workflow Task Load: If there are more Tasks than the Worker can handle concurrently, the available slots will be depleted. This can happen if the rate of incoming Tasks is higher than the rate at which tasks are being completed.
- Worker Configuration: The number of available slots is determined by the Worker configuration, specifically the `MaxConcurrentWorkflowTaskExecutionSize` setting. If these are set too low, the Worker may not have enough slots to handle the Task load.
- High `temporal_workflow_task_execution_latency` and `workflow_task_replay_latency`.

To prevent depletion of Workflow Task slots:

1. Monitor Worker CPU and Memory usage while increasing `(Max)ConcurrentWorkflowTaskExecutionSize` to add more execution slots.
2. Scale up Workers both vertically (increasing CPU and Memory) and horizontally (increasing Worker instances).

### Depletion of `temporal_worker_task_slots_available` for `ActivityWorker`

The [`temporal_worker_task_slots_available{worker_type=”ActivityWorker”}`](/references/sdk-metrics#worker_task_slots_available) metric indicates the number of available slots for executing Activity Tasks on a Worker.
This metric may go to zero for several reasons:

- Blocked Activities and Zombie Activities: The most common cause is activities that are blocked or not returning on time. Zombie Activities are a subset of this category. They occur when an Activity times out (hits its `StartToClose` or `HeartbeatTimeout` timeout) and has stopped Heartbeating but continues to run, occupying some or all the slots as more retries occur. This can happen if:
  - The Activity code is blocking on a downstream service call or an infinite loop.
  - There's a mismatch between the Activity's `StartToClose` timeout and any client-side timeouts for external calls.
- Resource Utilization: High CPU or memory usage on Workers can cause activities to block and not release slots.

To prevent depletion of Activity Task slots:

1. Monitor Worker CPU and Memory usage while increasing `(Max)ConcurrentActivityExecutionSize` to add more execution slots.
2. Add client-side timeout to your downstream API client.
3. Review your Task code to ensure Tasks complete within a reasonable time measured by `temporal_activity_execution_latency`.

## Network requests

Network issues can impact Temporal clients and workers, leading to delays, failures, and overall system instability.
This section focuses on metrics that reveal common network-related problems with your Temporal deployment, specifically related to network connectivity, latency, and request failures.
These metrics can indicate where bottlenecks exist within the communication channels between Temporal clients (including Temporal Workers) and the Temporal server.

### High `temporal_long_request_failure`

The [`temporal_long_request_failure`](/references/sdk-metrics#long_request_failure) metric counts the number of failed RPC long poll requests for `PollWorkflowTaskQueue`, `PollActivityTaskQueue`, and `GetWorkflowExecutionHistory` (when polling new events). High values of this metric can be caused by several factors:

- Network Issues: Problems with the network connection between the Temporal Client and the Temporal Server, including firewalls and proxies, can cause long poll requests to fail.
- Rate Limiting: If the rate of requests exceeds the configured limits on the Temporal Server or Temporal Cloud, additional requests may be rejected, increasing the `temporal_long_request_failure` count. This is often indicated by a `ResourceExhausted` status code.
- Server Errors: If the Temporal Server is experiencing issues, it may fail to respond to long poll requests correctly, leading to an increase in `temporal_long_request_failure`.

To diagnose the cause of high `temporal_long_request_failure`, you can:

1. Check the operation and the status or code tag of the `temporal_long_request_failure` metric to see the type of errors that are occurring.
2. If you receive a `ResourceExhausted` status code, review the rate limits configured on the Temporal Server or ask for help from Temporal Support for Temporal Cloud.
3. Check the network connection between the Temporal Client and the Temporal Server.

### High `temporal_request_failure_total`

The [`temporal_request_failure_total`](/references/sdk-metrics#request_failure) metric counts the number of RPC requests made by the Temporal Client that have failed.
High values of this metric can be caused by several factors:

- Network Issues: Problems with the network connection between the Temporal Client and the Temporal Server can cause requests to fail.
- Client Errors: If there's an issue with the Temporal Client, such as misconfiguration or resource exhaustion, it may fail to make requests correctly.
- Operation Errors: Specific operations like `SignalWorkflowExecution` or `TerminateWorkflowExecution` can fail if they are trying to act on a closed Workflow Execution that no longer exists (because it completed and was removed from persistence when it hit Namespace retention time).
- Rate Limiting: If the rate of requests exceeds the configured limits on the Temporal Server, additional requests may be rejected, increasing the counter. This is often indicated by a `ResourceExhausted` status code.
- Request Size Limit: If the Worker tries to return an Activity response that is larger than the blob size limit (2MB), the service will reject it, causing a request failure.
- Server Errors: If the Temporal Server is experiencing issues, it may fail to respond to requests correctly, leading to an increase in `temporal_request_failure_total`.

To diagnose the cause of high `temporal_request_failure_total`, you can:

1. Check the status or code tag of the `temporal_request_failure_total` metric to see the type of errors that are occurring.
2. Look at the operation tag of the `temporal_request_failure_total` metric to see which operations are failing.
3. Monitor the Temporal Server logs and the Temporal Client logs for any error messages or warnings.
4. Check the network connection between the Temporal Client and the Temporal Server.

### High `temporal_request_latency`

The [`temporal_request_latency`](/references/sdk-metrics#request_latency) metric measures the latency of gRPC requests made by the Temporal Client.
High values for this metric can be caused by several factors:

- Network Latency: The physical distance and network conditions between the Temporal Client and the Temporal Server can affect the latency of requests.
- Network Transfer Time: Larger payloads take longer to transfer over the network, which affects request latency. For example, large payloads in `RespondWorkflowTaskCompleted` can affect the latency of the request. This is especially true when Workflows are scheduling multiple activities with large inputs.
- Resource Exhaustion: Running out of resources (such as CPU or memory) on the client or server can cause delays in processing the request.
- Client Configuration: Improper client configuration, such as setting thread pool sizes too aggressively or having memory constraints that are too low for the number of allocated threads, can lead to situations where Tasks overwhelm the client, causing increased latency.
- Server Load: If the Temporal Server is under heavy load, it may take longer to respond to requests, leading to increased latency.

To diagnose and address high `temporal_request_latency`:

1. Monitor the `temporal_request_latency` metric to identify when and where latency spikes are occurring.
2. Check the network connection between the Temporal Client and the Temporal Server.
3. Monitor the resource usage on both the Temporal Client and the Temporal Server.
4. Review your Temporal Client configuration to ensure it is optimized for your workload.
5. If you're using Temporal Cloud, check if the Cloud’s [service-latency](https://docs.temporal.io/production-deployment/cloud/metrics/reference#service-latency) metric spikes up and reach out to Temporal Support for help.

### `rate(temporal_long_request_total{operation="PollActivityTaskQueue"})`

The [`rate(temporal_long_request_total{operation="PollActivityTaskQueue"})`](/references/sdk-metrics#long_request) expression measures the per-second average rate of `PollActivityTaskQueue` long poll requests over a certain period of time.

`PollActivityTaskQueue` is an operation where Workers poll for Activity Tasks from the Task Queue.
The `temporal_long_request_total` metric counts the number of these long poll requests.

By applying the `rate()` function in Prometheus, you can calculate the per-second average rate of these requests over the time range specified in the Query.
This can help you understand the load on your Temporal service and how often your Workers are polling for Activity Tasks.

### `rate(temporal_long_request_total{operation="PollWorkflowTaskQueue"})`

The [`rate(temporal_long_request_total{operation="PollWorkflowTaskQueue"})`](/references/sdk-metrics#long_request) expression measures the per-second average rate of `PollWorkflowTaskQueue` long poll requests over a certain period of time.

`PollWorkflowTaskQueue` is an operation where Workers poll for Workflow Tasks from the Task Queue.
The `temporal_long_request_total` metric counts the number of these long poll requests.

By applying the `rate()` function in Prometheus, you can calculate the per-second average rate of these requests over the time range specified in the query.
This can help you understand the load on your Temporal service and how often your Workers are polling for Workflow Tasks.

## Caching

Temporal Workers relies on caching to optimize performance by reducing the overhead of fetching Workflow state from the history and Replaying.
However, unlimited caching is impossible; there's a trade-off between the benefits of cached data and the memory consumed.
These metrics allow you to balance performance gains with responsible memory usage.

### `temporal_sticky_cache_size`

The [`temporal_sticky_cache_size`](/references/sdk-metrics#sticky_cache_size) metric represents the number of Workflow executions currently cached in a Worker's memory.

The sticky cache is used to improve performance by keeping the Workflow state in memory, reducing the need to reconstruct the Workflow from its Event History for every Task.
It’s particularly useful for latency-sensitive Workflows.

There is a direct relationship between the sticky cache size and Worker memory consumption.
As the cache size increases, so does the memory usage of the Worker.

The maximum size of the sticky cache can be configured. For example, the default in the Go SDK is 10,000 Workflows.

A larger sticky cache can improve performance by reducing the need to replay Workflow histories.
However, it also increases memory usage, which can lead to issues if not properly managed.

Monitor this metric alongside Worker memory usage.
A sudden increase in `sticky_cache_size` can correlate with increased memory consumption and potential performance issues.

If memory consumption is too high, you can reduce the maximum sticky cache size.
Conversely, if you have available memory and want to improve performance, you might increase it.

### `temporal_sticky_cache_hit_total` and `temporal_sticky_cache_miss_total`

The [`temporal_sticky_cache_hit_total`](https://docs.temporal.io/references/sdk-metrics#sticky_cache_hit) metric is a counter that measures the total number of times a Workflow Task found a cached Workflow Execution to run against, and
the opposite is [`temporal_sticky_cache_miss_total`](https://docs.temporal.io/references/sdk-metrics#sticky_cache_miss), which is a counter that measures the total number of times a Workflow Task did not find a cached Workflow Execution to run against.

Sticky Execution is a feature where a Worker caches a Workflow Execution and creates a dedicated Task Queue to listen on.
This improves performance because the Temporal Service only sends new events to the Worker instead of entire Event Histories, and the Workflow doesn't have to Replay.

A “hit” means the Worker finds the Workflow in its cache when processing a Workflow Task, allowing immediate processing without fetching the full Event History from the server and Replaying.
A "miss" means the Worker didn't find the Workflow in its cache, and it must fetch the Event History and Replay.

Monitoring these two metrics and comparing them can help you understand how your sticky cache is being used.
A high rate of cache hits with a low rate of cache misses indicates that your Workflows are being scheduled efficiently, with minimal need for fetching Event Histories and Replaying.

### `temporal_sticky_cache_total_forced_eviction_total`

The [`temporal_sticky_cache_total_forced_eviction_total`](https://docs.temporal.io/references/sdk-metrics#sticky_cache_hit) metric is a counter that measures the total number of Workflow Executions that have been forcibly evicted from the sticky cache.

Sticky Execution is a feature where a Worker caches a Workflow Execution and creates a dedicated Task Queue to listen on.
This improves performance because the Temporal Service only sends new events to the Worker instead of entire Event Histories, and the Workflow doesn't have to Replay.

A "forced eviction" in this context means that a Workflow Execution was removed from the cache before it completed, typically because the cache was full and needed to make room for other Workflow Executions.
This means that if the Worker needs to process more Tasks for the evicted Workflow Execution, it will have to fetch the entire Event History from the Temporal Service and Replay.

Monitoring the `temporal_sticky_cache_total_forced_eviction_total` metric can help you understand how often your Workflows are being evicted from the cache.
A high rate of forced evictions could indicate that your cache size is too small for your workload, and you may need to increase the `WorkflowCacheSize` setting if your Worker resources can accommodate it.

---

## Temporal Web UI

The Temporal Web UI provides users with Workflow Execution state and metadata for debugging purposes.
It ships with every [Temporal CLI](/cli) release and [Docker Compose](https://github.com/temporalio/docker-compose) update and is available with [Temporal Cloud](/cloud).

You can configure the Temporal Web UI to work in your own environment.
See the [UI configuration reference](/references/web-ui-configuration).

Web UI open source repos:

- [temporalio/ui](https://github.com/temporalio/ui)
- [temporalio/ui-server](https://github.com/temporalio/ui-server)

The Web UI is packed with several features.

### Namespaces

All Namespaces in your self-hosted Temporal Service or Temporal Cloud account are listed under **Namespaces** in the left section of the window.
You can also switch Namespaces from the Workflows view by selecting from the Namespace switcher at the top right corner of the window.
After you select a Namespace, the Web UI shows the Recent Workflows page for that Namespace.
In Temporal Cloud, users can access only the Namespaces that they have been granted access to.
For details, see [Namespace-level permissions](/cloud/users#namespace-level-permissions).

### Recent Workflows

The main Workflows page displays a table of recent Workflow Executions.
The Web UI displays a maximum of 1,000 Workflow Executions.

Users can list Workflow Executions by any of the following:

- Status
- [Workflow ID](/workflow-execution/workflowid-runid#workflow-id)
- [Workflow Type](/workflow-definition#workflow-type)
- Start time
- End time
- A [List Filter](/list-filter)

For start time and end time, users can set their preferred date and time format as one of the following:

- UTC
- Local
- Relative

Select a Workflow Execution to view the Workflow Execution's History, Workers, and pending Activities.

#### History

This is a view of the [Events](/workflow-execution/event#event) and Event fields within the Workflow Execution.
Approximately [40 different Events](/references/events) can appear in a Workflow Execution's Event History.

The top of the page lists the following execution metadata:

- [Workflow Type](/workflow-definition#workflow-type)
- [Run Id](/workflow-execution/workflowid-runid#run-id)
- Start Time and Close Time
- [Task Queue](/task-queue)
- Parent and Parent ID
- [State Transitions](/workflow-execution#state-transition)

The Input and Results section displays the function arguments and return values for debugging purposes.
Results are not available until the Workflow finishes.

The Recent Events tab has the following views:

- Timeline: A chronological or reverse-chronological order of events with a summary.
  Clicking into an Event displays all details for that Event.
  Clicking “Expand all” displays all Event details.
  Similarly, clicking “Collapse all” collapses the table and displays only the summary.
- Compact: A logical grouping of Activities, Signals and Timers.
- JSON: The full JSON code for the workflow.

#### Download Event History

The entire Workflow Execution Event History, in JSON format, can be downloaded from this section.

#### Terminate Workflow

Workflow Executions can be Terminated directly from the UI.
A custom note can be logged from the UI when that happens.

#### Workers

Displays the Workers currently polling on the Workflow Task Queue with a count.
If no Workers are polling, an error displays.

#### Pending Activities

Displays a summary of recently active and/or pending Activity Executions.
Clicking a pending Activity directs the user to the Pending Activities tab to view details.

#### Call Stack

The screen shows the captured result from the [\_\_stack_trace](/sending-messages#stack-trace-query) Query.
The Query is performed when the tab is selected.
It works only if a Worker is running and available to return the call stack. The call stack shows each location where Workflow code is waiting.

#### Queries

Lists all Queries sent to the Workflow Execution.

### Schedules

On Temporal Cloud and self-hosted Temporal Service Web UI, the Schedules page lists all the [Schedules](/schedule) created on the selected Namespace.

Click a Schedule to see details, such as configured frequency, start and end times, and recent and upcoming runs.

:::tip Setting Schedules with Strings

Temporal Workflow Schedule Cron strings follow this format:

```
┌───────────── minute (0 - 59)
│ ┌───────────── hour (0 - 23)
│ │ ┌───────────── day of the month (1 - 31)
│ │ │ ┌───────────── month (1 - 12)
│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
│ │ │ │ │
* * * * *
```

:::

To read more about Schedules, explore these links:

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/schedules" text="Schedules using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/schedules" text="Schedules using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/schedules" text="Schedules using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/schedules" text="Schedules using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/schedules" text="Schedules using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/schedules" text="Schedules using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

### Settings

On Temporal Cloud, **Settings** is visible only to Account Owner and Global Admin [roles](/cloud/users#account-level-roles).

Click **Settings** to see and manage the list of users in your account and to set up integrations such as [Observability](/cloud/metrics) and [Audit logging](/cloud/audit-logging).

On a self-hosted Temporal Service, manage your users, metrics, and logging in your [server configuration](/references/configuration).

### Archive

On a self-hosted Temporal Service, Archive shows [Archived](/temporal-service/archival) data of your Workflow Executions on the Namespace.

To see data in your self-hosted Temporal Service, you must have [Archival set up and configured](/self-hosted-guide/archival).

For information and details on the Archive feature in Temporal Cloud, contact your Temporal representative.

### Codec Server

The Web UI can use a [Codec Server](/codec-server) with a custom Data Converter to decode inputs and return values.
For details, see [Securing your data](/production-deployment/data-encryption).

The UI supports a [Codec Server endpoint](/production-deployment/data-encryption#web-ui).
For details on setting the Codec Server endpoint, see [Codec Server setup](/production-deployment/data-encryption#codec-server-setup).

### Labs mode

The Web UI provides a "labs" mode for users to try out upcoming, production-ready UI features and improvements.
When off, users will experience the current UI.
Features will move in and out of labs mode according to demand and feedback.
Labs mode can be turned on or off at any time in the left navigation bar via the Labs icon.
