# Temporal Core Concepts and Features

> Build invincible applications

This file contains all documentation content in a single document following the llmstxt.org standard.

## Safely deploying changes to Workflow code

Making changes safely to existing Workflow code require care. Your Workflow code--as opposed to your Activity code--must be [deterministic](https://docs.temporal.io/workflow-definition#deterministic-constraints). This means your changes to that code have to be as well. Changes to your Workflow code that qualify as non-deterministic need to be protected by either using the [patching APIs](https://docs.temporal.io/workflow-definition#workflow-versioning) within your Workflow code, or by using [Worker Versioning](/production-deployment/worker-deployments/worker-versioning) to pin your Workflows to specific code revisions.

In this article, we’ll provide some advice on how you can safely validate changes to your Workflow code, ensuring that you won’t experience unexpected non-determinism errors in production when rolling them out.

## Use Replay Testing before and during your deployments

The best way to verify that your code won’t cause non-determinism errors once deployed is to make use of [replay testing](https://docs.temporal.io/workflow-execution#replay).

Replay testing takes one or more existing [Workflow Histories](https://docs.temporal.io/workflow-execution/event#event-history) that ran against a previous version of Workflow code and runs them against your _current_ Workflow code, verifying that it is compatible with the provided history.

There are multiple points in your development lifecycle where running replay tests can make sense. They exist on a spectrum, with shortest time to feedback on one end, and most representative of a production deployment on the other.

- During development, replay testing lets you get feedback as early as possible on whether your changes are compatible. For example, you might include some integration tests that run your Workflows against the Temporal Test Server to produce histories which you then check in. You can use those checked-in histories for replay tests to verify you haven’t made breaking changes.
- During pre-deployment validation (such as during some automated deployment validation) you can get feedback in a more representative environment. For example, you might fetch histories from a live Temporal environment (whether production or some kind of pre-production) and use them in replay tests.
- At deployment time, your environment _is_ production, but you are using the new code to replay recent real-world Workflow histories.

When you're writing changes to Workflow code, you can fetch some representative histories from your pre-production or production Temporal environment and verify they work with your changes. You can do the same with the pre-merge CI pipeline. However, if you are using encrypted Payloads, which is a typical and recommended setup in production, you may not be able to decrypt the fetched histories. Additionally if your Workflows contain any PII (which should be encrypted), make sure this information is scrubbed for the purposes of your tests, or err on the side of caution and don’t use this method.
With that constraint in mind, we’ll focus on how you can perform replay tests in a production deployment of a Worker with new Workflow code. The core of how replay testing is done is the same regardless of when you choose to do it, so you can apply some of the lessons here to earlier stages in your development process.

## Implement a deployment-time replay test

The key to a successful safe deployment is to break it into two phases: a verification phase, where you’ll run the replay test, followed by the actual deployment of your new Worker code.

You can accomplish this by wrapping your Worker application with some code that can choose whether it will run in verification mode, or in production. This is most easily done if you do not deploy your Workers side-by-side with other application code, which is a recommended best practice. If you do deploy your Workers as part of some other application, you will likely need to separate out a different entry point specifically for verification.

### Run a replay and real Worker with the same code

The following code demonstrates how the same entry point could be used to either verify the new code using replay testing, or to actually run the Worker.

```python

from datetime import datetime, timedelta

from temporalio.client import Client
from temporalio.worker import Worker, Replayer

async def main():
    parser = argparse.ArgumentParser(prog='MyTemporalWorker')
    parser.add_argument('mode', choices=['verify', 'run'])
    args = parser.parse_args()

    temporal_url = "localhost:7233"
    task_queue = "your-task-queue"
    my_workflows = [YourWorkflow]
    my_activities = [your_activity]

    client = await Client.connect(temporal_url)
```

Everything up to this point is standard. You import the Workflow and Activity code, instantiate a parser with two modes, and create your Task Queue, Workflow, and Activity.

You can pass in the `args.mode` from any appropriate spot in your code. If the mode is set to `verify`, you conduct the replay testing by specifying the time period to test, and passing in the Workflows corresponding to that time period. Note that the Workflows are consumed as histories, using [the `map_histories()` function](https://python.temporal.io/temporalio.client.WorkflowExecutionAsyncIterator.html#map_histories).

```python
if args.mode == 'verify':
    start_time = (datetime.now() - timedelta(hours=10)).isoformat(timespec='seconds')
    workflows = client.list_workflows(
     f"TaskQueue={task_queue} and StartTime > '{start_time}'",
    limit = 100)
    histories = workflows.map_histories()
    replayer = Replayer(
        workflows=my_workflows,
        activities=my_activities,
    )
    await replayer.replay_workflows(histories)
    return
```

If any of the Workflows fail to replay, an error will be thrown. If no errors occur, you can return successfully to indicate success here, or communicate with an endpoint you've defined to indicate success or failure of the verification. You could switch to the `run` mode, and have this Worker transition to a real Worker that will start pulling from the Task Queue and processing Workflows:

```python
    else:
        worker = Worker(
            client,
            task_queue=task_queue,
            workflows=my_workflows,
            activities=my_activities,
        )
        await worker.run()

if __name__ == "__main__":
    asyncio.run(main())
```

### Use the multi-modal Worker

The most straightforward way to use this bimodal Worker is to deploy one instance of it at the beginning of your deployment process in verify mode, see that it passes, and then proceed to deploy the rest of your new workers in run mode.

---

## Worker performance

This page documents metrics and configurations that drive the efficiency of your Worker fleet.
It provides coverage of performance metric families, Worker configuration options, Task Queue information, backlog counts, Task rates, and how to evaluate Worker availability.
This content covers practical methods for querying Task Queue information, and strategies for tuning Workers and Task Queue processing so you manage your resources effectively.

:::info

All metrics on this page are prepended with the `temporal_` prefix.
For example, `worker_task_slots_available` is actually `temporal_worker_task_slots_available` when used.
The omitted prefix makes the names more readable and descriptive.

:::

## Worker performance concepts {#worker-performance-concepts}

A Worker's performance characteristics are affected by, but not limited to, the following elements.

### Task slots {#slots}

A **Worker Task Slot**, represents the capacity of a Temporal Worker to execute a single concurrent Task.
Slots are crucial for managing the workload and performance of Workers in a Temporal application.
They're used for both Workflow and Activity Tasks.
When a Worker starts processing a Task, it occupies one slot.
The number of available slots directly affects how many tasks a Worker can handle simultaneously.

### Slot suppliers {#slot-suppliers}

A **Slot Supplier** defines a strategy to provide slots for a Worker, increasing or decreasing the Worker's slot count.
The supplier determines when it's acceptable to begin a new Task.
Each supplier manages one slot type.
There are slot types for Activity, Workflow, Nexus, or Local Activity Tasks.
An available slot determines whether or not a Worker is willing to poll for, and execute, a new Task of that type.

Slot supplier strategies include manual assignment of fixed slot counts and resource-balanced "auto-tuner" assignment.
Resource-based suppliers adjust slot counts based on CPU and memory resources.
Available slot suppliers include:

- **Fixed Size Slot Suppliers**:
  Hands out slots up to a preset limit.
  This is useful if you have a concrete idea of how many resources your tasks are going to consume, and can easily determine an upper bound on how many should run at once.
  When you need the absolute best performance, review your hardware and environment characteristics.
  This information lets you calculate an appropriate fixed-size limit.
  Evaluate the maximum number of slots you can support without oversubscribing or hitting out-of-memory conditions ("OOMing").
  Using that value with a fixed-size supplier provides optimal results with the least overhead.

- **Resource-Based Slot Suppliers**:
  Hands out slots based on real-time CPU and memory usage.
  You set target utilization for both CPU and memory and the Slot Supplier tries to reach those values without exceeding them under load.
  A resource-based supplier will account for memory limits imposed in containerized environments.
  It dynamically adjusts the number of available slots for different task types with respect to current system resources.

- **Custom Slot Suppliers**:
  Hands out slots based on the custom logic that you define.
  Use this approach when you need complete control over when Workers accept and execute Tasks.
  For implementation details, see [Implement Custom Slot Suppliers](#custom-slot-implementation).

:::caution

- You cannot guarantee that the targets for resource-based suppliers won't ever be exceeded.
  Resources consumed during a task can't be known ahead of time.

- Worker tuners supersede the existing `maxConcurrentXXXTask` style Worker options.
  Using both styles will cause an error at Worker initialization time.

:::

### Worker tuning {#worker-tuning}

**Worker tuning** lets you manage and customize a Worker's runtime performance characteristics.
They use special types called **Worker tuners** that assign slot suppliers to various Task Types, including Worker, Activity, Nexus, and Local Activity Tasks.

For more on how to configure and use Worker tuners, see [Worker runtime performance tuning](#worker-performance-tuning) below.

:::caution

- Worker tuners supersede the existing `maxConcurrentXXXTask` style Worker options.
  Using both styles will cause an error at Worker initialization time.

:::

### Task pollers {#task-poller}

A Worker's **Task pollers** play a crucial role in the Temporal architecture by efficiently
distributing work to Workers to support scalable, resilient Workflow Execution.
They actively poll a Task Queue for Tasks to process.
Pollers create long-polling connections to the Temporal Service, allowing the service to dispatch Tasks to Workers.
When a Task Poller receives a Task, it delivers to the appropriate Executor Slot for processing.

Task Pollers enable efficient load balancing across multiple Worker processes.
The number of Task Pollers can be configured using `WorkerOptions` when creating a new Worker instance.

### Eager task execution

Workers may eagerly execute Activity and Workflow Tasks under the right circumstances.

Eager Activity Execution may happen automatically if the Worker processing a Workflow Task also has the Activity Definition being called registered.
If it does, it may try to reserve an Activity Slot for the execution of the Activity, and the server may respond to the Workflow Task completion with the Activity Task for the worker to execute immediately.

Eager Workflow execution is opt-in, and requires the Client which is starting the Workflow to be located in the same process as a Worker. When making the Start Workflow call, you can set the `request_eager_start` (or similar name) to true.
When set, and the Worker has a Workflow Task slot available and the Workflow Definition registered, the Worker can execute the first task of the Workflow locally without first making a round-trip to the Temporal Server.
This is typically most useful in combination with a Local Activity executing in the first Workflow Task, since other Workflow API calls that require waiting on something will force a round-trip.

## Performance metrics for tuning {#metrics}

The Temporal SDKs emit metrics from Temporal Client usage and Worker Processes.
Performance tuning uses three important SDK metric groups:

### Slot availability metrics

Temporal's [`worker_task_slots_available`](/references/sdk-metrics#worker_task_slots_available) and `worker_task_slots_used` gauges can report the number of available executor “slots” that are currently available and unoccupied for a Worker type.
Tag these with `worker_type=WorkflowWorker` for Workflow Task Workers or `worker_type=ActivityWorker` for Activity Workers.

:::tip

Unlike `worker_task_slots_used`, `worker_task_slots_available` can only be used with fixed size slot suppliers and can't be used with resource-based slot suppliers.

:::

### Latency metrics

Temporal provides two latency timers: [`workflow_task_schedule_to_start_latency`](/references/sdk-metrics#workflow_task_schedule_to_start_latency) for Workflow Tasks and [`activity_schedule_to_start_latency`](/references/sdk-metrics#activity_schedule_to_start_latency) for Activities.
A Schedule-To-Start latency is the time from when an Task is scheduled (that is, placed in a Queue) to when a Worker starts (that is, picks up from the Task Queue) that Task.
These metrics help ensure that Tasks are being processed from the queue in a timely manner.
For more information about `schedule_to_start` timeout and latency, see [Schedule-To-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout).

### Cache metrics

The [`sticky_cache_size`](/references/sdk-metrics#sticky_cache_size) and [`workflow_active_thread_count`](/references/sdk-metrics#workflow_active_thread_count) metrics report the size of the Workflow cache and the number of cached Workflow threads.

## Worker performance options {#configuration}

Each Worker can be configured by providing custom Worker options (`WorkerOptions`) at instantiation.
Options are specific to individual Workers and do not affect other members of your fleet.

### Executor slot options

The `maxConcurrentWorkflowTaskExecutionSize` and `maxConcurrentActivityExecutionSize` options define the number of total available Workflow Task and Activity Task slots for a Worker.

:::caution

- Worker tuners supersede the existing `maxConcurrentXXXTask` style Worker options.
  Using both styles will cause an error at Worker initialization time.

:::

### Poller options

`maxConcurrentWorkflowTaskPollers` (JavaSDK: `workflowPollThreadCount`) and `maxConcurrentActivityTaskPollers` (JavaSDK: `activityPollThreadCount`) define the maximum count of pollers performing poll requests on Workflow and Activity Task Queues.
The Worker's requests deliver Tasks to the related executor slots.

SDKs also have experimental support for automated poller tuning, which automatically selects an
appropriate number of pollers based on need. This option will likely result in more efficient poller usage, better throughput,
or both, for all scenarios.
This feature can be enabled by setting the `*_task_poller_behavior` options to `PollerBehaviorAutoscaling`.
Names may vary slightly depending on the SDK.
There are options within to configure minimum, maximum, and initial poller counts, but it is unlikely that you will need to adjust them.

### Cache options

A Workflow Cache is created and shared between all Workers on a single host.
It's designed to limit the resources used by the cache for each host/process.
These options are defined on `WorkerFactoryOptions` in JavaSDK and in `worker` package in GoSDK:

- `worker.setStickyWorkflowCacheSize` (JavaSDK: `WorkerFactoryOptions#workflowCacheSize`) defines the maximum number of cached Workflows Executions.
  Each cached Workflow contains at least one Workflow thread and its resources.
  Resources include memory, etc.
- `maxWorkflowThreadCount` defines the maximum number of Workflow threads that may exist concurrently at any time.

These cache options limit the resource consumption of the in-memory Workflow cache.
Workflow cache options are shared between all Workers because the Workflow cache is tightly integrated with the resource consumption of the entire host.
This includes memory and the total thread count, which should be limited per host/JVM.

### "Large value" drawbacks

There are drawbacks when you use "large values everywhere."
As with any multithreading system, specifying excessively large values without monitoring with the SDK and system metrics leads to constant resource contention/stealing
This decreases the total throughput and increases latency jitter of the system.

### Invariants (JavaSDK only) {#invariants}

These properties should always be true for a Worker's configuration.

Perform this sanity check after the adjustments to Worker settings.

1. `workflowCacheSize` should be ≤ `maxWorkflowThreadCount`. Each Workflow has at least one Workflow thread.
2. `maxConcurrentWorkflowTaskExecutionSize` should be ≤ `maxWorkflowThreadCount`. Having more Worker slots than the Workflow cache size will lead to resource contention/stealing between executors and unpredictable delays. It's recommended that `maxWorkflowThreadCount` be at least 2x of `maxConcurrentWorkflowTaskExecutionSize`.
3. `maxConcurrentWorkflowTaskPollers` should be significantly ≤ `maxConcurrentWorkflowTaskExecutionSize`. And `maxConcurrentActivityTaskPollers` should be significantly ≤ `maxConcurrentActivityExecutionSize`. The number of pollers should always be lower than the number of executors.

## Worker runtime performance tuning {#worker-performance-tuning}

Worker tuning manages the assignment of slot suppliers.
A **Worker Tuner** instance exists per-Worker, providing slot suppliers for different slot types (Activity, Workflow, Nexus, or Local Activity Tasks).
A tuner assigns different suppliers to each slot type.
For example, it might provide a fixed assignment slot supplier for Workflows and use a resource-based supplier for Activities.

### Choosing slot supplier types

Temporal offers three types of slot suppliers: fixed assignment, resource-based, and custom.
Here’s how to choose the best approach based on your system requirements and workload characteristics.

When choosing whether to opt for fixed assignment or resource-based suppliers, consider:

- Workflow Tasks make minimal demands on the CPU and, normally, do not consume much memory.
  They are well-served by fixed-sized slot suppliers.
- When very low Task completion latency is a concern, avoid resourced-based auto-tuning slot suppliers.
- Reserve auto-tuned resource-based slot suppliers for deployments focused on avoiding Worker overload.
  They provide excellent balance with built-in throttling that ensures the Worker will be cautious when handing out new executor slots.

The following use cases are particularly well suited to resource-based auto-tuning slot suppliers:

- **Fluctuating workloads with low per-Task consumption**:
  The resource-based supplier works well when each Task consumes few resources but may run for a (relatively) long time.
  For example: HTTP calls or other blocking I/Os that spend most of their time waiting on external events.
- **Protection from out-of-memory & over-subscription in the face of unpredictable per-task consumption:**
  Do your Tasks often consume an unpredictable number of resources?
  Do you want to avoid crashes without setting an overly-conservative fixed limit?
  In these cases, the resource-based supplier is a good match.
  Keep in mind that auto-tuning can never do a _perfect_ job and may sometimes exceed your requested system limits for CPU and memory.

For the highest level of control over slot allocation, consider custom slot suppliers.
This allows you to tailor the logic of how slots are allocated based on your system requirements.
Custom suppliers provide flexibility to optimize for specific use cases that fixed assignment and resource-based suppliers may not fully address.

Choosing the right slot supplier depends on your workload complexity and the control you need over resource allocation.
For predictable tasks, variable workloads, or complex dynamic scenarios, Temporal slot suppliers can meet your needs.

### Implement Custom Slot Suppliers {#custom-slot-implementation}

Implement your own Slot Supplier to control how Workers are allocated Tasks and manage the processing of Workflows, Activities, and Nexus Operations.
Custom Slot Suppliers let you fine-tune task processing based on your application's needs.

Each SDK's reference documentation explains the specifics of the interface, but the core concepts are consistent across SDKs:

| Language                                               | Slot Supplier Reference                                                                                                  |
| ------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------ |
|      | [`SlotSupplier`](https://pkg.go.dev/go.temporal.io/sdk/worker#SlotSupplier)                                              |
|        | [`SlotSupplier`](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/worker/tuning/SlotSupplier.html) |
|      | [`CustomSlotSupplier`](https://python.temporal.io/temporalio.worker.CustomSlotSupplier.html)                             |
|  | [`CustomSlotSupplier`](https://typescript.temporal.io/api/interfaces/worker.CustomSlotSupplier)                          |
|      | [`CustomSlotSupplier`](https://dotnet.temporal.io/api/Temporalio.Worker.Tuning.CustomSlotSupplier.html)                  |

Slot Suppliers issue `SlotPermit`s.
These represent the right to use a slot of a specific type, namely Workflow, Activity, Local Activity, or Nexus.
You control whether a Worker can perform certain tasks by issuing or withholding permits.

Custom Slot Suppliers must implement these functions:

- `reserveSlot` - Called before polling for new tasks. Your implementation can block and must return a Slot Permit once it decides to accept new work.
- `tryReserveSlot` - Called for slot reservations in cases like eager activity processing. This must not block.
- `markSlotUsed` - Called when a slot is about to be used for a task (not while it’s held during polling). It provides information about the task.
- `releaseSlot` - Called when a slot is no longer needed, whether or not it was used.

Custom policies require more effort, but provide finer control over Task processing.
By implementing your own Slot Supplier, you can tailor how Workflows, Activities, and Nexus Operations are handled, optimizing performance for your specific needs.

### Slot supplier throttles

Auto-tuned suppliers may diverge from requested thresholds.
The resources a given Task will use can't be known ahead of time.
There is a fundamental tradeoff between how quickly a slot supplier is willing to accept Tasks and how well it can respect the defined thresholds.

Slot throttling is a mechanism to control the rate at which new slots for concurrent tasks are made available for processing.
This concept is part of the resource-based auto-tuning feature for Workers.
By waiting a brief period between making slots available, the Worker can assess how resource usage has changed since the last task began processing

This throttle is called `rampThrottle` in the SDK options for resource-based slot suppliers.
It defines the minimum time the Worker will wait between handing out new slots after passing the minimum slots number.

If a just-started worker were to have no throttle, and there was a backlog of Tasks, it might immediately accept 100 Tasks at once.
If each Task allocated 1GB of RAM, the Worker would likely run out of memory and crash.
The throttle enforces a wait before handing out new slots (after a minimum number of slots have been occupied) so you can measure newly consumed resources.

## Performance tuning examples {#examples}

The following examples show how to create and provision composite Worker tuners and set other
performance related options.
Each tuner provides slot suppliers for various Task types.
These examples focus on Activities and Local Activities, since Workflow Tasks normally do not need resource-based tuning.

### Go SDK

```go
// Using the ResourceBasedTuner in worker options
tuner, err := resourcetuner.NewResourceBasedTuner(resourcetuner.ResourceBasedTunerOptions{
    TargetMem: 0.8,
    TargetCpu: 0.9,
})
if err != nil {
  return err
}
workerOptions := worker.Options{
    Tuner: tuner
}
// Combining different types
options := DefaultResourceControllerOptions()
options.MemTargetPercent = 0.8
options.CpuTargetPercent = 0.9
controller := NewResourceController(options)
wfSS, err := worker.NewFixedSizeSlotSupplier(10)
if err != nil {
  return err
}
actSS := &ResourceBasedSlotSupplier{controller: controller,
    options: defaultActivityResourceBasedSlotSupplierOptions()}
laSS := &ResourceBasedSlotSupplier{controller: controller,
    options: defaultActivityResourceBasedSlotSupplierOptions()}
nexusSS, err := worker.NewFixedSizeSlotSupplier(10)
if err != nil {
  return err
}
compositeTuner, err := worker.NewCompositeTuner(worker.CompositeTunerOptions{
    WorkflowSlotSupplier:      wfSS,
    ActivitySlotSupplier:      actSS,
    LocalActivitySlotSupplier: laSS,
    NexusSlotSupplier:         nexusSS,
})
if err != nil {
  return err
}
workerOptions := worker.Options{
    Tuner: compositeTuner
}
```

### Java SDK

```java
// Just resource based
WorkerOptions.newBuilder()
    .setWorkerTuner(
        ResourceBasedTuner.newBuilder()
            .setControllerOptions(
                ResourceBasedControllerOptions.newBuilder(0.8, 0.9).build())
            .build())
    .build())
// Combining different types
SlotSupplier<WorkflowSlotInfo> workflowTaskSlotSupplier = new FixedSizeSlotSupplier<>(10);
SlotSupplier<ActivitySlotInfo> activityTaskSlotSupplier =
    ResourceBasedSlotSupplier.createForActivity(
        resourceController, ResourceBasedTuner.DEFAULT_ACTIVITY_SLOT_OPTIONS);
SlotSupplier<LocalActivitySlotInfo> localActivitySlotSupplier =
    ResourceBasedSlotSupplier.createForLocalActivity(
        resourceController, ResourceBasedTuner.DEFAULT_ACTIVITY_SLOT_OPTIONS);
SlotSupplier<NexusSlotInfo> nexusSlotSupplier = new FixedSizeSlotSupplier<>(10);

WorkerOptions.newBuilder()
    .setWorkerTuner(
        new CompositeTuner(
            workflowTaskSlotSupplier,
            activityTaskSlotSupplier,
            localActivitySlotSupplier,
            nexusSlotSupplier))
    .build();
```

### TypeScript SDK

```tsx
// Just resource based
const resourceBasedTunerOptions: ResourceBasedTunerOptions = {
  targetMemoryUsage: 0.8,
  targetCpuUsage: 0.9,
};
const workerOptions = {
  tuner: {
    tunerOptions: resourceBasedTunerOptions,
  },
};
// Combining different types
const resourceBasedTunerOptions: ResourceBasedTunerOptions = {
  targetMemoryUsage: 0.8,
  targetCpuUsage: 0.9,
};
const workerOptions = {
  tuner: {
    activityTaskSlotSupplier: {
      type: 'resource-based',
      tunerOptions: resourceBasedTunerOptions,
    },
    workflowTaskSlotSupplier: {
      type: 'fixed-size',
      numSlots: 10,
    },
    localActivityTaskSlotSupplier: {
      type: 'resource-based',
      tunerOptions: resourceBasedTunerOptions,
    },
  },
};
```

### Python SDK

```python
# Just a resource based tuner, with poller autoscaling
tuner = WorkerTuner.create_resource_based(
    target_memory_usage=0.5,
    target_cpu_usage=0.5,
)
worker = Worker(
    client,
    task_queue="foo",
    tuner=tuner,
    workflow_task_poller_behavior=PollerBehaviorAutoscaling(),
    activity_task_poller_behavior=PollerBehaviorAutoscaling()
)
# Combining different types, with poller autoscaling
resource_based_options = ResourceBasedTunerConfig(0.8, 0.9)
tuner = WorkerTuner.create_composite(
    workflow_supplier=FixedSizeSlotSupplier(10),
    activity_supplier=ResourceBasedSlotSupplier(
        ResourceBasedSlotConfig(),
        resource_based_options,
    ),
    local_activity_supplier=ResourceBasedSlotSupplier(
        ResourceBasedSlotConfig(),
        resource_based_options,
    ),
)
worker = Worker(
    client,
    task_queue="foo",
    tuner=tuner,
    workflow_task_poller_behavior=PollerBehaviorAutoscaling(),
    activity_task_poller_behavior=PollerBehaviorAutoscaling()
)
```

### .NET C# SDK

```csharp
// Just resource based
var worker = new TemporalWorker(
    Client,
    new TemporalWorkerOptions("my-task-queue")
    {
        Tuner = WorkerTuner.CreateResourceBased(0.8, 0.9),
    });
// Combining different types
var resourceTunerOptions = new ResourceBasedTunerOptions(0.8, 0.9);
var worker = new TemporalWorker(
    Client,
    new TemporalWorkerOptions("my-task-queue")
    {
        Tuner = new WorkerTuner(
             new FixedSizeSlotSupplier(10),
             new ResourceBasedSlotSupplier(
                 new ResourceBasedSlotSupplierOptions(),
                 resourceTunerOptions),
             new ResourceBasedSlotSupplier(
                 new ResourceBasedSlotSupplierOptions(),
                 resourceTunerOptions)),
    });
```

## Workflow Cache Tuning

When the number of cached Workflow Executions reported by `sticky_cache_size` hits `workflowCacheSize` _or_ the number of threads reported by the `workflow_active_thread_count` metrics gauge hits `maxWorkflowThreadCount`, Workflow Executions will start to be evicted from the cache.
An evicted Workflow Execution will need to be replayed when it gets any action that may advance it.

If the Workflow Cache limits described above are hit, and Worker hosts have enough free RAM and are not close to reasonable thread limits, then you may choose to increase `workflowCacheSize` and `maxWorkflowThreadCount` limits to decrease the overall latency and cost of the Replays in the system.
If the opposite occurs, consider decreasing the limits.

:::note

In CoreSDK based SDKs, like TypeScript, this metric works differently and should be monitored and adjusted on a per Worker and Task Queue basis.

:::

## Available Task Queue information {#task-queue-metrics}

:::tip Support, stability, and dependency info

The information listed in this section is readable using the `DescribeTaskQueueEnhanced` method in the [Go SDK](https://github.com/temporalio/sdk-go/blob/74320648ab0e4178b1fedde01672f9b5b9f6c898/client/client.go), with the [Temporal CLI](https://github.com/temporalio/cli/releases/tag/v1.1.0) `task-queue describe` command, and using `DescribeTaskQueue` through RPC.

:::

The Temporal Service reports information separately for each Task Queue type (not aggregated).
Use the following Task Queue properties to retrieve and evaluate information about Task Queue health and performance.
Available data include:

- [`ApproximateBacklogCount`](#ApproximateBacklogCountAndAge) and [`ApproximateBacklogAge`](#ApproximateBacklogCountAndAge)
- [`TasksAddRate`](#TasksAddRate-and-TasksDispatchRate) and [`TasksDispatchRate`](#TasksAddRate-and-TasksDispatchRate)
- [`BacklogIncreaseRate`](#BacklogIncreaseRate) (derived from [`TasksAddRate`](#TasksAddRate-and-TasksDispatchRate) and [`TasksDispatchRate`](#TasksAddRate-and-TasksDispatchRate))

### `ApproximateBacklogCount` and `ApproximateBacklogAge` {#ApproximateBacklogCountAndAge}

`ApproximateBacklogCount` represents the approximate count of Tasks currently backlogged in this Task Queue.
The number may include expired Tasks as well as active Tasks, but it will eventually converge to the correct count over time.

`ApproximateBacklogAge` returns the approximate age of the oldest Task in the backlog.
The age is based on the creation time of the Task at the head of the queue.

You can rely on both these counts when making scaling decisions.

Please note: [Sticky queues](https://docs.temporal.io/sticky-execution) will affect these values, but only for a few seconds.
That's because Tasks sent to Sticky queues are not included in the returned values for `ApproximateBacklogCount` and `ApproximateBacklogAge`.
Inaccuracies diminish as the backlog grows.

### `TasksAddRate` and `TasksDispatchRate` {#TasksAddRate-and-TasksDispatchRate}

Reports the approximate Tasks-per-second added to or dispatched from a Task Queue.
This rate is averaged over the most recent 30-second time interval.
The calculations include Tasks that were added to or dispatched from the backlog as well as Tasks that were immediately dispatched and bypassed the backlog (sync-matched).

The actual Task delivery count may be significantly higher than the number reported by these two values:

- Eager dispatch refers to a Temporal feature where Activities can be requested by an SDK using one Workflow Task completion response.
  Tasks using Eager dispatch do not pass through Task Queues.
- Tasks passed to Sticky Task Queues not included in the returned values for `TasksAddRate` and `TasksDispatchRate`.

### `BacklogIncreaseRate` {#BacklogIncreaseRate}

Approximates the _net_ Tasks per second added to the backlog, averaged over the most recent 30 seconds.
This is calculated as:

```
TasksAddRate - TasksDispatchRate
```

- Positive values of `X` indicate the backlog is growing by about `X` Tasks per second.
- Negative values of `X` indicate the backlog is shrinking by about `X` Tasks per second.

While individual `add` and `dispatch` rates may be inaccurate due to Eager and Sticky Task Queues, the `BacklogIncreaseRate` reliably reflects the rate at which the backlog is shrinking or growing for backlogs older than a few seconds.

## Evaluate Task Queue performance {#evaluate-worker-loads}

A [Task Queue](https://docs.temporal.io/task-queue) is a lightweight, dynamically allocated queue.
[Worker Entities](/workers#worker-entity) poll the queue for [Tasks](https://docs.temporal.io/tasks#task) and retrieve Tasks to work on.
Tasks are contexts that a Worker progresses using a specific Workflow Execution, Activity Execution, or a Nexus Task Execution.
Each Task Queue type offers its Tasks to compatible Workers for Task completion.
The Temporal Service dynamically creates different [Task Queue types](/task-queue) including Activity Task Queues, Workflow Task Queues, and Nexus Task Queues.

With an accurate estimate of backlog Tasks, you can determine the optimal number of Workers to deploy.
Balance your Worker count with the number of Tasks to achieve the best performance.
This approach minimizes Task backlog saturation and reduces idle Workers.

Task Queue data provide numerical insights into your Task Queue activity and backlog characteristics.
Use these numbers to tune your production deployments.
Evaluate your Worker loads and assess whether you need to scale up or reduce your Worker deployment.

:::note RATE LIMITS

[Visibility API rate limits](/cloud/limits#visibility-api-rate-limit) apply to Task Queue performance data requests.

:::

### Query Task Queue info with Temporal CLI {#cli-task-queue-info}

The Temporal CLI helps you monitor and evaluate Worker performance.
Issue the following command to display a list of active Workers that have recently polled a Task Queue:

```
temporal task-queue describe \
    --task-queue YourTaskQueueName \
    [additional options]
```

This command retrieves poller information, backlog statistics, and task reachability for Task types (available in Temporal Server v1.25.0, Temporal CLI 1.1 and later).

:::warning

Task reachability status is experimental.
Determining Task reachability incurs a non-trivial computing cost.
This feature may significantly change or be removed in a future release.

:::

### Query Task Queue info with the Go SDK {#go-sdk-task-queue-info}

Retrieve Task Queue data using the Go SDK by calling `DescribeTaskQueueEnhanced`.
Specify the Task Queue name and set `ReportStats` to `true`, as in the following example:

```go
for _, taskQueueName := range taskQueueNames {
        resp, err := s.client.DescribeTaskQueueEnhanced(ctx, client.DescribeTaskQueueEnhancedOptions{
            TaskQueue:   taskQueueName,
            ReportStats: true,
        })
        if err != nil {
            log.Printf("Error describing task queue %s: %v", taskQueueName, err)
        }

        // Get the backlog count from the enhanced response
        backlogCount += getBacklogCount(resp)
    }
```

### Evaluate Worker availability and capacity issues {#worker-capacity-issues}

Each Temporal [Server](https://docs.temporal.io/temporal-service/temporal-server) records the last time of each poll request.
This time is displayed in the `temporal task-queue describe` output.

- A `LastAccessTime` value exceeding one minute may indicate that the Worker fleet is at capacity or that Workers have shut down or been removed.

- Values under 5 minutes typically suggest the Worker fleet is at capacity.
  "At capacity" means that all Workflow and Activity slots are full.

- Values over 5 minutes since the last poll request usually suggest that Workers have shut down or been removed.
  Workers are removed if 5 minutes have passed since the last poll request.

### Manage your Worker fleet {#manage-your-worker-fleet}

You can adjust the number of Workers to enhance Workflow Execution performance and manage your fleet size.
For instance, a large backlog of Tasks with too few Workers will slow down Workflow Execution completions and decrease processing efficiency.
Adding more Workers boosts speeds up completion rates and improves throughput.
An empty backlog indicates low Worker utilization, allowing you to reduce your fleet and associated costs.

The values provided by `temporal task-queue describe` can help you manage your Worker fleet deployment:

- `ApproximateBacklogAge` shows how long Tasks have been waiting to be dispatched.
  If this time grows too long, more Workers can boost Workflow efficiency.

- Calculate the demand per Worker by dividing the number of backlogged Tasks (`ApproximateBacklogCount`) by the number of Workers.
  Determine if your task processing rate is within an acceptable range for your needs using the per-Worker demand (how many Tasks each Worker has yet to process), the backlog consumption rate (`TasksDispatchRate`, the rate at which Workers are processing Tasks), and the dispatch latency (`ApproximateBacklogAge`, the time the oldest Task has been waiting to be assigned to a Worker).

- The backlog increase rate (`BacklogIncreaseRate`) shows the changing demand on your Workers over time.
  As this rate increases, you may need to add more Workers until demand and capacity are balanced.
  As it decreases, you may be able to reduce your Worker fleet.

## Task Queue processing tuning {#task-queues-processing-tuning}

The following steps limit delays in Task Queue processing due to insufficient or unbalanced Workers.
Review these steps if you notice high `schedule_to_start` metrics.

The steps are arranged in the recommended order of execution.

### Hosts and Resources provisioning

If currently provisioned Worker hosts are fully utilized (near full CPU usage, high load average, etc), additional Workers hosts have to be provisioned to increase the capacity of the Workers pool.

**It's possible to have too many Workers**

Monitor the poll success (`poll_success`/`poll_success_sync`) and poll timeout `poll_timeouts` Server metric counters.

Poll Success Rate = (`poll_success` + `poll_success_sync`) / (`poll_success` + `poll_success_sync` + `poll_timeouts`)

Poll Success Rate should be >90% in most cases of systems with a steady load. For high volume and low latency, try to target >95%.

If you see

1. low Poll Success Rate, and
2. low `schedule_to_start_latency`, and
3. low Worker hosts resource utilization at the same time,

then you might have too many workers, consider sizing down.

### Worker Executor Slots sizing

The main area to focus on when tuning is the number of Worker Executor Slots.
Increase the maximum number of working slots by adjusting `maxConcurrentWorkflowTaskExecutionSize` or `maxConcurrentActivityExecutionSize` if both of the following conditions are met:

1. The Worker hosts are underutilized (no bottlenecks on CPU, load average, etc.).
2. The `worker_task_slots_available` metric from the corresponding Worker type frequently shows a depleted number of available Worker slots.

Alternatively, consider using a resource-based slot supplier as described [here](#slot-suppliers).

### Poller count

Sometimes, it can be appropriate to increase the number of task pollers.
This is usually more common in situations where your Workers have somewhat high latency when communicating with the server.
You can simply use automated poller tuning to handle this automatically.

Consider manual adjustment if:

1. the `schedule_to_start` metric is abnormally long, and
2. the Worker hosts are underutilized (there are no bottlenecks on CPU, load average, etc), and
3. `worker_task_slots_available` metric from the corresponding Worker type shows that a significant percentage of Worker slots are available on a regular basis,

then consider increasing the number of pollers by adjusting `maxConcurrentWorkflowTaskPollers` or `maxConcurrentActivityTaskPollers`, depending on which type of `schedule_to_start` metric is elevated.

### Rate Limiting

If, after adjusting the poller and executors count as specified earlier, you still observe an elevated `schedule_to_start`, underutilized Worker hosts, or high `worker_task_slots_available`, you might want to check the following:

- If server-side rate limiting per Task Queue is set by `WorkerOptions#maxTaskQueueActivitiesPerSecond`, remove the limit or adjust the value up. (See [Go](/develop/go/core-application#taskqueueactivitiespersecond) and [Java](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/worker/WorkerOptions.Builder.html).)
- If Worker-side rate limiting per Worker is set by `WorkerOptions#maxWorkerActivitiesPerSecond`, remove the limit. (See [Go](/develop/go/core-application#workeractivitiespersecond), [TypeScript](https://typescript.temporal.io/api/interfaces/worker.WorkerOptions#maxconcurrentactivitytaskexecutions), and [Java](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/worker/WorkerOptions.Builder.html).)

## Related reading

- [Workers in production operation guide](https://temporal.io/blog/workers-in-production)
- [Full set of SDK Metrics reference](/references/sdk-metrics)

---

## What is a Temporal Activity?

This guide provides a comprehensive overview of Temporal Activities including [Activity Definition](/activity-definition), [Activity Type](/activity-definition#activity-type), [Activity Execution](/activity-execution), and [Local Activity](/local-activity).

An Activity is a normal function or method that executes a single, well-defined action (either short or long running), such as calling another service, transcoding a media file, or sending an email message.
Activity code can be non-deterministic.
We recommend that it be [idempotent](/activity-definition#idempotency).

Workflow code orchestrates the execution of Activities, persisting the results.
If an Activity Function Execution fails, any future execution starts from initial state (except [Heartbeats](/encyclopedia/detecting-activity-failures#activity-heartbeat)).

Activity Functions are executed by Worker Processes.
When the Activity Function returns, the Worker sends the results back to the Temporal Service as part of the [ActivityTaskCompleted](/references/events#activitytaskcompleted) Event.
The Event is added to the Workflow Execution's Event History.
For other Activity-related Events, see [Activity Events](/workflow-execution/event#activity-events).

---

## Activity Definition

This page discusses the following:

- [Activity Definition](#activity-definition)
- [Idempotency](#idempotency)
- [Constraints](#activity-constraints)
- [Parameters](#activity-parameters)
- [Activity Type](#activity-type)

In day-to-day conversation, the term _Activity_ denotes an [Activity Definition](/activity-definition), [Activity Type](/activity-definition#activity-type), or [Activity Execution](/activity-execution).
Temporal documentation aims to be explicit and differentiate between them.

## What is an Activity Definition? {#activity-definition}

An Activity Definition is the code that defines the constraints of an [Activity Task Execution](/tasks#activity-task-execution).
Activities encapsulate business logic that is prone to failure, allowing for automatic retries when issues occur.

- [How to develop an Activity Definition using the Go SDK](/develop/go/core-application#activity-definition)
- [How to develop an Activity Definition using the Java SDK](/develop/java/core-application#develop-activities)
- [How to develop an Activity Definition using the PHP SDK](/develop/php/core-application#develop-activities)
- [How to develop an Activity Definition using the Python SDK](/develop/python/core-application#develop-activities)
- [How to develop an Activity Definition using the TypeScript SDK](/develop/typescript/core-application#develop-activities)
- [How to develop an Activity Definition using the .NET SDK](/develop/dotnet/core-application#develop-activity)

The term 'Activity Definition' is used to refer to the full set of primitives in any given language SDK that provides an access point to an Activity Function Definition——the method or function that is invoked for an [Activity Task Execution](/tasks#activity-task-execution).
Therefore, the terms Activity Function and Activity Method refer to the source of an instance of an execution.

Activity Definitions are named and referenced in code by their [Activity Type](/activity-definition#activity-type).

<CaptionedImage
    src="/diagrams/activity-definition.svg"
    title="Activity Definition"
    />

### Idempotency {#idempotency}

Temporal recommends that Activities be idempotent.

Idempotence means that performing an operation multiple times has the same result as performing it once.
In the context of Temporal, Activities should be designed to be safely executed multiple times without causing unexpected or undesired side effects.

Consider the power button on your laptop. When you press it, the machine is changed from one state to the other, from on to off, and vice versa. This is not an idempotent operation. Each invocation leads to a different state. However, imagine that you modified your laptop to have separate on and off buttons. Pressing the On button multiple times would have no effect beyond the initial invocation as the laptop is already on. This action is considered idempotent.

<CaptionedImage
    src="/diagrams/idempotence-image.png"
    />

Idempotency is an important design consideration in software applications as well. You have probably encountered idempotent operations in your work already.

A few examples where idempotent operations are vital would be:

- **Infrastructure-as-Code (IaC) tool** - Conserving resources is important when you're provisioning infrastructure in the cloud. An IaC system that was not designed with idempotence in mind could lead to high costs if the function to provision a new server was accidentally invoked multiple times. An IaC tool that is designed with idempotence in mind ensures that multiple invocations of the tool doesn't lead to unintended instances being created.
- **Payment processing system** - A payment processing system must charge the customer only once for a given purchase. If the system was not designed to be idempotent, duplicate requests would result in extra charges and unhappy customers. A payment processing system that is designed to be idempotent ensures customers are not charged multiple times for the same transaction, preventing financial discrepancies.

:::info

By design, completed Activities will not re-execute as part of a [Workflow Replay](/workflow-execution#replay). However, Activities won’t record to the [Event History](/encyclopedia/retry-policies#event-history) until they return or produce an error. If an Activity fails to report to the server at all, it will be retried. Designing for idempotence, especially if you have a [Global Namespace](/global-namespace), will improve reusability and reliability.

:::

An Activity is idempotent if multiple [Activity Task Executions](/tasks#activity-task-execution) do not change the state of the system beyond the first Activity Task Execution.

The lack of idempotency might affect the correctness of your application but does not affect the Temporal Platform.
In other words, lack of idempotency doesn't lead to a platform error.

In some cases, whether something is idempotent doesn't affect the correctness of an application.
For example, if you have a monotonically incrementing counter, you might not care that retries increment the counter because you don't care about the actual value, only that the current value is greater than a previous value.

You should always make your business logic Activities idempotent in Temporal. Because Activities may be retried, these functions may be executed more than once. A non-idempotent Activity could adversely affect the state of the system.

Activities are an atomic unit of execution within Temporal. They are invoked and either complete successfully or not. Take this into consideration when you design your Activities.

For example, consider an Activity that has the following three steps:

1. Perform a database lookup
2. Make a call to a microservice with parameters retrieved from the database
3. Write the result of the microservice call to the filesystem

Imagine that the first two steps succeed, but the third step fails due to a permissions issue. During retry, the entire Activity—and therefore each of the three steps—is executed again. To maintain idempotency, design your Activities to be more granular. In this case, you could have three Activities, one for each step. This way, only the step that failed will be executed again. However, you must balance this against the potential for a larger Event History, since there would now be three Activity Executions instead of one.

Idempotence for Activities is also important due to a particular edge case inherent in distributed computing. Consider a scenario in which a Worker polls the Temporal Service, accepts the Activity Task, and begins executing the Activity. The Activity function completes successfully, but the Worker crashes just before it notifies the Temporal Service. In this case, the Event History won’t reflect the successful completion of the Task, so the Activity will be retried. If the Activity is not idempotent, this could have negative consequences, such as duplicate charges in a payment processing scenario.

For an Activity with a Retry Policy that permits retries, Temporal guarantees that the Activity will be observed as completed exactly once. However, the Activity may be executed multiple times and may even partially complete more than once during this process. This could lead to a scenario where certain parts of the Activity are executed multiple times before a successful execution is completed.

You can achieve idempotency in your application through the use of unique identifiers, known as idempotency keys, which are used to detect duplicate requests. These are enforced by the service you are calling from your Activity, not by the Activity itself.

For example, the APIs provided by most payment processors allow the client to include an idempotency key with the request. When the payment service receives a request, it checks a database to determine whether there has already been a request with this key. If so, the duplicate request is ignored and does not result in another charge. If not, then it writes a new record to the database with this key, allowing it to identify duplicate requests in the future.

In Temporal, the request to the payment service would be made from within an Activity. You can use a combination of the Workflow Run ID and the Activity ID as an idempotency key since this is guaranteed to be consistent across retry attempts but unique among Workflow Executions.

For more information about idempotency in Temporal, see the following post:

[Idempotency and Durable Execution](https://temporal.io/blog/idempotency-and-durable-execution)

### Constraints {#activity-constraints}

Activity Definitions are executed as normal functions.

In the event of failure, the function begins at its initial state when retried (except when Activity Heartbeats are established).

Therefore, an Activity Definition has no restrictions on the code it contains.

### Parameters {#activity-parameters}

An Activity Definition can support as many parameters as needed.

All values passed through these parameters are recorded in the [Event History](/workflow-execution/event#event-history) of the Workflow Execution.
Return values are also captured in the Event History for the calling Workflow Execution.

Activity Definitions must contain the following parameters:

- Context: an optional parameter that provides Activity context within multiple APIs.
- Heartbeat: a notification from the Worker to the Temporal Service that the Activity Execution is progressing. Cancelations are allowed only if the Activity Definition permits Heartbeating.
- Timeouts: intervals that control the execution and retrying of Activity Task Executions.

Other parameters, such as [Retry Policies](/encyclopedia/retry-policies) and return values, can be seen in the implementation guides, listed in the next section.

## What is an Activity Type? {#activity-type}

An Activity Type is the mapping of a name to an Activity Definition.

Activity Types are scoped through Task Queues.

---

## Activity Execution

This page discusses the following:

- [Activity Execution](#activity-execution)
- [Cancellation](#cancellation)
- [Activity Id](#activity-id)
- [Asynchronous Activity Completion](#asynchronous-activity-completion)
- [Task Token](#task-token)

## What is an Activity Execution? {#activity-execution}

An Activity Execution is the full chain of [Activity Task Executions](/tasks#activity-task-execution).

:::info

- [How to start an Activity Execution using the Go SDK](/develop/go/core-application#activity-execution)
- [How to start an Activity Execution using the Java SDK](/develop/java/core-application#activity-execution)
- [How to start an Activity Execution using the PHP SDK](/develop/php/core-application#activity-execution)
- [How to start an Activity Execution using the Python SDK](/develop/python/core-application#activity-execution)
- [How to start an Activity Execution using the TypeScript SDK](/develop/typescript/core-application#activity-execution)
- [How to start an Activity Execution using the .NET SDK](/develop/dotnet/core-application#activity-execution)

:::
<CaptionedImage
    src="/diagrams/activity-execution.svg"
    title="Activity Execution"
    />

You can customize [Activity Execution timeouts](/encyclopedia/detecting-activity-failures#start-to-close-timeout) and [retry policies](/encyclopedia/retry-policies).

If an Activity Execution fails (because it exhausted all retries, threw a [non-retryable error](/encyclopedia/retry-policies#non-retryable-errors), or was canceled), the error is returned to the [Workflow](/workflows), which decides how to handle it.

:::note

Temporal guarantees that an Activity Task either runs or timeouts.
There are multiple failure scenarios when an Activity Task is lost.
It can be lost during delivery to a Worker or after the Activity Function is called and the Worker crashed.

Temporal doesn't detect task loss directly.
It relies on [Start-To-Close timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout).
If the Activity Task times out, the Activity Execution will be retried according to the Activity Execution Retry Policy.

In scenarios where the Activity Execution Retry Policy is set to `1` and a Timeout occurs, the Activity Execution will not be tried.

:::

## Cancellation {#cancellation}

Activity Cancellation:

- lets the Activity know it doesn't need to keep doing work, and
- gives the Activity time to clean up any resources it has created.

Activities must heartbeat to receive cancellations from a Temporal Service.

An Activity may receive Cancellation if:

- The Activity was requested to be Cancelled. This can often cascade from Workflow Cancellation, but not always—SDKs have ways to stop Cancellation from cascading. {/* TODO link to workflow cancellation */}
- The Activity was considered failed by the Server because any of the Activity timeouts have triggered (for example, the Server didn't receive a heartbeat within the Activity's Heartbeat timeout). The [Cancelled Failure](/references/failures#cancelled-failure) that the Activity receives will have `message: 'TIMED_OUT'`.
- The Workflow Run reached a [Closed state](/workflow-execution#workflow-execution-status), in which case the Cancelled Failure will have `message: 'NOT_FOUND'`.
- In some SDKs:
  - The Worker is shutting down.
  - An Activity sends a Heartbeat but the Heartbeat details can't be converted by the Worker's configured [Data Converter](/dataconversion). This fails the Activity Task Execution with an Application Failure.
  - The Activity timed out on the Worker side and is not Heartbeating or the Temporal Service hasn't relayed a Cancellation.

There are different ways to receive Cancellation depending on the SDK. {/* TODO link to dev guide */}
An Activity may accept or ignore Cancellation:

- To allow Cancellation to happen, let the Cancellation Failure propagate.
- To ignore Cancellation, catch it and continue executing.

Some SDKs have ways to shield tasks from being stopped while still letting the Cancellation propagate.

The Workflow can also decide if it wants to wait for the Activity Cancellation to be accepted or to proceed without waiting.

Cancellation can only be requested a single time.
If you try to cancel your Activity Execution more than once, it will not receive more than one Cancellation request.

## What is an Activity Id? {#activity-id}

The identifier for an [Activity Execution](#activity-execution).
The identifier can be generated by the system, or it can be provided by the Workflow code that spawns the Activity Execution.
The identifier is unique among the open Activity Executions of a [Workflow Run](/workflow-execution/workflowid-runid#run-id).
(A single Workflow Run may reuse an Activity Id if an earlier Activity Execution with the same Id has closed.)

An Activity Id can be used to [complete the Activity asynchronously](#asynchronous-activity-completion).

## What is Asynchronous Activity Completion? {#asynchronous-activity-completion}

Asynchronous Activity Completion is a feature that enables an Activity Function to return without causing the Activity Execution to complete.
The Temporal Client can then be used from anywhere to both Heartbeat Activity Execution progress and eventually complete the Activity Execution and provide a result.

How to complete an Activity Asynchronously in:

- [Go](/develop/go/asynchronous-activity-completion)
- [Java](/develop/java/asynchronous-activity-completion)
- [PHP](/develop/php/asynchronous-activity-completion)
- [Python](/develop/python/asynchronous-activity-completion)
- [TypeScript](/develop/typescript/asynchronous-activity-completion)
- [.NET](/develop/dotnet/asynchronous-activity)

### When to use Async Completion

When an external system has the final result of a computation that is started by an Activity, there are three main ways of getting the result to the Workflow:

1. The external system uses Async Completion to complete the Activity with the result.
2. The Activity completes normally, without the result. Later, the external system sends a Signal to the Workflow with the result.
3. A subsequent Activity [polls the external system](https://community.temporal.io/t/what-is-the-best-practice-for-a-polling-activity/328/2) for the result.

If you don't have control over the external system—that is, you can't add Async Completion or a Signal to its code—then

- you can poll (#3), or
- if the external system can reliably call a webhook (and retry calling in the case of failure), you can write a webhook handler that sends a Signal to the Workflow (#2).

The decision between using #1 vs #2 involves a few factors.
Use Async Completion if

- the external system is unreliable and might fail to Signal, or
- you want the external process to Heartbeat or receive Cancellation.

Otherwise, if the external system can reliably be trusted to do the task and Signal back with the result, and it doesn't need to Heartbeat or receive Cancellation, then you may want to use Signals.

The benefit to using Signals has to do with the timing of failure retries.
For example, consider an external process that is waiting for a human to review something and respond, and they could take up to a week to do so.
If you use Async Completion (#1), you would

- set a [Start-To-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout) of one week on the Activity,
- in the Activity, notify the external process you need the human review, and
- have the external process Asynchronously Complete the Activity when the human responds.

If the Activity fails on the second step to notify the external system and doesn't throw an error (for example, if the Worker dies), then the Activity won't be retried for a week, when the Start-To-Close Timeout is hit.

If you use Signals, you would:

- set a [Start-To-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout) of one minute on the Activity,
- in the Activity, notify the external process you need the human review,
- complete the Activity without the result, and
- have the external process Signal the Workflow when the human responds.

If the Activity fails on the second step to notify the external system and doesn't throw an error, then the Activity will be retried in a minute.

In the second scenario, the failure is retried sooner. This is particularly helpful in scenarios like this in which the external process might take a long time.

### What is a Task Token? {#task-token}

A Task Token is a unique identifier for an [Activity Task Execution](/tasks#activity-task-execution).

[Asynchronous Activity Completion](#asynchronous-activity-completion) calls take either of the following as arguments:

- a Task Token, or
- an [Activity Id](#activity-id), a [Workflow Id](/workflow-execution/workflowid-runid#workflow-id), and optionally a [Run Id](/workflow-execution/workflowid-runid#run-id).

---

## Local Activity

This page discusses [Local Activity](#local-activity).

## What is a Local Activity? {#local-activity}

A Local Activity is an [Activity Execution](/activity-execution) that executes in the same process as the [Workflow Execution](/workflow-execution) that spawns it.

Some Activity Executions are very short-living and do not need the queuing semantic, flow control, rate limiting, and routing capabilities.
For this case, Temporal supports the Local Activity feature.

The main benefit of Local Activities is that they use less Temporal Service resources (for example, fewer History events) and have much lower latency overhead (because no need to roundtrip to the Temporal Service) compared to normal Activity Executions.
However, Local Activities are subject to shorter durations and a lack of rate limiting.

Consider using Local Activities for functions that are the following:

- can be implemented in the same binary as the Workflow that calls them.
- do not require global rate limiting.
- do not require routing to a specific Worker or Worker pool.
- no longer than a few seconds, inclusive of retries.

If it takes longer than 80% of the Workflow Task Timeout (which is 10 seconds by default), the Worker will ask the Temporal Service to create a new Workflow Task to extend the "lease" for processing the Local Activity.
The Worker will continue doing so until the Local Activity has completed.
This is called Workflow Task Heartbeating.
The drawbacks of long-running Local Activities are:

- Each new Workflow Task results in 3 more Events in History.
- The Workflow won't get notified of new events like Signals and completions until the next Workflow Task Heartbeat.
- New Commands created by the Workflow concurrently with the Local Activity will not be sent to the Temporal Service until either the Local Activity completes or the next Workflow Task Heartbeat.

Using a Local Activity without understanding its limitations can cause various production issues.
**We recommend using regular Activities unless your use case requires very high throughput and large Activity fan outs of very short-lived Activities.**
More guidance in choosing between [Local Activity vs Activity](https://community.temporal.io/t/local-activity-vs-activity/290/3) is available in our forums.

---

## Child Workflows

A Child Workflow Execution is a [Workflow Execution](/workflow-execution) that is spawned from within another Workflow in the same Namespace.

- [Go SDK Child Workflow feature guide](/develop/go/child-workflows)
- [Java SDK Child Workflow feature guide](/develop/java/child-workflows)
- [PHP SDK Child Workflow feature guide](/develop/php/child-workflows)
- [Python SDK Child Workflow feature guide](/develop/python/child-workflows)
- [TypeScript SDK Child Workflow feature guide](/develop/typescript/child-workflows)
- [.NET SDK Child Workflow feature guide](/develop/dotnet/child-workflows)

A Workflow Execution can be both a Parent and a Child Workflow Execution because any Workflow can spawn another Workflow.

<CaptionedImage
    src="/diagrams/parent-child-workflow-execution-relationship.svg"
    title="Parent and Child Workflow Execution entity relationship"
    />

A Parent Workflow Execution must await on the Child Workflow Execution to spawn.
The Parent can optionally await on the result of the Child Workflow Execution.
Consider the Child's [Parent Close Policy](/parent-close-policy) if the Parent does not await on the result of the Child, which includes any use of Continue-As-New by the Parent.

:::note

Child Workflows do not carry over when the Parent uses [Continue-As-New](/workflow-execution/continue-as-new).
This means that if a Parent Workflow Execution utilizes Continue-As-New, any ongoing Child Workflow Executions will not be retained in the new continued instance of the Parent.

:::

When a Parent Workflow Execution reaches a Closed status, the Temporal Service propagates Cancellation Requests or Terminations to Child Workflow Executions depending on the Child's [Parent Close Policy](/parent-close-policy).

If a Child Workflow Execution uses Continue-As-New, from the Parent Workflow Execution's perspective the entire chain of Runs is treated as a single execution.

<CaptionedImage
    src="/diagrams/parent-child-workflow-execution-with-continue-as-new.svg"
    title="Parent and Child Workflow Execution entity relationship with Continue As New"
    />

## When to use Child Workflows

There is no reason to use Child Workflows just for code organization.
You can use object oriented structure and other code organization techniques to deal with complexities.
It is typically recommended to start from a single Workflow Definition if your problem has bounded size in terms of the number of Activity Executions and processed Signals.
It is simpler than multiple asynchronously communicating Workflows.

However, there are several valid reasons for using Child Workflows.

### Create a separate service

Because a Child Workflow Execution can be processed by a completely separate set of [Workers](/workers#worker) than the Parent Workflow Execution, it can act as an entirely separate service.
However, this also means that a Parent Workflow Execution and a Child Workflow Execution do not share any local state.
As all Workflow Executions, they can communicate only via asynchronous [Signals](/sending-messages#sending-signals).

### Partition problems into smaller chunks

An individual Workflow Execution has an [Event History](/workflow-execution/event#event-history) size limit, which imposes a couple of considerations for using Child Workflows.

On one hand, because Child Workflow Executions have their own Event Histories, they are often used to partition large workloads into smaller chunks.
For example, a single Workflow Execution does not have enough space in its Event History to spawn 100,000 [Activity Executions](/activity-execution).
But a Parent Workflow Execution can spawn 1,000 Child Workflow Executions that each spawn 1,000 Activity Executions to achieve a total of 1,000,000 Activity Executions.

However, because a Parent Workflow Execution Event History contains [Events](/workflow-execution/event#event) that correspond to the status of the Child Workflow Execution, a single Parent should not spawn more than 1,000 Child Workflow Executions.

In general, however, Child Workflow Executions result in more overall Events recorded in Event Histories than Activities.
Because each entry in an Event History is a _cost_ in terms of compute resources, this could become a factor in very large workloads.
Therefore, we recommend starting with a single Workflow implementation that uses Activities until there is a clear need for Child Workflows.

### Represent a single resource

As all Workflow Executions, a Child Workflow Execution can create a one to one mapping with a resource.
It can be used to manage the resource using its ID to guarantee uniqueness.
For example, a Workflow that manages host upgrades could spawn a Child Workflow Execution per host (hostname being a Workflow ID) and use them to ensure that all operations on the host are serialized.

### Periodic logic execution

A Child Workflow can be used to execute some periodic logic without overwhelming the Parent Workflow Event History.
In this scenario, the Parent Workflow starts a Child Workflow which executes periodic logic calling [Continue-As-New](/workflow-execution/continue-as-new) as many times as needed, then completes.
From the Parent point of view, it is just a single Child Workflow invocation.

### Child Workflow versus an Activity

Child Workflow Executions and Activity Executions are both started from Workflows, so you might feel confused about when to use which.
Here are some important differences:

- A Child Workflow has access to all Workflow APIs but is subject to the same [deterministic constraints](/workflow-definition#deterministic-constraints) as other Workflows.
  An Activity has the inverse pros and cons—no access to Workflow APIs but no Workflow constraints.
- A Child Workflow Execution can continue on if its Parent is canceled with a [Parent Close Policy](/parent-close-policy) of `ABANDON`.
  An Activity Execution is _always_ canceled when its Workflow Execution is canceled.
  (It can react to a cancellation Signal for cleanup.)
  The decision is roughly analogous to spawning a child process in a terminal to do work versus doing work in the same process.
- Temporal tracks all state changes within a Child Workflow Execution in Event History.
  Only the input, output, and retry attempts of an Activity Execution is tracked.

A Workflow models composite operations that consist of multiple Activities or other Child Workflows.
An Activity usually models a single operation on the external world.

Our advice: **When in doubt, use an Activity.**

---

## Parent Close Policy

This page discusses [Parent Close Policy](#parent-close-policy).

## What is a Parent Close Policy? {#parent-close-policy}

A Parent Close Policy determines what happens to a Child Workflow Execution if its Parent changes to a Closed status (Completed, Failed, or Timed out).

- [How to set a Parent Close Policy using the Go SDK](/develop/go/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the Java SDK](/develop/java/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the PHP SDK](/develop/php/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the Python SDK](/develop/python/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the TypeScript SDK](/develop/typescript/child-workflows#parent-close-policy)
- [How to set a Parent Close Policy using the .NET SDK](/develop/dotnet/child-workflows#parent-close-policy)

There are three possible values:

- **Abandon:** the Child Workflow Execution is not affected.
- **Request Cancel:** a Cancellation request is sent to the Child Workflow Execution.
- **Terminate** (default): the Child Workflow Execution is forcefully Terminated.

[`ParentClosePolicy`](https://github.com/temporalio/api/blob/c1f04d0856a3ba2995e92717607f83536b5a44f5/temporal/api/enums/v1/workflow.proto#L44) proto definition.

Each Child Workflow Execution may have its own Parent Close Policy.
This policy applies only to Child Workflow Executions and has no effect otherwise.

<CaptionedImage
    src="/diagrams/parent-close-policy.svg"
    title="Parent Close Policy entity relationship"
    />

You can set policies per child, which means you can opt out of propagating terminates / cancels on a per-child basis.
This is useful for starting Child Workflows asynchronously (see [relevant issue here](https://community.temporal.io/t/best-way-to-create-an-async-child-workflow/114) or the corresponding SDK docs).

---

## Codec Server

This page discusses [Codec Server](#codec-server).

## What is a Codec Server? {#codec-server}

A Codec Server is an HTTP/HTTPS server that uses a [custom Payload Codec](/production-deployment/data-encryption) to decode your data remotely through endpoints.

{/* This should not have changed with tctl-to-temporal */}

<CaptionedImage
    src="/diagrams/tctl-diagram-codec-server.svg"
    title="Codec Server"
    width="50%"
    zoom="true"
/>

A Codec Server follows the Temporal [Codec Server Protocol](https://github.com/temporalio/samples-go/tree/main/codec-server#codec-server-protocol).
It implements two endpoints:

- `/encode`
- `/decode`

Each endpoint receives and responds with a JSON body that has a `payloads` property with an array of [Payloads](/dataconversion#payload).
The endpoints run the Payloads through a [Payload Codec](/payload-codec) before returning them.

Most SDKs provide example Codec Server implementation samples, listed here:

- [Go](https://github.com/temporalio/samples-go/tree/main/codec-server)
- [Java](https://github.com/temporalio/sdk-java/tree/master/temporal-remote-data-encoder)
- [.NET](https://github.com/temporalio/samples-dotnet/tree/main/src/Encryption)
- [Python](https://github.com/temporalio/samples-python/blob/main/encryption/codec_server.py)
- [TypeScript](https://github.com/temporalio/samples-typescript/blob/main/encryption/src/codec-server.ts)

#### Usage

When you apply custom encoding with encryption or compression on your Workflow data, it is stored in the encrypted/compressed format on the Temporal Server. For details on what data is encoded, see [Securing your data](/production-deployment/data-encryption).

To see decoded data when using the Temporal CLI or Web UI to perform some operations on a Workflow Execution, configure the Codec Server endpoint in the Web UI and the Temporal CLI.
When you configure the Codec Server endpoints, the Temporal CLI and Web UI send the encoded data to the Codec Server, and display the decoded data received from the Codec Server.

For details on creating your Codec Server, see [Codec Server Setup](/production-deployment/data-encryption#codec-server-setup).

---

## How does Temporal handle application data?

This guide provides an overview of data handling using a Data Converter on the Temporal Platform.

Data Converters in Temporal are SDK components that handle the serialization and encoding of data entering and exiting a Temporal Service.
Workflow inputs and outputs need to be serialized and deserialized so they can be sent as JSON to a Temporal Service.

<CaptionedImage
    src="/diagrams/default-data-converter.svg"
    title="Data Converter encodes and decodes data"
    />

The Data Converter encodes data from your application to a [Payload](/dataconversion#payload) before it is sent to the Temporal Service in the Client call.
When the Temporal Server sends the encoded data back to the Worker, the Data Converter decodes it for processing within your application.
This ensures that all your sensitive data exists in its original format only on hosts that you control.

Data Converter steps are followed when data is sent to a Temporal Service (as input to a Workflow) and when it is returned from a Workflow (as output).
Due to how Temporal provides access to Workflow output, this implementation is asymmetric:

- Data encoding is performed automatically using the default converter provided by Temporal or your custom Data Converter when passing input to a Temporal Service. For example, plain text input is usually serialized into a JSON object.
- Data decoding may be performed by your application logic during your Workflows or Activities as necessary, but decoded Workflow results are never persisted back to the Temporal Service. Instead, they are stored encoded on the Temporal Service, and you need to provide an additional parameter when using [`temporal workflow show`](/cli/workflow#show) or when browsing the Web UI to view output.

Each piece of data (like a single argument or return value) is encoded as a [Payload](/dataconversion#payload), which consists of binary data and key-value metadata.

For details, see the API references:

- [Go](https://pkg.go.dev/go.temporal.io/sdk/converter#DataConverter)
- [Java](https://www.javadoc.io/doc/io.temporal/temporal-sdk/latest/io/temporal/common/converter/DataConverter.html)
- [Python](https://python.temporal.io/temporalio.converter.DataConverter.html)
- [TypeScript](https://typescript.temporal.io/api/interfaces/common.DataConverter)

### What is a Payload? {#payload}

A [Payload](https://api-docs.temporal.io/#temporal.api.common.v1.Payload) represents binary data such as input and output from Activities and Workflows.
Payloads also contain metadata that describe their data type or other parameters for use by custom encoders/converters.

When processed through the SDK, the [default Data Converter](/default-custom-data-converters#default-data-converter) serializes your data/value to a Payload before sending it to the Temporal Server.
The default Data Converter processes supported type values to Payloads. You can create a custom [Payload Converter](/payload-converter) to apply different conversion steps.

You can additionally apply [custom codecs](/payload-codec), such as for encryption or compression, on your Payloads.

---

## Default and Custom Data Converters

This page discusses the following:

- [Default Data Converter](#default-data-converter)
- [Custom Data Converter](#custom-data-converter)

## What is a default Data Converter? {#default-data-converter}

Each Temporal SDK includes and uses a default Data Converter.
The default Data Converter converts objects to bytes using a series of Payload Converters and supports binary, Protobufs, and JSON formats.
It encodes values in the following order:

- Null
- Byte array
- Protobuf JSON
- JSON

In SDKs that cannot determine parameter types at runtime (for example, TypeScript), Protobufs aren't included in the default converter.

For example:

- If a value is an instance of a Protobuf message, it is encoded with [proto3 JSON](https://developers.google.com/protocol-buffers/docs/proto3#json).
- If a value isn't null, binary, or a Protobuf, it is encoded as JSON. Most common input types — including strings, integers, floating point numbers, and booleans — are serializable as JSON. If any part of it is not serializable as JSON, {/* (for example, a Date—see JSON data types) */} an error is thrown.

The default Data Converter serializes objects based on their root type, rather than nested types.
The JSON serializers of some SDKs cannot process lists with Protobuf children objects without implementing a [custom Data Converter](#custom-data-converter).

## What is a custom Data Converter? {#custom-data-converter}

A custom Data Converter extends the default Data Converter with custom logic for [Payload](/dataconversion#payload) conversion or encoding.

You can create a custom Data Converter to alter formats (for example, using [MessagePack](https://msgpack.org/) instead of JSON) or add compression and encryption.

A Payload Codec encodes and decodes [Payloads](/dataconversion#payload), with bytes-to-bytes conversion.
To use custom encryption or compression logic, create a custom Payload Codec with your encryption/compression logic in the `encode` function and your decryption/decompression logic in the `decode` function.
To implement a custom Payload Codec, you can override the default Data Converter, or create a customized Data Converter that defines its own Payload Converter.

Custom Data Converters are not applied to all data; for example, [Search Attributes](/search-attribute) are persisted unencoded so they can be indexed for searching.

A customized Data Converter can have the following three components:

- [Payload Converter](/payload-converter)
- [Payload Codec](/payload-codec)
- [Failure Converter](/failure-converter)

For details on how to implement custom encryption and compression in your SDK, see [Data Encryption](/production-deployment/data-encryption).

---

## Failure Converter

This page discusses [Failure Converter](#failure-converter).

## What is a Failure Converter? {#failure-converter}

As with input and output, Temporal also uses its own default converter logic for errors that are generated by Workflows.
The default Failure Converter copies error messages and call stacks as plain text, and this text output is then directly accessible in the `Message` field of these Workflow Executions.

This may be undesirable for your application. In some cases, errors could contain privileged or sensitive information that you would need to prevent from leaking or being available via a side channel.
Failure messages and call stacks are not encoded as codec-capable Payloads by default; you must explicitly enable encoding these common attributes on failures.

If your errors might contain sensitive information, you can encrypt the message and call stack by configuring the default Failure Converter to use your encoding.
This moves your `message` and `stack_trace` fields to a Payload that's run through your codec.

For example, with the Temporal Go SDK, you can do this by adding a `FailureConverter` parameter to your `client.Options{}` array when calling `client.Dial()`.
The `FailureConverter` should override the `DefaultFailureConverterOptions{}` by setting `EncodeCommonAttributes: true` like so:

```go
c, err := client.Dial(client.Options{
	// Set DataConverter here to ensure that workflow inputs and results are
	// encoded as required.
	DataConverter: mycustom.DataConverter,
	FailureConverter: temporal.NewDefaultFailureConverter(temporal.DefaultFailureConverterOptions{
		EncodeCommonAttributes: true,
	}),
})
```

If for some reason you need to specify a different set of Converter logic for your Failures, you can replace the `NewDefaultFailureConverter` with a custom method.
For example, if you are both working with highly sensitive data and using a sophisticated logging/observability implementation, you may need to implement different encryption methods for each of them.

---

## Key Management

This page discusses [Key Management](#key-management).

## What is Key Management? {#key-management}

Key Management is a fundamental part of working with encryption keys.

There are many computational and logistical aspects to generating and rotating keys, and this usually calls for a dedicated application in your stack. Here are some general recommendations for working with encryption keys for Temporal applications:

- [Symmetric Encryption](https://en.wikipedia.org/wiki/Symmetric-key_algorithm) is generally faster and will produce smaller payloads than asymmetric. Normally, an advantage of _asymmetric_ encryption is that it allows you to distribute your encryption and decryption keys separately, but depending on your infrastructure, this might not offer any security benefits with Temporal.

- AES-based algorithms are [hardware accelerated in Go](https://pkg.go.dev/crypto/aes) and other languages. AES algorithms are widely vetted and trusted, and there are many different variants that may suit your requirements. Load tests using `ALG_AES_256_GCM_HKDF_SHA512_COMMIT_KEY` have performed well.

- Store your encryption keys in the same manner as you store passwords, config details, and other sensitive data. When possible, load the key into your application, so you don't need to make a network call to retrieve it. Separate keys for each environment or namespace as much as possible.

- Make sure you have a key rotation strategy in place in the event that your keys are compromised or need to be replaced for another reason. Consider using a dedicated secrets engine or a key management system (KMS). Note that when you rotate keys, you may also need to retain old keys to query old Workflows.

### Key Rotation

National Institute of Standards and Technology (NIST) guidance recommends periodic rotation of encryption keys. For AES-GCM keys, rotation should occur before approximately 2^32 encryptions have been performed by a key version, following the guidelines of NIST publication 800-38D.

It is recommended that operators estimate the encryption rate of a key and use that to determine a frequency of rotation that prevents the guidance limits from being reached. For example, if one determines that the estimated rate is 40 million operations per day, then rotating a key every three months is sufficient.

Key rotation should generally be transparent to the Temporal Data Converter implementation. Temporal's `Encode()` and `Decode()` steps only need to trigger as expected, and Temporal has no knowledge of how or when you are generating your encryption keys.

You should design your Encode and Decode steps to accept all the necessary parameters for your key management, such as the key version, alongside your payloads. Like the Data Converters, keys should be mapped to a Namespace in Temporal.

### Using Vault for Key Management

[This repository](https://github.com/zboralski/codecserver) provides a robust and complete example of using Temporal with HashiCorp's [Vault](https://www.vaultproject.io/) secrets engine.

---

## Payload Codec

This page discusses [Payload Codec](#payload-codec).

## What is a Payload Codec? {#payload-codec}

A Payload Codec transforms an array of [Payloads](/dataconversion#payload) (for example, a list of Workflow arguments) into another array of Payloads.

When serializing to Payloads, the Payload Converter is applied first to convert your objects to bytes, followed by codecs that convert bytes to bytes.
When deserializing from Payloads, codecs are applied first to last to reverse the effect, followed by the Payload Converter.

Use a custom Payload Codec to transform your Payloads; for example, implementing compression and/or encryption on your Workflow Execution data.

### Encryption {#encryption}

Using end-to-end encryption in your custom Data Converter ensures that sensitive application data is secure when handled by the Temporal Server.

Apply your encryption logic in a custom Payload Codec and use it locally to encrypt data.
You maintain all the encryption keys, and the Temporal Server sees only encrypted data. Refer to [What is Key Management?](/key-management) for more guidance.

Your data exists unencrypted only on the Client and the Worker process that is executing the Workflows and Activities, on hosts that you control. For details, see [Securing your data](/production-deployment/data-encryption).

The following samples use encryption (AES GCM with 256-bit key) in a custom Data Converter:

- [Go sample](https://github.com/temporalio/samples-go/tree/main/encryption)
- [Java sample](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/encryptedpayloads)
- [Python sample](https://github.com/temporalio/samples-python/tree/main/encryption)
- [TypeScript sample](https://github.com/temporalio/samples-typescript/tree/main/encryption)

---

## Payload Converter

This page discusses [Payload Converter](#payload-converter).

## What is a Payload Converter? {#payload-converter}

A Payload Converter serializes data, converting values to bytes and back.

When you initiate a Workflow Execution through a Client and pass data as input, the input is serialized using a Data Converter that runs it through a set of Payload Converters.
When your Workflow Execution starts, this data input is deserialized and passed as input to your Workflow.

### Composite Data Converters {#composite-data-converters}

A Composite Data Converter is used to apply custom, type-specific Payload Converters in a specified order.
A Composite Data Converter can be comprised of custom rules that you created, and it can also leverage the default Data Converters built into Temporal.
In fact, the default Data Converter logic is implemented internally in the Temporal source as a Composite Data Converter. It defines these rules in this order:

```go
defaultDataConverter = NewCompositeDataConverter(
    NewNilPayloadConverter(),
    NewByteSlicePayloadConverter(),
    NewProtoJSONPayloadConverter(),
    NewProtoPayloadConverter(),
    NewJSONPayloadConverter(),
)
```

The order in which the Payload Converters are applied is important.
During serialization, the Data Converter tries the Payload Converters in that specific order until a Payload Converter returns a non-nil Payload.
A custom PayloadConverter must implement the functions:

- `FromPayload` (for a single value) or
- `FromPayloads` (for a list of values) to convert to values from a Payload, and
- `ToPayload` (for a single value) or
- `ToPayloads` (for a list of values) to convert values to a Payload.

Defining a new Composite Data Converter is not always necessary to implement custom data handling.
Each SDK allows you to override or configure the default Converter with a custom Payload Codec.

---

## Remote Data Encoding

This page discusses [Remote Data Encoding](#remote-data-encoding).

## What is remote data encoding? {#remote-data-encoding}

Remote data encoding is exposing your Payload Codec via HTTP endpoints to support remote encoding and decoding.

Running your encoding remotely allows you to use it with the [Temporal CLI](/cli) to encode/decode data for several commands including `temporal workflow show` and with Temporal Web UI to decode data in your Workflow Execution details view.

To run data encoding/decoding remotely, use a [Codec Server](/codec-server). A Codec Server is an HTTP server that uses your custom Codec logic to decode your data remotely.
The Codec Server is independent of the Temporal Service and decodes your encrypted payloads through predefined endpoints.
You create, operate, and manage access to your Codec Server in your own environment.
The Temporal CLI and the Web UI in turn provide built-in hooks to call the Codec Server to decode encrypted payloads on demand.

### Encoding data on the Web UI and CLI

You can perform some operations on your Workflow Execution using the Temporal CLI and the Web UI.
For example. you can start or signal an active Workflow Execution from the Temporal CLI or cancel a Workflow Execution from the Web UI, which might require inputs that contain sensitive data.

To encode this data, specify your [Codec Server endpoints](/codec-server) with the `codec-endpoint` parameter in [the Temporal CLI](/cli) and configure your Web UI to use the Codec Server endpoints.

### Decoding data on the Web UI and CLI

If you use custom encoding, Payload data handled by the Temporal Service is stored encoded. Since the Web UI uses the [Visibility](/temporal-service/visibility) database to show events and data stored on the Temporal Server, all data in the Workflow Execution History in your Web UI is displayed in the encoded format.

To decode output when using the Web UI and the Temporal CLI, use a [Codec Server](/codec-server).

Note that a remote data encoder is a separate system with access to your encryption keys and exposes APIs to encode and decode any data.
Evaluate and ensure that your remote data encoder endpoints are secured and only authorized users have access to them.

Samples:

- [Go](https://github.com/temporalio/samples-go/tree/main/codec-server)
- [Java](https://github.com/temporalio/sdk-java/tree/master/temporal-remote-data-encoder)
- [Python](https://github.com/temporalio/samples-python/tree/main/encryption)
- [TypeScript](https://github.com/temporalio/samples-typescript/tree/main/encryption)

---

## Detecting Activity failures

A Workflow can detect different kinds of Activity Execution failures through the following timeouts:

- [Schedule-To-Start Timeout](#schedule-to-start-timeout)
- [Start-To-Close Timeout](#start-to-close-timeout)
- [Schedule-To-Close Timeout](#schedule-to-close-timeout)
- [Activity Heartbeats](#activity-heartbeat)

## Schedule-To-Start Timeout {#schedule-to-start-timeout}

**What is a Schedule-To-Start Timeout in Temporal?**

A Schedule-To-Start Timeout is the maximum amount of time that is allowed from when an [Activity Task](/tasks#activity-task) is scheduled (that is, placed in a Task Queue) to when a [Worker](/workers#worker) starts (that is, picks up from the Task Queue) that Activity Task.
In other words, it's a limit for how long an Activity Task can be enqueued.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-timeouts" text="Set a Schedule-To-Start Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

The moment that the Task is picked by the Worker, from the Task Queue, is considered to be the start of the Activity Task Execution for the purposes of the Schedule-To-Start Timeout and associated metrics.
This definition of "Start" avoids issues that a clock difference between the Temporal Service and a Worker might create.

<CaptionedImage
    src="/diagrams/schedule-to-start-timeout.svg"
    title="Schedule-To-Start Timeout period" />

"Schedule" in Schedule-To-Start and Schedule-To-Close have different frequency guarantees.

The Schedule-To-Start Timeout is enforced for each Activity Task, whereas the Schedule-To-Close Timeout is enforced once per Activity Execution.
Thus, "Schedule" in Schedule-To-Start refers to the scheduling moment of _every_ Activity Task in the sequence of Activity Tasks that make up the Activity Execution, while
"Schedule" in Schedule-To-Close refers to the _first_ Activity Task in that sequence.

A [Retry Policy](/encyclopedia/retry-policies) attached to an Activity Execution retries an Activity Task.

<CaptionedImage
    src="/diagrams/schedule-to-start-timeout-with-retry.svg"
    title="Start-To-Close Timeout period with retries" />

This timeout has two primary use cases:

1. Detect whether an individual Worker has crashed.
2. Detect whether the fleet of Workers polling the Task Queue is not able to keep up with the rate of Activity Tasks.

**The default Schedule-To-Start Timeout is ∞ (infinity).**

If this timeout is used, we recommend setting this timeout to the maximum time a Workflow Execution is willing to wait for an Activity Execution in the presence of all possible Worker outages, and have a concrete plan in place to reroute Activity Tasks to a different Task Queue.
This timeout **does not** trigger any retries regardless of the Retry Policy, as a retry would place the Activity Task back into the same Task Queue.
We do not recommend using this timeout unless you know what you are doing.

In most cases, we recommend monitoring the `temporal_activity_schedule_to_start_latency` metric to know when Workers slow down picking up Activity Tasks, instead of setting this timeout.

## Start-To-Close Timeout {#start-to-close-timeout}

**What is a Start-To-Close Timeout in Temporal?**

A Start-To-Close Timeout is the maximum time allowed for a single [Activity Task Execution](/tasks#activity-task-execution).

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-timeouts" text="Set a Start-To-Close Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

**The default Start-To-Close Timeout is the same as the default [Schedule-To-Close Timeout](#schedule-to-close-timeout).**

An Activity Execution must have either this timeout (Start-To-Close) or the [Schedule-To-Close Timeout](#schedule-to-close-timeout) set.
We recommend always setting this timeout; however, make sure that Start-To-Close Timeout is always set to be longer than the maximum possible time for the Activity Execution to complete.
For long running Activity Executions, we recommend also using [Activity Heartbeats](#activity-heartbeat) and [Heartbeat Timeouts](#heartbeat-timeout).

:::tip

We strongly recommend setting a Start-To-Close Timeout.

The Temporal Server doesn't detect failures when a Worker loses communication with the Server or crashes.
Therefore, the Temporal Server relies on the Start-To-Close Timeout to force Activity retries.

:::

The main use case for the Start-To-Close timeout is to detect when a Worker crashes after it has started executing an Activity Task.

<CaptionedImage
    src="/diagrams/start-to-close-timeout.svg"
    title="Start-To-Close Timeout period" />

A [Retry Policy](/encyclopedia/retry-policies) attached to an Activity Execution retries an Activity Task Execution.
Thus, the Start-To-Close Timeout is applied to each Activity Task Execution within an Activity Execution.

If the first Activity Task Execution returns an error the first time, then the full Activity Execution might look like this:

<CaptionedImage
    src="/diagrams/start-to-close-timeout-with-retry.svg"
    title="Start-To-Close Timeout period with retries" />

If this timeout is reached, the following actions occur:

- An [ActivityTaskTimedOut](/references/events#activitytasktimedout) Event is written to the Workflow Execution's mutable state.
- If a Retry Policy dictates a retry, the Temporal Service schedules another Activity Task.
  - The attempt count increments by 1 in the Workflow Execution's mutable state.
  - The Start-To-Close Timeout timer is reset.

## Schedule-To-Close Timeout {#schedule-to-close-timeout}

**What is a Schedule-To-Close Timeout in Temporal?**

A Schedule-To-Close Timeout is the maximum amount of time allowed for the overall [Activity Execution](/activity-execution), from when the first [Activity Task](/tasks#activity-task) is scheduled to when the last Activity Task, in the chain of Activity Tasks that make up the Activity Execution, reaches a Closed status.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-timeouts" text="Set a Schedule-To-Close Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<CaptionedImage
    src="/diagrams/schedule-to-close-timeout.svg"
    title="Schedule-To-Close Timeout period" />

Example Schedule-To-Close Timeout period for an Activity Execution that has a chain Activity Task Executions:

<CaptionedImage
    src="/diagrams/schedule-to-close-timeout-with-retry.svg"
    title="Schedule-To-Close Timeout period with a retry" />

**The default Schedule-To-Close Timeout is ∞ (infinity).**

An Activity Execution must have either this timeout (Schedule-To-Close) or [Start-To-Close](#start-to-close-timeout) set.
This timeout can be used to control the overall duration of an Activity Execution in the face of failures (repeated Activity Task Executions), without altering the Maximum Attempts field of the Retry Policy.

:::tip

We strongly recommend setting a Start-To-Close Timeout.

The Temporal Server doesn't detect failures when a Worker loses communication with the Server or crashes.
Therefore, the Temporal Server relies on the Start-To-Close Timeout to force Activity retries.

:::

## Activity Heartbeat {#activity-heartbeat}

**What is an Activity Heartbeat in Temporal?**

An Activity Heartbeat is a ping from the Worker that is executing the Activity to the Temporal Service.
Each ping informs the Temporal Service that the Activity Execution is making progress and the Worker has not crashed.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#activity-heartbeats" text="Heartbeat an Activity using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

Activity Heartbeats work in conjunction with a [Heartbeat Timeout](#heartbeat-timeout).

Activity Heartbeats are implemented within the Activity Definition.
Custom progress information can be included in the Heartbeat which can then be used by the Activity Execution should a retry occur.

An Activity Heartbeat can be recorded as often as needed (e.g. once a minute or every loop iteration).
It is often a good practice to Heartbeat on anything but the shortest Activity Function Execution.
Temporal SDKs control the rate at which Heartbeats are sent to the Temporal Service.

Heartbeating is not required from [Local Activities](/local-activity), and does nothing.

For _long-running_ Activities, we recommend using a relatively short Heartbeat Timeout and a frequent Heartbeat.
That way if a Worker fails it can be handled in a timely manner.

A Heartbeat can include an application layer payload that can be used to _save_ Activity Execution progress.
If an [Activity Task Execution](/tasks#activity-task-execution) times out due to a missed Heartbeat, the next Activity Task can access and continue with that payload.

Activity Cancellations are delivered to Activities from the Temporal Service when they Heartbeat. Activities that don't Heartbeat can't receive a Cancellation.
Heartbeat throttling may lead to Cancellation getting delivered later than expected.

### Throttling

Heartbeats may not always be sent to the Temporal Service—they may be throttled by the Worker.
The throttle interval is the smaller of the following:

- If `heartbeatTimeout` is provided, `heartbeatTimeout * 0.8`; otherwise, `defaultHeartbeatThrottleInterval`
- `maxHeartbeatThrottleInterval`

`defaultHeartbeatThrottleInterval` is 30 seconds by default, and `maxHeartbeatThrottleInterval` is 60 seconds by default.
Each can be set in Worker options.

Throttling is implemented as follows:

- After sending a Heartbeat, the Worker sets a timer for the throttle interval.
- The Worker stops sending Heartbeats, but continues receiving Heartbeats from the Activity and remembers the most recent one.
- When the timer fires, the Worker:
  - Sends the most recent Heartbeat.
  - Sets the timer again.

Throttling allows the Worker to reduce network traffic and load on the Temporal Service by suppressing Heartbeats that aren’t necessary to prevent a Heartbeat Timeout.
Throttling does not apply to the final Heartbeat message in the case of Activity Failure.
If an Activity fails just after recording progress information in a Heartbeat message, that progress information will be available during the next retry attempt, provided that the Worker itself did not crash before delivering it to the Temporal Service.

### Which Activities should Heartbeat?

Heartbeating is best thought about not in terms of time, but in terms of "How do you know you are making progress?"
For short-term operations, progress updates are not a requirement.
However, checking the progress and status of Activity Executions that run over long periods is almost always useful.

Consider the following when setting Activity Hearbeats:

- Your underlying task must be able to report definite progress.
  Note that your Workflow cannot read this progress information while the Activity is still executing (or it would have to store it in Event History).
  You can report progress to external sources if you need it exposed to the user.

- Your Activity Execution is long-running, and you need to verify whether the Worker that is processing your Activity is still alive and has not run out of memory or silently crashed.

For example, the following scenarios are suitable for Heartbeating:

- Reading a large file from Amazon S3.
- Running a ML training job on some local GPUs.

And the following scenarios are not suitable for Heartbeating:

- Making a quick API call.
- Reading a small file from disk.

### Heartbeat Timeout {#heartbeat-timeout}

**What is a Heartbeat Timeout in Temporal?**

A Heartbeat Timeout is the maximum time between [Activity Heartbeats](#activity-heartbeat).

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-heartbeats" text="Set a Heartbeat Timeout using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-heartbeat-timeout" text="Set a Heartbeat Timeout using the TypeScript SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/failure-detection#heartbeat-timeout" text="Set a Heartbeat Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<CaptionedImage
    src="/diagrams/heartbeat-timeout.svg"
    title="Heartbeat Timeout periods" />

If this timeout is reached, the Activity Task fails and a retry occurs if a [Retry Policy](/encyclopedia/retry-policies) dictates it.

---

## Detecting application failures

In Temporal, timeouts detect application failures.
The system can then automatically mitigate these failures through retries.
Both Workflows and Activities have dedicated timeout configurations and can be configured with a RetryPolicy.

- [Detecting Workflow failures](/encyclopedia/detecting-workflow-failures)
- [Detecting Activity failures](/encyclopedia/detecting-activity-failures)
- [Retry Policies](/encyclopedia/retry-policies)

---

## Detecting Workflows failures

Each Workflow Timeout controls the maximum duration of a different aspect of a Workflow Execution. Workflow Timeouts are set when starting the Workflow Execution.

Before we continue, we want to note that we generally do not recommend setting Workflow Timeouts, because Workflows are designed to be long-running and resilient.
Instead, setting a Timeout can limit its ability to handle unexpected delays or long-running processes.
If you need to perform an action inside your Workflow after a specific period of time, we recommend using a Timer.

- [Workflow Execution Timeout](#workflow-execution-timeout)
- [Workflow Run Timeout](#workflow-run-timeout)
- [Workflow Task Timeout](#workflow-task-timeout)

## Workflow Execution Timeout? {#workflow-execution-timeout}

**What is a Workflow Execution Timeout in Temporal?**

A Workflow Execution Timeout is the maximum time that a Workflow Execution can be executing (have an Open status) including retries and any usage of Continue As New.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/failure-detection#workflow-timeouts" text="Set a Workflow Execution Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<CaptionedImage
    src="/diagrams/workflow-execution-timeout.svg"
    title="Workflow Execution Timeout period" />

**The default value is ∞ (infinite).**
If this timeout is reached, the Workflow Execution changes to a Timed Out status.
This timeout is different from the [Workflow Run Timeout](#workflow-run-timeout).
This timeout is most commonly used for stopping the execution of a [Temporal Cron Job](/cron-job) after a certain amount of time has passed.

## Workflow Run Timeout? {#workflow-run-timeout}

**What is a Workflow Run Timeout in Temporal?**

A Workflow Run is the instance of a specific Workflow Execution.

Due to the potential for Workflow Retries or Continue-as-New, a Workflow Execution may have multiple Workflow runs. For example, if a Workflow that specifies a Retry Policy initially fails and then succeeds during the next retry attempt, there is a single Workflow Execution that spans two Workflow Runs. Both runs will share the same Workflow ID but have a unique Run ID to distinguish them.

A Workflow Run Timeout restricts the maximum duration of a single Workflow Run. If the Workflow Run Timeout is reached, the Workflow Execution will be Timed Out. Because this Timeout only applies to an individual Workflow Run, this does not include retries or Continue-As-New.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set a Workflow Run Timeout using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/failure-detection#workflow-timeouts" text="Set a Workflow Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<CaptionedImage
    src="/diagrams/workflow-run-timeout.svg"
    title="Workflow Run Timeout period" />

**The default is set to the same value as the [Workflow Execution Timeout](#workflow-execution-timeout).**
This timeout is most commonly used to limit the execution time of a single [Temporal Cron Job Execution](/cron-job).

If the Workflow Run Timeout is reached, the Workflow Execution will be Timed Out.

## Workflow Task Timeout? {#workflow-task-timeout}

**What is a Workflow Task Timeout in Temporal?**

A Workflow Task Timeout is the maximum amount of time allowed for a [Worker](/workers#worker) to execute a [Workflow Task](/tasks#workflow-task) after the Worker has pulled that Workflow Task from the [Task Queue](/task-queue).

This Timeout is primarily available to recognize whether a Worker has gone down so that the Workflow Execution can be recovered on a different Worker.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/failure-detection#workflow-timeouts" text="Set a Workflow Task Timeout using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

<CaptionedImage
    src="/diagrams/workflow-task-timeout.svg"
    title="Workflow Task Timeout period" />

**The default value is 10 seconds.**
This timeout is primarily available to recognize whether a Worker has gone down so that the Workflow Execution can be recovered on a different Worker.
The main reason for increasing the default value is to accommodate a Workflow Execution that has an extensive Workflow Execution History, requiring more than 10 seconds for the Worker to load.
It's worth mentioning that although you can extend the timeout up to the maximum value of 120 seconds, it's not recommended to move beyond the default value.

---

## Event History Walkthrough with the .NET SDK

In order to understand how Workflow Replay works, this page will go through the following walkthroughs:

1. [How Workflow Code Maps to Commands](#How-Workflow-Code-Maps-To-Commands)
2. [How Workflow Commands Map to Events](#How-Workflow-Commands-Map-To-Events)
3. [How History Replay Provides Durable Execution](#How-History-Replay-Provides-Durable-Execution)
4. [Example of a Non-Deterministic Workflow](#Example-of-Non-Deterministic-Workflow)

## How Workflow Code Maps to Commands {#How-Workflow-Code-Maps-To-Commands}

This walkthrough will cover how the Workflow code maps to Commands that get sent to the Temporal Service, letting the Temporal Service know what to do.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands-021.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.023.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.024.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.025.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.026.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.027.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/code-commands/code-commands.028.jpeg",

]}
captions={[
"NA",
"Here is code for a basic Temporal Workflow Definition, which does the items described on the right side of the screen.",
"Some steps are internal to the Workflow and do not involve interaction with the Service.",
"On the other hand, some steps do involve interaction with the Temporal Service. For example, when the code requests execution of an Activity, it generates a Command to schedule the Activity Task. Another example is when the code returns a value from the Workflow, the Worker notifies the Temporal Service that the Workflow Execution is complete.",
"The code walkthrough will now begin. In this Workflow Definition, calculating the total price is an internal step. That is, this step doesn't require any interaction with the Temporal Service.",
"The Worker then reaches a statement that does require interaction with the Temporal Service. In this case, it's a request to execute an Activity. This causes the Worker to issue a Command to the Temporal Service and provides the details needed. For example, the `ScheduleActivityTask` Command contains details such as the Task Queue name, the Activity Type, and the input parameter values. Note that the Worker will wait for the `GetDistance` Activity to complete, and even though an Activity can take hours or days to complete, the Worker does not use resources.",
"After the `GetDistance` Activity has successfully completed, the Worker continues executing the Workflow code. The next line, highlighted here, evaluates a variable. Depending on the outcome, it may throw an exception, which would send a Command to the Server to request it to fail the Workflow Execution. However, this example assumes that this is a delivery for a nearby customer. The execution will continue.",
"The Worker now reaches the call to the Timer, which is another statement that involves interaction with the Temporal Service. This causes the Worker to issue another Command, one which requests that it start a Timer. The duration is one of the details specified in this Command. Further execution of this Workflow will now pause for 30 minutes until the Timer fires.",
"The Timer then fires. The next few lines, highlighted here, create and populate a record that represents the input for the next Activity. While it is related to the Activity, it doesn't involve any interaction with the Service.",
"The next statement involves interaction with the Temporal Service. It requests execution of an Activity, so the Worker issues another Command to the Temporal Service: `ScheduleActivityTask`.",
"Finally, returning from the Workflow method also results in a Command. It issues a `CompleteWorkflowExecution` Command to the Temporal Service, which includes the value that was returned from the method.",
]}
/>

## How Workflow Commands Map to Events {#How-Workflow-Commands-Map-To-Events}

The Commands that are sent to the Temporal Service are then turned into Events, which build up the Event History. The Event History is a detailed log of Events that occur during the lifecycle of a Workflow Execution, such as the execution of Workflow Tasks or Activity Tasks. Event Histories are persisted to the database used by the Temporal Service, so they're durable, and will even survive a crash of the Temporal Service itself.

These Events are what are used to recreate a Workflow Execution's state in the case of failure.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.014.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/commands-events/commands-events.015.jpeg",
]}
captions={[
"NA",
"In this walkthrough, there will be a running list of the Commands issued with the corresponding Event to the right.",
"The call to the Activity is the first line of code in the Workflow that causes a Command to be issued. In response to this Command, the Temporal Service creates an Activity Task, adds it to the Task Queue, and appends the `ActivityTaskScheduled` Event to the Event History. This Event is colored blue to indicate that it's the direct result of a Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Service will respond to the poll request with a Task, and the Worker will begin executing the code needed to complete the Task.",
"The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event. Once the Activity completes, the Temporal Service records another Event in response to the Worker accepting the Task: `ActivityTaskStarted`. This Event is colored pink to indicate that it's an indirect result of the Command. By the way, the `Start-to-Close` Timeout indicates the amount of time that the Activity has to complete.",
"The Worker executes the code within the Activity Definition, and when that method returns a result, the Worker sends a message to the Temporal Service, notifying it that the Task is complete. To reiterate, this is just a notification, not a Command, because it's not requesting that the Temporal Service do something that will allow the Workflow Execution to progress. In response to this notification, the Temporal Service records another Event: `ActivityTaskCompleted`.",
"The next statement that results in a Command is the call to start a Timer. It issues a `StartTimer` Command.",
"The Temporal Service responds after starting a Timer for 30 minutes in the Service, logging a `TimerStarted` Event to the history. It is a direct result of the `StartTimer` Command.",
"After 30 minutes has elapsed, the Timer is fired on the Temporal Service, which it then records the Event `TimerFired` to the history. The Workflow Execution continues with the next statement, but this is an internal step, meaning that it does not interact with the Temporal Service.",
"The Worker then reaches the call to the `SendBill` Activity and issues another `ScheduleActivityTask` Command. The Temporal Service adds an Activity Task to the Task Queue and records an `ActivityTaskScheduled` Event to the Event History.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker then removes the Task from the Task Queue, and begins working on it. The Temporal Service records an `ActivityTaskStarted` Event to the Event History, signifying that the Task has been dequeued.",
"When the Activity returns, the Task is complete and the Worker notifies the Temporal Service. In response, the Temporal Service records the `ActivityTaskCompleted` Event to the Event History. Execution will then continue until the Workflow has completed. There will be a complete walkthrough in the next section.",
]}
/>

## How History Replay Provides Durable Execution {#How-History-Replay-Provides-Durable-Execution}

Now that you have seen how code maps to Commands, and how Commands map to Events, this next walkthrough will take a look at how Temporal uses Replay with the Events to provide Durable Execution and restore a Workflow Execution in the case of a failure.

This code walkthrough will begin by walking through a Workflow Execution, describing how the code maps to Commands and Events. There will then be a Worker crash halfway through, explaining how Temporal uses Replay to recover the state of the Workflow Execution, ultimately resulting in a completed execution that's identical to one that had not crashed.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.014.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.018.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.019.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.020.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.023.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.024.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.025.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.026.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.028.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.029.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.031.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.032.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.033.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.034.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.035.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.038.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.040.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.041.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.042.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.043.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.044.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.045.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.048.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.049.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.050.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.051.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.053.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.054.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.056.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.057.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.058.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.060.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.061.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.059.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.063.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.064.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.065.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.067.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.068.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.069.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.070.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.071.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.072.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.073.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.074.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/history-replay/history-replay.075.jpeg",
]}
captions={[
"NA",
"This walkthrough begins with a request to execute this Workflow Definition, passing in some input data. In this case, the input data contains information about the customer and the pizzas ordered.",
"This request to execute the Workflow Definition results in the Temporal Service recording a `WorkflowExecutionStarted` Event into the Event History. This is always the first Event for any Workflow Execution. It's not indicated in the image, but the `WorkflowExecutionStarted` Event contains the input data provided to this Workflow Execution.",
"The Worker then adds a Workflow Task to the Task Queue, and records a `WorkflowTaskScheduled` Event.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker accepts the Task.",
"The Temporal Service records a `WorkflowTaskStarted` Event.",
"The Worker then invokes the Workflow code and runs the code within it, one statement at a time.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"However, the Worker encounters a request to execute an Activity, so the Worker will complete the current Workflow Task. The Service adds `WorkflowTaskCompleted` to the Event History.",
"The Worker then makes a single gRPC call - `RespondWorkflowTaskCompleted` - to the Temporal Service, which signals completion of the Workflow Task, and includes any commands such as `ScheduleActivityTask`, containing all details about the Activity Execution within this call. So to clarify, `WorkflowTaskCompleted` and `ActivityTaskScheduled` are technically one call.",
"In response, the Temporal Service queues an Activity Task and records an `ActivityTaskScheduled` Event to the Event History. This is shown in blue to indicate that it is the direct result of the Command. The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task and starts working on the code within this `GetDistance` Activity.",
"The Temporal Service records an `ActivityTaskStarted` Event to the Event History to signify that the Worker has started the Activity Task. This Event is in a pink box to indicate that it's the indirect result of the Command. The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event.",
"When the Activity method returns - with a result of 15 - the Worker notifies the Service that the Activity Execution is complete.",
"The Temporal Service records an `ActivityTaskCompleted` Event, which contains the result of the Activity.",
"In order to deliver the Activity Task result, 15, back to the Workflow, the Temporal Service creates another Workflow Task which includes the result of this Activity. `WorkflowTaskScheduled` is appended to the Event History.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker dequeues the Task and resumes execution of the Workflow. The `WorkflowTaskStarted` Event gets appended to the Event History. The Worker then executes the next few lines of code - evaluating the distance, calculating the price of the pizza, and so on.",
"The Worker reaches the request to start the Timer. Therefore, it notifies the Service to complete the current Workflow Task.",
"The Worker will complete the current Workflow Task, adding `WorkflowTaskCompleted` to the Event History. This Event includes the the `StartTimer` Command.",
"The Worker issues a `StartTimer` Command to the Service, requesting it to set the Timer for 30 minutes. The Service records a `TimerStarted` Event in response.",
"The Workflow does not progress until the Timer fires.",
"After 30 minutes has elapsed, the Timer fires, and the Service records a `TimerFired` Event.",
"The Service now adds a new Workflow Task to the Queue in order to deliver the `TimerFired` Event to the Workflow, so `WorkflowTaskScheduled` is added to the Event History to drive the Workflow progress forward.",
"The Worker polls for the Task, dequeues it, and continues execution of the Workflow code.",
"However, the Worker happens to crash right here. How does Temporal recover the state of the Workflow? But first, how do you know when a Worker has crashed?",
"Once a Worker has accepted a Task, it is expected to complete that task within a predefined duration, known as a Timeout. This timeout is available to recognize whether a Worker has gone down. This results in a Workflow Task Timeout, which has a default value of 10 seconds.",
"Therefore, if the Worker failed to complete this Workflow Task within that time, the Service will schedule a new Workflow Task.",
"The Worker polling might be done by another Worker that's running in the Worker fleet or by a new Worker process created by restarting the one that crashed.",
"In either case, the Worker will need the current Event History for this execution, so it requests it from the Service.",
"The Service provides the Event History. Notice the black horizontal line in the column on the right to indicate the final Event in the History at the time of the Worker Crash.",
"The Worker then begins a re-execution of the code, using the same input, which was stored in the `WorkflowExecutionStarted` Event. Remember, because the Workflow code is deterministic, the state of all variables encountered so far is identical to what it was before the crash.",
"When the Replay reaches the call to schedule to `GetDistance` Activity, it creates a `ScheduleActivityTask` Command but does not issue it to the Temporal Service. Instead, the Worker inspects the Event History and finds three Events related to this Activity.",
"The `ActivityTaskScheduled` Event, with the details including this specific Activity Type, indicates that the Task was previously scheduled by the Temporal Service.",
"The `ActivityTaskStarted` Event indicates that a Worker dequeued the Task.",
"The `ActivityTaskCompleted` Event indicates that the Worker successfully completed the Task for the `GetDistance` Activity, having returned a value of 15. The Worker now knows that the Activity has completed and does not need to issue the Command.",
"The Worker uses the value stored in the `ActivityTaskCompleted` Event, 15, and assigns it to the `distance` variable. To emphasize, the Worker is not re-executing the Activity, it's using the result stored in the Event History, so there is no way that the Activity behaves differently during History Replay than the original execution.",
"Replay continues replaying the code.",
"The Worker then reaches the request to start a Timer. It creates a Command, `StartTimer`. Again, the Worker does not issue the Command to the Service.",
"Instead, the Worker checks the Event History to see whether the Timer was started and fired during the previous execution. The Event History indicates that the Timer was started, because there is a `TimerStarted` Event. The Event History also indicates that the Timer was fired, because there is a `TimerFired` Event.",
"At this point, the Worker has reached the point where the crash occurred, and replaying the code has completely restored the state of the Workflow Execution prior to the crash.",
"For example, the `distance` variable was set using the value that was stored in the Event History from the previous Execution.",
"Since Replay uses the same input data as before, this also means that the conditional statement evaluates to `false`, like it did before.",
"The `totalPrice` variable also has the same value as it did before the crash.",
"The Worker has now reached a statement beyond where the crash occurred, which is evident because the Event History does not contain any Events related to this `SendBill` Activity. Further execution of this Workflow continues on as if the crash never happened.",
"Because the Worker encounters a request to execute an Activity, the Worker completes the current Workflow Task.",
"The Worker issues a Command to the Service, requesting execution of the Activity.",
"The Worker adds the Activity Task to the Task queue, adding `ActivityTaskScheduled` to the Event History. The Worker polls for the Task.",
"The Worker dequeues the Task, adding `ActivityTaskStarted` to the Event History.",
"When the Activity returns a result, the Worker notifies the Service.",
"The Worker records an `ActivityTaskCompleted` Event, which includes the result from the `SendBill` Activity.",
"But since the Service hasn't yet received a Command that says the Workflow Execution has completed or failed, the Service schedules another Workflow Task to continue progress of the execution.",
"The Worker polls for and accepts the Task.",
"When the Workflow completes, the Worker notifies the Service that the current Workflow Task is complete. The Service records a `WorkflowTaskCompleted` Event to reflect this.",
"Since the Worker has now successfully completed the execution of the Workflow, it issues a `CompleteWorkflowExecution` Command to the Service, which contains the result returned by the Workflow Execution.",
"The Service then records `WorkflowExecutionCompleted` as the final Event in the Event History. The Workflow Execution is now complete.",
]}
/>

## Example of a Non-Deterministic Workflow {#Example-of-Non-Deterministic-Workflow}

Now that Replay has been covered, this section will explain why Workflows need to be [deterministic](https://docs.temporal.io/workflows#deterministic-constraints) in order for Replay to work.

A Workflow is deterministic if every execution of its Workflow Definition produces the same Commands in the same sequence given the same input.

As mentioned in the [`How History Replay Provides Durable Execution`](#How-History-Replay-Provides-Durable-Execution) walkthrough, in the case of a failure, a Worker requests the Event History to replay it. During Replay, the Worker runs the Workflow code again to produce a set of Commands which is compared against the sequence of Commands in the Event History. When there’s a mismatch between the expected sequence of Commands the Worker expects based on the Event History and the actual sequence produced during Replay (due to non-determinism), Replay will be unable to continue.

To better understand why Workflows need to be deterministic, it's helpful to look at a Workflow Definition that violates it. In this case, this code will walk through a Workflow Definition that breaks the determinism constraint with a random number generator.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.014.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.018.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.019.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.020.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.021.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.023.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.024.jpeg",
"https://learn.temporal.io/courses/temporal-102/dotnet/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.025.jpeg",
]}
captions={[
"NA",
"Imagine the following Workflow Definition is being executed.",
"As the Workflow executes step by step, the first line that results in a Command is the call to the `ImportSalesData` Activity. The Worker issues the `ScheduleActivityTask` Command to the Service. In this case, the execution of the Activity is successful, so the Service logs three Events to the Event History: `ActivityTaskScheduled`, `ActivityTaskStarted`, `ActivityTaskCompleted`.",
"Now, the Worker reaches a conditional statement which evaluates the value of a random-generated number. The random number generator happens to return the value of 84 during this execution. Since the expression evaluates to `true`, execution continues with the next line.",
"The next line is a request to start a Timer, so the Worker issues a Command to the Service - `StartTimer` - requesting that it starts a Timer.",
"The Service starts the Timer, records an Event - `TimerStarted` - and then records another Event when the Timer fires - `TimerFired`.",
"Now imagine that the Worker happens to crash once it reaches to next line, so another Worker takes over, using Replay to restore the current state before continuing execution of the lines that follow.",
"The Worker then requests the Event History to replay it. Once the Worker has the Event History, the Worker determines the expected sequence of Commands needed to restore the current state. The Worker is expecting to encounter the `ScheduleActivityTask` and `StartTimer` Commands.",
"As the Worker executes the code during Replay, it reaches the first call to execute an Activity and creates a `ScheduleActivityTask` Command. This Command matches the one expected based on the Event History. It's not only the right type of Command, with the same details, but it also occurs at the right position in the sequence of expected Commands. Therefore, Replay proceeds.",
"The Worker now reaches the conditional statement with the random number generator. This time, the random number generator happens to return 14, so the conditional expression evaluates to `false`, and execution skips over the next line.",
"The Worker now reaches the next Command which is to request execution of the `RunDailyReport` Activity, so the Worker creates another `ScheduleActivityTask` Command.",
"However, this is a different Command than it expected to find at this position in the Event History. Since the Workflow produced a different sequence of Commands during Replay than it was expecting due to the Event History that was produced prior to the crash, the Worker is unable to restore the previous state.",
"The Workflow Execution was unable to be replayed due to a non-deterministic error.",
]}
/>

Note that non-deterministic failures do not fail the Workflow Execution by default. A non-deterministic failure is considered a [Workflow Task Failure](https://docs.temporal.io/references/failures#workflow-task-failures) which is considered a transient failure, meaning it retries over and over. Users can also fix the source of non-determinism, perhaps by removing the Activity, and then restart the Workers. This means that this type of failure can recover by itself. You can also use a strategy called versioning to address this non-determinism error. See [versioning](https://docs.temporal.io/develop/dotnet/versioning) to learn more.

For more information on how Temporal handles Durable Execution or to see these slides in a video format with more explanation, check out our free, self-paced courses: [Temporal 102](https://learn.temporal.io/courses/temporal_102/) and [Versioning Workflows](https://learn.temporal.io/courses/versioning/).

---

## Event History

With Temporal, your Workflows can seamlessly recover from crashes. This is made possible by the [Event History](https://docs.temporal.io/workflow-execution/event), a complete and durable log of everything that has happened in the lifecycle of a Workflow Execution, as well as the ability of the Temporal Service to durably persist the Events during Replay.

Temporal uses the Event History to record every step taken along the way. Each time your Workflow Definition makes an API call to execute an Activity or start a Timer for instance, it doesn’t perform the action directly. Instead, it sends a Command to the Temporal Service.

A Command is a requested action issued by a Worker to the Temporal Service after a Workflow Task Execution completes. The Temporal Service will act on these Commands such as scheduling an Activity or scheduling a timer. These Commands are then mapped to Events which are persisted in case of failure. For example, if the Worker crashes, the Worker uses the Event History to replay the code and recreate the state of the Workflow Execution to what it was immediately before the crash. It then resumes progress from the point of failure as if the failure never occurred.

For a deep dive on how the Event History works, refer to the walkthroughs in the dropdown.

- [Go](/encyclopedia/event-history/event-history-go)
- [Java](/encyclopedia/event-history/event-history-java)
- [Python](/encyclopedia/event-history/event-history-python)
- [Typescript](/encyclopedia/event-history/event-history-typescript)
- [.NET](/encyclopedia/event-history/event-history-dotnet)

---

## Event History Walkthrough with the Go SDK

In order to understand how Workflow Replay works, this page will go through the following walkthroughs:

1. [How Workflow Code Maps to Commands](#How-Workflow-Code-Maps-To-Commands)
2. [How Workflow Commands Map to Events](#How-Workflow-Commands-Map-To-Events)
3. [How History Replay Provides Durable Execution](#How-History-Replay-Provides-Durable-Execution)
4. [Example of a Non-Deterministic Workflow](#Example-of-Non-Deterministic-Workflow)

## How Workflow Code Maps to Commands {#How-Workflow-Code-Maps-To-Commands}

This walkthrough will cover how the Workflow code maps to Commands that get sent to the Temporal Service, letting the Temporal Service know what to do.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/code-commands/code-commands.012.jpeg",
]}
captions={[
"NA",
"Here is code for a basic Temporal Workflow Definition, which does the items described on the right side of the screen.",
"Some steps are internal to the Workflow and do not involve interaction with the Service.",
"On the other hand, some steps do involve interaction with the Temporal Service. For example, when the code requests execution of an Activity, it generates a Command to schedule the Activity Task. Another example is when the code returns a value from the Workflow, the Worker notifies the Temporal Service that the Workflow Execution is complete.",
"The code walkthrough will now begin. In this Workflow Definition, setting the Start-to-Close Timeout and setting a variable are internal steps. That is, these steps don't require any interaction with the Temporal Service.",
"The Worker then reaches a statement that does require interaction with the Temporal Service. In this case, it's a request to execute an Activity. This causes the Worker to issue a Command to the Temporal Service and provides the details needed. For example, the `ScheduleActivityTask` Command contains details such as the Task Queue name, the Activity Type, and the input parameter values. Even though an Activity can take hours or days to complete, the Worker does not use resources.",
"After the `GetDistance` Activity has successfully completed, the Worker continues executing the Workflow code. The next line, highlighted here, evaluates a variable. Depending on the outcome, it may return an error, which would send a Command to the Server to request it to fail the Workflow Execution. However, this example assumes that this is a delivery for a nearby customer. The execution will continue.",
"The Worker now reaches the call to start a Timer, which is another statement that involves interaction with the Temporal Service. This causes the Worker to issue another Command, one which requests the Temporal Service to start a Timer. The duration is one of the details specified in this Command. Further execution of this Workflow will now pause for 30 minutes until the Timer fires.",
"The Timer then fires. The next few lines, highlighted here, create and populate a data structure that represents the input for the next Activity. While it is related to the Activity, it doesn't involve any interaction with the Service.",
"The next statement involves interaction with the Temporal Service. It requests execution of an Activity, so the Worker issues another Command to the Temporal Service: `ScheduleActivityTask`.",
"Finally, returning from the Workflow function also results in a Command. It issues a `CompleteWorkflowExecution` Command to the Temporal Service, which includes the value that was returned from the function.",
]}
/>

## How Workflow Commands Map to Events {#How-Workflow-Commands-Map-To-Events}

The Commands that are sent to the Temporal Service are then turned into Events, which build up the Event History. The Event History is a detailed log of Events that occur during the lifecycle of a Workflow Execution, such as the execution of Workflow Tasks or Activity Tasks. Event Histories are persisted to the database used by the Temporal Service, so they're durable, and will even survive a crash of the Temporal Service itself.

These Events are what are used to recreate a Workflow Execution's state in the case of failure.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/commands-events/commands-events.014.jpeg",
]}
captions={[
"NA",
"In this walkthrough, there will be a running list of the Commands issued with the corresponding Event to the right.",
"The call to the Activity is the first line of code in the Workflow that causes a Command to be issued. In response to this Command, the Temporal Service creates an Activity Task, adds it to the Task Queue, and appends the `ActivityTaskScheduled` Event to the Event History. This Event is colored blue to indicate that it's the direct result of a Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Service will respond to the poll request with a Task, and the Worker will begin executing the code needed to complete the Task.",
"The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event. Once the Activity completes, the Temporal Service records another Event in response to the Worker accepting the Task: `ActivityTaskStarted`. This Event is colored pink to indicate that it's an indirect result of the Command. By the way, the `Start-to-Close` Timeout indicates the amount of time that the Activity has to complete.",
"The Worker executes the code within the Activity Definition, and when that method returns a result, the Worker sends a message to the Temporal Service, notifying it that the Task is complete. To reiterate, this is just a notification, not a Command, because it's not requesting that the Temporal Service do something that will allow the Workflow Execution to progress. In response to this notification, the Temporal Service records another Event: `ActivityTaskCompleted`.",
"The next statement that results in a Command is the call to start a Timer. It issues a `StartTimer` Command.",
"The Temporal Service responds after starting a Timer for 30 minutes in the Service, logging a `TimerStarted` Event to the history. It is a direct result of the `StartTimer` Command.",
"After 30 minutes has elapsed, the Timer is fired on the Temporal Service, which it then records the Event `TimerFired` to the history. The Workflow Execution continues with the next statement, but this is an internal step, meaning that it does not interact with the Temporal Service.",
"The Worker then reaches the call to the `SendBill` Activity and issues another `ScheduleActivityTask` Command. The Temporal Service adds an Activity Task to the Task Queue and records an `ActivityTaskScheduled` Event to the Event History.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker then removes the Task from the Task Queue, and begins working on it. The Temporal Service records an `ActivityTaskStarted` Event to the Event History, signifying that the Task has been dequeued.",
"When the Activity returns, the Task is complete and the Worker notifies the Temporal Service. In response, the Temporal Service records the `ActivityTaskCompleted` Event to the Event History. Execution will then continue until the Workflow has completed. There will be a complete walkthrough in the next section.",
]}
/>

## How History Replay Provides Durable Execution {#How-History-Replay-Provides-Durable-Execution}

Now that you have seen how code maps to Commands, and how Commands map to Events, this next walkthrough will take a look at how Temporal uses Replay with the Events to provide Durable Execution and restore a Workflow Execution in the case of a failure.

This code walkthrough will begin by walking through a Workflow Execution, describing how the code maps to Commands and Events. There will then be a Worker crash halfway through, explaining how Temporal uses Replay to recover the state of the Workflow Execution, ultimately resulting in a completed execution that's identical to one that had not crashed.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.017.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.018.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.019.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.021.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.024.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.025.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.026.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.027.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.028.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.029.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.031.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.032.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.033.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.034.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.035.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.036.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.037.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.040.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.043.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.044.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.046.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.047.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.048.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.049.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.054.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.057.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.058.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.059.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.060.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.061.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.063.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.064.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.066.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.067.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.069.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.070.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.073.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.075.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.076.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.077.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.079.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.081.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.082.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.083.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.084.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.085.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.087.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.088.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.089.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/history-walkthrough/history-walkthrough.090.jpeg",
]}
captions={[
"NA",
"This walkthrough begins with a request to execute this Workflow Definition, passing in some input data. In this case, the input data contains information about the customer and the pizzas ordered.",
"This request to execute the Workflow Definition results in the Temporal Service recording a `WorkflowExecutionStarted` Event into the Event History. This is always the first Event for any Workflow Execution. It's not indicated in the image, but the `WorkflowExecutionStarted` Event contains the input data provided to this Workflow Execution.",
"The Worker then adds a Workflow Task to the Task Queue, and records a `WorkflowTaskScheduled` Event.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker accepts the Task.",
"The Temporal Service records a `WorkflowTaskStarted` Event.",
"The Worker then invokes the Workflow code and runs the code within it, one statement at a time.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"However, the Worker encounters a request to execute an Activity, so the Worker will complete the current Workflow Task.",
"The Service adds `WorkflowTaskCompleted` to the Event History.",
"The Worker then makes a single gRPC call - `RespondWorkflowTaskCompleted` - to the Temporal Service, which signals completion of the Workflow Task, and includes any commands such as `ScheduleActivityTask`, containing all details about the Activity Execution within this call. So to clarify, `WorkflowTaskCompleted` and `ActivityTaskScheduled` are technically one call.",
"In response, the Temporal Service queues an Activity Task and records an `ActivityTaskScheduled` Event to the Event History. This is shown in blue to indicate that it is the direct result of the Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task and starts working on the code within this `GetDistance` Activity. The Temporal Service records an `ActivityTaskStarted` Event to the Event History to signify that the Worker has started the Activity Task. This Event is in a pink box to indicate that it's the indirect result of the Command. The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event.",
"When the Activity function returns - with a result of 15 - the Worker notifies the Service that the Activity Execution is complete.",
"The Temporal Service records an `ActivityTaskCompleted` Event, which contains the result of the Activity.",
"In order to deliver the Activity Task result, 15, back to the Workflow, the Temporal Service creates another Workflow Task which includes the result of this Activity. `WorkflowTaskScheduled` is appended to the Event History.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker dequeues the Task and resumes execution of the Workflow. The `WorkflowTaskStarted` Event gets appended to the Event History.",
"The Worker then executes the next few lines of code, evaluating the distance.",
"The Worker reaches the request to start the Timer. Therefore, it notifies the Service to complete the current Workflow Task.",
"The Worker will complete the current Workflow Task, adding `WorkflowTaskCompleted` to the Event History. This Event includes the the `StartTimer` Command.",
"The Worker issues a `StartTimer` Command to the Service, requesting it to set the Timer for 30 minutes. The Service records a `TimerStarted` Event in response.",
"The Workflow does not progress until the Timer fires.",
"After 30 minutes has elapsed, the Timer fires, and the Service records a `TimerFired` Event.",
"The Service now adds a new Workflow Task to the Queue in order to deliver the `TimerFired` Event to the Workflow, so `WorkflowTaskScheduled` is added to the Event History to drive the Workflow progress forward.",
"The Worker polls for the Task, dequeues it, and continues execution of the Workflow code.",
"However, the Worker happens to crash right here. How does Temporal recover the state of the Workflow? But first, how do you know when a Worker has crashed?",
"Once a Worker has accepted a Task, it is expected to complete that task within a predefined duration, known as a Timeout. This timeout is available to recognize whether a Worker has gone down. This results in a Workflow Task Timeout, which has a default value of 10 seconds.",
"Therefore, if the Worker failed to complete this Workflow Task within that time, the Service will schedule a new Workflow Task.",
"The Worker polling might be done by another Worker that's running in the Worker fleet or by a new Worker process created by restarting the one that crashed.",
"In either case, the Worker will need the current Event History for this execution, so it requests it from the Service.",
"The Service provides the Event History. Notice the black horizontal line in the column on the right to indicate the final Event in the History at the time of the Worker Crash.",
"The Worker then begins a re-execution of the code, using the same input, which was stored in the `WorkflowExecutionStarted` Event. Remember, because the Workflow code is deterministic, the state of all variables encountered so far is identical to what it was before the crash.",
"For example, the `totalPrice` variable was the same as it was prior to the crash.",
"When the Replay reaches the call to schedule to `GetDistance` Activity, it creates a `ScheduleActivityTask` Command but does not issue it to the Temporal Service. Instead, the Worker inspects the Event History and finds three Events related to this Activity.",
"The `ActivityTaskScheduled` Event, with the details including this specific Activity Type, indicates that the Task was previously scheduled by the Temporal Service.",
"The `ActivityTaskStarted` Event indicates that a Worker dequeued the Task.",
"The `ActivityTaskCompleted` Event indicates that the Worker successfully completed the Task for the `GetDistance` Activity, having returned a value of 15. The Worker now knows that the Activity has completed and does not need to issue the Command.",
"The Worker uses the value stored in the `ActivityTaskCompleted` Event, 15, and assigns it to the `distance` variable. To emphasize, the Worker is not re-executing the Activity, it's using the result stored in the Event History, so there is no way that the Activity behaves differently during History Replay than the original execution.",
"Replay continues replaying the code.",
"The Worker then reaches the request to start a Timer. It creates a Command, `StartTimer`. Again, the Worker does not issue the Command to the Service.",
"Instead, the Worker checks the Event History to see whether the Timer was started and fired during the previous execution. The Event History indicates that the Timer was started, because there is a `TimerStarted` Event.",
"The Event History also indicates that the Timer was fired, because there is a `TimerFired` Event.",
"At this point, the Worker has reached the point where the crash occurred, and replaying the code has completely restored the state of the Workflow Execution prior to the crash.",
"For example, the `totalPrice` variable was the same as it was prior to the crash.",
"Since Replay uses the same input data as before, this also means that the conditional statement evaluates to `false`, like it did before.",
"The Worker has now reached a statement beyond where the crash occurred, which is evident because the Event History does not contain any Events related to this `SendBill` Activity. Further execution of this Workflow continues on as if the crash never happened. Because the Worker encounters a request to execute an Activity, the Worker completes the current Workflow Task.",
"The Worker issues a Command to the Service, requesting execution of the Activity.",
"The Worker adds the Activity Task to the Task queue, adding `ActivityTaskScheduled` to the Event History. The Worker polls for the Task.",
"The Worker dequeues the Task, adding `ActivityTaskStarted` to the Event History.",
"When the Activity returns a result, the Worker notifies the Service.",
"The Worker records an `ActivityTaskCompleted` Event, which includes the result from the `SendBill` Activity.",
"But since the Service hasn't yet received a Command that says the Workflow Execution has completed or failed, the Service schedules another Workflow Task to continue progress of the execution.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task.",
"When the Workflow completes, the Worker notifies the Service that the current Workflow Task is complete.",
"The Service records a `WorkflowTaskCompleted` Event to reflect this.",
"Since the Worker has now successfully completed the execution of the Workflow, it issues a `CompleteWorkflowExecution` Command to the Service, which contains the result returned by the Workflow Execution.",
"The Service then records `WorkflowExecutionCompleted` as the final Event in the Event History. The Workflow Execution is now complete.",
]}
/>

## Example of a Non-Deterministic Workflow {#Example-of-Non-Deterministic-Workflow}

Now that Replay has been covered, this section will explain why Workflows need to be [deterministic](https://docs.temporal.io/workflows#deterministic-constraints) in order for Replay to work.

A Workflow is deterministic if every execution of its Workflow Definition produces the same Commands in the same sequence given the same input.

As mentioned in the [`How History Replay Provides Durable Execution`](#How-History-Replay-Provides-Durable-Execution) walkthrough, in the case of a failure, a Worker requests the Event History to replay it. During Replay, the Worker runs the Workflow code again to produce a set of Commands which is compared against the sequence of Commands in the Event History. When there’s a mismatch between the expected sequence of Commands the Worker expects based on the Event History and the actual sequence produced during Replay (due to non-determinism), Replay will be unable to continue.

To better understand why Workflows need to be deterministic, it's helpful to look at a Workflow Definition that violates it. In this case, this code will walk through a Workflow Definition that breaks the determinism constraint with a random number generator.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/go/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.014.jpeg",
]}
captions={[
"NA",
"Imagine the following Workflow Definition is being executed. As the Workflow executes step by step, the first line that results in a Command is the call to the `ImportSalesData` Activity. The Worker issues the `ScheduleActivityTask` Command to the Service. In this case, the execution of the Activity is successful, so the Service logs three Events to the Event History: `ActivityTaskScheduled`, `ActivityTaskStarted`, `ActivityTaskCompleted`.",
"Now, the Worker reaches a conditional statement which evaluates the value of a random-generated number. The random number generator happens to return the value of 84 during this execution. Since the expression evaluates to `true`, execution continues with the next line.",
"The next line is a request to start a Timer, so the Worker issues a Command to the Service - `StartTimer` - requesting that it starts a Timer. The Service starts the Timer, records an Event - `TimerStarted` - and then records another Event when the Timer fires - `TimerFired`.",
"Now imagine that the Worker happens to crash once it reaches to next line, so another Worker takes over, using Replay to restore the current state before continuing execution of the lines that follow.",
"The Worker then requests the Event History to replay it. Once the Worker has the Event History, the Worker determines the expected sequence of Commands needed to restore the current state. The Worker is expecting to encounter the `ScheduleActivityTask` and `StartTimer` Commands.",
"As the Worker executes the code during Replay, it reaches the first call to execute an Activity and creates a `ScheduleActivityTask` Command.",
"This Command matches the one expected based on the Event History. It's not only the right type of Command, but it also occurs at the right position in the sequence of expected Commands. Therefore, Replay proceeds.",
"The Worker now reaches the conditional statement with the random number generator. This time, the random number generator happens to return 14, so the conditional expression evaluates to `false`, and execution skips over the next line.",
"The Worker now reaches the next Command which is to request execution of the `RunDailyReport` Activity, so the Worker creates another `ScheduleActivityTask` Command.",
"However, this is a different Command than it expected to find at this position in the Event History. Since the Workflow produced a different sequence of Commands during Replay than it was expecting due to the Event History that was produced prior to the crash, the Worker is unable to restore the previous state.",
"The Workflow Execution was unable to be replayed due to a non-deterministic error.",
]}
/>

Note that non-deterministic failures do not fail the Workflow Execution by default. A non-deterministic failure is considered a [Workflow Task Failure](https://docs.temporal.io/references/failures#workflow-task-failures) which is considered a transient failure, meaning it retries over and over. Users can also fix the source of non-determinism, perhaps by removing the Activity, and then restart the Workers. This means that this type of failure can recover by itself. You can also use a strategy called versioning to address this non-determinism error. See [versioning](https://docs.temporal.io/develop/go/versioning) to learn more.

For more information on how Temporal handles Durable Execution or to see these slides in a video format with more explanation, check out our free, self-paced courses: [Temporal 102](https://learn.temporal.io/courses/temporal_102/) and [Versioning Workflows](https://learn.temporal.io/courses/versioning/).

---

## Event History Walkthrough with the Java SDK

In order to understand how Workflow Replay works, this page will go through the following walkthroughs:

1. [How Workflow Code Maps to Commands](#How-Workflow-Code-Maps-To-Commands)
2. [How Workflow Commands Map to Events](#How-Workflow-Commands-Map-To-Events)
3. [How History Replay Provides Durable Execution](#How-History-Replay-Provides-Durable-Execution)
4. [Example of a Non-Deterministic Workflow](#Example-of-Non-Deterministic-Workflow)

## How Workflow Code Maps to Commands {#How-Workflow-Code-Maps-To-Commands}

This walkthrough will cover how the Workflow code maps to Commands that get sent to the Temporal Service, letting the Temporal Service know what to do.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/code-commands/code-commands.013.jpeg",
]}
captions={[
"NA",
"Here is code for a basic Temporal Workflow Definition, which does the items described on the right side of the screen.",
"Some steps are internal to the Workflow and do not involve interaction with the Service.",
"On the other hand, some steps do involve interaction with the Temporal Service. For example, when the code requests execution of an Activity, it generates a Command to schedule the Activity Task. Another example is when the code returns a value from the Workflow, the Worker notifies the Temporal Service that the Workflow Execution is complete.",
"The code walkthrough will now begin. In this Workflow Definition, setting the Start-to-Close Timeout and setting a variable are internal steps. That is, these steps don't require any interaction with the Temporal Service.",
"The Worker then reaches a statement that does require interaction with the Temporal Service. In this case, it's a request to execute an Activity. This causes the Worker to issue a Command to the Temporal Service and provides the details needed. For example, the `ScheduleActivityTask` Command contains details such as the Task Queue name, the Activity Type, and the input parameter values. Even though an Activity can take hours or days to complete, the Worker does not use resources.",
"After the `getDistance` Activity has successfully completed, the Worker continues executing the Workflow code. The next line, highlighted here, evaluates a variable. Depending on the outcome, it may throw an exception, which would send a Command to the Server to request it to fail the Workflow Execution. However, this example assumes that this is a delivery for a nearby customer. The execution will continue.",
"The Worker now reaches the call to start a Timer, which is another statement that involves interaction with the Temporal Service. This causes the Worker to issue another Command, one which requests the Temporal Service to start a Timer. The duration is one of the details specified in this Command. Further execution of this Workflow will now pause for 30 minutes until the Timer fires.",
"The Timer then fires. The next few lines, highlighted here, create and populate a data structure that represents the input for the next Activity. While it is related to the Activity, it doesn't involve any interaction with the Service.",
"The next statement involves interaction with the Temporal Service. It requests execution of an Activity, so the Worker issues another Command to the Temporal Service: `ScheduleActivityTask`.",
"Finally, returning from the Workflow function also results in a Command. It issues a `CompleteWorkflowExecution` Command to the Temporal Service, which includes the value that was returned from the function.",
]}
/>

## How Workflow Commands Map to Events {#How-Workflow-Commands-Map-To-Events}

The Commands that are sent to the Temporal Service are then turned into Events, which build up the Event History. The Event History is a detailed log of Events that occur during the lifecycle of a Workflow Execution, such as the execution of Workflow Tasks or Activity Tasks. Event Histories are persisted to the database used by the Temporal Service, so they're durable, and will even survive a crash of the Temporal Service itself.

These Events are what are used to recreate a Workflow Execution's state in the case of failure.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/commands-events/commands-events.014.jpeg",
]}
captions={[
"NA",
"In this walkthrough, there will be a running list of the Commands issued with the corresponding Event to the right.",
"The call to the Activity is the first line of code in the Workflow that causes a Command to be issued. In response to this Command, the Temporal Service creates an Activity Task, adds it to the Task Queue, and appends the `ActivityTaskScheduled` Event to the Event History. This Event is colored blue to indicate that it's the direct result of a Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Service will respond to the poll request with a Task, and the Worker will begin executing the code needed to complete the Task.",
"The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event. Once the Activity completes, the Temporal Service records another Event in response to the Worker accepting the Task: `ActivityTaskStarted`. This Event is colored pink to indicate that it's an indirect result of the Command. By the way, the `Start-to-Close` Timeout indicates the amount of time that the Activity has to complete.",
"The Worker executes the code within the Activity Definition, and when that function returns a result, the Worker sends a message to the Temporal Service, notifying it that the Task is complete. To reiterate, this is just a notification, not a Command, because it's not requesting that the Temporal Service do something that will allow the Workflow Execution to progress. In response to this notification, the Temporal Service records another Event: `ActivityTaskCompleted`.",
"The next statement that results in a Command is the call to start a Timer. It issues a `StartTimer` Command.",
"The Temporal Service responds after starting a Timer for 30 minutes in the Service, logging a `TimerStarted` Event to the history. It is a direct result of the `StartTimer` Command.",
"After 30 minutes has elapsed, the Timer is fired on the Temporal Service, which it then records the Event `TimerFired` to the history. The Workflow Execution continues with the next statement, but this is an internal step, meaning that it does not interact with the Temporal Service.",
"The Worker then reaches the call to the `sendBill` Activity and issues another `ScheduleActivityTask` Command. The Temporal Service adds an Activity Task to the Task Queue and records an `ActivityTaskScheduled` Event to the Event History.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker then removes the Task from the Task Queue, and begins working on it. The Temporal Service records an `ActivityTaskStarted` Event to the Event History, signifying that the Task has been dequeued.",
"When the Activity returns, the Task is complete and the Worker notifies the Temporal Service. In response, the Temporal Service records the `ActivityTaskCompleted` Event to the Event History. Execution will then continue until the Workflow has completed. There will be a complete walkthrough in the next section.",
]}
/>

## How History Replay Provides Durable Execution {#How-History-Replay-Provides-Durable-Execution}

Now that you have seen how code maps to Commands, and how Commands map to Events, this next walkthrough will take a look at how Temporal uses Replay with the Events to provide Durable Execution and restore a Workflow Execution in the case of a failure.

This code walkthrough will begin by walking through a Workflow Execution, describing how the code maps to Commands and Events. There will then be a Worker crash halfway through, explaining how Temporal uses Replay to recover the state of the Workflow Execution, ultimately resulting in a completed execution that's identical to one that had not crashed.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.018.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.019.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.020.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.023.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.025.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.026.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.027.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.028.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.029.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.031.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.032.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.034.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.035.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.036.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.037.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.039.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.041.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.044.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.045.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.047.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.048.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.049.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.050.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.051.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.053.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.054.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.055.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.056.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.057.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.058.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.059.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.061.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.062.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.063.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.065.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.068.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.069.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.071.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.073.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.074.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.075.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.076.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.078.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.079.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.080.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.081.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.082.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.084.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.085.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.086.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/history-replay/history-replay.087.jpeg",
]}
captions={[
"NA",
"This walkthrough begins with a request to execute this Workflow Definition, passing in some input data. In this case, the input data contains information about the customer and the pizzas ordered.",
"This request to execute the Workflow Definition results in the Temporal Service recording a `WorkflowExecutionStarted` Event into the Event History. It's not indicated in the image, but the `WorkflowExecutionStarted` Event contains the input data provided to this Workflow Execution.",
"The Worker then adds a Workflow Task to the Task Queue, and records a `WorkflowTaskScheduled` Event.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker accepts the Task.",
"The Temporal Service records a `WorkflowTaskStarted` Event.",
"The Worker then invokes the Workflow code and runs the code within it, one statement at a time. The first few lines of code do not result in any interaction with the Temporal Service.",
"However, the Worker encounters a request to execute an Activity, so the Worker will complete the current Workflow Task. The Service adds `WorkflowTaskCompleted` to the Event History.",
"The Worker then makes a single gRPC call - `RespondWorkflowTaskCompleted` - to the Temporal Service, which signals completion of the Workflow Task, and includes any commands such as `ScheduleActivityTask`, containing all details about the Activity Execution within this call. So to clarify, `WorkflowTaskCompleted` and `ActivityTaskScheduled` are technically one call.",
"In response, the Temporal Service queues an Activity Task and records an `ActivityTaskScheduled` Event to the Event History. This is shown in blue to indicate that it is the direct result of the Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task and starts working on the code within this `getDistance` Activity. The Temporal Service records an `ActivityTaskStarted` Event to the Event History to signify that the Worker has started the Activity Task. This Event is in a pink box to indicate that it's the indirect result of the Command. The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event.",
"When the Activity function returns - with a result of 15 - the Worker notifies the Service that the Activity Execution is complete.",
"The Temporal Service records an `ActivityTaskCompleted` Event, which contains the result of the Activity.",
"In order to deliver the Activity Task result, 15, back to the Workflow, the Temporal Service creates another Workflow Task which includes the result of this Activity. `WorkflowTaskScheduled` is appended to the Event History.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker dequeues the Task and resumes execution of the Workflow. The `WorkflowTaskStarted` Event gets appended to the Event History. The Worker then executes the next few lines of code - evaluating the distance, calculating the price of the pizza, and so on.",
"The Worker reaches the request to start the Timer. Therefore, it notifies the Service to complete the current Workflow Task.",
"The Worker will complete the current Workflow Task, adding `WorkflowTaskCompleted` to the Event History. This Event includes the the `StartTimer` Command.",
"The Worker issues a `StartTimer` Command to the Service, requesting it to set the Timer for 30 minutes. The Service records a `TimerStarted` Event in response.",
"The Workflow does not progress until the Timer fires.",
"After 30 minutes has elapsed, the Timer fires, and the Service records a `TimerFired` Event.",
"The Service now adds a new Workflow Task to the Queue in order to deliver the `TimerFired` Event to the Workflow, so `WorkflowTaskScheduled` is added to the Event History to drive the Workflow progress forward.",
"The Worker polls for the Task, dequeues it, and continues execution of the Workflow code.",
"However, the Worker happens to crash right here. How does Temporal recover the state of the Workflow? But first, how do you know when a Worker has crashed?",
"Once a Worker has accepted a Task, it is expected to complete that task within a predefined duration, known as a Timeout. This timeout is available to recognize whether a Worker has gone down. This results in a Workflow Task Timeout, which has a default value of 10 seconds.",
"Therefore, if the Worker failed to complete this Workflow Task within that time, the Service will schedule a new Workflow Task.",
"The Worker polling might be done by another Worker that's running in the Worker fleet or by a new Worker process created by restarting the one that crashed.",
"In either case, the Worker will need the current Event History for this execution, so it requests it from the Service.",
"The Service provides the Event History. Notice the black horizontal line in the column on the right to indicate the final Event in the History at the time of the Worker Crash.",
"The Worker then begins a re-execution of the code, using the same input, which was stored in the `WorkflowExecutionStarted` Event. Remember, because the Workflow code is deterministic, the state of all variables encountered so far is identical to what it was before the crash.",
"For example, the `totalPrice` variable was the same as it was prior to the crash.",
"When the Replay reaches the call to schedule to `getDistance` Activity, it creates a `ScheduleActivityTask` Command but does not issue it to the Temporal Service. Instead, the Worker inspects the Event History and finds three Events related to this Activity.",
"The `ActivityTaskScheduled` Event, with the details including this specific Activity Type, indicates that the Task was previously scheduled by the Temporal Service.",
"The `ActivityTaskStarted` Event indicates that a Worker dequeued the Task.",
"The `ActivityTaskCompleted` Event indicates that the Worker successfully completed the Task for the `getDistance` Activity, having returned a value of 15. The Worker now knows that the Activity has completed and does not need to issue the Command.",
"The Worker uses the value stored in the `ActivityTaskCompleted` Event, 15, and assigns it to the `distance` variable. To emphasize, the Worker is not re-executing the Activity, it's using the result stored in the Event History, so there is no way that the Activity behaves differently during History Replay than the original execution.",
"Replay continues replaying the code.",
"The execution of each statement helps to restore the previous state of the Workflow.",
"The Worker then reaches the request to start a Timer. It creates a Command, `StartTimer`. Again, the Worker does not issue the Command to the Service.",
"Instead, the Worker checks the Event History to see whether the Timer was started and fired during the previous execution. The Event History indicates that the Timer was started, because there is a `TimerStarted` Event.",
"The Event History also indicates that the Timer was fired, because there is a `TimerFired` Event.",
"At this point, the Worker has reached the point where the crash occurred, and replaying the code has completely restored the state of the Workflow Execution prior to the crash.",
"For example, the variable used for `distance` has the same value now as it did before the crash.",
"Since Replay uses the same input data as before, this also means that the conditional statement evaluates to `false`, like it did before.",
"The Worker has now reached a statement beyond where the crash occurred, which is evident because the Event History does not contain any Events related to this `sendBill` Activity. Further execution of this Workflow continues on as if the crash never happened.",
"Because the Worker encounters a request to execute an Activity, the Worker completes the current Workflow Task.",
"The Worker issues a Command to the Service, requesting execution of the Activity.",
"The Worker adds the Activity Task to the Task queue, adding `ActivityTaskScheduled` to the Event History. The Worker polls for the Task.",
"The Worker dequeues the Task, adding `ActivityTaskStarted` to the Event History.",
"When the Activity returns a result, the Worker notifies the Service.",
"The Worker records an `ActivityTaskCompleted` Event, which includes the result from the `sendBill` Activity.",
"But since the Service hasn't yet received a Command that says the Workflow Execution has completed or failed, the Service schedules another Workflow Task to continue progress of the execution.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task.",
"When the Workflow completes, the Worker notifies the Service that the current Workflow Task is complete.",
"The Service records a `WorkflowTaskCompleted` Event to reflect this.",
"Since the Worker has now successfully completed the execution of the Workflow, it issues a `CompleteWorkflowExecution` Command to the Service, which contains the result returned by the Workflow Execution.",
"The Service then records `WorkflowExecutionCompleted` as the final Event in the Event History. The Workflow Execution is now complete.",
]}
/>

## Example of a Non-Deterministic Workflow {#Example-of-Non-Deterministic-Workflow}

Now that Replay has been covered, this section will explain why Workflows need to be [deterministic](https://docs.temporal.io/workflows#deterministic-constraints) in order for Replay to work.

A Workflow is deterministic if every execution of its Workflow Definition produces the same Commands in the same sequence given the same input.

As mentioned in the [`How History Replay Provides Durable Execution`](#How-History-Replay-Provides-Durable-Execution) walkthrough, in the case of a failure, a Worker requests the Event History to replay it. During Replay, the Worker runs the Workflow code again to produce a set of Commands which is compared against the sequence of Commands in the Event History. When there’s a mismatch between the expected sequence of Commands the Worker expects based on the Event History and the actual sequence produced during Replay (due to non-determinism), Replay will be unable to continue.

To better understand why Workflows need to be deterministic, it's helpful to look at a Workflow Definition that violates it. In this case, this code will walk through a Workflow Definition that breaks the determinism constraint with a random number generator.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.017.jpeg",
"https://learn.temporal.io/courses/temporal-102/java/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.018.jpeg",
]}
captions={[
"NA",
"Imagine the following Workflow Definition is being executed.",
"As the Workflow executes step by step, the first line that results in a Command is the call to the `importSalesData` Activity. The Worker issues the `ScheduleActivityTask` Command to the Service. In this case, the execution of the Activity is successful, so the Service logs three Events to the Event History: `ActivityTaskScheduled`, `ActivityTaskStarted`, `ActivityTaskCompleted`.",
"Now, the Worker reaches a conditional statement which evaluates the value of a random-generated number. The random number generator happens to return the value of 84 during this execution. Since the expression evaluates to `true`, execution continues with the next line.",
"The next line is a request to start a Timer, so the Worker issues a Command to the Service - `StartTimer` - requesting that it starts a Timer.",
"The Service starts the Timer, records an Event - `TimerStarted` - and then records another Event when the Timer fires - `TimerFired`.",
"Now imagine that the Worker happens to crash once it reaches to next line, so another Worker takes over, using Replay to restore the current state before continuing execution of the lines that follow.",
"The Worker then requests the Event History to replay it. Once the Worker has the Event History, the Worker determines the expected sequence of Commands needed to restore the current state. The Worker is expecting to encounter the `ScheduleActivityTask` and `StartTimer` Commands.",
"As the Worker executes the code during Replay, it reaches the first call to execute an Activity and creates a `ScheduleActivityTask` Command. This Command matches the one expected based on the Event History. It's not only the right type of Command, with the same details, but it also occurs at the right position in the sequence of expected Commands. Therefore, Replay proceeds.",
"The Worker now reaches the conditional statement with the random number generator. This time, the random number generator happens to return 14, so the conditional expression evaluates to `false`, and execution skips over the next line.",
"The Worker now reaches the next Command which is to request execution of the `runDailyReport` Activity, so the Worker creates another `ScheduleActivityTask` Command.",
"However, this is a different Command than it expected to find at this position in the Event History. Since the Workflow produced a different sequence of Commands during Replay than it was expecting due to the Event History that was produced prior to the crash, the Worker is unable to restore the previous state.",
"The Workflow Execution was unable to be replayed due to a non-deterministic error.",
]}
/>

Note that non-deterministic failures do not fail the Workflow Execution by default. A non-deterministic failure is considered a [Workflow Task Failure](https://docs.temporal.io/references/failures#workflow-task-failures) which is considered a transient failure, meaning it retries over and over. Users can also fix the source of non-determinism, perhaps by removing the Activity, and then restart the Workers. This means that this type of failure can recover by itself. You can also use a strategy called versioning to address this non-determinism error. See [versioning](https://docs.temporal.io/develop/java/versioning) to learn more.

For more information on how Temporal handles Durable Execution or to see these slides in a video format with more explanation, check out our free, self-paced courses: [Temporal 102](https://learn.temporal.io/courses/temporal_102/) and [Versioning Workflows](https://learn.temporal.io/courses/versioning/).

---

## Event History Walkthrough with the Python SDK

In order to understand how Workflow Replay works, this page will go through the following walkthroughs:

1. [How Workflow Code Maps to Commands](#How-Workflow-Code-Maps-To-Commands)
2. [How Workflow Commands Map to Events](#How-Workflow-Commands-Map-To-Events)
3. [How History Replay Provides Durable Execution](#How-History-Replay-Provides-Durable-Execution)
4. [Example of a Non-Deterministic Workflow](#Example-of-Non-Deterministic-Workflow)

## How Workflow Code Maps to Commands {#How-Workflow-Code-Maps-To-Commands}

This walkthrough will cover how the Workflow code maps to Commands that get sent to the Temporal Service, letting the Temporal Service know what to do.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/code-commands/code-commands.012.jpeg",
]}
captions={[
"NA",
"Here is code for a basic Temporal Workflow Definition, which does the items described on the right side of the screen.",
"Some steps are internal to the Workflow and do not involve interaction with the Service.",
"On the other hand, some steps do involve interaction with the Temporal Service. For example, when the code requests execution of an Activity, it generates a Command to schedule the Activity Task. Another example is when the code returns a value from the Workflow, the Worker notifies the Temporal Service that the Workflow Execution is complete.",
"The code walkthrough will now begin. In this Workflow Definition, setting a variable is an internal step. That is, this step doesn't require any interaction with the Temporal Service.",
"The Worker then reaches a statement that does require interaction with the Temporal Service. In this case, it's a request to execute an Activity. This causes the Worker to issue a Command to the Temporal Service and provides the details needed. For example, the `ScheduleActivityTask` Command contains details such as the Task Queue name, the Activity Type, and the input parameter values. Even though an Activity can take hours or days to complete, the Worker does not use resources.",
"After the `get_distance` Activity has successfully completed, the Worker continues executing the Workflow code. The next line, highlighted here, evaluates a variable. Depending on the outcome, it may throw an exception, which would send a Command to the Server to request it to fail the Workflow Execution. However, this example assumes that this is a delivery for a nearby customer. The execution will continue.",
"The Worker now reaches the call to start a Timer, which is another statement that involves interaction with the Temporal Service. This causes the Worker to issue another Command, one which requests the Temporal Service to start a Timer. The duration is one of the details specified in this Command. Further execution of this Workflow will now pause for 30 minutes until the Timer fires.",
"The Timer then fires. The next few lines, highlighted here, create and populate a data structure that represents the input for the next Activity. While it is related to the Activity, it doesn't involve any interaction with the Service.",
"The next statement involves interaction with the Temporal Service. It requests execution of an Activity, so the Worker issues another Command to the Temporal Service: `ScheduleActivityTask`.",
"Finally, returning from the Workflow function also results in a Command. It issues a `CompleteWorkflowExecution` Command to the Temporal Service, which includes the value that was returned from the function.",
]}
/>

## How Workflow Commands Map to Events {#How-Workflow-Commands-Map-To-Events}

The Commands that are sent to the Temporal Service are then turned into Events, which build up the Event History. The Event History is a detailed log of Events that occur during the lifecycle of a Workflow Execution, such as the execution of Workflow Tasks or Activity Tasks. Event Histories are persisted to the database used by the Temporal Service, so they're durable, and will even survive a crash of the Temporal Service itself.

These Events are what are used to recreate a Workflow Execution's state in the case of failure.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/commands-events/commands-events.014.jpeg",
]}
captions={[
"NA",
"In this walkthrough, there will be a running list of the Commands issued with the corresponding Event to the right.",
"The call to the Activity is the first line of code in the Workflow that causes a Command to be issued. In response to this Command, the Temporal Service creates an Activity Task, adds it to the Task Queue, and appends the `ActivityTaskScheduled` Event to the Event History. This Event is colored blue to indicate that it's the direct result of a Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Service will respond to the poll request with a Task, and the Worker will begin executing the code needed to complete the Task.",
"The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event. Once the Activity completes, the Temporal Service records another Event in response to the Worker accepting the Task: `ActivityTaskStarted`. This Event is colored pink to indicate that it's an indirect result of the Command. By the way, the `Start-to-Close` Timeout indicates the amount of time that the Activity has to complete.",
"The Worker executes the code within the Activity Definition, and when that function returns a result, the Worker sends a message to the Temporal Service, notifying it that the Task is complete. To reiterate, this is just a notification, not a Command, because it's not requesting that the Temporal Service do something that will allow the Workflow Execution to progress. In response to this notification, the Temporal Service records another Event: `ActivityTaskCompleted`.",
"The next statement that results in a Command is the call to start a Timer. It issues a `StartTimer` Command.",
"The Temporal Service responds after starting a Timer for 30 minutes in the Service, logging a `TimerStarted` Event to the history. It is a direct result of the `StartTimer` Command.",
"After 30 minutes has elapsed, the Timer is fired on the Temporal Service, which it then records the Event `TimerFired` to the history. The Workflow Execution continues with the next statement, but this is an internal step, meaning that it does not interact with the Temporal Service.",
"The Worker then reaches the call to the `send_bill` Activity and issues another `ScheduleActivityTask` Command. The Temporal Service adds an Activity Task to the Task Queue and records an `ActivityTaskScheduled` Event to the Event History.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker then removes the Task from the Task Queue, and begins working on it. The Temporal Service records an `ActivityTaskStarted` Event to the Event History, signifying that the Task has been dequeued.",
"When the Activity returns, the Task is complete and the Worker notifies the Temporal Service. In response, the Temporal Service records the `ActivityTaskCompleted` Event to the Event History. Execution will then continue until the Workflow has completed. There will be a complete walkthrough in the next section.",
]}
/>

## How History Replay Provides Durable Execution {#How-History-Replay-Provides-Durable-Execution}

Now that you have seen how code maps to Commands, and how Commands map to Events, this next walkthrough will take a look at how Temporal uses Replay with the Events to provide Durable Execution and restore a Workflow Execution in the case of a failure.

This code walkthrough will begin by walking through a Workflow Execution, describing how the code maps to Commands and Events. There will then be a Worker crash halfway through, explaining how Temporal uses Replay to recover the state of the Workflow Execution, ultimately resulting in a completed execution that's identical to one that had not crashed.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.014.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.018.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.019.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.020.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.023.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.026.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.027.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.028.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.029.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.030.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.031.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.032.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.033.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.034.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.035.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.037.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.038.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.039.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.043.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.045.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.046.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.048.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.049.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.050.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.051.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.054.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.055.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.056.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.057.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.058.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.059.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.061.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.062.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.063.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.064.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.066.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.068.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.069.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.071.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.072.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.074.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.075.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.076.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.078.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.079.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.080.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.081.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.082.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.084.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.085.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.086.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/history-replay/history-replay.087.jpeg",
]}
captions={[
"NA",
"This walkthrough begins with a request to execute this Workflow Definition, passing in some input data. In this case, the input data contains information about the customer and the pizzas ordered.",
"This request to execute the Workflow Definition results in the Temporal Service recording a `WorkflowExecutionStarted` Event into the Event History. It's not indicated in the image, but the `WorkflowExecutionStarted` Event contains the input data provided to this Workflow Execution.",
"The Worker then adds a Workflow Task to the Task Queue, and records a `WorkflowTaskScheduled` Event.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker accepts the Task.",
"The Temporal Service records a `WorkflowTaskStarted` Event.",
"The Worker then invokes the Workflow code and runs the code within it, one statement at a time.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"However, the Worker encounters a request to execute an Activity, so the Worker will complete the current Workflow Task. The Service adds `WorkflowTaskCompleted` to the Event History.",
"The Worker then makes a single gRPC call - `RespondWorkflowTaskCompleted` - to the Temporal Service, which signals completion of the Workflow Task, and includes any commands such as `ScheduleActivityTask`, containing all details about the Activity Execution within this call. So to clarify, `WorkflowTaskCompleted` and `ActivityTaskScheduled` are technically one call.",
"In response, the Temporal Service queues an Activity Task and records an `ActivityTaskScheduled` Event to the Event History. This is shown in blue to indicate that it is the direct result of the Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task and starts working on the code within this `get_distance` Activity. The Temporal Service records an `ActivityTaskStarted` Event to the Event History to signify that the Worker has started the Activity Task. This Event is in a pink box to indicate that it's the indirect result of the Command. The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event.",
"When the Activity function returns - with a result of 15 - the Worker notifies the Service that the Activity Execution is complete.",
"The Temporal Service records an `ActivityTaskCompleted` Event, which contains the result of the Activity.",
"In order to deliver the Activity Task result, 15, back to the Workflow, the Temporal Service creates another Workflow Task which includes the result of this Activity. `WorkflowTaskScheduled` is appended to the Event History.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker dequeues the Task and resumes execution of the Workflow. The `WorkflowTaskStarted` Event gets appended to the Event History.",
"The Worker then executes the next few lines of code, evaluating the distance.",
"The Worker reaches the request to start the Timer. Therefore, it notifies the Service to complete the current Workflow Task.",
"The Worker will complete the current Workflow Task, adding `WorkflowTaskCompleted` to the Event History. This Event includes the the `StartTimer` Command.",
"The Worker issues a `StartTimer` Command to the Service, requesting it to set the Timer for 30 minutes. The Service records a `TimerStarted` Event in response.",
"The Workflow does not progress until the Timer fires.",
"After 30 minutes has elapsed, the Timer fires, and the Service records a `TimerFired` Event.",
"The Service now adds a new Workflow Task to the Queue in order to deliver the `TimerFired` Event to the Workflow, so `WorkflowTaskScheduled` is added to the Event History to drive the Workflow progress forward.",
"The Worker polls for the Task, dequeues it, and continues execution of the Workflow code.",
"However, the Worker happens to crash right here. How does Temporal recover the state of the Workflow? But first, how do you know when a Worker has crashed?",
"Once a Worker has accepted a Task, it is expected to complete that task within a predefined duration, known as a Timeout. This timeout is available to recognize whether a Worker has gone down. This results in a Workflow Task Timeout, which has a default value of 10 seconds.",
"Therefore, if the Worker failed to complete this Workflow Task within that time, the Service will schedule a new Workflow Task.",
"The Worker polling might be done by another Worker that's running in the Worker fleet or by a new Worker process created by restarting the one that crashed.",
"In either case, the Worker will need the current Event History for this execution, so it requests it from the Service.",
"The Service provides the Event History. Notice the black horizontal line in the column on the right to indicate the final Event in the History at the time of the Worker Crash.",
"The Worker then begins a re-execution of the code, using the same input, which was stored in the `WorkflowExecutionStarted` Event. Remember, because the Workflow code is deterministic, the state of all variables encountered so far is identical to what it was before the crash.",
"When the Replay reaches the call to schedule to `get_distance` Activity, it creates a `ScheduleActivityTask` Command but does not issue it to the Temporal Service. Instead, the Worker inspects the Event History and finds three Events related to this Activity.",
"The `ActivityTaskScheduled` Event, with the details including this specific Activity Type, indicates that the Task was previously scheduled by the Temporal Service.",
"The `ActivityTaskStarted` Event indicates that a Worker dequeued the Task.",
"The `ActivityTaskCompleted` Event indicates that the Worker successfully completed the Task for the `get_distance` Activity, having returned a value of 15. The Worker now knows that the Activity has completed and does not need to issue the Command.",
"The Worker uses the value stored in the `ActivityTaskCompleted` Event, 15, and assigns it to the `distance` variable. To emphasize, the Worker is not re-executing the Activity, it's using the result stored in the Event History, so there is no way that the Activity behaves differently during History Replay than the original execution.",
"Replay continues replaying the code.",
"NA",
"The Worker then reaches the request to start a Timer. It creates a Command, `StartTimer`. Again, the Worker does not issue the Command to the Service.",
"Instead, the Worker checks the Event History to see whether the Timer was started and fired during the previous execution. The Event History indicates that the Timer was started, because there is a `TimerStarted` Event.",
"The Event History also indicates that the Timer was fired, because there is a `TimerFired` Event.",
"At this point, the Worker has reached the point where the crash occurred, and replaying the code has completely restored the state of the Workflow Execution prior to the crash.",
"For example, the `distance` variable was set using the value that was stored in the Event History from the previous Execution.",
"Since Replay uses the same input data as before, this also means that the conditional statement evaluates to `false`, like it did before.",
"The Worker has now reached a statement beyond where the crash occurred, which is evident because the Event History does not contain any Events related to this `send_bill` Activity. Further execution of this Workflow continues on as if the crash never happened.",
"Because the Worker encounters a request to execute an Activity, the Worker completes the current Workflow Task.",
"The Worker issues a Command to the Service, requesting execution of the Activity.",
"The Worker adds the Activity Task to the Task queue, adding `ActivityTaskScheduled` to the Event History. The Worker polls for the Task.",
"The Worker dequeues the Task, adding `ActivityTaskStarted` to the Event History.",
"When the Activity returns a result, the Worker notifies the Service.",
"The Worker records an `ActivityTaskCompleted` Event, which includes the result from the `send_bill` Activity.",
"But since the Service hasn't yet received a Command that says the Workflow Execution has completed or failed, the Service schedules another Workflow Task to continue progress of the execution.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task.",
"When the Workflow completes, the Worker notifies the Service that the current Workflow Task is complete.",
"The Service records a `WorkflowTaskCompleted` Event to reflect this.",
"Since the Worker has now successfully completed the execution of the Workflow, it issues a `CompleteWorkflowExecution` Command to the Service, which contains the result returned by the Workflow Execution.",
"The Service then records `WorkflowExecutionCompleted` as the final Event in the Event History. The Workflow Execution is now complete.",
]}
/>

## Example of a Non-Deterministic Workflow {#Example-of-Non-Deterministic-Workflow}

Now that Replay has been covered, this section will explain why Workflows need to be [deterministic](https://docs.temporal.io/workflows#deterministic-constraints) in order for Replay to work.

A Workflow is deterministic if every execution of its Workflow Definition produces the same Commands in the same sequence given the same input.

As mentioned in the [`How History Replay Provides Durable Execution`](#How-History-Replay-Provides-Durable-Execution) walkthrough, in the case of a failure, a Worker requests the Event History to replay it. During Replay, the Worker runs the Workflow code again to produce a set of Commands which is compared against the sequence of Commands in the Event History. When there’s a mismatch between the expected sequence of Commands the Worker expects based on the Event History and the actual sequence produced during Replay (due to non-determinism), Replay will be unable to continue.

To better understand why Workflows need to be deterministic, it's helpful to look at a Workflow Definition that violates it. In this case, this code will walk through a Workflow Definition that breaks the determinism constraint with a random number generator.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.017.jpeg",
"https://learn.temporal.io/courses/temporal-102/python/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.018.jpeg",
]}
captions={[
"NA",
"Imagine the following Workflow Definition is being executed.",
"As the Workflow executes step by step, the first line that results in a Command is the call to the `import_sales_data` Activity. The Worker issues the `ScheduleActivityTask` Command to the Service. In this case, the execution of the Activity is successful, so the Service logs three Events to the Event History: `ActivityTaskScheduled`, `ActivityTaskStarted`, `ActivityTaskCompleted`.",
"Now, the Worker reaches a conditional statement which evaluates the value of a random-generated number. The random number generator happens to return the value of 84 during this execution. Since the expression evaluates to `true`, execution continues with the next line.",
"The next line is a request to start a Timer, so the Worker issues a Command to the Service - `StartTimer` - requesting that it starts a Timer.",
"The Service starts the Timer, records an Event - `TimerStarted` - and then records another Event when the Timer fires - `TimerFired`.",
"Now imagine that the Worker happens to crash once it reaches to next line, so another Worker takes over, using Replay to restore the current state before continuing execution of the lines that follow.",
"The Worker then requests the Event History to replay it. Once the Worker has the Event History, the Worker determines the expected sequence of Commands needed to restore the current state. The Worker is expecting to encounter the `ScheduleActivityTask` and `StartTimer` Commands.",
"As the Worker executes the code during Replay, it reaches the first call to execute an Activity and creates a `ScheduleActivityTask` Command. This Command matches the one expected based on the Event History. It's not only the right type of Command, with the same details, but it also occurs at the right position in the sequence of expected Commands. Therefore, Replay proceeds.",
"The Worker now reaches the conditional statement with the random number generator. This time, the random number generator happens to return 14, so the conditional expression evaluates to `false`, and execution skips over the next line.",
"The Worker now reaches the next Command which is to request execution of the `run_daily_report` Activity, so the Worker creates another `ScheduleActivityTask` Command.",
"However, this is a different Command than it expected to find at this position in the Event History. Since the Workflow produced a different sequence of Commands during Replay than it was expecting due to the Event History that was produced prior to the crash, the Worker is unable to restore the previous state.",
"The Workflow Execution was unable to be replayed due to a non-deterministic error.",
]}
/>

Note that non-deterministic failures do not fail the Workflow Execution by default. A non-deterministic failure is considered a [Workflow Task Failure](https://docs.temporal.io/references/failures#workflow-task-failures) which is considered a transient failure, meaning it retries over and over. Users can also fix the source of non-determinism, perhaps by removing the Activity, and then restart the Workers. This means that this type of failure can recover by itself. You can also use a strategy called versioning to address this non-determinism error. See [versioning](https://docs.temporal.io/develop/python/versioning) to learn more.

For more information on how Temporal handles Durable Execution or to see these slides in a video format with more explanation, check out our free, self-paced courses: [Temporal 102](https://learn.temporal.io/courses/temporal_102/) and [Versioning Workflows](https://learn.temporal.io/courses/versioning/).

---

## Event History Walkthrough with the TypeScript SDK

In order to understand how Workflow Replay works, this page will go through the following walkthroughs:

1. [How Workflow Code Maps to Commands](#How-Workflow-Code-Maps-To-Commands)
2. [How Workflow Commands Map to Events](#How-Workflow-Commands-Map-To-Events)
3. [How History Replay Provides Durable Execution](#How-History-Replay-Provides-Durable-Execution)
4. [Example of a Non-Deterministic Workflow](#Example-of-Non-Deterministic-Workflow)

## How Workflow Code Maps to Commands {#How-Workflow-Code-Maps-To-Commands}

This walkthrough will cover how the Workflow code maps to Commands that get sent to the Temporal Service, letting the Temporal Service know what to do.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.018.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.019.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.020.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.021.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.023.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/code-commands/code-commands.024.jpeg",
]}
captions={[
"NA",
"Here is code for a basic Temporal Workflow Definition, which does the items described on the right side of the screen.",
"Some steps are internal to the Workflow and do not involve interaction with the Service.",
"On the other hand, some steps do involve interaction with the Temporal Service. For example, when the code requests execution of an Activity, it generates a Command to schedule the Activity Task. Another example is when the code returns a value from the Workflow, the Worker notifies the Temporal Service that the Workflow Execution is complete.",
"The code walkthrough will now begin. In this Workflow Definition, setting the Start-to-Close Timeout and setting a variable are internal steps. That is, these steps don't require any interaction with the Temporal Service.",
"The Worker then reaches a statement that does require interaction with the Temporal Service. In this case, it's a request to execute an Activity. This causes the Worker to issue a Command to the Temporal Service and provides the details needed. For example, the `ScheduleActivityTask` Command contains details such as the Task Queue name, the Activity Type, and the input parameter values. Even though an Activity can take hours or days to complete, the Worker does not use resources.",
"After the `getDistance` Activity has successfully completed, the Worker continues executing the Workflow code. The next line, highlighted here, evaluates a variable. Depending on the outcome, it may throw an exception, which would send a Command to the Server to request it to fail the Workflow Execution. However, this example assumes that this is a delivery for a nearby customer. The execution will continue.",
"The next step also does not involve interaction with the Service.",
"The Worker now reaches the call to start a Timer, which is another statement that involves interaction with the Temporal Service. This causes the Worker to issue another Command, one which requests the Temporal Service to start a Timer. The duration is one of the details specified in this Command. Further execution of this Workflow will now pause for 30 minutes until the Timer fires.",
"The Timer then fires. The next few lines, highlighted here, create and populate an object that represents the input for the next Activity. While it is related to the Activity, it doesn't involve any interaction with the Service.",
"The next statement involves interaction with the Temporal Service. It requests execution of an Activity, so the Worker issues another Command to the Temporal Service: `ScheduleActivityTask`.",
"Finally, returning from the Workflow function also results in a Command. It issues a `CompleteWorkflowExecution` Command to the Temporal Service, which includes the value that was returned from the function.",
]}
/>

## How Workflow Commands Map to Events {#How-Workflow-Commands-Map-To-Events}

The Commands that are sent to the Temporal Service are then turned into Events, which build up the Event History. The Event History is a detailed log of Events that occur during the lifecycle of a Workflow Execution, such as the execution of Workflow Tasks or Activity Tasks. Event Histories are persisted to the database used by the Temporal Service, so they're durable, and will even survive a crash of the Temporal Service itself.

These Events are what are used to recreate a Workflow Execution's state in the case of failure.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/commands-events/commands-events.014.jpeg",
]}
captions={[
"NA",
"In this walkthrough, there will be a running list of the Commands issued with the corresponding Event to the right.",
"The call to the Activity is the first line of code in the Workflow that causes a Command to be issued. In response to this Command, the Temporal Service creates an Activity Task, adds it to the Task Queue, and appends the `ActivityTaskScheduled` Event to the Event History. This Event is colored blue to indicate that it's the direct result of a Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Service will respond to the poll request with a Task, and the Worker will begin executing the code needed to complete the Task.",
"The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event. Once the Activity completes, the Temporal Service records another Event in response to the Worker accepting the Task: `ActivityTaskStarted`. This Event is colored pink to indicate that it's an indirect result of the Command. By the way, the `Start-to-Close` Timeout indicates the amount of time that the Activity has to complete.",
"The Worker executes the code within the Activity Definition, and when that function returns a result, the Worker sends a message to the Temporal Service, notifying it that the Task is complete. To reiterate, this is just a notification, not a Command, because it's not requesting that the Temporal Service do something that will allow the Workflow Execution to progress. In response to this notification, the Temporal Service records another Event: `ActivityTaskCompleted`.",
"The next statement that results in a Command is the call to start a Timer. It issues a `StartTimer` Command.",
"The Temporal Service responds after starting a Timer for 30 minutes in the Service, logging a `TimerStarted` Event to the history. It is a direct result of the `StartTimer` Command.",
"After 30 minutes has elapsed, the Timer is fired on the Temporal Service, which it then records the Event `TimerFired` to the history. The Workflow Execution continues with the next statement, but this is an internal step, meaning that it does not interact with the Temporal Service.",
"The Worker then reaches the call to the `sendBill` Activity and issues another `ScheduleActivityTask` Command. The Temporal Service adds an Activity Task to the Task Queue and records an `ActivityTaskScheduled` Event to the Event History.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker then removes the Task from the Task Queue, and begins working on it. The Temporal Service records an `ActivityTaskStarted` Event to the Event History, signifying that the Task has been dequeued.",
"When the Activity returns, the Task is complete and the Worker notifies the Temporal Service. In response, the Temporal Service records the `ActivityTaskCompleted` Event to the Event History. Execution will then continue until the Workflow has completed. There will be a complete walkthrough in the next section.",
]}
/>

## How History Replay Provides Durable Execution {#How-History-Replay-Provides-Durable-Execution}

Now that you have seen how code maps to Commands, and how Commands map to Events, this next walkthrough will take a look at how Temporal uses Replay with the Events to provide Durable Execution and restore a Workflow Execution in the case of a failure.

This code walkthrough will begin by walking through a Workflow Execution, describing how the code maps to Commands and Events. There will then be a Worker crash halfway through, explaining how Temporal uses Replay to recover the state of the Workflow Execution, ultimately resulting in a completed execution that's identical to one that had not crashed.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.003.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.005.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.007.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.012.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.018.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.019.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.020.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.021.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.022.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.026.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.027.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.028.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.029.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.031.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.032.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.035.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.036.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.039.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.040.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.042.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.043.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.044.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.045.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.047.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.048.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.049.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.050.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.051.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.053.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.054.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.057.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.058.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.059.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.061.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.062.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.063.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.064.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.067.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.068.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.069.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.070.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.071.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.073.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.074.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.075.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.076.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.077.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.079.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.080.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.081.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/history-replay/history-replay.082.jpeg",
]}
captions={[
"NA",
"This walkthrough begins with a request to execute this Workflow Definition, passing in some input data. In this case, the input data contains information about the customer and the pizzas ordered.",
"This request to execute the Workflow Definition results in the Temporal Service recording a `WorkflowExecutionStarted` Event into the Event History. It's not indicated in the image, but the `WorkflowExecutionStarted` Event contains the input data provided to this Workflow Execution.",
"The Worker then adds a Workflow Task to the Task Queue, and records a `WorkflowTaskScheduled` Event.",
"The Service will then dispatch this Activity to the Worker.",
"The Worker accepts the Task.",
"The Temporal Service records a `WorkflowTaskStarted` Event.",
"The Worker then invokes the Workflow code and runs the code within it, one statement at a time.",
"The first few lines of code do not result in any interaction with the Temporal Service.",
"However, the Worker encounters a request to execute an Activity, so the Worker will complete the current Workflow Task. The Service adds `WorkflowTaskCompleted` to the Event History.",
"The Worker then makes a single gRPC call - `RespondWorkflowTaskCompleted` - to the Temporal Service, which signals completion of the Workflow Task, and includes any commands such as `ScheduleActivityTask`, containing all details about the Activity Execution within this call. So to clarify, `WorkflowTaskCompleted` and `ActivityTaskScheduled` are technically one call.",
"In response, the Temporal Service queues an Activity Task and records an `ActivityTaskScheduled` Event to the Event History. This is shown in blue to indicate that it is the direct result of the Command.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task and starts working on the code within this `getDistance` Activity. The Temporal Service records an `ActivityTaskStarted` Event to the Event History to signify that the Worker has started the Activity Task. This Event is in a pink box to indicate that it's the indirect result of the Command. The `ActivityTaskStarted` Event is not written to the Event History until a Task closes, because the number of retry attempts is an attribute of the `ActivityTaskStarted` Event.",
"When the Activity function returns - with a result of 15 - the Worker notifies the Service that the Activity Execution is complete.",
"The Temporal Service records an `ActivityTaskCompleted` Event, which contains the result of the Activity.",
"In order to deliver the Activity Task result, 15, back to the Workflow, the Temporal Service creates another Workflow Task which includes the result of this Activity. `WorkflowTaskScheduled` is appended to the Event History.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker dequeues the Task and resumes execution of the Workflow. The `WorkflowTaskStarted` Event gets appended to the Event History. The Worker then executes the next few lines of code - evaluating the distance, calculating the price of the pizza, and so on.",
"The Worker reaches the request to start the Timer. Therefore, it notifies the Service to complete the current Workflow Task.",
"The Worker will complete the current Workflow Task, adding `WorkflowTaskCompleted` to the Event History. This Event includes the the `StartTimer` Command.",
"The Worker issues a `StartTimer` Command to the Service, requesting it to set the Timer for 30 minutes. The Service records a `TimerStarted` Event in response.",
"The Workflow does not progress until the Timer fires.",
"After 30 minutes has elapsed, the Timer fires, and the Service records a `TimerFired` Event.",
"The Service now adds a new Workflow Task to the Queue in order to deliver the `TimerFired` Event to the Workflow, so `WorkflowTaskScheduled` is added to the Event History to drive the Workflow progress forward.",
"The Worker polls for the Task, dequeues it, and continues execution of the Workflow code.",
"However, the Worker happens to crash right here. How does Temporal recover the state of the Workflow? But first, how do you know when a Worker has crashed?",
"Once a Worker has accepted a Task, it is expected to complete that task within a predefined duration, known as a Timeout. This timeout is available to recognize whether a Worker has gone down. This results in a Workflow Task Timeout, which has a default value of 10 seconds.",
"Therefore, if the Worker failed to complete this Workflow Task within that time, the Service will schedule a new Workflow Task.",
"The Worker polling might be done by another Worker that's running in the Worker fleet or by a new Worker process created by restarting the one that crashed.",
"In either case, the Worker will need the current Event History for this execution, so it requests it from the Service.",
"The Service provides the Event History. Notice the black horizontal line in the column on the right to indicate the final Event in the History at the time of the Worker Crash.",
"The Worker then begins a re-execution of the code, using the same input, which was stored in the `WorkflowExecutionStarted` Event. Remember, because the Workflow code is deterministic, the state of all variables encountered so far is identical to what it was before the crash.",
"When the Replay reaches the call to schedule to `getDistance` Activity, it creates a `ScheduleActivityTask` Command but does not issue it to the Temporal Service. Instead, the Worker inspects the Event History and finds three Events related to this Activity.",
"The `ActivityTaskScheduled` Event, with the details including this specific Activity Type, indicates that the Task was previously scheduled by the Temporal Service.",
"The `ActivityTaskStarted` Event indicates that a Worker dequeued the Task.",
"The `ActivityTaskCompleted` Event indicates that the Worker successfully completed the Task for the `getDistance` Activity, having returned a value of 15. The Worker now knows that the Activity has completed and does not need to issue the Command.",
"The Worker uses the value stored in the `ActivityTaskCompleted` Event, 15, and assigns it to the `distance` variable. To emphasize, the Worker is not re-executing the Activity, it's using the result stored in the Event History, so there is no way that the Activity behaves differently during History Replay than the original execution.",
"Replay continues replaying the code.",
"NA",
"The Worker then reaches the request to start a Timer. It creates a Command, `StartTimer`. Again, the Worker does not issue the Command to the Service.",
"Instead, the Worker checks the Event History to see whether the Timer was started and fired during the previous execution. The Event History indicates that the Timer was started, because there is a `TimerStarted` Event.",
"The Event History also indicates that the Timer was fired, because there is a `TimerFired` Event.",
"At this point, the Worker has reached the point where the crash occurred, and replaying the code has completely restored the state of the Workflow Execution prior to the crash.",
"For example, the `distance` variable was set using the value that was stored in the Event History from the previous Execution.",
"Since Replay uses the same input data as before, this also means that the conditional statement evaluates to `false`, like it did before.",
"The `totalPrice` variable also has the same value as it did before the crash.",
"The Worker has now reached a statement beyond where the crash occurred, which is evident because the Event History does not contain any Events related to this `sendBill` Activity. Further execution of this Workflow continues on as if the crash never happened.",
"Because the Worker encounters a request to execute an Activity, the Worker completes the current Workflow Task.",
"The Worker issues a Command to the Service, requesting execution of the Activity.",
"The Worker adds the Activity Task to the Task queue, adding `ActivityTaskScheduled` to the Event History. The Worker polls for the Task.",
"The Worker dequeues the Task, adding `ActivityTaskStarted` to the Event History.",
"When the Activity returns a result, the Worker notifies the Service.",
"The Worker records an `ActivityTaskCompleted` Event, which includes the result from the `sendBill` Activity.",
"But since the Service hasn't yet received a Command that says the Workflow Execution has completed or failed, the Service schedules another Workflow Task to continue progress of the execution.",
"The Service will then dispatch this Activity to an available Worker.",
"The Worker accepts the Task.",
"When the Workflow completes, the Worker notifies the Service that the current Workflow Task is complete.",
"The Service records a `WorkflowTaskCompleted` Event to reflect this.",
"Since the Worker has now successfully completed the execution of the Workflow, it issues a `CompleteWorkflowExecution` Command to the Service, which contains the result returned by the Workflow Execution.",
"The Service then records `WorkflowExecutionCompleted` as the final Event in the Event History. The Workflow Execution is now complete.",
]}
/>

## Example of a Non-Deterministic Workflow {#Example-of-Non-Deterministic-Workflow}

Now that Replay has been covered, this section will explain why Workflows need to be [deterministic](https://docs.temporal.io/workflows#deterministic-constraints) in order for Replay to work.

A Workflow is deterministic if every execution of its Workflow Definition produces the same Commands in the same sequence given the same input.

As mentioned in the [`How History Replay Provides Durable Execution`](#How-History-Replay-Provides-Durable-Execution) walkthrough, in the case of a failure, a Worker requests the Event History to replay it. During Replay, the Worker runs the Workflow code again to produce a set of Commands which is compared against the sequence of Commands in the Event History. When there’s a mismatch between the expected sequence of Commands the Worker expects based on the Event History and the actual sequence produced during Replay (due to non-determinism), Replay will be unable to continue.

To better understand why Workflows need to be deterministic, it's helpful to look at a Workflow Definition that violates it. In this case, this code will walk through a Workflow Definition that breaks the determinism constraint with a random number generator.

<PhotoCarousel
images={[
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.001.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.002.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.004.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.006.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.008.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.009.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.010.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.011.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.013.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.015.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.016.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.017.jpeg",
"https://learn.temporal.io/courses/temporal-102/typescript/event-history-walkthrough/nondeterministic-workflow/nondeterministic-workflow.018.jpeg",
]}
captions={[
"NA",
"Imagine the following Workflow Definition is being executed.",
"As the Workflow executes step by step, the first line that results in a Command is the call to the `importSalesData` Activity. The Worker issues the `ScheduleActivityTask` Command to the Service. In this case, the execution of the Activity is successful, so the Service logs three Events to the Event History: `ActivityTaskScheduled`, `ActivityTaskStarted`, `ActivityTaskCompleted`.",
"Now, the Worker reaches a conditional statement which evaluates the value of a random-generated number. The random number generator happens to return the value of 84 during this execution. Since the expression evaluates to `true`, execution continues with the next line.",
"The next line is a request to start a Timer, so the Worker issues a Command to the Service - `StartTimer` - requesting that it starts a Timer.",
"The Service starts the Timer, records an Event - `TimerStarted` - and then records another Event when the Timer fires - `TimerFired`.",
"Now imagine that the Worker happens to crash once it reaches to next line, so another Worker takes over, using Replay to restore the current state before continuing execution of the lines that follow.",
"The Worker then requests the Event History to replay it. Once the Worker has the Event History, the Worker determines the expected sequence of Commands needed to restore the current state. The Worker is expecting to encounter the `ScheduleActivityTask` and `StartTimer` Commands.",
"As the Worker executes the code during Replay, it reaches the first call to execute an Activity and creates a `ScheduleActivityTask` Command. This Command matches the one expected based on the Event History. It's not only the right type of Command, with the same details, but it also occurs at the right position in the sequence of expected Commands. Therefore, Replay proceeds.",
"The Worker now reaches the conditional statement with the random number generator. This time, the random number generator happens to return 14, so the conditional expression evaluates to `false`, and execution skips over the next line.",
"The Worker now reaches the next Command which is to request execution of the `runDailyReport` Activity, so the Worker creates another `ScheduleActivityTask` Command.",
"However, this is a different Command than it expected to find at this position in the Event History. Since the Workflow produced a different sequence of Commands during Replay than it was expecting due to the Event History that was produced prior to the crash, the Worker is unable to restore the previous state.",
"The Workflow Execution was unable to be replayed due to a non-deterministic error.",
]}
/>

Note that non-deterministic failures do not fail the Workflow Execution by default. A non-deterministic failure is considered a [Workflow Task Failure](https://docs.temporal.io/references/failures#workflow-task-failures) which is considered a transient failure, meaning it retries over and over. Users can also fix the source of non-determinism, perhaps by removing the Activity, and then restart the Workers. This means that this type of failure can recover by itself. You can also use a strategy called versioning to address this non-determinism error. See [versioning](https://docs.temporal.io/develop/typescript/versioning) to learn more.

For more information on how Temporal handles Durable Execution or to see these slides in a video format with more explanation, check out our free, self-paced courses: [Temporal 102](https://learn.temporal.io/courses/temporal_102/) and [Versioning Workflows](https://learn.temporal.io/courses/versioning/).

---

## Temporal Encyclopedia

[Temporal](/evaluate/why-temporal) provides developers a suite of effective tools for building reliable applications at scale.

The following Encyclopedia pages describe the concepts, components, and features of Temporal in detail:

- [Temporal](/temporal)
- [Temporal SDKs](/encyclopedia/temporal-sdks)
- [Workflows](/workflows)
- [Activities](/activities)
- [Detecting application failures](/encyclopedia/detecting-application-failures)
- [Workers](/workers)
- [Event History](/encyclopedia/event-history/)
- [Workflow Message Passing](/encyclopedia/workflow-message-passing/)
- [Child Workflows](/child-workflows)
- [Visibility](/visibility)
- [Temporal Service](/temporal-service)
- [Namespaces](/namespaces)
- [Temporal Nexus](/nexus)
- [Data conversion](/dataconversion)

For a complete list of Temporal terms, see the [Glossary](/glossary).

For information on how to implement the developer-facing features see the [Develop](/develop) section.

For information on how to use Temporal Cloud see the [Temporal Cloud production deployment](/cloud) section.

For information on how to self-host a Temporal Service see the [Self-hosted production deployment](/self-hosted-guide) section.

---

## Global Namespace

This page provides an overview of Global Namespace.

## What is a Global Namespace? {#global-namespace}

A Global Namespace is a [Namespace](/namespaces) that exists across Clusters when [Multi-Cluster Replication](/temporal-service/multi-cluster-replication) is set up.

- [How to register a Global Namespace](/cli/operator#create)
- [How to change the active Cluster for a Global Namespace](/cli/operator#update)

The Global Namespace feature enables Workflow Executions to progress through another Cluster in the event of a failover.

A Global Namespace may be replicated to any number of Clusters, but is active in only one Cluster at any given time.

For a failover to be successful, Worker Processes must be polling for Tasks for the Global Namespace on all Clusters.

A Global Namespace has a failover version.
Because a failover can be triggered from any Cluster, the failover version prevents certain conflicts from occurring if a failover is mistakenly triggered simultaneously on two Clusters.

Only the active Cluster dispatches [Tasks](/tasks#task); however, certain conflicts are possible.
Unlike regular Namespaces, which provide at-most-once semantics for an Activity Execution, Global Namespaces can support only at-least-once semantics (see [Conflict resolution](/temporal-service/multi-cluster-replication#conflict-resolution)).
Worker Processes on the standby Clusters are idle until a failover occurs and their Cluster becomes active.

Temporal Application API calls made to a non-active Cluster are rejected with a **NamespaceNotActiveError** which contains the name of the current active Cluster.
It is the responsibility of the Temporal Application to call the Cluster that is currently active.

---

## Temporal Namespace

This guide provides a comprehensive overview of Namespaces.

A Namespace is a unit of isolation within the Temporal Platform.

A single Namespace is still multi-tenant.

## Usage

Namespaces are created on the Temporal Service, and provide a range of controls to achieve isolation on Workflow Executions.

- Namespaces are a mechanism for resource isolation. Heavy traffic from one Namespace will not impact other Namespaces running on the same Temporal Service.
  For example, you can use Namespaces to match the development lifecycle by having separate `dev` and `prod` Namespaces.
- If no other Namespace is specified, the Temporal Service uses the Namespace "default" for all Temporal SDKs and the Temporal CLI.
  See the [Registration](#registration) section for details.
- Namespaces created on self-hosted Temporal Service are case-sensitive. For example, `foo` and `Foo` are two different Namespaces.
  On Temporal Cloud, Namespaces are case-insensitive, and we recommend using lowercase for Namespace names to avoid potential issues.
- **Membership:** [Task Queue](/task-queue) names and [Workflow Ids](/workflow-execution/workflowid-runid#workflow-id) must all correspond to a specific Namespace.
  For example, when a Workflow Execution is spawned, it does so within a specific Namespace.
- **Uniqueness:** Temporal guarantees a unique Workflow Id within a Namespace.
  Workflow Executions may have the same Workflow Id if they are in different Namespaces.
- **Namespace Configuration:** Various configuration options like the [Retention Period](/temporal-service/temporal-server#retention-period) and the [Archival](/temporal-service/archival) destination are configured per Namespace through a special CRUD API or through the [Temporal CLI](/cli).

## Registration

Registering a Namespace creates the Namespace on the Temporal Service.
When you register your Namespace, you must also set the [Retention Period](/temporal-service/temporal-server#retention-period) for the Namespace.

On Temporal Cloud, use the [Temporal Cloud UI](/cloud/namespaces#create-a-namespace) or [tcld commands](https://docs.temporal.io/cloud/tcld/namespace/) to create and manage Namespaces.

On self-hosted Temporal Service, you can register your Namespaces using the Temporal CLI (recommended) or programmatically using APIs. Note that these APIs and Temporal CLI commands will not work with Temporal Cloud.

All SDKs require a Namespace on the Temporal Service (or Temporal Cloud) for their Client calls. If not set using Client options, the Workflow Client API looks for the `default` Namespace. If there is no default Namespace registered with your Temporal Service (or Temporal Cloud), all calls will throw errors.
You must register your Namespace with the Temporal Service (or Temporal Cloud) before setting it in your Client.

On self-hosted Temporal Service, you can register your Namespaces in the following ways:

- In your Temporal Service setup, create your Namespaces, including the default, in your setup script.
  For example:

  - If deploying through Docker Compose or using the [auto-setup image](https://github.com/temporalio/docker-builds/blob/main/docker/auto-setup.sh) in a custom Docker Compose application, the Namespace "default" is created, through the auto-setup script.
  - If deploying through the [Temporal Helm charts](https://github.com/temporalio/helm-charts), you can create the "default" Namespace by using the Temporal CLI; for example, `temporal operator namespace create --namespace default`

- Use the `temporal operator namespace create` or `temporal operator namespace update` command with the `--retention` modfiier to register your Namespaces, one at a time, and set the Retention Period on each.

  - [How to create a new Namespace using the Temporal CLI](/cli/operator#create)
  - [How to create a new Namespace using the Go SDK](/develop/go/namespaces#register-namespace)
  - [How to create a new Namespace using the Java SDK](/develop/java/namespaces#register-namespace)

- In your Client program, register your Namespace using `RegisterNamespaceRequest` API available in all the SDKs.

Note that registering a Namespace takes up to 15 seconds to complete. Ensure that you are waiting for this process to complete before making calls to the Namespace.

## Manage Namespaces

Use a custom [Authorizer](/self-hosted-guide/security#authorizer-plugin) on your Frontend Service in the Temporal Service to set restrictions on who can create, update, or deprecate Namespaces.

On Temporal Cloud, use the [Temporal Cloud UI](/cloud/namespaces) or [tcld commands](/cloud/tcld/namespace/) to manage Namespaces.

On self-hosted Temporal Service, you can manage your registered Namespaces using the Temporal CLI (recommended) or programmatically using APIs.

{/* Technically correct but is this confusing for people since you can do this for non-self-hosted: _/}
{/_ Note that these APIs and temporal CLI commands will not work with Temporal Cloud. */}

- [How to manage Namespaces using the Go SDK](/develop/go/namespaces#manage-namespaces)
- [How to manage Namespaces using the Java SDK](/develop/java/namespaces#manage-namespaces)

- Update information and configuration for a registered Namespace on your Temporal Service:

  - With the Temporal CLI: [`temporal operator namespace update`](/cli/operator#update)
  - Use the Update Namespace API to update configuration on a Namespace.

- Get details for a registered Namespace on your Temporal Service:

  - With the Temporal CLI: [`temporal operator namespace describe`](/cli/operator#describe)
  - Use the Describe Namespace to return information and configuration details for a registered Namespace.

- Get details for all registered Namespaces on your Temporal Service:

  - With the Temporal CLI: [`temporal operator namespace list`](/cli/operator#list)
  - Use the List Namespace API to return information and configuration details for all registered Namespaces on your Temporal Service.

- Deprecate a Namespace: The Deprecate Namespace updates the state of a registered Namespace to "DEPRECATED". Once a Namespace is deprecated, you cannot start new Workflow Executions on it. All existing and running Workflow Executions on a deprecated Namespace will continue to run.

- Delete a Namespace: Deletes a Namespace and all Workflow Executions on the Namespace. Note that this API is supported for Temporal Server version 1.17 and later.
- With the Temporal CLI: [`temporal operator namespace delete`](/cli/operator#delete).
- Use the DeleteNamespace API to delete a registered Namespaces. All the running Workflow Executions on a deleted Namespace are also deleted.

## Setting

Set Namespaces in your SDK Client to isolate your Workflow Executions to the Namespace.
If you do not set a Namespace, all Workflow Executions started using the Client will be associated with the "default" Namespace. This means, you must have a default Namespace called "default" registered with your Temporal Service. See [Registration](#registration) for details.

{/* TODO add sample for this to link to -[How to set the Namespace for a Temporal Client](/) */}

- [How to list Namespaces in a Temporal Service using the Temporal CLI](/cli/operator#list)
- [How to view (describe) Namespace metadata and details using the Temporal CLI](/cli/operator#describe)

---

## Nexus Endpoints

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

A [Temporal Nexus Endpoint](/glossary#nexus-endpoint) is a reverse proxy that can route Nexus requests from a caller Workflow to an upstream target Namespace and Task Queue.
A [Nexus Service](/nexus/services) runs in a Worker that is polling the Endpoint's target Task Queue.

An Endpoint decouples the caller and handler, so the caller only needs to know the Endpoint name.
The Endpoint encapsulates the upstream target Namespace and Task Queue from the caller.
A Worker handles Nexus requests by registering one or more [Nexus Services](/nexus/services) and polling the Endpoint's target Task Queue.

<CaptionedImage
    src="/img/cloud/nexus/nexus-overview-short.png"
    title="Nexus Overview"
/>

Multiple Nexus Endpoints can target different Task Queues in the same target Namespace.

## Reverse proxy for Nexus Services, not a general purpose L7 proxy

A [Temporal Nexus Endpoint](/glossary#nexus-endpoint) is a reverse proxy for [Nexus Services](/nexus/services).
It is not a general purpose L7 reverse proxy like NGINX which can route arbitrary HTTP requests to different upstream targets.
A Nexus Endpoint currently supports routing Nexus requests to a single upstream target.
The Temporal Nexus [EndpointSpec](https://github.com/temporalio/api/blob/2a5b3951e71565e28628edea1b3d88d69ed26607/temporal/api/nexus/v1/message.proto#L170) has two [Endpoint target types](https://github.com/temporalio/api/blob/2a5b3951e71565e28628edea1b3d88d69ed26607/temporal/api/nexus/v1/message.proto#L185):

- Worker: route Nexus requests to a target Namespace and Task Queue.
- External (experimental): route Nexus requests to an external target [Nexus RPC endpoint](https://github.com/nexus-rpc/api/blob/main/SPEC.md) with experimental support in `temporal operator nexus create endpoint` for `--target-url` which may be used with the Nexus Registry in a self-hosted Temporal Service.

## Deploying a Nexus Endpoint

Adding a Nexus Endpoint to the [Nexus Registry](/nexus/registry) deploys the Endpoint in the Temporal Service, so it is available at runtime to serve Nexus requests.

---

## Error Handling - Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

Nexus Operations can return an error for a caller Workflow to handle.
If an asynchronous Nexus Operation starts a Workflow that returns an error, it will be propagated back to the caller Workflow.

## Errors in Nexus handlers

In Temporal, a user-defined Nexus handler is primarily responsible for starting a Nexus Operation.
Nexus handlers run in a Temporal Worker and use Temporal SDK builder functions like New-Sync-Operation or New-Workflow-Run-Operation to start an Operation.
Nexus handlers may return [different error types](/references/failures#nexus-errors).
Nexus Operations can end up in [completed](/references/events#nexusoperationcompleted), [failed](/references/events#nexusoperationfailed), [canceled](/references/events#nexusoperationcanceled), and [timed out](/references/events#nexusoperationtimedout) states.

The Nexus Machinery breaks up the [Nexus Operation lifecycle](/nexus/operations#operation-lifecycle) into one or more [Nexus Tasks](/tasks#nexus-task) that a Nexus handler is responsible for processing.
It creates a Nexus Task to start an Operation and may create additional Nexus Tasks, for example to cancel a long-running [asynchronous Operation](/nexus/operations#asynchronous-operation-lifecycle).

By default, Nexus handler errors are considered retryable, unless specified below:

- [Application Failures](/references/failures#nexus-errors) marked as non-retryable.
- [Unsuccessful Operation errors](/references/failures#nexus-errors) that can resolve an operation as either failed or canceled.
- [Non-retryable Nexus errors](/references/failures#non-retryable-nexus-errors).

For example, if an unknown error is returned from a Nexus handler it will be classified as a retryable error.

When an error is received by the caller's Nexus Machinery:

- If a [non-retryable error](/references/failures#non-retryable-nexus-errors) is returned, the caller Workflow will have a [NexusOperationFailed](/references/events#nexusoperationfailed) event added to its Workflow History.
- If a [retryable error](/references/failures#retryable-nexus-errors) is returned, the Nexus Machinery will automatically retry the [Nexus Task](/tasks#nexus-task), as discussed in [automatic retries](/nexus/operations#automatic-retries).
  These errors are visible to the caller Workflow as part of integrated execution debugging in [Pending Operations](/nexus/execution-debugging/#pending-operations).

:::tip

To avoid infinite [automatic retries](/nexus/operations#automatic-retries) and improve semantics, custom Nexus handlers should return a [specific Nexus error type](/references/failures#nexus-errors).

See [errors in Nexus Operations](/references/failures#errors-in-nexus-operations) for additional details.

:::

## Nexus error handling in caller Workflows

A Nexus Operation Failure is delivered to the Workflow Execution when a Nexus Operation fails.
It contains information about the failure and the Nexus Operation Execution; for example, the Nexus Operation name and
Nexus Operation token.
The reason for the failure is in the message and in the underlying cause is typically an Application Error or a Canceled Error.

:::tip RESOURCES

- [Errors in Nexus Operations](/references/failures#errors-in-nexus-operations)
- [Nexus Errors](/references/failures#nexus-errors)
- [Nexus Operation Failures](/references/failures#nexus-operation-failure)

:::

---

## Execution Debugging - Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

Nexus supports end-to-end execution debugging that may span:

- Caller Workflows
- One or more Nexus Operations executed within and across Namespaces
- Underlying Temporal primitives, like a Workflow, created by a Nexus Operation handler

This includes [multi-level Nexus calls](/nexus#multi-level-calls), for example:

- Workflow A → Nexus Operation 1 → Workflow B → Nexus Operation 2 → Workflow C

## Bi-directional linking

Bi-directional links enable navigation of an end-to-end execution across Namespace boundaries in the Temporal UI.
They are automatically added by the Temporal SDK for builder functions like New-Workflow-Run-Operation.
Links are auto-wired from a specific Nexus Operation event in the caller's Workflow history to a specific event in the handler's Workflow history.

<CaptionedImage
    src="/img/cloud/nexus/nexus-bi-directional-linking.png"
    title="Bi-directional linking"
    zoom="true"
/>

Bi-directional links enable navigating across Namespace boundaries:

- Forward through the Nexus Operation execution:
  - From a Nexus Operation event in the caller's Workflow history.
  - To the underlying event in the handler's Workflow.
- Backwards through the Nexus Operation execution:
  - From the underlying event in the handler's Workflow.
  - To a Nexus Operation event in the caller's Workflow history.

## Pending Operations

Similar to pending Activities, pending Nexus Operations are displayed in the Workflow details page and using: `temporal workflow describe`.

For example, from the Temporal UI:

<CaptionedImage
    src="/img/cloud/nexus/pending-nexus-operations.png"
    title="Pending Operations"
    zoom="true"
/>

For example, from the `temporal` CLI:

```
temporal workflow describe

Pending Nexus Operations: 1

  Endpoint                 myendpoint
  Service                  my-hello-service
  Operation                echo
  OperationToken
  State                    BackingOff
  Attempt                  6
  ScheduleToCloseTimeout   0s
  NextAttemptScheduleTime  20 seconds from now
  LastAttemptCompleteTime  11 seconds ago
  LastAttemptFailure       {"message":"handler error (INTERNAL): internal error","applicationFailureInfo":{}}
```

Retryable Nexus errors [returned from a Nexus handler](/nexus/error-handling#errors-in-nexus-handlers) will surface as part of the Pending Operation in a caller Workflow.
Non-retryable errors will result in the Nexus Operation reaching a final state in the caller Workflow, with a [Failed](/references/events#nexusoperationfailed), [TimedOut](/references/events#nexusoperationtimedout) or [Canceled](/references/events#nexusoperationcanceled) event.

## Pending Callbacks

Nexus callbacks are sent from the handler's Namespace to the caller's Namespace to complete an asynchronous Nexus Operation.
These show up in the UI and using: `temporal workflow describe`.

For example, from the Temporal UI:

<CaptionedImage
    src="/img/cloud/nexus/nexus-callback.png"
    title="Pending Callbacks"
    zoom="true"
/>

For example, from the `temporal` CLI:

```
temporal workflow describe

Callbacks: 1

  URL               https://nexus.phil-caller-Namespace.a2dd6.cluster.tmprl.cloud:7243/Namespaces/phil-caller-Namespace.a2dd6/nexus/callback
  Trigger           WorkflowClosed
  State             Succeeded
  Attempt           1
  RegistrationTime  32 minutes ago
```

## Tracing

Temporal integrates with tracing libraries like [OpenTelemetry](https://opentelemetry.io/) and [OpenTracing](https://opentracing.io/).
Tracing allows you to visualize the call graph of a Workflow, including its Activities, Nexus Operations, and Child Workflows.
You can enable tracing by installing an interceptor on the Temporal Client or Worker in the supported SDKs.
See the samples linked below to enable tracing for the SDKs:

- [Go SDK](https://github.com/temporalio/samples-go/tree/main/opentelemetry)
- [Java SDK](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/tracing)

---

## Nexus Metrics

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

Nexus provides SDK metrics, Cloud metrics, and OSS Cluster metrics in addition to integrated [execution debugging](/nexus/execution-debugging).

## SDK Metrics

[SDK metrics](/references/sdk-metrics) are emitted from a Nexus Worker, including:

- [nexus_poll_no_task](/references/sdk-metrics#nexus_poll_no_task)
- [nexus_task_schedule_to_start_latency](/references/sdk-metrics#nexus_task_schedule_to_start_latency)
- [nexus_task_execution_failed	Worker](/references/sdk-metrics#nexus_task_execution_failed)
- [nexus_task_execution_latency](/references/sdk-metrics#nexus_task_execution_latency)
- [nexus_task_endtoend_latency](/references/sdk-metrics#nexus_task_endtoend_latency)

## Cloud Metrics

[Cloud metrics](/production-deployment/cloud/metrics/reference) are emitted by Temporal Cloud, including:

- Caller Namespace
  - RespondWorkflowTaskCompleted \- schedule a Nexus Operation.
- Handler Namespace
  - PollNexusTaskQueue \- get a [Nexus Task](/tasks#nexus-task) to process, for example to start a Nexus Operation.
  - RespondNexusTaskCompleted \- report the Nexus Task was successful.
  - RespondNexusTaskFailed \- report the Nexus Task failed.

## OSS Cluster Metrics

[Cluster metrics](/references/cluster-metrics#nexus-metrics) are emitted from an OSS Cluster, including:

- History Service metrics
- Concurrency Limiter metrics
- Frontend Service metrics

---

## Nexus Operations

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

[Nexus Operations](/glossary#nexus-operation) are arbitrary-duration operations that may be synchronous or asynchronous, short-lived or long-lived, and are used to connect Temporal Applications within and across Namespaces, clusters, regions, and clouds.

Unlike a traditional RPC, an asynchronous Nexus Operation has an operation token that can be used to re-attach to a long-lived Nexus Operation, for example, one backed by a Temporal Workflow.
Nexus Operations support a uniform interface to get the status of an operation or its result, receive a completion callback, or cancel the operation – all of which are fully integrated into the Temporal Platform.

## SDK support

The Temporal SDK provides an integrated Temporal experience to build, run, and use Nexus Operations.

:::tip RESOURCES

- [Go SDK - Nexus quick start and code sample](/develop/go/nexus)
- [Java SDK - Nexus quick start and code sample](/develop/java/nexus)
  :::

Caller Workflows use the Temporal SDK to execute Nexus Operations.

Nexus Operation handlers are created with Temporal SDK builder functions such as:

- New-Workflow-Run-Operation
  - Start a Workflow as an asynchronous Operation.
- New-Sync-Operation
  - Invoke an underlying Query or Signal as a synchronous Operation.
  - Invoke an Update as a synchronous Operation.
  - Execute arbitrary code as a synchronous Operation.

## Nexus Operation lifecycle {#operation-lifecycle}

When you execute a Nexus Operation from a caller Workflow using the Temporal SDK, a command is sent to Temporal to schedule the Nexus Operation which is atomically handed off to the Nexus Machinery.
The [Nexus Machinery](/glossary#nexus-machinery) uses state-machine-based invocation and completion callbacks to ensure [at-least-once](#at-least-once-execution-semantics-and-idempotency) execution of a Nexus Operation and reliable delivery of the result.

<CaptionedImage
    src="/img/cloud/nexus/nexus-overview.png"
    title="Nexus Overview"
/>

The Nexus Machinery is responsible for making the Nexus RPC calls on behalf of the caller Workflow, with [automatic-retries](#automatic-retries).
This means you don't have to use Nexus RPC directly, only the Temporal SDK along with the Temporal Service.

### Synchronous Operation lifecycle

Nexus supports synchronous Operations that take less than 10 seconds to execute, as measured from the caller's Nexus Machinery.

<CaptionedImage
    src="/img/cloud/nexus/nexus-sync-operation.png"
    title="Nexus Sync Operation Lifecycle"
/>

The lifecycle for a synchronous Nexus Operation, for example to Signal or Query a Workflow:

1. Caller Workflow executes a Nexus Operation using the Temporal SDK.
1. Caller Worker issues a [ScheduleNexusOperation](/references/commands#schedulenexusoperation) command to its Namespace gRPC endpoint.
1. Caller Namespace records a [NexusOperationScheduled](/references/events#nexusoperationscheduled) event in the caller's Workflow History.
1. Caller Nexus Machinery makes a Nexus call to start a Nexus Operation.
1. Handler Nexus Machinery receives the Nexus request and sync matches to a handler Worker.
1. Handler Worker gets a [Nexus Task](/tasks#nexus-task) to start a Nexus Operation, by polling the Nexus Endpoint's target Task Queue.
1. Handler processes the Nexus Task, using the Temporal SDK **New-Sync-Operation**.
1. Handler responds to its Namespace gRPC endpoint with the Operation result.
1. Caller Namespace records the result in the caller's Workflow history as a Nexus event, for example [Completed](/references/events#nexusoperationcompleted) or [Failed](/references/events#nexusoperationfailed).
1. Caller Worker polls for a Workflow Task on its Workflow Task Queue.
1. Caller Workflow gets the Operation result, using the Temporal SDK.

<CaptionedImage
    src="/img/cloud/nexus/nexus-workers-short-sync-op-sequence.png"
    title="Nexus"
/>

:::tip

Stay within the remaining request deadline budget to avoid being timed out.
If a Nexus handler times out, the Operation will be retried by the caller's Nexus Machinery until the Operation's Schedule-to-Close timeout has been exceeded.

:::

### Asynchronous Operation lifecycle {#asynchronous-operation-lifecycle}

An asynchronous Nexus Operation may take up to 60 days to complete in Temporal Cloud, which is the maximum Schedule-to-Close-Timeout.

<CaptionedImage
    src="/img/cloud/nexus/nexus-async-operation.png"
    title="Nexus Async Operation Lifecycle"
/>

The lifecycle of an asynchronous Nexus Operation, with differences between the synchronous lifecycle in bold:

1. Caller Workflow executes a Nexus Operation using the Temporal SDK.
1. Caller Worker issues a [ScheduleNexusOperation](/references/commands#schedulenexusoperation) command to its Namespace gRPC endpoint.
1. Caller Namespace records a [NexusOperationScheduled](/references/events#nexusoperationscheduled) event in the caller Workflow's History.
1. Caller Nexus Machinery makes a Nexus RPC to start a Nexus Operation.
1. Handler Nexus Machinery receives the Nexus request and sync matches to a handler Worker.
1. Handler Worker gets a [Nexus Task](/tasks#nexus-task) to start a Nexus Operation, by polling the Nexus Endpoint's target Task Queue.
1. Handler processes the Nexus Task, using the Temporal SDK **New-Workflow-Run-Operation**.
1. Handler responds to its Namespace gRPC endpoint with the **start Operation response**.
1. Caller Namespace records the response in the caller's Workflow history as a Nexus event, for example **[NexusOperationStarted](/references/events#nexusoperationstarted)**.
1. **Handler Workflow completes and the [Nexus Completion Callback](/glossary#nexus-async-completion-callback) is delivered to the caller's Nexus Machinery.**
1. Caller Namespace records the result in the caller's Workflow history as a Nexus event, for example [Completed](/references/events#nexusoperationcompleted) or [Failed](/references/events#nexusoperationfailed).
1. Caller Worker polls for a Workflow Task on its Workflow Task Queue.
1. Caller Workflow gets the Operation result, using the Temporal SDK.

<CaptionedImage
    src="/img/cloud/nexus/nexus-workers-short-async-op-sequence.png"
    title="Nexus"
/>

### Executing arbitrary code from a synchronous Nexus Operation handler {#executing-arbitrary-code-from-a-sync-handler}

Synchronous Nexus Operation handlers can execute arbitrary code, but unlike Activities they should be short-lived.
As mentioned above, a synchronous Nexus Operation handler has less than 10 seconds to process a Nexus start Operation request and should stay within the remaining request deadline budget for the Nexus request.
For example, this may be done by looking at the Request-Timeout header or hooking into cancelation that is triggered when the timeout is exceeded.

<CaptionedImage
    src="/img/cloud/nexus/nexus-sync-operation-arbitrary-code.png"
    title="Nexus Operations with Arbitrary Code"
/>

### System interactions

Temporal Nexus Operations are requested and processed using the Temporal queue-based Worker architecture.
Workers interact with their Namespace gRPC endpoint as before.
Nexus Machinery on both sides handles the cross-namepace communication.

<CaptionedImage
    src="/img/cloud/nexus/nexus-workers.png"
    title="Nexus Queue-based Worker Architecture"
/>

For example, when you execute a Nexus Operation in a caller Workflow the following Namespace gRPC calls are made:

1. **RespondWorkflowTaskCompleted ([ScheduleNexusOperation command](/references/commands#schedulenexusoperation)) is used by the caller Worker to schedule a Nexus Operation, which atomically hands off execution to the caller's Nexus Machinery.
1. **PollNexusTaskQueue** is used by the handler Worker to receive a [Nexus Task](/tasks#nexus-task) to process, for example to start a Nexus Operation.
1. **RespondNexusTaskCompleted** or **RespondNexusTaskFailed** is used by the handler Worker to return the Nexus Task result.
   When asked to start a Nexus Operation, the Nexus handler decides if the Operation will be synchronous or asynchronous.
   1. This is typically a static decision based on the [Temporal SDK builder function used](#sdk-support).
   1. [Asynchronous Nexus Operations](#asynchronous-operation-lifecycle), created with the New-Workflow-Run-Operation SDK helper, will return a Nexus Operation token, that can be used to perform additional actions like canceling an Operation.
   1. [Synchronous Nexus Operations](#synchronous-operation-lifecycle), created with the New-Sync-Operation SDK helper, will return the Operation result directly.
   1. The caller's Nexus Machinery receives the result and records a NexusOperation event in the caller's Workflow History.
1. **PollWorkflowTaskQueue** is used by the caller Worker to receive a Workflow Task with the Nexus Operation event which may be
   [Started](/references/events#nexusoperationstarted),
   [Completed](/references/events#nexusoperationcompleted),
   [Failed](/references/events#nexusoperationfailed),
   [Canceled](/references/events#nexusoperationcanceled), or
   [TimedOut](/references/events#nexusoperationtimedout).

## Automatic retries {#automatic-retries}

Once the caller Workflow schedules an Operation with the caller's Temporal Service, the caller's Nexus Machinery keeps trying to start the Operation.
If a [retryable Nexus error](/references/failures#nexus-errors) is returned the Nexus Machinery will retry until the Nexus Operation's Start-to-Close-Timeout is exceeded.

For example, if a Nexus handler returns a [retryable error](/references/failures#nexus-errors), or an [upstream timeout](https://github.com/nexus-rpc/api/blob/main/SPEC.md#predefined-handler-errors) is encountered by the caller, the Nexus request will be retried up to the [default Retry Policy's](https://github.com/temporalio/temporal/blob/de7c8879e103be666a7b067cc1b247f0ac63c25c/components/nexusoperations/config.go#L111) max attempts and expiration interval.

:::note
This differs from how Activities and Workflows handle errors and retries:

- [Errors in Activities](/references/failures#errors-in-activities)
- [Non-retryable errors](/references/failures#non-retryable)

:::

See [errors in Nexus handlers](/nexus/error-handling#errors-in-nexus-handlers) to control the retry behavior by returning a [non-retryable Nexus error](/references/failures#non-retryable-nexus-errors).

## Circuit breaking {#circuit-breaking}

Circuit breaking handles deployment issues, such as remote service faults, that take time to recover.
The circuit-breaker pattern improves application stability and resilience by detecting repeated errors and enforcing a "timeout" to allow external resources to recover.
Nexus implements the circuit-breaker pattern for each pair of caller Namespaces and target Nexus Endpoints.

This pair is called a "destination pair" and consists of one Namespace and one Endpoint.
The circuit breaker for each pair is unique to those two elements.
It will trip and reset independently from all other Nexus destination pairs.

Here's an example of how the circuit breaker functionality works.
Say that all Nexus Workers associated with a Nexus Endpoint are unavailable for some reasons.
Five consecutive requests fail due to request timeouts.
By default, the circuit breaker activates after five consecutive Nexus requests fail due to [retryable errors](/references/failures#nexus-errors).

After a circuit breaker trips, it enters the _open_ state.
In this state, the caller's Nexus Machinery fails early and stops sending requests to the target Nexus Endpoint.
After 60 seconds in the _open_ state, the circuit breaker transitions to the _half-open_ state, allowing a single trailblazing request from the Client.
If the request is successful, the circuit breaker returns to the _closed_ state, its default operational state.
Once the circuit breaker closes, all requests are allowed through.
If it fails, the circuit breaker returns to the _half-open_ state for another 60 seconds.

<CaptionedImage
    src="/img/cloud/nexus/circuit-breaker.png"
    title="Flow chart showing the states of the Temporal Nexus Circuit Breaker"
/>

The circuit breaker state is surfaced in a caller Workflow's [Pending Nexus Operations](/nexus/execution-debugging#pending-operations) and in the handler's Workflow [Pending Nexus Callbacks](/nexus/execution-debugging#pending-callbacks).
You can check the circuit breaker state using the UI, the Temporal CLI, or the `DescribeWorkflowExecution` API.

When the circuit breaker for a destination pair is tripped (i.e., the circuit breaker is _open_), the [Pending Nexus Operation](/nexus/execution-debugging#pending-operations) for a [Nexus Operation Scheduled](/references/events#nexusoperationscheduled) event surfaces a State of Blocked along with a BlockedReason.

Here's how that looks in the Web UI:

<CaptionedImage
    src="/img/cloud/nexus/circuit-breaking.png"
    title="Circuit Breaking"
/>

In the preceding screen shot, the open circuit breaker has made 1 attempt.
For a given destination pair, differing Nexus Operations may contribute to tripping the circuit breaker count.
When the circuit breaker is open, a given Nexus Operation may have no attempts or fewer than 5 attempts.

To check from the command line, issue:

```sh
temporal workflow describe -w my-workflow-id
```

Here's how that looks:

```sh
Execution Info:
  WorkflowId            my-workflow-id
  ...

Pending Activities: 0
Pending Child Workflows: 0
Pending Nexus Operations: 1

  Endpoint                 my-nexus-endpoint
  Service                  nexus-playground
  Operation                sync-op-ok
  OperationToken
  State                    Blocked
  Attempt                  1
  ScheduleToCloseTimeout   1d 0h 0m 0s
  LastAttemptCompleteTime  56 seconds ago
  LastAttemptFailure       {"message":"handler error (UPSTREAM_TIMEOUT): upstream timeout","cause":{"message":"upstream timeout","applicationFailureInfo":{"type":"NexusFailure"}},"applicationFailureInfo":{"type":"NexusHandlerError"}}
  BlockedReason            The circuit breaker is open.
```

Here's what a [Nexus Operation Cancel Request](/references/events#nexusoperationcancelrequested) surfaces for a CancelationState of Blocked and a CancelationBlockedReason:

```sh
Execution Info:
  WorkflowId            my-workflow-id
  ...

Pending Activities: 0
Pending Child Workflows: 0
Pending Nexus Operations: 1

  Endpoint                            my-nexus-endpoint
  Service                             nexus-playground
  Operation                           async-op-workflow-wait-for-cancel
  OperationToken                      eyJ2IjowLCJ0IjoxLCJucyI6Im5zIiwid2lkIjoidyJ
  State                               Started
  Attempt                             1
  ScheduleToCloseTimeout              1d 0h 0m 0s
  LastAttemptCompleteTime             51 seconds ago
  CancelationState                    Blocked
  CancelationAttempt                  5
  CancelationRequestedTime            37 seconds ago
  CancelationLastAttemptCompleteTime  27 seconds ago
  CancelationLastAttemptFailure       {"message":"handler error (UPSTREAM_TIMEOUT): upstream timeout","cause":{"message":"upstream timeout","applicationFailureInfo":{"type":"NexusFailure"}},"applicationFailureInfo":{"type":"NexusHandlerError"}}
  CancelationBlockedReason            The circuit breaker is open.
```

## Execution semantics {#execution-semantics}

### At-least-once execution semantics and idempotency

The Nexus Machinery provides reliable execution with at-least-once execution semantics for a Nexus Operation, until the caller's Schedule-to-Close-Timeout is exceeded, at which time the overall Nexus Operation times out.

The Nexus Machinery breaks up the [Nexus Operation lifecycle](/nexus/operations#operation-lifecycle) into one or more [Nexus Tasks](/tasks#nexus-task) that a Nexus handler is responsible for processing.
If a Nexus handler times out or returns a non-retryable Nexus error, then the Nexus Machinery will retry the Nexus request to provide at-least-once execution.
This means it's possible for your Nexus handler to be invoked multiple times for a given Nexus Operation.

To deal with at-least-once execution, the Nexus Operation handler should be idempotent, like Activities should be idempotent.
It's not required in all cases, but highly recommended in general.

### Exactly-once execution semantics through an underlying WorkflowIDReusePolicy

To deduplicate work and get exactly-once execution semantics, a Nexus Operation can start a Workflow with a WorkflowIDReusePolicy of RejectDuplicates which only allows one Workflow Execution per Workflow ID within a Namespace for the Retention Period.

## Cancelation

The request to cancel a caller Workflow is automatically propagated to all pending Nexus Operations, and in turn any underlying handler Workflows.

If an underlying handler Workflow is canceled, the Nexus Operation will report a [Canceled Failure](/references/failures#cancelled-failure) to the caller's Workflow Execution.

## Termination

If the caller Workflow is Terminated, all pending Nexus Operations are abandoned.
If possible, consider [cancellation](#cancelation) instead.

## Versioning {#versioning}

Task Routing is the simplest way to version your service code.

If you have a new backward-incompatible Nexus Operation Handler, for example due to a wire-level incompatible breaking change, start by using a different Service and Task Queue.
The version may be part of the service name, for example `prod.payments.v2`.
Callers can then migrate to the new version in their normal deployment schedule.

## Attaching multiple Nexus callers to a handler Workflow {#attaching-multiple-nexus-callers}

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Using a [Conflict-Policy of Use-Existing](/workflow-execution/workflowid-runid#workflow-id-conflict-policy) with the [New-Workflow-Run-Operation](/nexus/operations#sdk-support) SDK helper is currently a [Public Preview](/evaluate/development-production-features/release-stages#public-preview) feature.

:::

Nexus Operations that start a Workflow with the [New-Workflow-Run-Operation](/nexus/operations#sdk-support) SDK helper will automatically attach a completion Callback on the handler Workflow, so the Nexus caller receives the result.
Additional Nexus callers may attach to the same handler Workflow if the Nexus handler uses a [Conflict-Policy of Use-Existing](/workflow-execution/workflowid-runid#workflow-id-conflict-policy).

A single handler Workflow Execution has a [Callback limit](/workflow-execution/limits#workflow-execution-callback-limits) that governs how many Nexus callers can be attached.
Nexus callers that exceed the limit will receive an error.

When a handler Workflow uses [Continue-As-New](/workflow-execution/continue-as-new) the existing Nexus completion Callbacks will be copied to the new Workflow Execution
and the previous Workflow Execution's completion Callbacks will be left in the Standby state indefinitely.

---

## Nexus Registry

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

The [Nexus Registry](/glossary#nexus-registry) is used to view and manage [Nexus Endpoints](/nexus/endpoints).
Adding a Nexus Endpoint to the Nexus Registry deploys the Endpoint, so it is available at runtime to serve Nexus requests.

<CaptionedImage
    src="/img/cloud/nexus/nexus-overview-short.png"
    title="Nexus Overview"
    width="100%"
    zoom="true"
/>

:::info

The Nexus Registry is scoped to an Account in Temporal Cloud and scoped to a Cluster for self-hosted deployments.

:::

Developers can advertise available Endpoints and Services, so others can find them for use in their caller Workflows.
Endpoint names must be unique within the Nexus Registry.

## View and Manage Nexus Endpoints

Nexus Endpoints may be managed using the Temporal UI, CLI, Cloud Terraform provider, or [Cloud Ops API](/ops).

:::tip RESOURCES

- [Terraform support](/production-deployment/cloud/terraform-provider#manage-temporal-cloud-nexus-endpoints-with-terraform) for Temporal Cloud.
- [tcld nexus](/cloud/tcld/nexus) for Temporal Cloud.
- [temporal operator nexus](/cli/operator#nexus) for self-hosted deployments.
  :::

### Search for a Nexus Endpoint

You can search the Nexus Registry for Endpoint name or an Endpoint's target Namespace to quickly find an Endpoint of interest.

<CaptionedImage
    src="/img/cloud/nexus/nexus-endpoints-ss.png"
    title="Nexus Endpoints"
/>

The Endpoint details page shows the target Namespace and target Task Queue along with the endpoint description rendered as markdown.

<CaptionedImage
    src="/img/cloud/nexus/nexus-billing-ss.png"
    title="Nexus Billing"
/>

### Create a Nexus Endpoint

Creating a Nexus Endpoint includes setting an Access Policy of caller Namespaces that can access the Endpoint.
Even the target Namespace must be added to the Access Policy to access the Endpoint.
Temporal Cloud also provides built-in Endpoint access control in the form of a caller Namespace allowlist, which must be set for any caller to access a Nexus Endpoint, even if in the same Namespace.

<CaptionedImage
    src="/img/cloud/nexus/create-nexus-endpoint-ss.png"
    title="Create Nexus Endpoint"
/>

### Edit a Nexus Endpoint

Editing a Nexus Endpoint allows changing everything but the Endpoint Name.
The target Namespace and target Task Queue can be updated without interrupting existing in-flight Nexus Operations that are already being processed, and new Nexus Operations will be routed to the updated target Namespace and target Task Queue.

<CaptionedImage
    src="/img/cloud/nexus/target-namespace-ss.png"
    title="Edit Nexus Endpoint"
/>

### Configure runtime access controls

Configure the Endpoint's Access Policy to control which callers can access a Nexus Endpoint at runtime.

<CaptionedImage
    src="/img/cloud/nexus/create-nexus-endpoint-ss.png"
    title="Configure runtime access controls"
/>

The Access Policy allows specifying the caller Namespaces that can use Nexus Services on an Endpoint at runtime.

No callers are allowed by default, even if the caller is in the same Namespace as the Endpoint target.

See [Runtime Access Controls](/nexus/security#runtime-access-controls) for more information.

## Roles and permissions

:::info

Temporal Cloud has built-in Nexus security. For self-hosted deployments you can implement [custom Authorizers](/self-hosted-guide/security#authorizer-plugin).

:::

In Temporal Cloud, access to the Nexus Registry is controlled with the following roles and permissions:

- View, list, and search Nexus Endpoints:
  - Read-only role (or higher) in an Account
- Manage a Nexus Endpoint (create, edit, delete) requires **both**:
  - Developer role (or higher) in an Account
  - Namespace Admin permission on the Endpoint's target Namespace

  See [Nexus Security in Temporal Cloud](/cloud/nexus/security) for more information.

## Terraform and Ops API support

Nexus Endpoint provisioning and lifecycle management may be automated with Terraform or the Ops API.

:::tip RESOURCES

- [Terraform support](/production-deployment/cloud/terraform-provider#manage-temporal-cloud-nexus-endpoints-with-terraform) for Temporal Cloud.
- [Cloud Ops API](/ops) for Temporal Cloud.
- [Operator API](https://github.com/temporalio/api/blob/master/temporal/api/operatorservice/v1/service.proto) for self-hosted deployments.

:::

---

## Security in Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

Nexus supports restricting access to Nexus Endpoints.
Temporal Cloud has built-in Endpoint access controls and provides secure Nexus connectivity across Namespaces.
For self-hosted deployments you can implement custom Authorizers.

## Runtime access controls {#runtime-access-controls}

In Temporal Cloud, access to a Nexus Endpoint at runtime is controlled by the Endpoint's access control policy (allowlist of caller Namespaces) for each Endpoint in the Nexus Registry.

<CaptionedImage
    src="/img/cloud/nexus/nexus-workers-short.png"
    title="Nexus Security"
/>

Workers in each Namespace may authenticate with Temporal Cloud as they do now with mTLS certificates or API key as allowed by the caller Namespace.
Once a Worker has authenticated it can send Nexus Operation commands to Temporal Cloud using a Temporal SDK to start a Nexus Operation in a different Namespace.
For example, in the Temporal Go SDK a caller Workflow would use `nexusClient.ExecuteOperation` to issue a command to start a Nexus Operation.

To process a `ScheduleNexusOperation` command from a caller Workflow, Temporal Cloud obtains the handler Namespace and Task Queue for the handler endpoint, and restricts access by verifying that the caller's Namespace is in the endpoint's allowlist.

In this way, Temporal Cloud acts as a trusted broker across Namespace boundaries, and relies on authenticated workers in each Namespace.

See [Configure Runtime Access Controls](/nexus/registry#configure-runtime-access-controls) for additional information.

## Secure connectivity {#secure-connectivity}

:::info

Temporal Cloud has built-in security connectivity across all Namespaces in an Account.

Self-hosted deployments rely on the Temporal Cluster being secure.

:::

In Temporal Cloud multiple security provisions are in place to ensure it can act as a trusted broker across Namespace boundaries:

- Workers authenticate to their Namespaces via mTLS or an API key as allowed by their Namespace configuration.
- mTLS is used for all Nexus communication, including across cloud cells and regions, to:
  - Start or Cancel a Nexus Operation.
  - Callback on completion of an asynchronous Nexus Operation.
- Nexus Endpoints are only privately accessible from within a Temporal Cloud account.
  - Accessible from within a caller Workflow using the Temporal SDK.
  - Not externally accessible for arbitrary clients yet.

## Payload encryption and Data Converter {#payload-encryption-data-converter}

The Data Converter works the same for a Nexus Operation as it does for other payloads sent between a Worker and Temporal Cloud.
The caller and handler Workers must have compatible Data Converters as operation inputs and results are passed between the two.

If encryption keys are used to encrypt payloads, they must be available in both the caller and handler. For example,
the caller and handler can use a shared symmetric key stored in your KMS.

Please let us know if you need per-Service payload encryption or better handling for asymmetric encryption keys.

## Nexus Registry security {#managing-nexus-endpoints}

See [Nexus Registry Roles and Permissions](/nexus/registry#roles-and-permissions).

## Learn more

- [Evaluate](/evaluate/nexus) why you should use Nexus and watch the [Nexus keynote and demo](https://youtu.be/qqc2vsv1mrU?feature=shared&t=2082).
- Learn how Nexus works in the [Nexus deep dive talk](https://www.youtube.com/watch?v=izR9dQ_eIe4&t=934s).
- Explore [additional resources](/evaluate/nexus#learn-more) to learn more about Nexus.

---

## Nexus Services

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

[Nexus Services](/glossary#nexus-service) are named collections of arbitrary-duration [Nexus Operations](/nexus/operations) that provide a contract suitable for sharing across team boundaries.

<CaptionedImage
    src="/img/cloud/nexus/nexus-overview-short.png"
    title="Nexus Security"
    width="100%"
    zoom="true"
/>

A [Nexus Endpoint](/nexus/endpoints) exposes Nexus Services for others to use.
Services are handled in a Temporal Worker that is polling an Endpoint's target Namespace and Task Queue.
Multiple Nexus Services may be run in the same Worker polling the same Endpoint target Namespace and Task Queue.

For example, a Nexus Service is often registered in the same Worker as the underlying Workflows they abstract:

```go
func main() {
	c, err := client.Dial(client.Options{})
	if err != nil {
		log.Fatalln("Unable to create client", err)
	}
	defer c.Close()

	w := worker.New(c, taskQueue, worker.Options{})
	service := nexus.NewService(service.HelloServiceName)
	err = service.Register(handler.EchoOperation, handler.HelloOperation)
	if err != nil {
		log.Fatalln("Unable to register operations", err)
	}
	w.RegisterNexusService(service)
	w.RegisterWorkflow(handler.HelloHandlerWorkflow)

	err = w.Run(worker.InterruptCh())
	if err != nil {
		log.Fatalln("Unable to start worker", err)
	}
}
```

The Nexus Service name is used when invoking a Nexus Operation from a caller workflow.

:::tip RESOURCES

- [Go SDK - build and use Nexus Services](/develop/go/nexus#develop-nexus-service-operation-handlers).
- [Java SDK - build and use Nexus Services](/develop/java/nexus#develop-nexus-service-operation-handlers).
  :::

---

## Common Use Cases for Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

[Temporal Nexus](/evaluate/nexus) enables the following use cases:

- **Cross-team, cross-domain, and cross-namespace** \-
  connect Temporal Applications within and across Namespaces.
- **Share a subset of a Temporal Application** \-
  abstract and share a subset of an Temporal Application as a Nexus Service.
- **Modular design for growth** \-
  modular application design that can evolve as you grow.
- **Smaller failure domains** \-
  each team to have their own Namespace for improved security, troubleshooting, and fault isolation.
- **Multi-region** \-
  Nexus requests in Temporal Cloud are routed across a global mTLS-secured Envoy mesh.

:::tip RELATED

- [Evaluate](/evaluate/nexus) why you should use Nexus and learn more about [Nexus use cases](/evaluate/nexus#use-cases).

:::

## Share Workflows Across Namespaces

Nexus is purpose-built to connect Temporal Applications within and across Namespaces.
It addresses the limitations of Child Workflows, Activity Wrappers, and bespoke APIs that target a remote Namespace.
Nexus has a streamlined Temporal developer experience, reliable execution, and integrated observability.

Without Nexus, when a caller Workflow invokes another Workflow directly the caller must know:

- target Workflow's Namespace and Task Queue.
- target Workflow Retry Policy and Timeouts.
- target Workflow options including [Workflow-Id-Reuse-Policy](/workflow-execution/workflowid-runid#workflow-id-reuse-policy) and [Workflow-Id-Conflict-Policy](/workflow-execution/workflowid-runid#workflow-id-conflict-policy).
- target Workflow ID uniqueness constraints, so it doesn't conflict with other Workflow types in the handler Namespace.

This creates a high degree of coupling between the caller and handler, by exposing internal implementation details to the caller.
This adds friction for the caller, who shouldn't need to know this level of detail.
It's more difficult to refactor or migrate handler Workflows to different Namespace or Task Queue.
In short, Workflow to Workflow is a leaky abstraction.

Nexus addresses this by providing a cleaner service contract between the caller and handler.
Nexus is suitable for abstracting and sharing Workflows across team, domain, and Namespace boundaries.
Nexus requests in Temporal Cloud are routed across a global mTLS-secured Envoy mesh, so they're also suitable for multi-region use cases.

Enable calls across Namespaces by:

1. Creating a [Nexus Endpoint](/nexus/endpoints) in the [Nexus Registry](/nexus/registry) that:
   1. Targets the handler Namespace.
   2. Allows the caller Namespace.
2. Creating a [Nexus Service](/nexus/services) in a Worker within a handler Namespace.
   1. Abstract Workflows with Nexus Operations [using Temporal SDK builder functions for Nexus Operations](/nexus/operations#sdk-support).
   2. Register the Nexus Service with the Worker.
   3. Ensure the Worker is polling the Endpoint's Task Queue.
3. Calling the Nexus Service from a Workflow in a different Namespace.
   1. Execute a Nexus Operation from a caller Workflow [using the Temporal SDK](/nexus/operations#sdk-support).

---

## Temporal Nexus

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

[Temporal Nexus](/evaluate/nexus) allows you to reliably connect Temporal Applications.
It promotes a more modular architecture for sharing a subset of your team's capabilities with well-defined microservice contracts for other teams to use.
Nexus was designed with Durable Execution in mind and enables each team to have their own Namespace for improved modularity, security, debugging, and fault isolation.

## Connect Temporal Applications

[Nexus Services](/nexus/services) are exposed from a [Nexus Endpoint](/nexus/endpoints) created in the [Nexus Registry](/nexus/registry).
Adding a Nexus Endpoint to the Nexus Registry deploys the Endpoint, so it is available at runtime to serve Nexus requests.
The Nexus Registry is scoped to an Account in Temporal Cloud and scoped to a Cluster for self-hosted deployments.

<CaptionedImage
    src="/img/cloud/nexus/nexus-overview-short.png"
    title="Nexus Overview"
    width="100%"
    zoom="true"
/>

A Nexus Endpoint is a reverse proxy that decouples the caller from the handler and routes requests to upstream targets. It currently supports routing to a single target Namespace and Task Queue.
Nexus Services and [Nexus Operations](/nexus/operations) are often registered in the same Worker as the underlying Temporal primitives they abstract.

Nexus connectivity across Namespaces is provided by the Temporal Service.
Temporal Cloud supports Nexus connectivity [within and across regions](/cloud/nexus#multi-region-connectivity) and has [built-in access controls](/cloud/nexus#built-in-access-controls).
Self-hosted Nexus connectivity is supported within a single Cluster and [custom Authorizers](/self-hosted-guide/security#authorizer-plugin) may be used for access control.

## Build and use Nexus Services

Nexus has a familiar programming model to build and use Nexus Services using the Temporal SDK.
The [Nexus Operation lifecycle](/nexus/operations#operation-lifecycle) supports both [synchronous](/nexus/operations#synchronous-operation-lifecycle) and [asynchronous](/nexus/operations#asynchronous-operation-lifecycle) Operations.
It is suitable for low-latency and long-running use cases.
Nexus Operations can be implemented with Temporal primitives, like Workflows, or [execute arbitrary code](/nexus/operations#executing-arbitrary-code-from-a-sync-handler).

:::tip RESOURCES

- [Go SDK - Nexus quick start and code sample](/develop/go/nexus)
- [Java SDK - Nexus quick start and code sample](/develop/java/nexus)
  :::

## Queue-based Worker architecture

Nexus uses the Temporal queue-based Worker architecture and built-in Nexus Machinery to ensure reliable execution of Nexus Operations.
If a Nexus Service is down, a caller Workflow can continue to schedule Nexus Operations and they will be processed when the service is up.

Nexus handler Workers poll the Endpoint's target Namespace and Task Queue for [Nexus Tasks](/tasks#nexus-task) to process.
Workers authenticate to their Namespace's gRPC endpoint with supported methods including mTLS client certificates or API Keys in Temporal Cloud.

<CaptionedImage
    src="/img/cloud/nexus/nexus-workers-short.png"
    title="Queue-based Worker architecture"
    width="100%"
    zoom="true"
/>

See [system interactions](/nexus/operations/#system-interactions) for additional detail.

## Built-in Nexus Machinery

The built-in [Nexus Machinery](/glossary#nexus-machinery) uses state-machine-based invocation and completion callbacks.
It guarantees [at-least-once](/nexus/operations#execution-semantics) execution, with automatic retries, circuit breaking, rate limiting, and load balancing.

The Nexus Machinery uses [Nexus RPC](/glossary#nexus-rpc) on the wire, a protocol designed with Durable Execution in mind, to support arbitrary-duration Operations that extend beyond a traditional RPC.

For example, when you execute a Nexus Operation in a caller Workflow, a command is sent to Temporal to schedule the Operation, and the Nexus Machinery is responsible for making the Nexus RPC calls on your behalf.
This means you don't have to use Nexus RPC directly, only the Temporal SDK along with the Temporal Service.

## Multi-level calls

Nexus supports multi-level Nexus calls, for example:

- Workflow A → Nexus Operation 1 → Workflow B → Nexus Operation 2 → Workflow C

## Public Preview features

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

The following Nexus features are currently in [Public Preview](/evaluate/development-production-features/release-stages#public-preview).

:::

- [Attaching multiple Nexus callers to a handler Workflow](/nexus/operations#attaching-multiple-nexus-callers)

---

## What is a Temporal Retry Policy?

A Retry Policy works in cooperation with the timeouts to provide fine controls to optimize the execution experience.

A Retry Policy is a collection of attributes that instructs the Temporal Server how to retry a failure of a [Workflow Execution](/workflow-execution) or an [Activity Task Execution](/tasks#activity-task-execution).
Note that Retry Policies do not apply to [Workflow Task Executions](/tasks#workflow-task-execution), which retry until the Workflow Execution Timeout (which is unlimited by default) with an exponential backoff and a max interval of 10 minutes.

Try out the [Activity retry simulator](/develop/activity-retry-simulator) to visiualize how a Retry Policy works.

---

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in Go" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in Java" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in PHP" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in Python" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-retries" text="Set a custom Retry Policy for an Activity in TypeScript" archetype="feature-guide" />
</RelatedReadContainer>

---

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in Go" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in Java" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in PHP" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in Python" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#workflow-retries" text="Set a Retry Policy for a Workflow in TypeScript" archetype="feature-guide" />
</RelatedReadContainer>

## Default behavior

- **Workflow Execution:** When a Workflow Execution is spawned, it is not associated with a default Retry Policy and thus does not retry by default.
  The intention is that a Workflow Definition should be written to never fail due to intermittent issues; an Activity is designed to handle such issues.

- **Activity Execution:** When an Activity Execution is spawned, it is associated with a default Retry Policy, and thus Activity Task Executions are retried by default.
  When an Activity Task Execution is retried, the Temporal Service places a new [Activity Task](/tasks#activity-task) into its respective [Activity Task Queue](/task-queue), which results in a new Activity Task Execution.

## Custom Retry Policy

To use a custom Retry Policy, provide it as an options parameter when starting a Workflow Execution or Activity Execution.
Only certain scenarios merit starting a Workflow Execution with a custom Retry Policy, such as the following:

- A [Temporal Cron Job](/cron-job) or some other stateless, always-running Workflow Execution that can benefit from retries.
- A file-processing or media-encoding Workflow Execution that downloads files to a host.

## Properties

### Default values for Retry Policy

```
Initial Interval     = 1 second
Backoff Coefficient  = 2.0
Maximum Interval     = 100 × Initial Interval
Maximum Attempts     = ∞
Non-Retryable Errors = []
```

### Initial Interval

- **Description:** Amount of time that must elapse before the first retry occurs.
  - **The default value is 1 second.**
- **Use case:** This is used as the base interval time for the [Backoff Coefficient](#backoff-coefficient) to multiply against.

### Backoff Coefficient

- **Description:** The value dictates how much the _retry interval_ increases.
  - **The default value is 2.0.**
  - A backoff coefficient of 1.0 means that the retry interval always equals the [Initial Interval](#initial-interval).
- **Use case:** Use this attribute to increase the interval between retries.
  By having a backoff coefficient greater than 1.0, the first few retries happen relatively quickly to overcome intermittent failures, but subsequent retries happen farther and farther apart to account for longer outages.
  Use the [Maximum Interval](#maximum-interval) attribute to prevent the coefficient from increasing the retry interval too much.

### Maximum Interval

- **Description:** Specifies the maximum interval between retries.
  - **The default value is 100 times the [Initial Interval](#initial-interval).**
- **Use case:** This attribute is useful for [Backoff Coefficients](#backoff-coefficient) that are greater than 1.0 because it prevents the retry interval from growing infinitely.

### Maximum Attempts

- **Description:** Specifies the maximum number of execution attempts that can be made in the presence of failures.
  - **The default is unlimited.**
  - If this limit is exceeded, the execution fails without retrying again. When this happens an error is returned.
  - Setting the value to 0 also means unlimited.
  - Setting the value to 1 means a single execution attempt and no retries.
  - Setting the value to a negative integer results in an error when the execution is invoked.
- **Use case:** Use this attribute to ensure that retries do not continue indefinitely.
  In most cases, we recommend using the Workflow Execution Timeout for [Workflows](/workflows) or the Schedule-To-Close Timeout for Activities to limit the total duration of retries, rather than using this attribute.

### Non-Retryable Errors

- **Description:** Specifies errors that shouldn't be retried.
  - **Default is none.**
  - Errors are matched against the `type` field of the [Application Failure](/references/failures#application-failure).
  - If one of those errors occurs, a retry does not occur.
- **Use case:** If you know of errors that should not trigger a retry, you can specify that, if they occur, the execution is not retried.

## Retry interval

The wait time before a retry is the _retry interval_. A retry interval is the smaller of two values:

- The [Initial Interval](#initial-interval) multiplied by the [Backoff Coefficient](#backoff-coefficient) raised to the power of the number of retries.
- The [Maximum Interval](#maximum-interval).

<CaptionedImage
    src="/img/info/retry-interval-diagram.png"
    title="Diagram that shows the retry interval and its formula" />

### Per-error next Retry delay

Sometimes, your Activity or Workflow raises a special exception that needs a different retry interval from the Retry Policy.
To accomplish this, you may throw an [Application Failure](/references/failures#application-failure) with the next Retry delay field set. This value will replace and override whatever the retry interval would be on the Retry Policy.
Note that your retries will still cap out under the Retry Policy's Maximum Attempts, as well as overall timeouts. For an Activity, its Schedule-to-Close Timeout applies. For a Workflow, the Execution Timeout applies.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/java/failure-detection#activity-next-retry-delay" text="Customize retry delays per error in the Java SDK." archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-next-retry-delay" text="Customize retry delays per error in the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

## Event History

There are some subtle nuances to how Events are recorded to an Event History when a Retry Policy comes into play.

- For an Activity Execution, the [ActivityTaskStarted](/references/events#activitytaskstarted) Event will not show up in the Workflow Execution Event History until the Activity Execution has completed or failed (having exhausted all retries).
  This is to avoid filling the Event History with noise.
  Use the Describe API to get a pending Activity Execution's attempt count.

- For a Workflow Execution with a Retry Policy, if the Workflow Execution fails, the Workflow Execution will [Continue-As-New](/workflow-execution/continue-as-new) and the associated Event is written to the Event History.
  The [WorkflowExecutionContinuedAsNew](/references/events#workflowexecutioncontinuedasnew) Event will have an "initiator" field that will specify the Retry Policy as the value and the new Run Id for the next retry attempt.
  The new Workflow Execution is created immediately.
  But the first Workflow Task won't be scheduled until the backoff duration is exhausted.
  That duration is recorded as the `firstWorkflowTaskBackoff` field of the new run's `WorkflowExecutionStartedEventAttributes` event.

---

## About Temporal SDKs

Temporal SDKs (software development kits) are an open source collection of tools, libraries, and APIs that enable Temporal Application development.

They offer a [Temporal Client](#temporal-client) to interact with the [Temporal Service](/temporal-service), APIs to develop your [Temporal Application](#temporal-application), and APIs to run horizontally scalable [Workers](/workers#worker).

SDKs are more than just a development tool, however.
The SDK APIs enable developers to write code in a particular pattern that mirrors real world processes.
The SDK's internal implementation, working in collaboration with the Temporal Service, steps through that code, guaranteeing execution progression during application runtime.

## Temporal Applications {#temporal-application}

A Temporal Application is the code you write, comprised of [Workflow Definitions](/workflow-definition), [Activity Definitions](/workflow-definition), code used to configure [Temporal Clients](#temporal-client), and code used to configure and start [Workers](/workers#worker).
Developers create Temporal Applications using an [official Temporal SDK](#official-sdks).

Consider that the Workflow Definition code can be executed repeatedly.
The Temporal Platform can concurrently support millions to billions of Workflow Executions, each of which representing an invoked Workflow Definition.

Additionally, a Temporal Workflow Execution is both resumable and recoverable, and it can react to external events.

- Resumable: The ability of a process to resume execution after suspending on an _awaitable_.
- Recoverable: The ability of a process to resume execution after suspending due to a _failure_.
- Reactive: The ability of a process to respond to external events.

Hence, a Temporal Application can run for seconds or years in the presence of arbitrary load and failures.

## Official SDKs {#official-sdks}

**What are the officially supported SDKs?**

Each Temporal SDK targets a specific programming language.

- [Go SDK feature guides](/develop/go)
- [Java SDK feature guides](/develop/java)
- [PHP SDK feature guides](/develop/php)
- [Python SDK feature guides](/develop/python/)
- [TypeScript SDK feature guides](/develop/typescript/)
- [.NET SDK feature guides](/develop/dotnet)
- [Ruby SDK README](https://github.com/temporalio/sdk-ruby)

Despite supporting multiple languages, and supporting many features, Temporal SDKs aim to make developers feel at home in their language.

### Third-party SDKs

The following third-party SDKs exist but are not supported in Temporal's documentation:

- [Clojure](https://github.com/manetu/temporal-clojure-sdk) - from [@Manetu](https://github.com/manetu)
- [Scala](https://github.com/vitaliihonta/zio-temporal) from [@vitaliihonta](https://github.com/vitaliihonta)
- [Ruby](https://github.com/coinbase/temporal-ruby) from [@coinbase](https://github.com/coinbase)

## Why use a Temporal SDK? {#why-use-an-sdk}

Temporal SDKs empowers developers to concentrate on creating dependable and scalable business logic, alleviating the need to build home grown supervisor systems to ensure reliability and fault-tolerance. This is possible because the Temporal SDK provides a unified library that abstracts the intricacies of how Temporal handles distributed systems.

### Development pattern

By abstracting complexities and streamlining boilerplate code, developers can craft straightforward code that directly aligns with their business logic, enhancing code readability and bolstering developer productivity.

Consider a bank loan application.
Developers can design the business logic of a bank loan using the Temporal SDK.
The Workflow defines the overarching business logic, encompassing tasks such as validating applicant information, credit checks, loan approval, and applicant notifications, as Activities.

:::caution Do not copy and use code

The following is pseudocode. For tested samples see your language SDK's developer's guide.

:::

```
func LoanApplicationWorkflow {

    sdk.ExecuteActivity(CreditCheck)

    sdk.ExecuteActivity(AutomatedApproval)

    sdk.ExecuteActivity(NotifyApplicant)

    // ...
}
```

For instance, Temporal SDKs have built-in support for handling failures, timeouts, and retries.
In the event of an Activity failure, the SDK automatically initiates retries according to configurable policies established by the developer within the SDK. This streamlined process simplifies the integration of fault-tolerance mechanisms into applications.

:::caution Do not copy and use code

The following is pseudocode. For tested samples see your language SDK's developer's guide.

:::

```
func LoanApplicationWorkflow {

    options = {
        MaxAttempts: 3,
        StartToCloseTimeout: 30min,
        HeartbeatTimeout: 10min,
    }

    sdk.ExecuteActivity(CreditCheck, options)

    sdk.ExecuteActivity(AutomatedApproval)

    sdk.ExecuteActivity(NotifyApplicant)

    // ...
}
```

### Replays

Another quality of the SDKs lies in their ability to replay Workflow Executions, a complex operation that contributes significantly to the Platform's promised reliability.

<CaptionedImage
    src="/diagrams/replay-basic.svg"
    title="The SDKs Replay code execution to continue from the last step" />

We will delve into this idea more later, but for now, it signifies that the SDKs can automatically continue a process from the point of interruption, should a failure occur.
This capability stems from the SDK's ability to persist each step the program takes.

{/* - [Developing for Durable Execution using the Go SDK](/develop/go/durable-execution) */}

## Temporal SDKs major components {#major-components}

**What are the major components of Temporal SDKs?**

Temporal SDKs offer developers the following:

- A Temporal Client to communicate with a Temporal Service
- APIs to develop application code (Workflows & Activities)
- APIs to configure and run Workers

<CaptionedImage
    src="/diagrams/temporal-sdk-components.svg"
    title="Temporal SDK components create a runtime across your environment and a Temporal Service" />

Let's break down each one.

### Temporal Client

A Temporal Client acts as the bridge for communication between your applications and the Temporal Service.
The Client performs key functions that facilitate the execution of, management of, and communication with Workflows.

The most common operations that a Temporal Client enables you to perform are the following:

- Get the result of Workflow Execution.
- List Workflow Executions.
- Query a Workflow Execution.
- Signal a Workflow Execution.
- Start a Workflow Execution.

The following code is an example using the Go SDK.
It showcases how to initialize a Temporal Client, create a connection to a local Temporal Service, and start a Workflow Execution:

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

- [Go SDK Temporal Client feature guide](/develop/go/temporal-client)
- [Java SDK Temporal Client feature guide](/develop/java/temporal-client)
- [PHP SDK Temporal Client feature guide](/develop/php/temporal-client#connect-to-a-dev-cluster)
- [Python SDK Temporal Client feature guide](/develop/python/temporal-client#connect-to-a-dev-cluster)
- [TypeScript SDK Temporal Client feature guide](/develop/typescript/core-application#connect-to-a-dev-cluster)

:::

```go
package main

	"context"

	"go.temporal.io/sdk/client"
)

func main() {
	// Temporal Client setup code
	c, err := client.NewClient(client.Options{})
	if err != nil {
		log.Fatalln("Unable to create client", err)
	}
	defer c.Close()
	// Prepare Workflow option and parameters
	workflowOptions := client.StartWorkflowOptions{
		ID:        "loan-application-1",
		TaskQueue: "loan-application-task-queue",
	}
	applicantDetails := ApplicantDetails{
		// ...
	}
	// Start the Workflow
	workflowRun, err := c.ExecuteWorkflow(context.Background(), workflowOptions, "loan-application-workflow", applicantDetails)
	if err != nil {
		// ...
	}
	// ...
}
```

Developers can then use the Client as the main entry point for interacting with the application through Temporal.
Using that Client, developers may for example start or Signal Workflows, Query a Workflow's state, etc.
We can see in the example above how the developer has used `ExecuteWorkflow` API to start a Workflow.

### APIs to Develop Workflows

Workflows are defined as code: either a function or an object method, depending on the language.

For example, the following is a valid Temporal Workflow in Go:

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
func LoanApplication(ctx context.Context) (error) {
    // ...
	return nil
}
```

The Workflow code uses Temporal SDK APIs to orchestrate the steps of the application.

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
func LoanApplication(ctx workflow.Context, input *LoanApplicationWorkflowInput) (*LoanApplicationWorkflowResult, error) {
	// ...
	var result activities.CreditCheckResult
	f := workflow.ExecuteActivity(ctx, a.CreditCheck, CreditCheckInput(*input))
	err := f.Get(ctx, &result)
	// ...
	// Return the results
	return &loanApplicationResults, nil
}
```

A Workflow executes Activities (other functions that interact with external systems), handles and sends messages (Queries, Signals, Updates), and interacts with other Workflows.

This Workflow code, while executing, can be paused, resumed, and migrated across physical machines without losing state.

When a Workflow calls the API to execute an Activity, the Worker sends a [Command](https://docs.temporal.io/references/commands) back to the Temporal Service. The Temporal Service creates Activity Tasks in response which the same or a different Worker can then pick up and begin executing. In this way, the Worker and Temporal Service work together to incrementally execute Workflow code in a reliable way.
We discuss this more in detail in [The SDK and Temporal Service relationship](/encyclopedia/temporal-sdks#sdk-and-cluster-relationship) section.

The SDK APIs also enable developers to write code that more genuinely maps to their process. This is because without a specialized SDK, developers might have to write a lot of boilerplate code. This can lead to code that's hard to maintain, difficult to understand, or that doesn't directly correspond to the underlying business process.

For example, the bank loan application Workflow might actually look like this:

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
// LoanApplicationWorkflow is the workflow definition.
func LoanApplicationWorkflow(ctx workflow.Context, applicantName string, loanAmount int) (string, error) {
	// Step 1: Notify the applicant that the application process has started
	err := workflow.ExecuteActivity(ctx, NotifyApplicantActivity, applicantName, "Application process started").Get(ctx, nil)
	if err != nil {
		return "", err
	}

	// Step 2: Perform a credit check
	var creditCheckResult string
	err = workflow.ExecuteActivity(ctx, LoanCreditCheckActivity, loanAmount).Get(ctx, &creditCheckResult)
	if err != nil {
		return "", err
	}

	// Step 3: Perform an automatic approval check
	var approvalCheckResult string
	err = workflow.ExecuteActivity(ctx, AutomaticApprovalCheckActivity, creditCheckResult).Get(ctx, &approvalCheckResult)
	if err != nil {
		return "", err
	}

	// Step 4: Notify the applicant of the decision
	var notificationResult string
	err = workflow.ExecuteActivity(ctx, NotifyApplicantActivity, applicantName, approvalCheckResult).Get(ctx, &notificationResult)
	if err != nil {
		return "", err
	}

	return notificationResult, nil
}
```

The level of abstraction that APIs offer enables the developer to focus on business logic without having to worry about the intricacies of distributed computing such as retries, or having to explicitly maintain a state machine and the intermediate state for each step of the process.

Additionally, the state of the Workflow is automatically persisted so if a failure does occur, it resumes right where it left off.

### APIs to create and manage Worker Processes

Workers are responsible for executing Workflow and Activity code (application code). The SDK provides APIs for configuring and starting Workers, enabling developers to control how the code is executed.
Workers are horizontally scalable, often run with systems like Kubernetes, and configured according to the application's needs.

Here is an example of how you could initialize a Worker using the Go SDK.

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
func main() {
    // Create the client object just once per process
    c, err := client.NewClient(client.Options{})
    if err != nil {
        log.Fatalln("Unable to create Temporal client", err)
    }
    defer c.Close()

    // Create the Worker instance
    w := worker.New(c, "loan-application-task-queue", worker.Options{})

    // Register the workflow and activity with the worker
    w.RegisterWorkflow(LoanApplicationWorkflow)
    w.RegisterActivity(LoanCreditCheck)

    // Start listening to the Task Queue
    err = w.Run(worker.InterruptCh())
    if err != nil {
        log.Fatalln("Unable to start Worker", err)
    }
}
```

The Worker polls on the specified Task Queue, processing those Tasks, and reporting the results back to the Temporal Service. They execute both the Workflows and Activities, and the SDK ensures that they perform these tasks efficiently and reliably.

### APIs to customize Activity Execution behavior

Activities in Temporal are individual units of work that often represent non-deterministic parts of the code logic, such as querying a database or calling an external service. The SDK provides APIs to customize the behavior of an Activity Execution.

By default, if an Activity attempts to communicate with another system and encounters a transient failure like a network issue, Temporal ensures the Activity is tried again automatically.

However, Temporal enables developers to control a variety of timeouts, a Retry Policy, Heartbeat monitoring, and asynchronous completion.

The following code is an example of a custom set of Activity Execution options that affect the timeout and retry behavior of the execution, should the Activity encounter a failure.

:::caution Do not copy and use code

The following code is for example purposes only.
For tested code samples and best practices, use your preferred language SDK's developer's guide.

:::

```go
// LoanApplicationWorkflow is the Workflow Definition.
func LoanApplicationWorkflow(ctx workflow.Context, applicantName string, loanAmount int) (string, error) {
    // ...
    var creditCheckResult string
    // set a Retry Policy
    ao := workflow.ActivityOptions{
		ScheduleToCloseTimeout: time.Hour,
		HeartbeatTimeout:       time.Minute,
		RetryPolicy:            &temporal.RetryPolicy{
			InitialInterval:    time.Second,
			BackoffCoefficient: 2,
			MaximumInterval:    time.Minute,
			MaximumAttempts:    5,
		},
	}
    ctx = workflow.WithActivityOptions(ctx, ao)
    err = workflow.ExecuteActivity(ctx, LoanCreditCheckActivity, loanAmount).Get(ctx, &creditCheckResult)
    if err != nil {
        return "", err
    }
	// ...
    return notificationResult, nil
}

// LoanCreditCheckActivity is an Activity function that performs a credit check.
func LoanCreditCheckActivity(ctx context.Context, loanAmount int) (string, error) {
	// ... your logic here ...
	return "Credit check passed", nil
}
```

## The SDK and Temporal Service relationship {#sdk-and-cluster-relationship}

**How do the Temporal SDKs work with the Temporal Service?**

The Temporal Service functions more as a choreographer than a conductor. Rather than directly assigning tasks to Workers, the Temporal Service arranges the Tasks into a Task Queue while Workers poll the Task Queue. Developers may create a fleet of Workers and tune them so that a Task is picked up as soon as it is available. If a Worker goes down, Tasks can wait until the next Worker is available.

A Workflow might request to execute an Activity, start a Timer, or start a Child Workflow, each of which translates into a Command, dispatched to the Temporal Service.
In addition to acting on these Commands, the Temporal Service documents that interaction by appending their corresponding Events into to the Workflow Execution's Event History.

Take for instance the call to execute an Activity. When a Workflow invokes it, the Worker doesn't immediately execute that Activity code. Instead, it generates a ScheduleActivityTask Command, dispatching it to the Cluster. In response, the Cluster queues up a new Activity Task. Only when a Worker finds itself free, it collects the task and begins executing the Activity code.

The Temporal Service persists Workflow Execution Event History, so that if there is a failure, the SDK Worker is able to Replay the execution and resume where it left off.

This is where the deterministic constraints of the Workflow code comes into play, requiring the use of Activities to create side effects and interact with the outside world.

Let's look at an example Workflow with a single Activity.

```go
func LoanApplication(ctx workflow.Context, input *LoanApplicationWorkflowInput) (*LoanApplicationWorkflowResult, error) {

	ctx = workflow.WithActivityOptions(ctx, workflow.ActivityOptions{
		StartToCloseTimeout: time.Minute,
	})

	var result activities.NotifyApplicantActivityResult
	f := workflow.ExecuteActivity(ctx, a.NotifyApplicantActivity, NotifyApplicantActivityInput(*input))

	err := f.Get(ctx, &result)

	// Return the results
	return &l.LoanApplicationState, nil
}

type Activities struct {}

func (a *Activities) NotifyApplicantActivity(ctx context.Context, input *NotifyApplicantActivityInput) (*NotifyApplicantActivityResult, error) {
	var result NotifyApplicantActivityResult

	// Call the thirdparty API and handle the result

	return &result, err
}
```

The Activity above is performing a single call to an external API. Since the call can fail due to transient issues, we define it outside of the Workflow and provide it with retry options.

When you create a new Worker process, the Worker creates a long-lasting connection to the Temporal Service, polling a Task Queue for Tasks that related to the code it is capable of executing.

<CaptionedImage
    src="/diagrams/how-sdk-works-1.svg"
    title="A Worker long polls for Tasks" />

Although the Worker is now running, unless a Workflow is explicitly started, the Task Queue doesn't have any Tasks on it and so, no code executes.
We can use a Temporal Client (available in Temporal SDKs and the Temporal CLI) to start a new Workflow.

<CaptionedImage
    src="/diagrams/how-sdk-works-2.svg"
    title="Start a Workflow using a Temporal Client" />

Starting a Workflow Execution creates a new Event, WorkflowExecutionStarted, and adds it to the Workflow Execution's Event History.

The Temporal Service then schedules a Workflow Task by adding it to the Task Queue.
When the Worker has capacity, it picks up this Task, and begin executing code.

Each step of the Task (e.g. Scheduled, Started, and Completed), gets recorded into the Event History.

- Scheduled means that the Temporal Service has added a Task to the Task Queue.
- Started means that the Worker has dequeued the Task.
- Completed means that the Worker finished executing the Task by responding to the Temporal Service.

When the call to invoke the Activity is evaluated, the Worker suspends executing the code and sends a Command to the Temporal Service to schedule an Activity Task.

<CaptionedImage
    src="/diagrams/how-sdk-works-3.svg"
    title="Worker suspends code execution and sends a Command to the Temporal Service" />

When the Worker process can perform more work, it picks up the Activity Task and begins executing the Activity code, which includes the call to the external API.

If the Activity fails, say the API goes down, Temporal will automatically retry the Activity with one second between intervals, as the configurations have defined, an infinite amount of times until the Activity succeeds or is canceled.

In the case where the calls succeeds, and the code completes, the Worker tells the Temporal Service the Activity Task completed.

<CaptionedImage
    src="/diagrams/how-sdk-works-activity.svg"
    title="The Worker reports that the Activity Execution completed" />

Included is any data that was returned from the Activity (results of the API call), which is then persisted in the Workflow Execution Event History, and is now accessible to the Workflow code.

The Temporal Service creates a new Workflow Task which the Worker picks up.

<CaptionedImage
    src="/diagrams/how-sdk-works-1.svg"
    title="The Worker picks up the new Task" />

This is when the SDK Worker Replays the Workflow code, uses the Event History as guidance on what to expect. If the Replay encounters an Event that doesn't match up with what is expected from the code, a [non-determinism](/references/errors#non-deterministic-error) error gets thrown.

If there is alignment, the Worker continues evaluating code.

Assuming the Activity Execution is successful, the Workflow now has the result of the Activity and the Worker is able to finish evaluating and executing the Workflow code, responding to the Temporal Service when complete.

The result of the Workflow can now be retrieved using a Temporal Client.

<CaptionedImage
    src="/diagrams/how-sdk-works-4.svg"
    title="The Temporal Client can now access the result of the Workflow" />

And that’s how a Temporal Worker and Temporal Service work together.

---

## Archival

This page discusses [Archival](#archival).

## What is Archival? {#archival}

Archival is a feature that automatically backs up [Event Histories](/workflow-execution/event#event-history) and Visibility records from Temporal Service persistence to a custom blob store.

- [How to create a custom Archiver](/self-hosted-guide/archival#custom-archiver)
- [How to set up Archival](/self-hosted-guide/archival#set-up-archival)

Workflow Execution Event Histories are backed up after the [Retention Period](/temporal-service/temporal-server#retention-period) is reached.
Visibility records are backed up immediately after a Workflow Execution reaches a Closed status.

Archival enables Workflow Execution data to persist as long as needed, while not overwhelming the Temporal Service's persistence store.

This feature is helpful for compliance and debugging.

Temporal's Archival feature is considered **experimental** and not subject to normal [versioning and support policy](/temporal-service/temporal-server#versions-and-support).

Archival is not supported when running Temporal through Docker.
It's disabled by default when installing the system manually and when deploying through [helm charts](https://github.com/temporalio/helm-charts/blob/main/charts/temporal/templates/server-configmap.yaml).
It can be enabled in the [config](https://github.com/temporalio/temporal/blob/main/config/development.yaml).

---

## Multi-Cluster Replication

This page discusses the following:

- [Multi-Cluster Replication](#multi-cluster-replication)
- [Namespace Versions](#namespace-versions)
- [Version History](#version-history)
- [Conflict Resolution](#conflict-resolution)
- [Zombie Workflows](#zombie-workflows)
- [Workflow Task Processing](#workflow-task-processing)

## What is Multi-Cluster Replication? {#multi-cluster-replication}

Multi-Cluster Replication is a feature which asynchronously replicates Workflow Executions from active Clusters to other passive Clusters, for backup and state reconstruction.
When necessary, for higher availability, Cluster operators can failover to any of the backup Clusters.

Temporal's Multi-Cluster Replication feature is considered **experimental** and not subject to normal [versioning and support policy](/temporal-service/temporal-server#versions-and-support).

Temporal automatically forwards Start, Signal, and Query requests to the active Cluster.
This feature must be enabled through a Dynamic Config flag per [Global Namespace](/global-namespace).

When the feature is enabled, Tasks are sent to the Parent Task Queue partition that matches that Namespace, if it exists.

All Visibility APIs can be used against active and standby Clusters.
This enables [Temporal UI](https://docs.temporal.io/web-ui) to work seamlessly for Global Namespaces.
Applications making API calls directly to the Temporal Visibility API continue to work even if a Global Namespace is in standby mode.
However, they might see a lag due to replication delay when querying the Workflow Execution state from a standby Cluster.

## Namespace Versions

A _version_ is a concept in Multi-Cluster Replication that describes the chronological order of events per Namespace.

With Multi-Cluster Replication, all Namespace change events and Workflow Execution History events are replicated asynchronously for high throughput.
This means that data across clusters is **not** strongly consistent.
To guarantee that Namespace data and Workflow Execution data will achieve eventual consistency (especially when there is a data conflict during a failover), a **version** is introduced and attached to Namespaces.
All Workflow Execution History entries generated in a Namespace will also come with the version attached to that Namespace.

All participating Clusters are pre-configured with a unique initial version and a shared version increment:

- `initial version < shared version increment`

When performing failover for a Namespace from one Cluster to another Cluster, the version attached to the Namespace will be changed by the following rule:

- for all versions which follow `version % (shared version increment) == (active cluster's initial version)`, find the smallest version which has `version >= old version in namespace`

When there is a data conflict, a comparison will be made and Workflow Execution History entries with the highest version will be considered the source of truth.

When a cluster is trying to mutate a Workflow Execution History, the version will be checked.
A cluster can mutate a Workflow Execution History only if the following is true:

- The version in the Namespace belongs to this cluster, i.e.
  `(version in namespace) % (shared version increment) == (this cluster's initial version)`
- The version of this Workflow Execution History's last entry (event) is equal or less than the version in the Namespace, i.e.
  `(last event's version) <= (version in namespace)`

<details>
    <summary>
      Namespace version change example
    </summary>

Assuming the following scenario:

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: Namespace α is registered, with active Cluster set to Cluster A

```
namespace α's version is 1
all workflows events generated within this namespace, will come with version 1
```

T = 1: namespace β is registered, with active Cluster set to Cluster B

```
namespace β's version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 2: Namespace α is updated to with active Cluster set to Cluster B

```
namespace α's version is 2
all workflows events generated within this namespace, will come with version 2
```

T = 3: Namespace β is updated to with active Cluster set to Cluster A

```
namespace β's version is 11
all workflows events generated within this namespace, will come with version 11
```

</details>

## Version history

Version history is a concept which provides a high level summary of version information in regards to Workflow Execution History.

Whenever there is a new Workflow Execution History entry generated, the version from Namespace will be attached.
The Workflow Executions's mutable state will keep track of all history entries (events) and the corresponding version.

<details>
    <summary>
        Version history example (without data conflict)
    </summary>

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Shared version increment: 10

T = 0: adding event with event ID == 1 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 1               | 1       |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 2 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: adding event with event ID == 3 & version == 1

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               |                 |         |
| 3        | 1               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 3: Namespace failover triggered, Namespace version is now 2
adding event with event ID == 4 & version == 2

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 4: adding event with event ID == 5 & version == 2

View in both Cluster A & B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 3               | 1       |
| 2        | 1               | 5               | 2       |
| 3        | 1               |                 |         |
| 4        | 2               |                 |         |
| 5        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

</details>

Since Temporal is AP, during failover (change of active Temporal Service Namespace), there can exist cases where more than one Cluster can modify a Workflow Execution, causing divergence of Workflow Execution History. Below shows how the version history will look like under such conditions.

<details>
    <summary>
      Version history example (with data conflict)
    </summary>

Below, shows version history of the same Workflow Execution in 2 different Clusters.

- Cluster A comes with initial version: 1
- Cluster B comes with initial version: 2
- Cluster C comes with initial version: 3
- Shared version increment: 10

T = 0:

View in both Cluster B & C

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: adding event with event ID == 4 & version == 2 in Cluster B

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 4               | 2       |
| 3        | 2               |                 |         |
| 4        | 2               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 1: namespace failover to Cluster C, adding event with event ID == 4 & version == 3 in Cluster C

```
| -------- | ------------- | --------------- | ------- |
| Events   | Version History |
| -------- | --------------- | --------------- | ------- |
| Event ID | Event Version   | Event ID        | Version |
| -------- | -------------   | --------------- | ------- |
| 1        | 1               | 2               | 1       |
| 2        | 1               | 3               | 2       |
| 3        | 2               | 4               | 3       |
| 4        | 3               |                 |         |
| -------- | -------------   | --------------- | ------- |
```

T = 2: replication task from Cluster C arrives in Cluster B

Note: below are a tree structures

```
                | -------- | ------------- |
                | Events        |
                | ------------- | ------------- |
                | Event ID      | Event Version |
                | --------      | ------------- |
                | 1             | 1             |
                | 2             | 1             |
                | 3             | 2             |
                | --------      | ------------- |
                |               |
                | ------------- | ------------  |
                |               |
                | --------      | ------------- |  | -------- | ------------- |
                | Event ID      | Event Version |  | Event ID | Event Version |
                | --------      | ------------- |  | -------- | ------------- |
                | 4             | 2             |  | 4        | 3             |
                | --------      | ------------- |  | -------- | ------------- |

          | --------------- | ------- |
          | Version History |
          | --------------- | ------------------- |
          | Event ID        | Version             |
          | --------------- | -------             |
          | 2               | 1                   |
          | 3               | 2                   |
          | --------------- | -------             |
          |                 |
          | -------         | ------------------- |
          |                 |
          | --------------- | -------             |  | --------------- | ------- |
          | Event ID        | Version             |  | Event ID        | Version |
          | --------------- | -------             |  | --------------- | ------- |
          | 4               | 2                   |  | 4               | 3       |
          | --------------- | -------             |  | --------------- | ------- |
```

T = 2: replication task from Cluster B arrives in Cluster C, same as above

</details>

## Conflict resolution

When a Workflow Execution History diverges, proper conflict resolution is applied.

In Multi-cluster Replication, Workflow Execution History Events are modeled as a tree, as shown in the second example in [Version History](#version-history).

Workflow Execution Histories that diverge will have more than one history branch.
Among all history branches, the history branch with the highest version is considered the `current branch` and the Workflow Execution's mutable state is a summary of the current branch.
Whenever there is a switch between Workflow Execution History branches, a complete rebuild of the Workflow Execution's mutable state will occur.

Temporal Multi-Cluster Replication relies on asynchronous replication of Events across Clusters, so in the case of a failover it is possible to have an Activity Task dispatched again to the newly active Cluster due to a replication task lag.
This also means that whenever a Workflow Execution is updated after a failover by the new Cluster, any previous replication tasks for that Execution cannot be applied.
This results in loss of some progress made by the Workflow Execution in the previous active Cluster.
During such conflict resolution, Temporal re-injects any external Events like Signals in the new Event History before discarding replication tasks.
Even though some progress could roll back during failovers, Temporal provides the guarantee that Workflow Executions won't get stuck and will continue to make forward progress.

Activity Execution completions are not forwarded across Clusters.
Any outstanding Activities will eventually time out based on the configuration.
Your application should have retry logic in place so that the Activity gets retried and dispatched again to a Worker after the failover to the new Cluster.
Handling this is similar to handling an Activity Task timeout caused by a Worker restarting.

## Zombie Workflows

There is an existing contract that for any Namespace and Workflow Id combination, there can be at most one run (Namespace + Workflow Id + Run Id) open / executing.

Multi-cluster Replication aims to keep the Workflow Execution History as up-to-date as possible among all participating Clusters.

Due to the nature of Multi-cluster Replication (for example, Workflow Execution History events are replicated asynchronously) different Runs (same Namespace and Workflow Id) can arrive at the target Cluster at different times, sometimes out of order, as shown below:

```
| ------------- |          | ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
        |                          |                          |
        | Run 1 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        | Run 2 Replication Events |                          |
        | -----------------------> |                          |
        |                          |                          |
        |                          |                          |
        |                          |                          |
        |                          | Run 2 Replication Events |
        |                          | -----------------------> |
        |                          |                          |
        |                          | Run 1 Replication Events |
        |                          | -----------------------> |
        |     |  |
        | --- || ------------- |          | ------------- |
| Cluster A |  | Network Layer |  | Cluster B |
| --------- || ------------- |          | ------------- |
```

Because Run 2 appears in Cluster B first, Run 1 cannot be replicated as "runnable" due to the rule `at most one Run open` (see above), thus the "zombie" Workflow Execution state is introduced.
A "zombie" state is one in which a Workflow Execution which cannot be actively mutated by a Cluster (assuming the corresponding Namespace is active in this Cluster). A zombie Workflow Execution can only be changed by a replication Task.

Run 1 will be replicated similar to Run 2, except when Run 1's execution will become a "zombie" before Run 1 reaches completion.

## Workflow Task processing

In the context of Multi-cluster Replication, a Workflow Execution's mutable state is an entity which tracks all pending tasks.
Prior to the introduction of Multi-cluster Replication, Workflow Execution History entries (events) are from a single branch, and the Temporal Server will only append new entries (events) to the Workflow Execution History.

After the introduction of Multi-cluster Replication, it is possible that a Workflow Execution can have multiple Workflow Execution History branches.
Tasks generated according to one history branch may become invalidated by switching history branches during conflict resolution.

Example:

T = 0: task A is generated according to Event Id: 4, version: 2

```
| -------- | ------------- |
| Events   |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 1        | 1             |
| 2        | 1             |
| 3        | 2             |
| -------- | ------------- |
|          |
|          |
| -------- | ------------- |
| Event ID | Event Version |
| -------- | ------------- |
| 4        | 2             | <-- task A belongs to this event |
| -------- | ------------- |
```

T = 1: conflict resolution happens, Workflow Execution's mutable state is rebuilt and history Event Id: 4, version: 3 is written down to persistence

```
| -------- | ------------- |
| Events        |
| ------------- | -------------------------------------------- |
| Event ID      | Event Version                                |
| --------      | -------------                                |
| 1             | 1                                            |
| 2             | 1                                            |
| 3             | 2                                            |
| --------      | -------------                                |
|               |
| ------------- | -------------------------------------------- |
|               |
| --------      | -------------                                |                                  | -------- | ------------- |
| Event ID      | Event Version                                |                                  | Event ID | Event Version |
| --------      | -------------                                |                                  | -------- | ------------- |
| 4             | 2                                            | <-- task A belongs to this event | 4        | 3             | <-- current branch / mutable state |
| --------      | -------------                                |                                  | -------- | ------------- |
```

T = 2: task A is loaded.

At this time, due to the rebuild of a Workflow Execution's mutable state (conflict resolution), Task A is no longer relevant (Task A's corresponding Event belongs to non-current branch).
Task processing logic will verify both the Event Id and version of the Task against a corresponding Workflow Execution's mutable state, then discard task A.

---

## Persistence

This page discusses the following:

- [Persistence](#persistence)
- [Dependency Versions](#dependency-versions)

## What is Persistence? {#persistence}

The Temporal Persistence store is a database used by the [Temporal Server](/temporal-service/temporal-server) to persist events generated and processed in your Temporal Service and SDK.

A Temporal Service's only required dependency for basic operation is the Persistence database.
Multiple types of databases are supported.

<Components.CaptionedImage
src="/diagrams/temporal-database.svg"
title="Persistence"
/>

The database stores the following types of data:

- Tasks: Tasks to be dispatched.
- State of Workflow Executions:
  - Execution table: A capture of the mutable state of Workflow Executions.
  - History table: An append-only log of Workflow Execution History Events.
- Namespace metadata: Metadata of each Namespace in the Temporal Service.
- [Visibility](/temporal-service/visibility) data: Enables operations like "show all running Workflow Executions".
  For production environments, we recommend using Elasticsearch as your Visibility store.

An Elasticsearch database must be configured in a self-hosted Temporal Service to enable [advanced Visibility](/visibility#advanced-visibility) on Temporal Server versions 1.19.1 and earlier.

With Temporal Server version 1.20 and later, advanced Visibility features are available on SQL databases like MySQL (version 8.0.17 and later), PostgreSQL (version 12 and later), SQLite (v3.31.0 and later), and Elasticsearch.

### Dependency versions

Temporal tests compatibility by spanning the minimum and maximum stable major versions for each supported database.
The following versions are used in our test pipelines and actively tested before we release any version of Temporal:

- **Cassandra v3.11 and v4.0**
- **PostgreSQL 13.18, 14.15, 15.10 and 16.6**
- **MySQL v5.7 and v8.0** (specifically 8.0.19+ due to a bug)

You can verify supported databases in the [Temporal Server release notes](https://github.com/temporalio/temporal/releases).

- Because Temporal Server primarily relies on core database functionality, we do not expect compatibility to break often.
  {/* Temporal has no opinions on database upgrade paths; as long as you can upgrade your database according to each project's specifications, Temporal should work with any version within supported ranges. */}
- We do not run tests with vendors like Vitess and CockroachDB.
- Temporal also supports SQLite v3.x persistence, but this is meant only for development and testing, not production usage.

---

## Temporal Server

This page discusses the following:

- [Frontend Service](#frontend-service)
- [History Service](#history-service)
- [History Shard](#history-shard)
- [Matching Service](#matching-service)
- [Worker Service](#worker-service)
- [Retention Period](#retention-period)

## What is the Temporal Server? {#temporal-server}

The Temporal Server consists of four independently scalable services:

- Frontend gateway: for rate limiting, routing, authorizing.
- History subsystem: maintains data (mutable state, queues, and timers).
- Matching subsystem: hosts Task Queues for dispatching.
- Worker Service: for internal background Workflows.

For example, a real-life production deployment can have 5 Frontend, 15 History, 17 Matching, and 3 Worker Services per Temporal Service.

The Temporal Server services can run independently or be grouped together into shared processes on one or more physical or virtual machines.
For live (production) environments, we recommend that each service runs independently, because each one has different scaling requirements and troubleshooting becomes easier.
The History, Matching, and Worker Services can scale horizontally within a Temporal Service.
The Frontend Service scales differently than the others because it has no sharding or partitioning; it is just stateless.

Each service is aware of the others, including scaled instances, through a membership protocol via [Ringpop](https://github.com/temporalio/ringpop-go).

### Versions and support

:::tip

We release new versions of the Temporal SDKs and Temporal Server software independently of one another.
That said, All SDK versions support all server versions.

To take advantage of bug fixes, performance improvements, and new features, please upgrade both SDK and servers to the latest versions on a regular cadence.

:::

All Temporal Server releases abide by the [Semantic Versioning Specification](https://semver.org/).

We support upgrade paths from every version beginning with Temporal v1.7.0.
For details on upgrading your Temporal Service, see [Upgrade Server](/self-hosted-guide/upgrade-server#upgrade-server).

We provide maintenance support for previously published minor and major versions by continuing to release critical bug fixes related to security, the prevention of data loss, and reliability, whenever they are found.

We aim to publish incremental upgrade guides for each minor and major version, which include specifics about dependency upgrades that we have tested for (such as Cassandra 3.0 -> 3.11).

We offer maintenance support of the last three **minor** versions after a release and do not plan to "backport" patches beyond that.

We offer maintenance support of **major** versions for at least 12 months after a GA release, and we provide at least 6 months' notice before EOL/deprecating support.

**Dependencies**

Temporal offers official support for, and is tested against, dependencies with the exact versions described in the `go.mod` file of the corresponding release tag.
(For example, [v1.5.1](https://github.com/temporalio/temporal/tree/v1.5.1) dependencies are documented in [the go.mod for v1.5.1](https://github.com/temporalio/temporal/blob/v1.5.1/go.mod).)

## What is a Frontend Service? {#frontend-service}

The Frontend Service is a stateless gateway service that exposes a strongly typed [Proto API](https://github.com/temporalio/api/blob/master/temporal/api/workflowservice/v1/service.proto).
The Frontend Service is responsible for rate limiting, authorizing, validating, and routing all inbound calls.

<CaptionedImage
    src="/diagrams/temporal-frontend-service.svg"
    title="Frontend Service"
/>

Types of inbound calls include the following:

- [Namespace](/namespaces) CRUD
- External events
- Worker polls
- [Visibility](/temporal-service/visibility) requests
- [Temporal CLI](/cli) (the Temporal CLI) operations
- Calls from a remote Temporal Service related to [Multi-Cluster Replication](/temporal-service/multi-cluster-replication)

Every inbound request related to a Workflow Execution must have a Workflow Id, which is hashed for routing purposes.
The Frontend Service has access to the hash rings that maintain service membership information, including how many nodes (instances of each service) are in the Temporal Service.

Inbound call rate limiting is applied per host and per namespace.

The Frontend Service talks to the Matching Service, History Service, Worker Service, the database, and Elasticsearch (if in use).

- It uses the grpcPort 7233 to host the service handler.
- It uses port 6933 for membership-related communication.

Ports are configurable in the Temporal Service configuration.

## What is a History Service? {#history-service}

The History Service is responsible for persisting Workflow Execution state to the Workflow History.
When the Workflow Execution is able to progress, the History Service adds a Task with the Workflow's updated history to the Task Queue.
From there, a Worker can poll for work, receive this updated history, and resume execution.

<CaptionedImage
    src="/diagrams/temporal-history-service.svg"
    title="Block diagram of how the History Service relates to the other services of the Temporal Server and to the Temporal Service"
/>

The total number of History Service processes can be between 1 and the total number of [History Shards](#history-shard).
An individual History Service can support many History Shards.
Temporal recommends starting at a ratio of 1 History Service process for every 500 History Shards.

Although the total number of History Shards remains static for the life of the Temporal Service, the number of History Service processes can change.

The History Service talks to the Matching Service and the database.

- It uses grpcPort 7234 to host the service handler.
- It uses port 6934 for membership-related communication.

Ports are configurable in the Temporal Service configuration.

### What is a History Shard? {#history-shard}

A History Shard is an important unit within a Temporal Service by which concurrent Workflow Execution throughput can be scaled.

Each History Shard maps to a single persistence partition.
A History Shard assumes that only one concurrent operation can be within a partition at a time.
In essence, the number of History Shards represents the number of concurrent database operations that can occur for a Temporal Service.
This means that the number of History Shards in a Temporal Service plays a significant role in the performance of your Temporal Application.

Before integrating a database, the total number of History Shards for the Temporal Service must be chosen and set in the Temporal Service's configuration (see [persistence](/references/configuration#persistence)).
After the Shard count is configured and the database integrated, the total number of History Shards for the Temporal Service cannot be changed.

In theory, a Temporal Service can operate with an unlimited number of History Shards, but each History Shard adds compute overhead to the Temporal Service.
The Temporal Service has operated successfully using anywhere from 1 to 128K History Shards, with each Shard responsible for tens of thousands of Workflow Executions.
One Shard is useful only in small scale setups designed for testing, while 128k Shards is useful only in very large scale production environments.
The correct number of History Shards for any given Temporal Service depends entirely on the Temporal Application that it is supporting and the type of database.

A History Shard is represented as a hashed integer.
Each Workflow Execution is automatically assigned to a History Shard.
The assignment algorithm hashes Workflow Execution metadata such as Workflow Id and Namespace and uses that value to match a History Shard.

Each History Shard maintains the Workflow Execution Event History, Workflow Execution mutable state, and the following internal Task Queues:

- Internal Transfer Task Queue: Transfers internal tasks to the Matching Service.
  Whenever a new Workflow Task needs to be scheduled, the History Service's Transfer Task Queue Processor transactionally dispatches it to the Matching Service.
- Internal Timer Task Queue: Durably persists Timers.
- Internal Replicator Task Queue: Asynchronously replicates Workflow Executions from active Clusters to other passive Clusters.
  (Relies on the experimental Multi-Cluster feature.)
- Internal Visibility Task Queue: Pushes data to the [Advanced Visibility](/visibility#advanced-visibility) index.

## What is a Matching Service? {#matching-service}

The Matching Service is responsible for hosting user-facing [Task Queues](/task-queue) for Task dispatching.

<CaptionedImage
    src="/diagrams/temporal-matching-service.svg"
    title="Matching Service"
/>

It is responsible for matching Workers to Tasks and routing new Tasks to the appropriate queue.
This service can scale internally by having multiple instances.

It talks to the Frontend Service, History Service, and the database.

- It uses grpcPort 7235 to host the service handler.
- It uses port 6935 for membership related communication.

Ports are configurable in the Temporal Service configuration.

## What is a Worker Service? {#worker-service}

The Worker Service runs background processing for the replication queue, system Workflows, and (in versions older than 1.5.0) the Kafka visibility processor.

  
    Worker Service
  
  
    
  

It talks to the Frontend Service.

- It uses port 6939 for membership-related communication.

Ports are configurable in the Temporal Service configuration.

## What is a Retention Period? {#retention-period}

Retention Period is the duration for which the Temporal Service stores data associated with closed Workflow Executions on a Namespace in the Persistence store.

- [How to set the Retention Period for a Namespace](/cli/operator#create)
- [How to set the Retention Period for a Namespace using the Go SDK](/develop/go/namespaces)
- [How to set the Retention Period for a Namespace using the Java SDK](/develop/java/namespaces)

A Retention Period applies to all closed Workflow Executions within a [Namespace](/namespaces) and is set when the Namespace is registered.

The Temporal Service triggers a Timer task at the end of the Retention Period that cleans up the data associated with the closed Workflow Execution on that Namespace.

The minimum Retention Period is 1 day.
On Temporal Service version 1.18 and later, the maximum Retention Period value for Namespaces can be set to anything over the minimum requirement of 1 day. Ensure that your Persistence store has enough capacity for the storage.
On Temporal Service versions 1.17 and earlier, the maximum Retention Period you can set is 30 days.
Setting the Retention Period to 0 results in the error _A valid retention period is not set on request_.

If you don't set the Retention Period value when using the [`temporal operator namespace create`](/cli/operator#create) command, it defaults to 3 days.
If you don't set the Retention Period value when using the Register Namespace Request API, it returns an error.

When changing the Retention Period (with [`temporal operator namespace update`](/cli/operator#update) or the `UpdateNamespace` API), the new duration applies to Workflow Executions that close after the change is saved.

:::info

Changing the Retention Period does NOT affect existing closed Workflow Executions: they retain their original cleanup timers based on the Retention Period that was in effect when they closed.

::: 

### Manual cleanup of closed Workflow Executions

For cases where you need to remove closed Workflow Executions before their retention timer expires, you can use [`temporal workflow delete`](/cli/workflow#delete) or the `DeleteWorkflowExecution` command.
This is particularly useful along with reducing the Retention Period to clean up previously closed Workflow Executions to reduce storage costs.

---

## Temporal Service configuration

This page discusses the following:

- [Static Configuration](#static-configuration)
- [Dynamic Configuration](#dynamic-configuration)
- [Security Configuration](#temporal-cluster-security-configuration)
- [Observability](#monitoring-and-observation)

## What is Temporal Service configuration? {#cluster-configuration}

Temporal Service configuration is the setup and configuration details of your self-hosted Temporal Service, defined using YAML.
You must define your Temporal Service configuration when setting up your self-hosted Temporal Service.

For details on using Temporal Cloud, see [Temporal Cloud documentation](/cloud).

Temporal Service configuration is composed of two types of configuration: [Static configuration](#static-configuration) and [Dynamic configuration](#dynamic-configuration).

### Static configuration

Static configuration contains details of how the Temporal Service should be set up.
The static configuration is read just once and used to configure service nodes at startup.
Depending on how you want to deploy your self-hosted Temporal Service, your static configuration must contain details for setting up:

- Temporal Services—Frontend, History, Matching, Worker
- Membership ports for the Temporal Services
- Persistence (including History Shard count), Visibility, Archival store setups.
- TLS, authentication, authorization
- Server log level
- Metrics
- Temporal Service metadata
- Dynamic config Client

Static configuration values cannot be changed at runtime.
Some values, such as the Metrics configuration or Server log level can be changed in the static configuration but require restarting the Temporal Service for the changes to take effect.

For details on static configuration keys, see [Temporal Service configuration reference](/references/configuration).

For static configuration examples, see [https://github.com/temporalio/temporal/tree/master/config](https://github.com/temporalio/temporal/tree/master/config).

### Dynamic configuration

Dynamic configuration contains configuration keys that you can update in your Temporal Service setup without having to restart the server processes.

All dynamic configuration keys provided by Temporal have default values that are used by the Temporal Service.
You can override the default values by setting different values for the keys in a YAML file and setting the [dynamic configuration client](/references/configuration#dynamicconfigclient) to poll this file for updates.
Setting dynamic configuration for your Temporal Service is optional.

Setting overrides for some configuration keys updates the Temporal Service configuration immediately.
However, for configuration fields that are checked at startup (such as thread pool size), you must restart the server for the changes to take effect.

Use dynamic configuration keys to fine-tune your self-deployed Temporal Service setup.

For details on dynamic configuration keys, see [Dynamic configuration reference](/references/dynamic-configuration).

For dynamic configuration examples, see [https://github.com/temporalio/temporal/tree/master/config/dynamicconfig](https://github.com/temporalio/temporal/tree/master/config/dynamicconfig).

## What is Temporal Service security configuration? {#temporal-cluster-security-configuration}

Secure your Temporal Service (self-hosted and Temporal Cloud) by encrypting your network communication and setting authentication and authorization protocols for API calls.

For details on setting up your Temporal Service security, see [Temporal Platform security features](/security).

### mTLS encryption

Temporal supports Mutual Transport Layer Security (mTLS) to encrypt network traffic between services within a Temporal Service, or between application processes and a Temporal Service.

On the self-hosted Temporal Service, configure mTLS in the `tls` section of the [Temporal Service configuration](/references/configuration#tls).
mTLS configuration is a [static configuration](#static-configuration) property.

You can then use either the [`WithConfig`](/references/server-options#withconfig) or [`WithConfigLoader`](/references/server-options#withconfigloader) server option to start your Temporal Service with this configuration.

The mTLS configuration includes two sections that serve to separate communication within a Temporal Service and client calls made from your application to the Temporal Service.

- `internode`: configuration for encrypting communication between nodes within the Temporal Service.
- `frontend`: configuration for encrypting the public endpoints of the Frontend Service.

Setting mTLS for `internode` and `frontend` separately lets you use different certificates and settings to encrypt each section of traffic.

### Using certificates for Client connections

Use CA certificates to authenticate client connections to your Temporal Service.

On Temporal Cloud, you can [set your CA certificates in your Temporal Cloud settings](/cloud/certificates) and use the end-entity certificates in your client calls.

On the self-hosted Temporal Service, you can restrict access to Temporal Service endpoints by using the `clientCAFiles` or `clientCAData` property and the [`requireClientAuth`](/references/configuration#tls) property in your Temporal Service configuration.
These properties can be specified in both the `internode` and `frontend` sections of the [mTLS configuration](/references/configuration#tls).
For details, see the [tls configuration reference](/references/configuration#tls).

### Server name specification

On the self-hosted Temporal Service, you can specify `serverName` in the `client` section of your mTLS configuration to prevent spoofing and [MITM attacks](https://en.wikipedia.org/wiki/Man-in-the-middle_attack).

Entering a value for `serverName` enables established connections to authenticate the endpoint.
This ensures that the server certificate presented to any connected client has the specified server name in its CN property.

This measure can be used for `internode` and `frontend` endpoints.

For more information on mTLS configuration, see [tls configuration reference](/references/configuration#tls).

### Authentication and authorization

{/* commenting this very generic explanation out. Can include it back in if everyone feels strongly.
**Authentication** is the process of verifying users who want to access your application are actually the users you want accessing it.
**Authorization** is the verification of applications and data that a user on your Temporal Service or application has access to. */}

Temporal provides authentication interfaces that can be set to restrict access to your data.
These protocols address three areas: servers, client connections, and users.

Temporal offers two plugin interfaces for authentication and authorization of API calls.

- [`ClaimMapper`](/self-hosted-guide/security#claim-mapper)
- [`Authorizer`](/self-hosted-guide/security#authorizer-plugin)

The logic of both plugins can be customized to fit a variety of use cases.
When plugins are provided, the Frontend Service invokes their implementation before running the requested operation.

## What is Temporal Service observability? {#monitoring-and-observation}

You can monitor and observe performance with metrics emitted by your self-hosted Temporal Service or by Temporal Cloud.

Temporal emits metrics by default in a format that is supported by Prometheus.
Any metrics software that supports the same format can be used.
Currently, we test with the following Prometheus and Grafana versions:

- **Prometheus >= v2.0**
- **Grafana >= v2.5**

Temporal Cloud emits metrics through a Prometheus HTTP API endpoint, which can be directly used as a Prometheus data source in Grafana or to query and export Cloud metrics to any observability platform.

For details on Cloud metrics and setup, see the following:

- [Temporal Cloud metrics reference](/cloud/metrics/)
- [Set up Grafana with Temporal Cloud observability to view metrics](/cloud/metrics/prometheus-grafana#grafana-data-sources-configuration)

On the self-hosted Temporal Service, expose Prometheus endpoints in your Temporal Service configuration and configure Prometheus to scrape metrics from the endpoints.
You can then set up your observability platform (such as Grafana) to use Prometheus as a data source.

For details on self-hosted Temporal Service metrics and setup, see the following:

- [Temporal Service OSS metrics reference](/references/cluster-metrics)
- [Set up Prometheus and Grafana to view SDK and self-hosted Temporal Service metrics](/self-hosted-guide/monitoring)

---

## Temporal Service

:::info
Please note an important update in our terminology.

We now refer to the Temporal Cluster as the Temporal Service.
:::

This guide provides a comprehensive technical overview of a Temporal Service.

A Temporal Service is the group of services, known as the [Temporal Server](/temporal-service/temporal-server), combined with [Persistence](/temporal-service/persistence) and [Visibility](/temporal-service/visibility) stores, that together act as a component of the Temporal Platform.

See the Self-hosted Temporal Service [production deployment guide](/self-hosted-guide) for implementation guidance.

<Components.CaptionedImage
src="/diagrams/temporal-cluster.svg"
title="A Temporal Service (Server + persistence)"
/>

---

## Visibility

This page discusses [Visibility](#visibility).

## What is Visibility? {#visibility}

The term [Visibility](/visibility), within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view, filter, and search for Workflow Executions that currently exist within a Temporal Service.

The [Visibility store](/self-hosted-guide/visibility) in your Temporal Service stores persisted Workflow Execution Event History data and is set up as a part of your [Persistence store](/temporal-service/persistence) to enable listing and filtering details about Workflow Executions that exist on your Temporal Service.

- [How to set up a Visibility store](/self-hosted-guide/visibility)

With Temporal Server v1.21, you can set up [Dual Visibility](/dual-visibility) to migrate your Visibility store from one database to another.

Support for separate standard and advanced Visibility setups will be deprecated from Temporal Server v1.21 onwards.
Check [Supported databases](/self-hosted-guide/visibility) for updates.

---

## What is Temporal?

Temporal is a scalable and reliable runtime for durable function executions called [Temporal Workflow Executions](/workflow-execution).

Said another way, it's a platform that guarantees the [Durable Execution](#durable-execution) of your application code.

It enables you to develop as if failures don't even exist.
Your application will run reliably even if it encounters problems, such as network outages or server crashes, which would be catastrophic for a typical application.
The Temporal Platform handles these types of problems, allowing you to focus on the business logic, instead of writing application code to detect and recover from failures.

<CaptionedImage
    src="/diagrams/temporal-system-simple.svg"
    title="The Temporal System"
    />

## Durable Execution {#durable-execution}

Durable Execution in the context of Temporal refers to the ability of a Workflow Execution to maintain its state and progress even in the face of failures, crashes, or server outages.
This is achieved through Temporal's use of an [Event History](/workflow-execution/event#event-history), which records the state of a Workflow Execution at each step.
If a failure occurs, the Workflow Execution can resume from the last recorded event, ensuring that progress isn't lost.
This durability is a key feature of Temporal Workflow Executions, making them reliable and resilient.
It enables application code to execute effectively once and to completion, regardless of whether it takes seconds or years.

## What is the Temporal Platform? {#temporal-platform}

The Temporal Platform consists of a [Temporal Service](/temporal-service) and [Worker Processes](/workers#worker-process).
Together these components create a runtime for Workflow Executions.

The Temporal Platform consists of a supervising software typically called the [Temporal Service](/temporal-service) and application code bundled as Worker Processes.
Together these components create a runtime for your application.

<CaptionedImage
    src="/diagrams/temporal-platform-simple.svg"
    title="The Temporal Platform"
    />

A Temporal Service consists of the [Temporal Server](https://github.com/temporalio/temporal), written in Go, and a database.

Our software as a service (SaaS) offering, Temporal Cloud, offers an alternative to hosting the Temporal Service yourself.

Worker Processes are hosted and operated by you and execute your code. Workers run using one of our SDKs.

<CaptionedImage
    src="/diagrams/temporal-platform-component-topology.svg"
    title="Basic component topology of the Temporal Platform"
    width="90%"
    />

## What is a Temporal Application? {#temporal-application}

A Temporal Application is a set of [Temporal Workflow Executions](/workflow-execution).
Each Temporal Workflow Execution has exclusive access to its local state, executes concurrently to all other Workflow Executions, and communicates with other Workflow Executions and the environment via message passing.

A Temporal Application can consist of millions to billions of Workflow Executions.
Workflow Executions are lightweight
A Workflow Execution consumes few compute resources; in fact, if a Workflow Execution is suspended, such as when it is in a waiting state, the Workflow Execution consumes no compute resources at all.

**Reentrant Process**

A Temporal Workflow Execution is a Reentrant Process. A Reentrant Process is resumable, recoverable, and reactive.

- Resumable: Ability of a process to continue execution after execution was suspended on an _awaitable_.
- Recoverable: Ability of a process to continue execution after execution was suspended on a _failure_.
- Reactive: Ability of a process to react to external events.

Therefore, a Temporal Workflow Execution executes a [Temporal Workflow Definition](/workflow-definition), also called a Temporal Workflow Function, your application code, exactly once and to completion—whether your code executes for seconds or years, in the presence of arbitrary load and arbitrary failures.

## What is a Failure? {#failure}

[Temporal Failures](/references/failures) are representations (in the SDKs and Event History) of various types of errors that occur in the system.

Failure handling is an essential part of development.
For more information, including the difference between application-level and platform-level failures, see [Handling Failure From First Principles](https://dominik-tornow.medium.com/handling-failures-from-first-principles-1ed976b1b869).
For the practical application of those concepts in Temporal, see [Failure Handling in Practice](https://temporal.io/blog/failure-handling-in-practice).

For languages that throw (or raise) errors (or exceptions), throwing an error that is not a Temporal Failure from a Workflow fails the Workflow Task (and the Task will be retried until it succeeds), whereas throwing a Temporal Failure (or letting a Temporal Failure propagate from Temporal calls, like an [Activity Failure](/references/failures#activity-failure) from an Activity call) fails the Workflow Execution.
For more information, see [Application Failure](/references/failures#application-failure).

---

## Dual Visibility

This page discusses [Dual Visibility](#dual-visibility).

## What is Dual Visibility? {#dual-visibility}

Dual Visibility is a feature that lets you set a secondary Visibility store in addition to a primary store in your Temporal Service.
Setting up Dual Visibility is optional and can be used to [migrate your Visibility database](/self-hosted-guide/visibility#migrating-visibility-database) or create a backup Visibility store.

For example, if you have Cassandra configured as your Visibility database, you can set up a supported SQL database as your secondary Visibility store and gradually migrate your data to the secondary store before deprecating your primary one.

A Dual Visibility setup requires two Visibility store configurations:

- **Primary Visibility:** The primary Visibility store where Visibility data is written to and read from by default. The primary Visibility store is set with the `visibilityStore` configuration key in your Temporal Service.
- **Secondary Visibility:** A secondary storage for your Visibility data. The secondary Visibility store is set with the `secondaryVisibilityStore` configuration key in your Temporal Service.

For configuration details, see [Dual Visibility setup](/self-hosted-guide/visibility#dual-visibility).

The following combinations are allowed in a Dual Visibility setting.

| Primary                     | Secondary                       |
| --------------------------- | ------------------------------- |
| Standard (Cassandra or SQL) | Advanced (SQL or Elasticsearch) |
| Advanced (SQL)              | Advanced (SQL)                  |
| Advanced (Elasticsearch)    | Advanced (Elasticsearch)        |

With Dual Visibility, you can read from only one Visibility store at a time, but can configure your Temporal Service to write to primary only, secondary only, or to both primary and secondary Visibility stores.
When migrating from one Visibility store database to another, set up the database you want to migrate to as your secondary Visibility store.

You can plan your migration using specific dynamic configuration keys that help you transition your read and write operations from the primary to the secondary Visibility store.
For details on migrating your Visibility store databases, see [Dual Visibility](/self-hosted-guide/visibility#dual-visibility).

---

## List Filter

This page discusses [List Filter](#list-filter).

## What is a List Filter? {#list-filter}

The [Visibility](/temporal-service/visibility) List API requires you to provide a List Filter as an SQL-like string parameter.

A List Filter includes [Search Attribute](/search-attribute) names, Search Attribute values, and [operators](#supported-operators) so that it can retrieve a filtered list of Workflow Executions from the Visibility Store.

List Filter [Search Attribute](/search-attribute) names are case sensitive.
A single [Namespace](/namespaces) scopes each List Filter.

A List Filter using a time range provides a resolution of 1 ns on [Elasticsearch](/self-hosted-guide/visibility#elasticsearch) and 1 µs for [SQL databases](/self-hosted-guide/visibility).

### Supported operators

List Filters support the following operators:

- **`=, !=, >, >=, <, <=`**
- **`AND, OR, ()`**
- **`BETWEEN ... AND`**
- **`IN`**
- **STARTS_WITH**

:::note

The **ORDER BY** operator is currently not supported in Temporal Cloud.

The default ordering is: `ClosedTime DESC NULL FIRST`, `StartTime DESC`. {/* `RunID DESC` depends on which visibility store is used. */}

Custom Search Attributes of the `Text` type cannot be used in **ORDER BY** clauses.

:::

### Partial string match

There are different options for partial string matching when the type of the Search Attribute is [Text](#text) versus [Keyword](#keyword).

#### Text

Search Attributes of type `Text` are [broken up into words](https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-standard-tokenizer.html) that match with the `=` operator.

For example, if you have a custom `Text` Search Attribute named `Description` with either of the following values—

```
my-business-id-foobar
my business id foobar
```

—then the following List Filter matches—

```
Description = 'foobar'
```

—but a partial word does not:

```
// Doesn't match
Description = 'foo'
```

#### Keyword

For Search Attributes of type `Keyword` like `WorkflowId`, perform partial string matching using STARTS_WITH for prefixes and BETWEEN for suffixes.

- `WorkflowId STARTS_WITH "order-"` matches Workflow Ids with the "order-" prefix, regardless of the following text.

  ```
  order-
  order-1234
  order-abracadabra
  order-~~~abracadabra
  ```

- `WorkflowId BETWEEN "order-" AND "order-~"` matches Workflow Ids that have characters after `order-` with ASCII values lower than `~` (126, the highest-value printable character), such as the following:

  ```
  order-
  order-1234
  order-abracadabra
  ```

  It does not match `order-~~`.

:::note Filter Composition Quick Reference

**Composition**

- Data types:
  - String literals with single or double quotes
  - Numbers (Integer and Floating Point)
  - Booleans
- Comparison: `=`, `!=`, `>`, `>=`, `<`, `<=`
- Expressions/Operators:
  - `IN array`
  - `BETWEEN value AND value`
  - `STARTS_WITH string`
  - `IS NULL`, `IS NOT NULL`
  - `expr AND expr`, `expr OR expr`, `( expr )`
- Array: `( comma-separated-values )`

**Please note**

- Wrap attributes with backticks if it contains characters not in
  `[a-zA-Z0-9]`.
- `STARTS_WITH` is only available for Keyword search attributes.

:::

### Efficient API usage

If the Advanced List Filter API retrieves a substantial number of Workflow Executions (more than 10,000), the response time might be longer.

Beginning with Temporal Server v1.20, you can employ the `CountWorkflow` API to efficiently count the number of [Workflow Executions](/workflow-execution).

To paginate the results using the `ListWorkflow` API, use the page token to retrieve the next page.
Continue until the page token becomes `null`/`nil`.

#### List Filter examples

Here are examples of List Filters set with the [Temporal CLI](/cli/workflow#list):

```
WorkflowType = "main.YourWorkflowDefinition" and ExecutionStatus != "Running" and (StartTime > "2021-06-07T16:46:34.236-08:00" or CloseTime > "2021-06-07T16:46:34-08:00")
```

When you use the preceding example, you receive a list of Workflows fulfilling the following criteria:

- Workflow Type is `main.YourWorkflowDefinition`.
- Workflow isn't in a running state.
- Workflow either started after "2021-06-07T16:46:34.236-08:00" or closed after "2021-06-07T16:46:34-08:00".

The following are additional examples of List Filters.

```sql
WorkflowId = '<workflow-id>'
```

```sql
WorkflowId = '<workflow-id>' or WorkflowId = '<another-workflow-id>'
```

```sql
WorkflowId IN ('<workflow-id>', '<another-workflow-id>')
```

```sql
WorkflowId = '<workflow-id>' and ExecutionStatus = 'Running'
```

```sql
WorkflowId = '<workflow-id>' or ExecutionStatus = 'Running'
```

```sql
WorkflowId = '<workflow-id>' and StartTime > '2021-08-22T15:04:05+00:00'
```

```sql
ExecutionTime between '2021-08-22T15:04:05+00:00' and '2021-08-28T15:04:05+00:00'
```

```sql
ExecutionTime < '2021-08-28T15:04:05+00:00' or ExecutionTime > '2021-08-22T15:04:05+00:00'
```

```sql
WorkflowType STARTS_WITH '<workflow-type-prefix>'
```

{/*

```sql
order by ExecutionTime
```

```sql
order by StartTime desc, CloseTime asc
```

```sql
order by CustomIntField asc
```

*/}

---

## Search Attributes

This page discusses the following:

- [Search Attributes](#search-attribute)
- [Default Search Attributes](#default-search-attribute)
- [Custom Search Attributes](#custom-search-attribute)

## What is a Search Attribute? {#search-attribute}

A Search Attribute is an indexed field used in a [List Filter](/list-filter) to filter a list of [Workflow Executions](/workflow-execution) that have the Search Attribute in their metadata.

Each Search Attribute is a key-value pair metadata object included in a Workflow Execution's Visibility information.
This information is available in the Visibility store.

:::note

Search Attribute values are not encrypted because the Temporal Server must be able to read these values from the Visibility store when retrieving Workflow Execution details.

:::

Temporal provides some [default Search Attributes](/search-attribute#default-search-attribute), such as `ExecutionStatus`, the current state of your Workflow Executions.
You can also create [custom Search Attribute](/search-attribute#custom-search-attribute) keys in your Visibility store and assign values when starting a Workflow Execution or in Workflow code.

When using [Continue-As-New](/workflow-execution/continue-as-new) or a [Temporal Cron Job](/cron-job), Search Attribute keys are carried over to the new Workflow Run by default.
Search Attribute values are only available for as long as the Workflow is.

Search Attributes are most effective for search purposes or tasks requiring collection-based result sets.
For business logic in which you need to get information about a Workflow Execution, consider one of the following:

- Storing state in a local variable and exposing it with a Query.
- Storing state in an external datastore through Activities and fetching it directly from the store.

If your business logic requires high throughput or low latency, store and fetch the data through Activities.
You might experience lag due to time passing between the Workflow's state change and the Activity updating the Visibility store.

### Default Search Attributes {#default-search-attribute}

A Temporal Service has a set of default Search Attributes already available.
Default Search Attributes are set globally in any Namespace.
These Search Attributes are created when the initial index is created.

| NAME                               | TYPE         | DEFINITION                                                                                                                                                                                                   |
| ---------------------------------- | ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| BatcherUser                        | Keyword      | Used by internal batcher Workflow that runs in `TemporalBatcher` Namespace division to indicate the user who started the batch operation.                                                                    |
| BinaryChecksums                    | Keyword List | List of binary Ids of Workers that run the Workflow Execution. Deprecated since server version 1.21 in favor of the `BuildIds` search attribute.                                                             |
| BuildIds                           | Keyword List | List of Worker Build Ids that have processed the Workflow Execution, formatted as `versioned:{BuildId}` or `unversioned:{BuildId}`, or the sentinel `unversioned` value. Available from server version 1.21. |
| CloseTime                          | Datetime     | The time at which the Workflow Execution completed.                                                                                                                                                          |
| ExecutionDuration                  | Int          | The time needed to run the Workflow Execution (in nanoseconds). Available only for closed Workflows.                                                                                                         |
| ExecutionStatus                    | Keyword      | The current state of the Workflow Execution.                                                                                                                                                                 |
| ExecutionTime                      | Datetime     | The time at which the Workflow Execution actually begins running; same as `StartTime` for most cases but different for Cron Workflows and retried Workflows.                                                 |
| HistoryLength                      | Int          | The number of events in the history of Workflow Execution. Available only for closed Workflows.                                                                                                              |
| HistorySizeBytes                   | Long         | The size of the Event History.                                                                                                                                                                               |
| RunId                              | Keyword      | Identifies the current Workflow Execution Run.                                                                                                                                                               |
| StartTime                          | Datetime     | The time at which the Workflow Execution started.                                                                                                                                                            |
| StateTransitionCount               | Int          | The number of times that Workflow Execution has persisted its state. Available only for closed Workflows.                                                                                                    |
| TaskQueue                          | Keyword      | Task Queue used by Workflow Execution.                                                                                                                                                                       |
| TemporalChangeVersion              | Keyword List | Stores change/version pairs if the GetVersion API is enabled.                                                                                                                                                |
| TemporalScheduledStartTime         | Datetime     | The time that the Workflow is schedule to start according to the Schedule Spec. Can be manually triggered. Set on Schedules.                                                                                 |
| TemporalScheduledById              | Keyword      | The Id of the Schedule that started the Workflow.                                                                                                                                                            |
| TemporalSchedulePaused             | Boolean      | Indicates whether the Schedule has been paused. Set on Schedules.                                                                                                                                            |
| TemporalWorkerDeploymentName       | Keyword      | Indicates the name of the associated Worker Deployment.                                                                                                                                                      |
| TemporalWorkerDeploymentVersion    | Keyword      | Indicates the Version string of the associated Worker Deployment, in the format `<deployment name>:<build id>`.                                                                                              |
| TemporalWorkflowVersioningBehavior | Keyword      | Indicates the associated Worker Versioning behavior ("Pinned", "Auto-Upgrade", or null if not using Worker Versioning).                                                                                      |
| WorkflowId                         | Keyword      | Identifies the Workflow Execution.                                                                                                                                                                           |
| WorkflowType                       | Keyword      | The type of Workflow.                                                                                                                                                                                        |

- All default Search Attributes are reserved and read-only.
  You cannot create a custom one with the same name or alter the existing one.

- Search attributes are not encrypted in the system.
  Do not use PII as either the search attribute name or the value.

- ExecutionStatus values correspond to Workflow Execution statuses: Running, Completed, Failed, Canceled, Terminated, ContinuedAsNew, TimedOut.

- StartTime, CloseTime, and ExecutionTime are stored as dates but are supported by queries that use either EpochTime in nanoseconds or a string in [RFC3339Nano format](https://pkg.go.dev/time#pkg-constants) (such as "2006-01-02T15:04:05.999999999Z07:00").

- ExecutionDuration is stored in nanoseconds but is supported by queries that use integers in nanoseconds, [Golang duration format](https://pkg.go.dev/time#ParseDuration), or "hh:mm:ss" format.

- CloseTime, HistoryLength, StateTransitionCount, and ExecutionDuration are present only in a closed Workflow Execution.

- ExecutionTime can differ from StartTime in retry and cron use cases.

You can use the default Search Attributes in a List Filter, such as in the Temporal Web UI or with the `temporal workflow list` commands, under the following conditions:

- Without advanced Visibility, you can only use the `=` operator with a single default Search Attribute in your List Filter.
  For example: `temporal workflow list --query "ExecutionStatus = 'Completed'"` or `temporal workflow list --query "WorkflowType = 'YourWorkflow'"`.
- With advanced Visibility, you can combine default Search Attributes in a List Filter to get a list of specific Workflow Executions.
  For example: `temporal workflow list --query "WorkflowType = 'main.YourWorkflowDefinition' and ExecutionStatus != 'Running' and (StartTime > '2022-06-07T16:46:34.236-08:00' or CloseTime < '2022-06-08T16:46:34-08:00')"`

### Custom Search Attributes {#custom-search-attribute}

You can [create custom Search Attributes](/self-hosted-guide/visibility#create-custom-search-attributes) with unique key names that are relevant to your business needs.

Use custom Search Attributes in a List Filter, such as in the Temporal Web UI or with the `temporal workflow list` commands, under the following conditions:

- Without advanced Visibility, you cannot use a custom Search Attribute in your List Filter.
- With advanced Visibility, you can create multiple custom Search Attributes and use them in combinations with List Filters to get a list of specific Workflow Executions.
  For example: `temporal workflow list --query "WorkflowType = 'main.YourWorkflowDefinition' and YourCustomSA = 'YourCustomSAValue' and (StartTime > '2022-06-07T16:46:34.236-08:00' or CloseTime < '2022-06-08T16:46:34-08:00')"`
  - With Temporal Server v1.19 and earlier, you must [integrate Elasticsearch](/self-hosted-guide/visibility#elasticsearch) to use custom Search Attributes with List Filters.
  - With Temporal Server v1.20 and later, custom Search Attribute capabilities are available on MySQL (v8.0.17 or later), PostgreSQL (v12 and later), and SQLite (v3.31.0 and later), in addition to Elasticsearch.

If you use Elasticsearch as your Visibility store, your custom Search Attributes apply globally and can be used across Namespaces.
However, if using any of the [supported SQL databases](/self-hosted-guide/visibility) with Temporal Server v1.20 and later, your custom Search Attributes are associated with a specific Namespace and can be used for Workflow Executions in that Namespace.

See [custom Search Attributes limits](/search-attribute#custom-search-attribute-limits) for limits on the number and size of custom Search Attributes you can create.

#### Supported types {#supported-types}

Custom Search Attributes must be one of the following types:

- Bool
- Datetime
- Double
- Int
- Keyword
- KeywordList
- Text

Note:

- **Double** is backed up by `scaled_float` Elasticsearch type with scale factor 10000 (4 decimal digits).
- **Datetime** is backed up by `date` type with milliseconds precision in Elasticsearch 6 and `date_nanos` type with nanoseconds precision in Elasticsearch 7.
- **Int** is 64-bit integer (`long` Elasticsearch type).
- **Keyword** and **Text** types are concepts taken from Elasticsearch. Each word in a **Text** is considered a searchable keyword.
  For a UUID, that can be problematic because Elasticsearch indexes each portion of the UUID separately.
  To have the whole string considered as a searchable keyword, use the **Keyword** type.
  For example, if the key `ProductId` has the value of `2dd29ab7-2dd8-4668-83e0-89cae261cfb1`:
  - As a **Keyword** it would be matched only by `ProductId = "2dd29ab7-2dd8-4668-83e0-89cae261cfb1`.
  - As a **Text** it would be matched by `ProductId = 2dd8`, which could cause unwanted matches.
- With Temporal Server v1.19 and earlier, the **Keyword** type can store a list of values.
- With Temporal Server v1.20 and later, the **Keyword** type supports only a single value.
  To store a list of values, use **KeywordList**.
- The **Text** type cannot be used in the "Order By" clause.

#### Custom Search Attributes limits {#custom-search-attribute-limits}

{/* TODO - [How to configure maximum number of Search Attribute keys per Cluster](#) */}

The following table lists the maximum number of custom Search Attributes you can create per Namespace by supported Visibility database.

| Search Attribute type | MySQL (v8.0.17 and later) | PostgreSQL (v12 and later) | SQLite (v3.31.0 and later) | Temporal Cloud |
| --------------------- | :-----------------------: | :------------------------: | :------------------------: | :------------: |
| Bool                  |             3             |             3              |             3              |       20       |
| Datetime              |             3             |             3              |             3              |       20       |
| Double                |             3             |             3              |             3              |       20       |
| Int                   |             3             |             3              |             3              |       20       |
| Keyword               |            10             |             10             |             10             |       40       |
| KeywordList           |             3             |             3              |             3              |       5        |
| Text                  |             3             |             3              |             3              |       5        |

Temporal does not impose a limit on the number of custom Search Attributes you can create with Elasticsearch. However, [Elasticsearch sets a default mapping limit](https://www.elastic.co/guide/en/elasticsearch/reference/8.6/mapping-settings-limit.html) that may apply.
Custom Search Attributes are an advanced Visibility feature and are not supported on Cassandra.

Size limits for a custom Search Attribute:

{/*
_This refers to the SA key you create in the visibility store with `tctl search-attribute create`. this value is no longer applicable so commenting out for ref later_
Default total maximum number of Search Attribute **keys** per Temporal Service is 100. */}

- The default single Search Attribute **value** size limit is 2 KB.

{/* TODO - [How to configure Search Attribute value size limit](#) */}

- The maximum total Search Attribute size is 40 KB.

{/* TODO - [How to configure total Search Attribute size limit](#) */}

- The maximum total characters per Search Attribute value is 255.

{/* temp keeping for reference
This is configurable with [`SearchAttributesNumberOfKeysLimit`, `SearchAttributesTotalSizeLimit` and `SearchAttributesSizeOfValueLimit`](https://github.com/temporalio/temporal/blob/v1.7.0/service/history/configs/config.go#L440-L442), if you know what you are doing.
*/}

For Temporal Cloud specific configurations, see the [Defaults, limits, and configurable settings -Temporal Cloud](/cloud/limits#number-of-custom-search-attributes) guide.

### Usage {#usage}

Search Attributes available in your Visibility store can be used with Workflow Executions for the Temporal Service.
To actually have results from the use of a [List Filter](/list-filter), Search Attributes must be added to a Workflow Execution as metadata.

- To create custom Search Attributes in your Visibility store, see [Create custom Search Attributes](/self-hosted-guide/visibility#create-custom-search-attributes).
- To remove a custom Search Attribute from the Visbility store, see [Remove custom Search Attributes](/self-hosted-guide/visibility#remove-custom-search-attributes).
  Removing custom Search Attributes is not supported on Temporal Cloud.
- To rename a custom Search Attribute on Temporal Cloud, see [`tcld namespace search-attributes rename`](/cloud/tcld/namespace/#rename).

With Workflows you can do the following:

- Set the value of Search Attributes in your Workflow
- Update the value set for a Search Attribute from within the Workflow code
- Remove the value set for a Search Attribute from within the Workflow code

:::info Manage Search Attributes by SDK

- [How to manage Search Attributes using the Go SDK](/develop/go/observability#visibility)
- [How to manage Search Attributes using the Java SDK](/develop/java/observability#visibility)
- [How to manage Search Attributes using the PHP SDK](/develop/php/observability#visibility)
- [How to manage Search Attributes using the Python SDK](/develop/python/observability#visibility)
- [How to manage Search Attributes using the TypeScript SDK](/develop/typescript/observability#visibility)
- [How to manage Search Attributes using the .NET SDK](/develop/dotnet/observability#search-attributes)

:::

- To get a list of Search Attributes using the Temporal CLI, issue `temporal operator search-attribute list`. See [Search Attributes](/search-attribute).

After you add and set your Search Attributes, use your default or custom Search Attributes in a List Filter.

{/* commenting out this part. added this detail in how to create a custom search attribute under clusters.
The [temporalio/auto-setup](https://hub.docker.com/r/temporalio/auto-setup) Docker image uses a pre-defined set of custom Search Attributes that are handy for testing.
Their names indicate their types:

- CustomBoolField
- CustomDatetimeField
- CustomDoubleField
- CustomIntField
- CustomKeywordField
- CustomTextField
  */}

---

## Temporal Visibility

This page provides an overview of Temporal Visibility.

The term [Visibility](/visibility), within the Temporal Platform, refers to the subsystems and APIs that enable an operator to view, filter, and search for Workflow Executions that currently exist within a Temporal Service.

The [Visibility store](/self-hosted-guide/visibility) in your Temporal Service stores persisted Workflow Execution Event History data and is set up as a part of your [Persistence store](/temporal-service/persistence) to enable listing and filtering details about Workflow Executions that exist on your Temporal Service.

- [How to set up a Visibility store](/self-hosted-guide/visibility)

With Temporal Server v1.21, you can set up [Dual Visibility](/dual-visibility) to migrate your Visibility store from one database to another.

Support for separate standard and advanced Visibility setups will be deprecated from Temporal Server v1.21 onwards. Check [Supported databases](/self-hosted-guide/visibility) for updates.

## What is standard Visibility? {#standard-visibility}

Standard Visibility, within the Temporal Platform, is the subsystem and APIs that list Workflow Executions by a predefined set of filters.

Open Workflow Executions can be filtered by a time constraint and either a Workflow Type, Workflow Id, or Run Id.

Closed Workflow Executions can be filtered by a time constraint and either a Workflow Type, Workflow Id, Run Id, or Execution Status (Completed, Failed, Timed Out, Terminated, Canceled, or Continued-As-New).

[Custom Search Attributes](https://docs.temporal.io/search-attribute#custom-search-attribute) are not supported with Standard Visibility.

Support for standard Visibility is deprecated beginning with Temporal Server v1.21.
For updates, check [Supported databases](/self-hosted-guide/visibility).

## What is advanced Visibility? {#advanced-visibility}

Visibility, within the Temporal Platform, is the subsystem and APIs that enable the listing, filtering, and sorting of [Workflow Executions](/workflow-execution) through a custom SQL-like [List Filter](/list-filter).

- In Temporal Service version 1.20 and later, advanced Visibility is available on SQL databases like MySQL (version 8.0.17 and later) and PostgreSQL (version 12 and later), in addition to support for Elasticsearch.
- For Temporal Server versions 1.19.1 and earlier, you must [integrate with ElasticSearch](/self-hosted-guide/visibility#elasticsearch) to use advanced Visibility.
  Elasticsearch takes on the Visibility request load, relieving potential performance issues.
  We highly recommend operating a Temporal Service with Elasticsearch for any use case that spawns more than just a few Workflow Executions.
- On Temporal Cloud, advanced Visibility is enabled by default for [all users](/cloud/users#invite-users).

---

## Worker Versioning (Legacy)

:::tip Support, stability, and dependency info

- This document refers to the 2023 draft of Worker Versioning, which was deprecated
- It was not made available in Temporal Cloud
- The 2024 draft was available in Cloud on an opt-in basis, and is documented in this [Pre-release README.md](https://github.com/temporalio/temporal/blob/main/docs/worker-versioning.md).

For newer revisions of this feature set, please see [Worker Versioning](/production-deployment/worker-deployments/worker-versioning) instead.

:::

Worker Versioning simplifies the process of deploying changes to [Workflow Definitions](/workflow-definition).
It does this by letting you define sets of versions that are compatible with each other, and then assigning a Build ID to the code that defines a Worker.
The Temporal Server uses the Build ID to determine which versions of a Workflow Definition a Worker can process.

We recommend that you read about Workflow Definitions before proceeding, because Workflow Versioning is largely concerned with helping to manage nondeterministic changes to those definitions.

Worker Versioning helps manage nondeterministic changes by providing a convenient way to ensure that [Workers](/workers) with different Workflow and Activity Definitions operating on the same Task Queue don't attempt to process [Workflow Tasks](/tasks#workflow-task) and [Activity Tasks](/tasks#activity-task-execution) that they can't successfully process, according to sets of versions associated with that Task Queue that you've defined.

Accomplish this goal by assigning a Build ID (a free-form string) to the code that defines a Worker, and specifying which Build IDs are compatible with each other by updating the version sets associated with the Task Queue, stored by the Temporal Server.

### When and why you should use Worker Versioning

:::caution

This section is for a deprecated Worker Versioning API. Please redirect your attention to [Worker Versioning](/production-deployment/worker-deployments/worker-versioning).

:::

The main reason to use this feature is to deploy incompatible changes to short-lived [Workflows](/workflows).
On Task Queues using this feature, the Workflow starter doesn't have to know about the introduction of new versions.

The new code in the newly deployed Workers executes new [Workflow Executions](/workflow-execution), while only Workers with an appropriate version process old Workflow Executions.

#### Decommission old Workers

You can decommission old Workers after you archive all open Workflows using their version.
If you have no need to query closed Workflows, you can decommission them when no open Workflows remain at that version.

For example, if you have a Workflow that completes within a day, a good strategy is to assign a new Build ID to every new Worker build and add it as the new overall default in the version sets.

Because your Workflow completes in a day, you know that you won't need to keep older Workers running for more than a day after you deploy the new version (assuming availability).
You can apply this technique to longer-lived Workflows too; however, you might need to run multiple Worker versions simultaneously while open Workflows complete.

Version sets have a maximum size limit, which defaults to 100 Build IDs across all sets.
Operations to add new Build IDs to the sets will fail if they exceed this limit.
There is also a limit on the number of Version Sets, which defaults to 10.
A version can only be garbage collected after a Workflow Execution is deleted.

#### Deploy code changes to Workers

The feature also lets you implement compatible changes to or prevent a buggy code path from executing on currently open Workflows.
You can achieve this by adding a new version to an existing set and defining it as _compatible_ with an existing version, which shouldn't execute any future Workflow Tasks.
Because the new version processes existing [Event Histories](/workflow-execution/event#event-history), it must adhere to the usual [deterministic constraints](/workflow-definition#deterministic-constraints), and you might need to use one of the [versioning APIs](/workflow-definition#workflow-versioning).

Moreover, this feature lets you make incompatible changes to Activity Definitions in conjunction with incompatible changes to Workflow Definitions that use those Activities.
This functionality works because any Activity that a Workflow schedules on the same Task Queue gets dispatched by default only to Workers compatible with the Workflow that scheduled it.
If you want to change an Activity Definition's type signature while creating a new incompatible Build ID for a Worker, you can do so without worrying about the Activity failing to execute on some other Worker with an incompatible definition.
The same principle applies to Child Workflows.
For both Activities and Child Workflows, you can override the default behavior and run the Activity or Child Workflow on latest default version.

:::tip

Public-facing Workflows on a versioned Task Queue shouldn't change their signatures because doing so contradicts the purpose of Workflow-launching Clients remaining unaware of changes in the Workflow Definition.
If you need to change a Workflow's signature, use a different Workflow Type or a completely new Task Queue.

:::

:::note

If you schedule an Activity or a Child Workflow on _a different_ Task Queue from the one the Workflow runs on, the system doesn't assign a specific version.
This means if the target queue is versioned, they run on the latest default, and if it's unversioned, they operate as they would have without this feature.

:::

**Continue-As-New and Worker Versioning**

By default, a versioned Task Queue's Continue-as-New function starts the continued Workflow on the same compatible set as the original Workflow.

If you continue-as-new onto a different Task Queue, the system doesn't assign any particular version.
You also have the option to specify that the continued Workflow should start using the Task Queue's latest default version.

### How to use Worker Versioning

:::caution

This section is for a deprecated Worker Versioning API. See [Worker Versioning](/production-deployment/worker-deployments/worker-versioning).

:::

To use Worker Versioning, follow these steps:

1. Define Worker build-identifier version sets for the Task Queue.
   You can use either the Temporal CLI or your choice of SDK.
2. Enable the feature on your Worker by specifying a Build ID.

#### Defining the version sets

Whether you use [Temporal CLI](/cli/) or an SDK, updating the version sets feels the same.
You specify the Task Queue that you're targeting, the Build ID that you're adding (or promoting), whether it becomes the new default version, and any existing versions it should be considered compatible with.

The rest of this section uses updates to one Task Queue's version sets as examples.

By default, both Task Queues and Workers are in an unversioned state.
[Unversioned Worker](#unversioned-workers) can poll unversioned Task Queues and receive tasks.
To use this feature, both the Task Queue and the Worker must be associated with Build IDs.

If you run a Worker using versioning against a Task Queue that has not been set up to use versioning (or is missing that Worker's Build ID), it won't get any tasks.
Likewise, a unversioned Worker polling a Task Queue with versioning won't work either.

:::note Versions don't need to follow semver or any other semantic versioning scheme!

The versions in the following examples look like semver versions for clarity, but they don't need to be.
Versions can be any arbitrary string.

:::

First, add a version `1.0` to the Task Queue as the new default.
Your version sets now look like this:

| set 1 (default) |
| --------------- |
| 1.0 (default)   |

All new Workflows started on the Task Queue have their first tasks assigned to version `1.0`.
Workers with their Build ID set to `1.0` receive these Tasks.

If Workflows that don't have an assigned version are still running on the Task Queue, Workers without a version take those tasks.
So ensure that such Workers are still operational if any Workflows were open when you added the first version.
If you deployed any Workers with a _different_ version, those Workers receive no Tasks.

Now, imagine you need change the Workflow for some reason.

Add `2.0` to the sets as the new default:

| set 1         | set 2 (default) |
| ------------- | --------------- |
| 1.0 (default) | 2.0 (default)   |

All new Workflows started on the Task Queue have their first tasks assigned to version `2.0`.
Existing `1.0` Workflows keep generating tasks targeting `1.0`.
Each deployment of Workers receives their respective Tasks.
This same concept carries forward for each new incompatible version.

Maybe you have a bug in `2.0`, and you want to make sure all open `2.0` Workflows switch to some new code as fast as possible.
So, you add `2.1` to the sets, marking it as compatible with `2.0`.
Now your sets look like this:

| set 1         | set 2 (default) |
| ------------- | --------------- |
| 1.0 (default) | 2.0             |
|               | 2.1 (default)   |

All new Workflow Tasks that are generated for Workflows whose last Workflow Task completion was on version `2.0` are now assigned to version `2.1`.
Because you specified that `2.1` is compatible with `2.0`, Temporal Server assumes that Workers with this version can process the existing Event Histories successfully.

Continue with your normal development cycle, adding a `3.0` version.
Nothing new here:

| set 1         | set 2         | set 3 (default) |
| ------------- | ------------- | --------------- |
| 1.0 (default) | 2.0           | 3.0 (default)   |
|               | 2.1 (default) |                 |

Now imagine that version `3.0` doesn't have an explicit bug, but something about the business logic
is less than ideal.
You are okay with existing `3.0` Workflows running to completion, but you want new Workflows to use the old `2.x` branch.
This operation is supported by performing an update targeting `2.1` (or `2.0`) and setting its set as the current default, which results in these sets:

| set 1         | set 3         | set 2 (default) |
| ------------- | ------------- | --------------- |
| 1.0 (default) | 3.0 (default) | 2.0             |
|               |               | 2.1 (default)   |

Now new Workflows start on `2.1`.

#### Permitted and forbidden operations on version sets

A request to change the sets can do one of the following:

- Add a version to the sets as the new default version in a new overall-default compatible set.
- Add a version to an existing set that's compatible with an existing version.
  - Optionally making it the default for that set.
  - Optionally making that set the overall-default set.
- Promote a version within an existing set to become the default for that set.
- Promote a set to become the overall-default set.

You can't explicitly delete versions.This helps you avoid the situation in which Workflows accidentally become stuck with no means of making progress because the version they're associated with no longer exists.

However, sometimes you might want to do this intentionally.
If you _want_ to make sure that all Workflows currently being processed by, say, `2.0` stop (even if you don't yet have a new version ready), you can add a new version `2.1` to the sets marked as compatible with `2.0`.
New tasks will target `2.1`, but because you haven't deployed any `2.1` Workers, they won't make any progress.

#### Set constraints

The sets have a maximum size limit, which defaults to 100 build IDs across all sets.
This limit is configurable on Temporal Server via the `limit.versionBuildIdLimitPerQueue` dynamic config property.
Operations to add new Build IDs to the sets fail if the limit would be exceeded.

There is also a limit on the number of sets, which defaults to 10.
This limit is configurable via the `limit.versionCompatibleSetLimitPerQueue` dynamic config property.

In practice, these limits should rarely be a concern because a version is no longer needed after no open Workflows are using that version, and a background process will delete IDs and sets that are no longer needed.

There is also a limit on the size of each Build ID or version string, which defaults to 255 characters.
This limit is configurable on the server via the `limit.workerBuildIdSize` dynamic config property.

### Build ID reachability

:::caution

This section is for a deprecated Worker Versioning API. See [Worker Versioning](/production-deployment/worker-deployments/worker-versioning).

:::

Eventually, you'll want to know whether you can retire the old Worker versions.
Temporal provides functionality to help you determine whether a version is still in use by open or closed Workflows.
You can use the Temporal CLI to do this with the following command:

```command
temporal task-queue get-build-id-reachability
```

The command determines, for each Task Queue, whether the Build ID in question is unreachable, only reachable by closed Workflows, or reachable by open and new Workflows.
For example, this "2.0" Build ID is shown here by the Temporal CLI to be reachable by both new Workflows and some existing Workflows:

```command
temporal task-queue get-build-id-reachability --build-id "2.0"
```

```output
BuildId                         TaskQueue                                   Reachability
    2.0  build-id-versioning-dc0068f6-0426-428f-b0b2-703a7e409a97  [NewWorkflows
                                                                   ExistingWorkflows]
```

For more information, see the [CLI documentation](/cli/) or help output.

You can also use this API `GetWorkerTaskReachability` directly from within language SDKs.

### Unversioned Workers

Unversioned Workers refer to Workers that have not opted into the Worker Versioning feature in their configuration.
They receive tasks only from Task Queues that do not have any version sets defined on them, or that have open Workflows that began executing before versions were added to the queue.

To migrate from an unversioned Task Queue, add a new default Build ID to the Task Queue.
From there, deploy Workers with the same Build ID.
Unversioned Workers will continue processing open Workflows, while Workers with the new Build ID will process new Workflow Executions.

---

## Sticky Execution

This page discusses [Sticky Execution](#sticky-execution).

## What is a Sticky Execution? {#sticky-execution}

Workers cache the state of the Workflow they execute.
To make this caching more effective, Temporal employs a performance optimization known as "Sticky Execution", which directs Workflow Tasks to the same Worker that previously processed tasks for a specific Workflow Execution.

### How Sticky Execution Works

Once Workflow Execution begins, the Temporal Service schedules a Workflow Task and puts it into a Task Queue with the name you specify.
Any Worker that polls that Task Queue is eligible to accept the Task and begin executing the Workflow.

The Worker that picks up this Workflow Task will continue polling the original Task Queue, but will also begin polling an additional Task Queue, which the Temporal Service shares exclusively with that specific Worker.
This queue, which has an automatically-generated name, is known as a **Sticky Queue**.

The Worker caches the Workflow state in memory, which improves performance by reducing the need to reconstruct the Workflow from its Event History for every Task.
As the Workflow Execution progresses, the Temporal Service schedules additional Workflow Tasks into this Worker-specific Sticky Queue.

If the Worker fails to start a Workflow Task in the Sticky Queue shortly after it's scheduled (within five seconds by default), the Temporal Service disables stickiness for that Workflow Execution.
When stickiness is disabled, the Temporal Service reschedules the Workflow Task in the original queue, allowing any Worker to pick it up and continue the Workflow Execution.

If a Workflow Task fails, the Worker removes that Workflow Execution from its cache (as it's now in an unknown state), which invalidates the Sticky Execution.
The Workflow Task is then put back into the original Task Queue.

### Why Sticky Execution?

The main benefit of Sticky Execution is improved performance.
By caching the Workflow state in memory and directing tasks to the same Worker, it reduces the need to reconstruct the Workflow from its Event History for every Task, which is particularly useful for latency-sensitive Workflows.

Sticky Execution is the default behavior of the Temporal Platform and only applies to Workflow Tasks.
Since Event History is associated with a Workflow, the concept of Sticky Execution is not relevant to Activity Tasks.

- [How to set a `StickyScheduleToStartTimeout` on a individual Worker in Go](/develop/go/core-application#stickyscheduletostarttimeout)

Sticky Executions are the default behavior of the Temporal Platform.

---

## Task Queues and Naming Best Practices

# Task Queue Names

The Temporal Service maintains a set of Task Queues, which Workers poll to see
what work needs to be done. Each Task Queue is identified by a name, which is
provided to the Temporal Service when launching a Workflow Execution.

<Tabs groupId="start-workflow-configure-worker-by-sdk" queryString>

<TabItem value="python" label="Python">

**Excerpt of code used to start the Workflow in Python**

```python
client = await Client.connect("localhost:7233", namespace="default")

# Execute a workflow
result = await client.execute_workflow(
    GreetingWorkflow.run,
    name,
    id="my-workflow",
    task_queue="my-task-queue-name",
)
```

**Excerpt of code used to configure the Worker in Python**

```python
worker = Worker(
    client,
    task_queue="my-task-queue-name",
    workflows=[GreetingWorkflow],
    activities=[activities.say_hello],
)
```

</TabItem>
<TabItem value="go" label="Go">

**Excerpt of code used to start the Workflow in Go**

```go
options := client.StartWorkflowOptions{
    ID:        "my-workflow",
    TaskQueue: "my-task-queue-name",
}

run, err := c.ExecuteWorkflow(ctx, options, ProcessOrderWorkflow, input)
```

**Excerpt of code used to configure the Worker in Go**

```go
w := worker.New(c, "my-task-queue-name", worker.Options{})
```

</TabItem>
<TabItem value="java" label="Java">

**Excerpt of code used to start the Workflow in Java**

```java
WorkflowOptions options = WorkflowOptions.newBuilder()
        .setWorkflowId("my-workflow")
        .setTaskQueue("my-task-queue-name")
        .build();

MyWorkflow workflow = client.newWorkflowStub(MyWorkflow.class, options);
```

**Excerpt of code used to configure the Worker in Java**

```java
Worker worker = factory.newWorker("my-task-queue-name");
```

</TabItem>
<TabItem value="typescript" label="Typescript">

**Excerpt of code used to start the Workflow in TypeScript**

```typescript
await client.workflow.start(OrderProcessingWorkflow, {
  args: [order],
  taskQueue: 'my-task-queue',
  workflowId: `workflow-order-${order.id},`,
});
```

**Excerpt of code used to configure the Worker in TypeScript**

```typescript
const worker = await Worker.create({
  taskQueue: 'my-task-queue',
  connection,
  workflowsPath: require.resolve('./workflows'),
  activities,
});
```

</TabItem>
<TabItem value="dotnet" label=".NET">

**Excerpt of code used to start the Workflow in C# and .NET**

```csharp
var options = new WorkflowOptions(
            id: "translation-workflow",
            taskQueue: "my-task-queue");

// Run workflow
var result = await client.ExecuteWorkflowAsync(
    (TranslationWorkflow wf) => wf.RunAsync(input),
    options);
```

**Excerpt of code used to configure the Worker in C# and .NET**

```csharp
using var worker = new TemporalWorker(
    client,
    new TemporalWorkerOptions("my-task-queue")
    .AddAllActivities(activities)
    .AddWorkflow<TestWorkflow>());
```

</TabItem>

</Tabs>

Since Task Queues are created dynamically when they are first used, a mismatch
between these two values does not result in an error. Instead, it will result
in the creation of two different Task Queues. Consequently, the Worker will
not receive any tasks from the Temporal Service and the Workflow Execution
will not progress. Therefore, we recommend that you define the Task Queue name
in a constant that is referenced by the Client and Worker if possible, as this
will ensure that they always use the same value.

<Tabs groupId="start-workflow-configure-worker-by-sdk" queryString>

<TabItem value="python" label="Python">

**Excerpt of code used to define a constant with the Task Queue name in Python (in a shared.py file)**

```python
TASK_QUEUE_NAME = "my-task-queue-name"
```

**Excerpt of code used to start the Workflow, referencing the constant
defined with the Task Queue name in Python**

```python
from shared import TASK_QUEUE_NAME

...

client = await Client.connect("localhost:7233", namespace="default")

# Execute a workflow
result = await client.execute_workflow(
    GreetingWorkflow.run,
    name,
    id="my-workflow",
    task_queue=TASK_QUEUE_NAME,
)
```

**Excerpt of code used to configure the Worker, referencing the constant
defined with the Task Queue name in Python**

```python
worker = Worker(
    client,
    task_queue=TASK_QUEUE_NAME,
    workflows=[GreetingWorkflow],
    activities=[activities.say_hello],
)
```

</TabItem>
<TabItem value="go" label="Go">

**Excerpt of code used to define a constant with the Task Queue name in Go**

```go
package app 

const TaskQueueName = "my-taskqueue-name"
```

**Excerpt of code used to start the Workflow, referencing the constant defined with the Task Queue name in Go**

```go
options := client.StartWorkflowOptions{
    ID:        "my-workflow",
    TaskQueue: app.TaskQueueName,
}

run, err := c.ExecuteWorkflow(ctx, options, ProcessOrderWorkflow, input)
```

**Excerpt of code used to configure the Worker, referencing the constant defined with the Task Queue name in Go**

```go
w := worker.New(c, app.TaskQueueName, worker.Options{})
```

</TabItem>
<TabItem value="java" label="Java">

**Excerpt of code used to define a constant with the Task Queue name in Java**

```java
package app;

public class Constants {

  public static final String taskQueueName = "my-task-queue-name";

}
```

**Excerpt of code used to start the Workflow, referencing the constant defined with the Task Queue name in Java**

```java
WorkflowOptions options = WorkflowOptions.newBuilder()
        .setWorkflowId("my-workflow")
        .setTaskQueue(Constants.taskQueueName)
        .build();

MyWorkflow workflow = client.newWorkflowStub(MyWorkflow.class, options);
```

**Excerpt of code used to configure the Worker, referencing the constant defined with the Task Queue name in Java**

```java
Worker worker = factory.newWorker(Constants.taskQueueName);
```

</TabItem>
<TabItem value="typescript" label="Typescript">

**Excerpt of code used to define a constant with the Task Queue name in TypeScript**

```typescript
const TASK_QUEUE_NAME = 'my-taskqueue-name';
```

**Excerpt of code used to start the Workflow, referencing the constant defined with the Task Queue name in TypeScript**

```typescript

// additional code would follow

await client.workflow.start(OrderProcessingWorkflow, {
  args: [order],
  taskQueue: TASK_QUEUE_NAME,
  workflowId: `workflow-order-${order.id},`,
});
```

**Excerpt of code used to configure the Worker, referencing the constant defined with the Task Queue name in TypeScript**

```typescript

// additional code would follow

const worker = await Worker.create({
  taskQueue: TASK_QUEUE_NAME,
  connection,
  workflowsPath: require.resolve('./workflows'),
  activities,
});
```

</TabItem>
<TabItem value="dotnet" label=".NET">

**Excerpt of code used to define a constant with the Task Queue name in C# and .NET**

```csharp
public static class WorkflowConstants
{
    public const string TaskQueueName = "translation-tasks";
}
```

**Excerpt of code used to start the Workflow, referencing the constant defined with the Task Queue name in C# and .NET**

```csharp
var options = new WorkflowOptions(
            id: "translation-workflow",
            taskQueue: WorkflowConstants.TaskQueueName);

// Run workflow
var result = await client.ExecuteWorkflowAsync(
    (TranslationWorkflow wf) => wf.RunAsync(input),
    options);
```

**Excerpt of code used to configure the Worker, referencing the constant defined with the Task Queue name in C# and .NET**

```csharp
using var worker = new TemporalWorker(
    client,
    new TemporalWorkerOptions(WorkflowConstants.TaskQueueName)
    .AddAllActivities(activities)
    .AddWorkflow<TranslationWorkflow>());
```

</TabItem>

</Tabs>

However, it’s not always possible to do define the Task Queue name in a constant, such as when the Client used
to start the Workflow is running on another system or is implemented in a
different programming language.

---

## Task Queues

This page discusses [Task Queues](#task-queue) including [where to set Task Queues](#set-task-queue) and [Task Ordering](#task-ordering).

## What is a Task Queue? {#task-queue}

A Task Queue is a lightweight, dynamically allocated queue that one or more [Worker Entities](/workers#worker-entity) poll for [Tasks](/tasks).
There are three types of Task Queues: Activity Task Queues, Workflow Task Queues, and Nexus Task Queues.

<CaptionedImage
    src="/diagrams/task-queue.svg"
    title="Task Queue component"
    />

A Nexus Endpoint creates an entry point that separates callers from the underlying Nexus Task Queue.
The Nexus callers only interact with the Nexus Endpoint.
This endpoint routes Nexus Requests to a target Task Queue that's polled by a Nexus Worker.

<CaptionedImage
    src="/img/encyclopedia/workers/nexus-task-queue.png"
    title="Nexus Endpoint component"
    />

Task Queues are lightweight components that don’t require explicit registration.
They’re created on demand when a Workflow Execution, Activity, or Nexus Operation is invoked, and/or when a Worker Process subscribes to start polling.
When a named Task Queue is created, individual Task Queues for Workflows, Activities, and Nexus are created using the same name.
A Temporal Application can use, and the Temporal Service can maintain, an unlimited number of Task Queues.

Workers poll for Tasks in Task Queues via synchronous RPC.
This implementation offers several benefits:

- A Worker Process polls for a message only when it has spare capacity, avoiding overloading itself.
- In effect, Task Queues enable load balancing across many Worker Processes.
- Task Queues enable [Task Routing](/task-routing), which is the routing of specific Tasks to specific Worker Processes or even a specific process.
- Activity Task Queues support server-side throttling, which enables you to limit the Task dispatching rate to the pool of Worker Processes while still supporting Task dispatching at higher rates when spikes happen.
- Workflow and Activity Tasks persist in a Task Queue.
  When a Worker Process goes down, the messages remain until the Worker recovers and can process the Tasks.
- Nexus and Query Tasks are not persisted.
  Instead, they are sync matched when, and only when, polled by a Worker.
  Sync matching immediately matches and delivers a Task to an available Worker without persisting a Task to the Service database.
  The caller is responsible to retry failed operations.
  Caller Workflows that invoke Nexus Operations will automatically retry Nexus Tasks until exceeding the Schedule-to-Close timeout.
- Worker Processes do not need to advertise themselves through DNS or any other network discovery mechanism.
- Worker Processes connect directly to the Temporal Service for secure communication without needing to open exposed ports.

Any Worker can pick up any Task on a given Task Queue.
You must ensure that if a Worker accepts a Task that it can process that task using one of its registered Workflows, Activities, or Nexus Operation handlers.
This means that all Workers listening to a Task Queue must register all Workflows, Activities, and Nexus Operations that live on that Queue.

There are two exceptions to this "Task Queue Workers with identical registrations" rule.
First, Worker Versioning may be used.
During Worker upgrade binary rollouts, it's okay to have temporarily misaligned registrations.
Second, dynamic Workflows or Activity components may be used.
If a Task arrives with a recognized method signature, the Worker can use a pre-registered dynamic stand-in.

When Workers don't have a registered Workflow, Activity, Nexus Operation, or dynamic Workflow or Activity component for a given Task, the Task will fail with a "Not Found" error.

- "Not Found" Workflow Tasks and Activity Tasks are treated as _retryable_ errors.
- "Not Found" Nexus Operation handlers are _non-retryable_ and must be manually retried from the caller Workflow.

#### Where to set Task Queues {#set-task-queue}

There are five places where the name of the Task Queue can be set by the developer.

1. A Task Queue must be set when spawning a Workflow Execution:

   - [How to start a Workflow Execution using the Temporal CLI](/cli/workflow#start)
   - [How to start a Workflow Execution using the Go SDK](/develop/go/temporal-client#start-workflow-execution)
   - [How to start a Workflow Execution using the Java SDK](/develop/java/temporal-client#start-workflow-execution)
   - [How to start a Workflow Execution using the PHP SDK](/develop/php/temporal-client#start-workflow-execution)
   - [How to start a Workflow Execution using the Python SDK](/develop/python/temporal-client#start-workflow-execution)
   - [How to start a Workflow Execution using the TypeScript SDK](/develop/typescript/temporal-client#start-workflow-execution)
   - [How to start a Workflow Execution using the .NET SDK](/develop/dotnet/temporal-client#start-workflow)

2. A Task Queue name must be set when creating a Worker Entity and when running a Worker Process:

   - [How to run a development Worker using the Go SDK](/develop/go/core-application#develop-worker)
   - [How to run a development Worker using the Java SDK](/develop/java/core-application#run-a-dev-worker)
   - [How to run a development Worker using the PHP SDK](/develop/php/core-application#run-a-dev-worker)
   - [How to run a development Worker using the Python SDK](/develop/python/core-application#run-a-dev-worker)
   - [How to run a development Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-dev-worker)
   - [How to run a development Worker using the .NET SDK](/develop/dotnet/core-application#run-worker-process)
   - [How to run a Temporal Cloud Worker using the Go SDK](/develop/go/core-application#run-a-temporal-cloud-worker)
   - [How to run a Temporal Cloud Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-temporal-cloud-worker)

   Note that all Worker Entities listening to the same Task Queue name must be registered to handle the exact same Workflows Types, Activity Types, and Nexus Operations.

   If a Worker Entity polls a Task for a Workflow Type or Activity Type it does not know about, it will fail that Task.
   However, the failure of the Task will not cause the associated Workflow Execution to fail.

3. A Task Queue name can be provided when spawning an Activity Execution:

   This is optional.
   An Activity Execution inherits the Task Queue name from its Workflow Execution if one is not provided.

   - [How to start an Activity Execution using the Go SDK](/develop/go/core-application#activity-execution)
   - [How to start an Activity Execution using the Java SDK](/develop/java/core-application#activity-execution)
   - [How to start an Activity Execution using the PHP SDK](/develop/php/core-application#activity-execution)
   - [How to start an Activity Execution using the Python SDK](/develop/python/core-application#activity-execution)
   - [How to start an Activity Execution using the TypeScript SDK](/develop/typescript/core-application#activity-execution)
   - [How to start an Activity Execution using the .NET SDK](/develop/dotnet/core-application#activity-execution)

4. A Task Queue name can be provided when spawning a Child Workflow Execution:

   This is optional.
   A Child Workflow Execution inherits the Task Queue name from its Parent Workflow Execution if one is not provided.

   - [How to start a Child Workflow Execution using the Go SDK](/develop/go/child-workflows)
   - [How to start a Child Workflow Execution using the Java SDK](/develop/java/child-workflows)
   - [How to start a Child Workflow Execution using the PHP SDK](/develop/php/continue-as-new)
   - [How to start a Child Workflow Execution using the Python SDK](/develop/python/child-workflows)
   - [How to start a Child Workflow Execution using the TypeScript SDK](/develop/typescript/child-workflows)
   - [How to start a Child Workflow Execution using the .NET SDK](/develop/dotnet/child-workflows)

5. A Task Queue name can be provided when creating a Nexus Endpoint.
   Nexus Endpoints route requests to the target Task Queue.
   Nexus Workers poll the target Task Queue to handle the Nexus Tasks, such as starting or cancelling a Nexus Operation.

   - [How to run a Nexus Worker using the Go SDK](https://docs.temporal.io/develop/go/nexus#register-a-nexus-service-in-a-worker)
   - [How to run a Nexus Worker using the Java SDK](https://docs.temporal.io/develop/java/nexus#register-a-nexus-service-in-a-worker)

#### Task ordering

Task Queues can be scaled by adding partitions.
The [default](/references/dynamic-configuration#service-level-rps-limits) number of partitions is 4.

Task Queues with multiple partitions do not have any ordering guarantees.
Once there is a backlog of Tasks that have been written to disk, Tasks that can be dispatched immediately (“sync matches”) are delivered before tasks from the backlog (“async matches”).
This approach optimizes throughput.

Task Queues with a single partition are almost always first-in, first-out, with rare edge case exceptions.
However, using a single partition limits you to low- and medium-throughput use cases.

:::note

This section is on the ordering of individual Tasks, and does not apply to the ordering of Workflow Executions, Activity Executions, or [Events](/workflow-execution/event#event) in a single Workflow Execution.
The order of Events in a Workflow Execution is guaranteed to remain constant once they have been written to that Workflow Execution's [History](/workflow-execution/event#event-history).

:::

---

## Task Routing and Worker Sessions

This page discusses the following:

- [Task Routing](#task-routing)
- [Worker Sessions](#worker-session)

## What is Task Routing? {#task-routing}

Task Routing is simply when a Task Queue is paired with one or more Workers, primarily for Activity Task Executions.

This could also mean employing multiple Task Queues, each one paired with a Worker Process.

Task Routing has many applicable use cases.

Some SDKs provide a [Session API](#worker-session) that provides a straightforward way to ensure that Activity Tasks are executed with the same Worker without requiring you to manually specify Task Queue names.
It also includes features like concurrent session limitations and worker failure detection.

### Flow control

A Worker that consumes from a Task Queue asks for an Activity Task only when it has available capacity, so it is never overloaded by request spikes.
If Activity Tasks get created faster than Workers can process them, they are backlogged in the Task Queue.

### Throttling

The rate at which each Activity Worker polls for and processes Activity Tasks is configurable per Worker.
Workers do not exceed this rate even if it has spare capacity.
There is also support for global Task Queue rate limiting.
This limit works across all Workers for the given Task Queue.
It is frequently used to limit load on a downstream service that an Activity calls into.

### Specific environments

In some cases, you might need to execute Activities in a dedicated environment.
To send Activity Tasks to this environment, use a dedicated Task Queue.

#### Route Activity Tasks to a specific host

In some use cases, such as file processing or machine learning model training, an Activity Task must be routed to a specific Worker Process or Worker Entity.

For example, suppose that you have a Workflow with the following three separate Activities:

- Download a file.
- Process the file in some way.
- Upload a file to another location.

The first Activity, to download the file, could occur on any Worker on any host.
However, the second and third Activities must be executed by a Worker on the same host where the first Activity downloaded the file.

In a real-life scenario, you might have many Worker Processes scaled over many hosts.
You would need to develop your Temporal Application to route Tasks to specific Worker Processes when needed.

Code samples:

- [Go file processing example](https://github.com/temporalio/samples-go/tree/main/fileprocessing)
- [Java file processing example](https://github.com/temporalio/samples-java/tree/main/core/src/main/java/io/temporal/samples/fileprocessing)
- [PHP file processing example](https://github.com/temporalio/samples-php/tree/master/app/src/FileProcessing)

#### Route Activity Tasks to a specific process

Some Activities load large datasets and cache them in the process.
The Activities that rely on those datasets should be routed to the same process.

In this case, a unique Task Queue would exist for each Worker Process involved.

#### Workers with different capabilities

Some Workers might exist on GPU boxes versus non-GPU boxes.
In this case, each type of box would have its own Task Queue and a Workflow can pick one to send Activity Tasks.

### Multiple priorities

If your use case involves more than one priority, you can create one Task Queue per priority, with a Worker pool per priority.

### Versioning

Task Routing is the simplest way to version your code.

If you have a new backward-incompatible Activity Definition, start by using a different Task Queue.

## What is a Worker Session? {#worker-session}

A Worker Session is a feature provided by some SDKs that provides a straightforward API for [Task Routing](#task-routing) to ensure that Activity Tasks are executed with the same Worker without requiring you to manually specify Task Queue names.
It also includes features like concurrent session limitations and Worker failure detection.

- [How to use Worker Sessions](/develop/go/sessions)

---

## Tasks

This page discusses the following:

- [Task](#task)
- [Workflow Task](#workflow-task)
- [Workflow Task Execution](#workflow-task-execution)
- [Activity Task](#activity-task)
- [Activity Task Execution](#activity-task-execution)
- [Nexus Task](#nexus-task)
- [Nexus Task Execution](#nexus-task-execution)

## What is a Task? {#task}

A Task is the context that a Worker needs to progress with a specific [Workflow Execution](/workflow-execution), [Activity Execution](/activity-execution), or a [Nexus Task Execution](#nexus-task-execution).

There are three types of Tasks:

- [Workflow Task](#workflow-task)
- [Activity Task](#activity-task)
- [Nexus Task](#nexus-task)

## What is a Workflow Task? {#workflow-task}

A Workflow Task is a Task that contains the context needed to make progress with a Workflow Execution.

- Every time a new external event that might affect a Workflow state is recorded, a Workflow Task that contains the event is added to a Task Queue and then picked up by a Workflow Worker.
- After the new event is handled, the Workflow Task is completed with a list of [Commands](/workflow-execution#command).
- Handling of a Workflow Task is usually very fast and is not related to the duration of operations that the Workflow invokes.

### What is a Workflow Task Execution? {#workflow-task-execution}

A Workflow Task Execution occurs when a [Worker](/workers#worker-entity) picks up a [Workflow Task](#workflow-task) and uses it to make progress on the execution of a [Workflow Definition](/workflow-definition) (also known as a Workflow function).

## What is an Activity Task? {#activity-task}

An Activity Task contains the context needed to proceed with an [Activity Task Execution](#activity-task-execution).
Activity Tasks largely represent the Activity Task Scheduled Event, which contains the data needed to execute an Activity Function.

If Heartbeat data is being passed, an Activity Task will also contain the latest Heartbeat details.

### What is an Activity Task Execution? {#activity-task-execution}

An Activity Task Execution occurs when a [Worker](/workers#worker-entity) uses the context provided from the [Activity Task](#activity-task) and executes the [Activity Definition](/activity-definition) (also known as the Activity Function).

The [ActivityTaskScheduled Event](/references/events#activitytaskscheduled) corresponds to when the Temporal Service puts the Activity Task into the Task Queue.

The [ActivityTaskStarted Event](/references/events#activitytaskstarted) corresponds to when the Worker picks up the Activity Task from the Task Queue.

Either [ActivityTaskCompleted](/references/events#activitytaskcompleted) or one of the other Closed Activity Task Events corresponds to when the Worker has yielded back to the Temporal Service.

The API to schedule an Activity Execution provides an "effectively once" experience, even though there may be several Activity Task Executions that take place to successfully complete an Activity.

Once an Activity Task finishes execution, the Worker responds to the Temporal Service with a specific Event:

- ActivityTaskCanceled
- ActivityTaskCompleted
- ActivityTaskFailed
- ActivityTaskTerminated
- ActivityTaskTimedOut

## What is a Nexus Task? {#nexus-task}

A Nexus Task represents a single Nexus request to start or cancel a Nexus Operation.
The Nexus Task includes details such as the Nexus Service and Nexus Operation names, and other information required to process the Nexus request.
The Temporal Worker triggers the registered Operation handler based on the Nexus task information.

### What is a Nexus Task Execution? {#nexus-task-execution}

A Nexus Task Execution occurs when a Worker uses the context provided from the Nexus Task and executes an action associated with a Nexus Operation which commonly includes starting a Nexus Operation using it's Nexus Operation handler plus many additional actions that may be performed on a Nexus Operation.

The NexusOperationScheduled Event corresponds to when the Temporal Service records the Workflow's intent to schedule an operation.

The NexusOperationStarted Event corresponds to when the Worker picks up the Nexus Task from the Task Queue, starts an asynchronous Nexus Operation, and returns an Operation token to the caller indicating the asynchronous Nexus Operation has started.

Either NexusOperationCompleted or one of the other Closed Nexus Operation Events corresponds to when the Nexus Operation has reached a final state due to successfully completing the operation or unsuccessfully completing the operation in the case of a failure, timeout, or cancellation.

A Nexus Operation Execution appears to the caller Workflow as a single RPC, while under the hood the Temporal Service may issue several Nexus Tasks to attempt to start the Operation.
Hence, a Nexus Operation Handler implementation should be idempotent.
The WorkflowRunOperation provided by the SDK leverages Workflow ID based deduplication to ensure idempotency and provide an "effectively once" experience.

A Nexus Task Execution completes when a Worker responds to the Temporal Service with either a RespondNexusTaskCompleted or RespondNexusTaskFailed call, or when the Task times out.

The Temporal Service interprets the outcome and determines whether to retry the Task or record the progress in a History Event:

- NexusTaskCompleted
- NexusTaskFailed

---

## Worker Shutdown Behavior


When a Worker shuts down, it stops polling for new tasks and begins the shutdown sequence.
In the case of in-flight Workflow Tasks, shutdown may cause them to fail if they aren’t completed in time, after exhausting Retry Policy attempts.

There are two types of shutdown behavior that can occur, depending on whether an idea of “graceful shutdown” is configured.

## Graceful Shutdown

Graceful shutdown configures how much time a Worker has to complete its current task before shutting down.
An Activity is able to determine that the Worker it’s running on is being shut down, through the Activity context.

> Core SDKs - `graceful_shutdown_period`

> Go - `WorkerStopTimeout`

> Java - `shutdown()` followed by `awaitTermination(timeout, unit)`

### Workflow tasks

Any in-flight Workflow Tasks are (attempted to be) completed.
The only reason they may not immediately, is if Workflow code is (incorrectly) blocking, or because of Local Activities (see below).

### Activities

Activities are allowed to complete during the graceful shutdown period.

### Local Activities

Because Local Activities run within a Workflow Task, current and future Local Activities within the same Workflow Task will be allowed to run and complete, assuming there is no additional command to yield to.

If the Local Activity is unable to complete by the graceful shutdown period, the Local Activity attempt is sent a cancel signal.
In this case, no new Local Activities will be retried or started, and the Worker is shut down.
The Worker still waits for the current Workflow Task to complete, meaning you can eventually hit your Workflow Task or execution timeout, unless another Worker is spun up.

## Non-Graceful Period Shutdown

This behavior is for either no graceful period being specified, or if the shutdown has taken longer than the configured graceful period.
In all cases, the Activity context is canceled and the Worker will finish shutdown when the current Workflow Task completes (with either success or failure).

:::note
Go and Core SDKs behave differently when we pass task timeout and the Activity or Local Activity is still running:

**Go** - The shutdown completes, but the Activity will continue to run and use a slot.

**Core** - The Worker shutdown will not complete while the Activity completes.
:::

### Local Activities

The Local Activity is sent a cancel signal, then the Workflow Task heartbeats stop, and no new Local Activities will be retried or started.
The Worker still waits for the current Workflow Task to complete, meaning you can eventually hit your Workflow Task or execution timeout, unless another Worker is spun up.

## General Developer Guidance

- Ensure Activities and Local Activities **honor context cancellation** or other shutdown signals.
- Expect that **long or hung Local Activities may block shutdown** unless you fail early.
  It is recommended that Local Activities should already generally be used for short Activities.

---

## Worker Versioning

This page defines some of the underlying concepts used in [Worker Versioning](/production-deployment/worker-deployments/worker-versioning):

- [Worker Deployments](#deployments)
- [Worker Deployment Versions](#deployment-versions)
- [Versioning Behaviors](#versioning-behaviors)
- [Versioning Statuses](#versioning-statuses)
- [Continue-as-new, Child Workflow, and Retry Semantics](#inheritance-semantics)

## Worker Deployments {#deployments}

A Worker Deployment is a logical service that groups similar Workers together for unified management.
Each Deployment has a name (such as your service name) and supports versioning through a series of Worker Deployment Versions.

## Worker Deployment Versions {#deployment-versions}

A Worker Deployment Version represents an iteration of a Worker Deployment.
Each Deployment Version consists of Workers that share the same code build and environment.
When a Worker starts polling for Workflow and Activity Tasks, it reports its Deployment Version to the Temporal Server.

## Versioning Behaviors {#versioning-behaviors}

Using **Workflow Pinning**, you can declare each Workflow type to have a **Versioning Behavior**, either Pinned or Auto-Upgrade.

### Pinned Workflows {#pinned}

A **Pinned** Workflow is guaranteed to complete on a single Worker Deployment Version. You can mark a Workflow Type as pinned when you register it by adding an additional Pinned parameter. If you need to move a pinned Workflow to a new version, use [`temporal workflow update-options`](https://docs.temporal.io/cli/workflow#update-options).

### Auto-Upgrade Workflows {#auto-upgrade}

An **Auto-Upgrade** Workflow will move to the latest Worker Deployment Version automatically whenever you change the current version. Auto-upgrade Workflows are not restricted to a single Deployment Version and need to be kept replay-safe manually, i.e. with [patching](/workflow-definition#workflow-versioning).

## Versioning Statuses {#versioning-statuses}

A Worker Deployment Version moves through the following states:

1. **Inactive**: The version exists because a Worker with that version has polled the server. If this version never becomes Active, it will never be Draining or Drained.
2. **Active**: The version is either Current or Ramping, so it is accepting new Workflows and existing auto-upgrade Workflows.
3. **Draining**: The version has open pinned Workflows running on it, but stopped being Current or Ramping, usually because a newer version has been deployed. It is possible to be Draining and have no open pinned Workflows for a short time, since the drainage status is updated only periodically.
4. **Drained**: The version was draining and now all the pinned Workflows that were running on it are closed. Closed Workflows may still re-run some code paths if they are [Queried](https://docs.temporal.io/sending-messages#sending-queries) within their [Retention Period](https://docs.temporal.io/temporal-service/temporal-server#retention-period) and Workers with that version are still polling.

## Continue-as-new, Child Workflow, and Retry Semantics {#inheritance-semantics}

When Workflows start new runs (e.g. by continuing-as-new or retrying) the new run may inherit their versioning behavior. This section explains how inheritance works across different Workflow execution patterns.

### Ways Workflows Start New Runs

A Workflow can start a new run through:

- Starting a [Child Workflow](https://docs.temporal.io/child-workflows)
- Invoking [Continue-As-New](https://docs.temporal.io/workflow-execution/continue-as-new)
- Retrying per its [Retry Policy](https://docs.temporal.io/encyclopedia/retry-policies)
- Starting another iteration of a [Cron Job](https://docs.temporal.io/cron-job) (superseded by [Schedules](https://docs.temporal.io/schedule))

### Inheritance Rules Overview

Auto-upgrade Workflows never inherit versions.
By default, Pinned workflows will pass their version to any Pinned children.

This section provides more detail on specific inheritance scenarios.

### Inheritance by Scenario

#### Child Workflows

**When Parent is Pinned:**

- Child inherits the parent's version if the child's Task Queue belongs to that version
- Child's first Workflow task executes in the same version as its parent
- If child is also Pinned: child remains Pinned to the inherited version for its lifetime
- If child is Auto-Upgrade: child's behavior changes to Auto-Upgrade after the first task completes
- If child's Task Queue is not in the same Worker Deployment as parent: no inheritance occurs, child starts on Current Version of its task queue

**When Parent is Auto-upgrade:**

- Child inherits no initial Versioning Behavior
- Child starts on the Current Version of its Worker Deployment like all new Workflow executions

#### Continue-As-New

**When Original Workflow is Pinned:**

- The Pinned version is inherited across the Continue-As-New chain
- If the new run's Task Queue is not in the same Worker Deployment as the original Workflow: no inheritance occurs, new run starts on Current Version of its task queue

**When Original Workflow is Auto-upgrade:**

- No version inheritance occurs

#### Retries

**Inheritance Conditions (all must be met):**

- The retried run is effectively pinned at the time of retry
- The retried run inherited a pinned version when it started (i.e., it is a child of a pinned parent, or a Continue-As-New of a pinned run)
- The retried run is running on a Task Queue in the inherited version

**When Conditions Not Met:**

- No version inheritance occurs

#### Cron Jobs

- **Never inherit** versioning behavior or version

### Versioning Override Inheritance

- Children, crons, retries, and continue-as-new inherit the source run's override **if**:
  - The override is pinned, **AND**
  - The new Workflow's Task Queue belongs to the override version
- Override inheritance is evaluated separately and takes precedence over inherited base version

---

## What is a Temporal Worker?

This page discusses the following:

- [Worker](#worker)
- [Worker Program](#worker-program)
- [Worker Entity](#worker-entity)
- [Worker Identity](#worker-identity)
- [Worker Process](#worker-process)

## What is a Worker? {#worker}

In day-to-day conversations, the term Worker is used to denote either a [Worker Program](#worker-program), a [Worker Process](#worker-process), or a [Worker Entity](/workers#worker-entity).
Temporal documentation aims to be explicit and differentiate between them.

## What is a Worker Program? {#worker-program}

A Worker Program is the static code that defines the constraints of the Worker Process, developed using the APIs of a Temporal SDK.

:::info

- [How to run a development Worker using the Go SDK](/develop/go/core-application#develop-worker)
- [How to run a development Worker using the Java SDK](/develop/java/core-application#run-a-dev-worker)
- [How to run a development Worker using the PHP SDK](/develop/php/core-application#run-a-dev-worker)
- [How to run a development Worker using the Python SDK](/develop/python/core-application#run-a-dev-worker)
- [How to run a development Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-dev-worker)
- [How to run a development Worker using the .NET SDK](/develop/dotnet/core-application#run-worker-process)

- [How to run a Temporal Cloud Worker using the Go SDK](/develop/go/core-application#run-a-temporal-cloud-worker)
- [How to run a Temporal Cloud Worker using the TypeScript SDK](/develop/typescript/core-application#run-a-temporal-cloud-worker)

:::

## What is a Worker Entity? {#worker-entity}

A Worker Entity is the individual Worker within a Worker Process that listens to a specific Task Queue.

A Worker Entity listens and polls on a single Task Queue.
A Worker Entity contains a Workflow Worker and/or an Activity Worker, which makes progress on Workflow Executions and Activity Executions, respectively.

**Can a Worker handle more Workflow Executions than its cache size or number of supported threads?**

Yes it can.
However, the trade off is added latency.

Workers are stateless, so any Workflow Execution in a blocked state can be safely removed from a Worker.
Later on, it can be resurrected on the same or different Worker when the need arises (in the form of an external event).
Therefore, a single Worker can handle millions of open Workflow Executions, assuming it can handle the update rate and that a slightly higher latency is not a concern.

**Operation guides:**

- [How to tune Workers](/develop/worker-performance)

## What is a Worker Identity? {#worker-identity}

Workers have an associated identifier that helps identify the specific Worker instance.
By default, Temporal SDKs set a Worker Identity to `${process.pid}@${os.hostname()}`, which combines the Worker's process ID (`process.pid`) and the hostname of the machine running the Worker (`os.hostname()`).

The Worker Identity is visible in various contexts, such as Workflow History and the list of pollers on a Task Queue.

You can use the Worker Identity to aid in debugging operational issues.
By providing a user assigned identifier, you can trace issues back to specific Worker instances.

**What are some limitations of the default identity?**

While the default identity format may seem sensible, it often proves to be of limited usefulness in cloud environments.
Some common issues include:

- **Docker containers**: When running Workers inside Docker containers, the process ID is always `1`, as each container typically runs a single process. This makes the process identifier meaningless for identification purposes.
- **Random hostnames**: In some cloud environments, such as Amazon ECS (Elastic Container Service), the hostname is a randomly generated string that does not provide any meaningful information about the Worker's execution context.
- **Ephemeral IP addresses**: In certain cases, the hostname might be set to an ephemeral IP address, which can change over time and does not uniquely identify a Worker instance.

**What are some recommended approaches?**

It is recommended that you ensure that the Worker Identity can be linked back to the corresponding machine, process, execution context, or log stream.
In some execution environments, this might require that you explicitly specify the Worker Identity.

Here are some approaches:

- **Use environment-specific identifiers**: Choose an identifier that is specific to your execution environment. For example, when running Workers on Amazon ECS, you can set the Worker Identity to the ECS Task ID, which uniquely identifies the task running the Worker.
- **Include relevant context**: Incorporate information that helps establish the context of the Worker, such as the deployment environment (`staging` or `production`), region, or any other relevant details.
- **Ensure uniqueness**: Make sure that the Worker Identity is unique within your system to avoid ambiguity when debugging issues.
- **Keep it concise**: While including relevant information is important, try to keep the Worker Identity concise and easily readable to facilitate quick identification and troubleshooting.

## What is a Worker Process? {#worker-process}

<CaptionedImage
    src="/diagrams/worker-and-server-component.svg"
    title="Component diagram of a Worker Process and the Temporal Server"
    />

A Worker Process is responsible for polling a [Task Queue](/task-queue), dequeueing a [Task](/tasks#task), executing your code in response to a Task, and responding to the [Temporal Service](/temporal-service) with the results.

More formally, a Worker Process is any process that implements the Task Queue Protocol and the Task Execution Protocol.

- A Worker Process is a Workflow Worker Process if the process implements the Workflow Task Queue Protocol and executes the Workflow Task Execution Protocol to make progress on a Workflow Execution.
  A Workflow Worker Process can listen on an arbitrary number of Workflow Task Queues and can execute an arbitrary number of Workflow Tasks.
- A Worker Process is an Activity Worker Process if the process implements the Activity Task Queue Protocol and executes the Activity Task Processing Protocol to make progress on an Activity Execution.
  An Activity Worker Process can listen on an arbitrary number of Activity Task Queues and can execute an arbitrary number of Activity Tasks.

**Worker Processes are external to a Temporal Service.**
Temporal Application developers are responsible for developing [Worker Programs](#worker-program) and operating Worker Processes.
Said another way, the [Temporal Service](/temporal-service) (including the Temporal Cloud) doesn't execute any of your code (Workflow and Activity Definitions) on Temporal Service machines. The Temporal Service is solely responsible for orchestrating [State Transitions](/workflow-execution#state-transition) and providing Tasks to the next available [Worker Entity](/workers#worker-entity).

While data transferred in Event Histories is [secured by mTLS](/self-hosted-guide/security#encryption-in-transit-with-mtls), by default, it is still readable at rest in the Temporal Service.

To solve this, Temporal SDKs offer a [Data Converter API](/dataconversion) that you can use to customize the serialization of data going out of and coming back in to a Worker Entity, with the net effect of guaranteeing that the Temporal Service cannot read sensitive business data.

In many of our tutorials, we show you how to run both a Temporal Service and one Worker on the same machine for local development.
However, a production-grade Temporal Application typically has a _fleet_ of Worker Processes, all running on hosts external to the Temporal Service.
A Temporal Application can have as many Worker Processes as needed.

A Worker Process can be both a Workflow Worker Process and an Activity Worker Process.
Many SDKs support the ability to have multiple Worker Entities in a single Worker Process.
(Worker Entity creation and management differ between SDKs.)
A single Worker Entity can listen to only a single Task Queue.
But if a Worker Process has multiple Worker Entities, the Worker Process could be listening to multiple Task Queues.

<CaptionedImage
    src="/diagrams/worker-and-server-entity-relationship.svg"
    title="Entity relationship diagram (meta model) of Worker Processes, Task Queues, and Tasks"
/>

Worker Processes executing Activity Tasks must have access to any resources needed to execute the actions that are defined in Activity Definitions, such as the following:

- Network access for external API calls.
- Credentials for infrastructure provisioning.
- Specialized GPUs for machine learning utilities.

The Temporal Service itself has [internal workers](https://temporal.io/blog/workflow-engine-principles/#system-workflows-1910) for system Workflow Executions.
However, these internal workers are not visible to the developer.

---

## Temporal Cron Job

This page discusses [Cron Job](#temporal-cron-job) including [Cron Schedules](#cron-schedules), [Time Zones](#cron-job-time-zones), and [how to stop a Cron Schedule](#stop-cron-schedules).

## What is a Temporal Cron Job? {#temporal-cron-job}

:::note

We recommend using [Schedules](/schedule) instead of Cron Jobs.
Schedules were built to provide a better developer experience, including more configuration options and the ability to update or pause running Schedules.

:::

A Temporal Cron Job is the series of Workflow Executions that occur when a Cron Schedule is provided in the call to spawn a Workflow Execution.

- [How to set a Cron Schedule using the Go SDK](/develop/go/schedules#temporal-cron-jobs)
- [How to set a Cron Schedule using the Java SDK](/develop/java/schedules#cron-schedule)
- [How to set a Cron Schedule using the PHP SDK](/develop/php/schedules#temporal-cron-jobs)
- [How to set a Cron Schedule using the Python SDK](/develop/python/schedules#temporal-cron-jobs)
- [How to set a Cron Schedule using the TypeScript SDK](/develop/typescript/schedules#temporal-cron-jobs)

<CaptionedImage
    src="/diagrams/temporal-cron-job.svg"
    title="Temporal Cron Job timeline" />

A Temporal Cron Job is similar to a classic unix cron job.
Just as a unix cron job accepts a command and a schedule on which to execute that command, a Cron Schedule can be provided with the call to spawn a Workflow Execution.
If a Cron Schedule is provided, the Temporal Server will spawn an execution for the associated Workflow Type per the schedule.

Each Workflow Execution within the series is considered a Run.

- Each Run receives the same input parameters as the initial Run.
- Each Run inherits the same Workflow Options as the initial Run.

The Temporal Server spawns the first Workflow Execution in the chain of Runs immediately.
However, it calculates and applies a backoff (`firstWorkflowTaskBackoff`) so that the first Workflow Task of the Workflow Execution does not get placed into a Task Queue until the scheduled time.
After each Run Completes, Fails, or reaches the [Workflow Run Timeout](/encyclopedia/detecting-workflow-failures#workflow-run-timeout), the same thing happens: the next run will be created immediately with a new `firstWorkflowTaskBackoff` that is calculated based on the current Server time and the defined Cron Schedule.

The Temporal Server spawns the next Run only after the current Run has Completed, Failed, or has reached the Workflow Run Timeout.
This means that, if a Retry Policy has also been provided, and a Run Fails or reaches the Workflow Run Timeout, the Run will first be retried per the Retry Policy until the Run Completes or the Retry Policy has been exhausted.
If the next Run, per the Cron Schedule, is due to spawn while the current Run is still Open (including retries), the Server automatically starts the new Run after the current Run completes successfully.
The start time for this new Run and the Cron definitions are used to calculate the `firstWorkflowTaskBackoff` that is applied to the new Run.

A [Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) is used to limit how long a Workflow can be executing (have an Open status), including retries and any usage of Continue As New.
The Cron Schedule runs until the Workflow Execution Timeout is reached or you terminate the Workflow.

<CaptionedImage
    src="/diagrams/temporal-cron-job-failure-with-retry.svg"
    title="Temporal Cron Job Run Failure with a Retry Policy" />

## Cron Schedules {#cron-schedules}

Cron Schedules are interpreted in UTC time by default.

The Cron Schedule is provided as a string and must follow one of two specifications:

**Classic specification**

This is what the "classic" specification looks like:

```
┌───────────── minute (0 - 59)
│ ┌───────────── hour (0 - 23)
│ │ ┌───────────── day of the month (1 - 31)
│ │ │ ┌───────────── month (1 - 12)
│ │ │ │ ┌───────────── day of the week (0 - 6) (Sunday to Saturday)
│ │ │ │ │
│ │ │ │ │
* * * * *
```

For example, `15 8 * * *` causes a Workflow Execution to spawn daily at 8:15 AM UTC.
Use the [crontab guru site](https://crontab.guru/) to test your cron expressions.

### `robfig` predefined schedules and intervals

You can also pass any of the [predefined schedules](https://pkg.go.dev/github.com/robfig/cron/v3#hdr-Predefined_schedules) or [intervals](https://pkg.go.dev/github.com/robfig/cron/v3#hdr-Intervals) described in the [`robfig/cron` documentation](https://pkg.go.dev/github.com/robfig/cron/v3).

```
| Schedules              | Description                                | Equivalent To |
| ---------------------- | ------------------------------------------ | ------------- |
| @yearly (or @annually) | Run once a year, midnight, Jan. 1st        | 0 0 1 1 *     |
| @monthly               | Run once a month, midnight, first of month | 0 0 1 * *     |
| @weekly                | Run once a week, midnight between Sat/Sun  | 0 0 * * 0     |
| @daily (or @midnight)  | Run once a day, midnight                   | 0 0 * * *     |
| @hourly                | Run once an hour, beginning of hour        | 0 * * * *     |
```

For example, "@weekly" causes a Workflow Execution to spawn once a week at midnight between Saturday and Sunday.

Intervals just take a string that can be accepted by [time.ParseDuration](http://golang.org/pkg/time/#ParseDuration).

```
@every <duration>
```

## Time zones {#cron-job-time-zones}

_This feature only applies in Temporal 1.15 and up_

You can change the time zone that a Cron Schedule is interpreted in by prefixing the specification with `CRON_TZ=America/New_York` (or your [desired time zone from tz](https://en.wikipedia.org/wiki/List_of_tz_database_time_zones)). `CRON_TZ=America/New_York 15 8 * * *` therefore spawns a Workflow Execution every day at 8:15 AM New York time, subject to caveats listed below.

Consider that using time zones in production introduces a surprising amount of complexity and failure modes!
**If at all possible, we recommend specifying Cron Schedules in UTC (the default)**.

If you need to use time zones, here are a few edge cases to keep in mind:

- **Beware Daylight Saving Time:** If a Temporal Cron Job is scheduled around the time when daylight saving time (DST) begins or ends (for example, `30 2 * * *`), **it might run zero, one, or two times in a day**! The Cron library that we use does not do any special handling of DST transitions. Avoid schedules that include times that fall within DST transition periods.
  - For example, in the US, DST begins at 2 AM. When you "fall back," the clock goes `1:59 … 1:00 … 1:01 … 1:59 … 2:00 … 2:01 AM` and any Cron jobs that fall in that 1 AM hour are fired again. The inverse happens when clocks "spring forward" for DST, and Cron jobs that fall in the 2 AM hour are skipped.
  - In other time zones like Chile and Iran, DST "spring forward" is at midnight. 11:59 PM is followed by 1 AM, which means `00:00:00` never happens.
- **Self Hosting note:** If you manage your own Temporal Service, you are responsible for ensuring that it has access to current `tzdata` files. The official Docker images are built with [tzdata](https://docs.w3cub.com/go/time/tzdata/index) installed (provided by Alpine Linux), but ultimately you should be aware of how tzdata is deployed and updated in your infrastructure.
- **Updating Temporal:** If you use the official Docker images, note that an upgrade of the Temporal Service may include an update to the tzdata files, which may change the meaning of your Cron Schedule. You should be aware of upcoming changes to the definitions of the time zones you use, particularly around daylight saving time start/end dates.
- **Absolute Time Fixed at Start:** The absolute start time of the next Run is computed and stored in the database when the previous Run completes, and is not recomputed. This means that if you have a Cron Schedule that runs very infrequently, and the definition of the time zone changes between one Run and the next, the Run might happen at the wrong time. For example, `CRON_TZ=America/Los_Angeles 0 12 11 11 *` means "noon in Los Angeles on November 11" (normally not in DST). If at some point the government makes any changes (for example, move the end of DST one week later, or stay on permanent DST year-round), the meaning of that specification changes. In that first year, the Run happens at the wrong time, because it was computed using the older definition.

## How to stop a Temporal Cron Job {#stop-cron-schedules}

A Temporal Cron Job does not stop spawning Runs until it has been Terminated or until the [Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) is reached.

A Cancellation Request affects only the current Run.

Use the Workflow Id in any requests to Cancel or Terminate.

---

## Dynamic Handler

This page discusses [Dynamic Handler](#dynamic-handler).

## What is a Dynamic Handler? {#dynamic-handler}

Temporal supports Dynamic Workflows, Activities, Signals, and Queries.

:::note

Currently, the Temporal SDKs that support Dynamic Handlers are:

- [Java](/develop/java/message-passing#dynamic-handler)
- [Python](/develop/python/message-passing#dynamic-handler)
- [.NET](/develop/dotnet/message-passing#dynamic-handler)

The Go SDK supports Dynamic Signals through the [GetUnhandledSignalNames](https://pkg.go.dev/go.temporal.io/sdk/workflow#GetUnhandledSignalNames) function.

:::

These are unnamed handlers that are invoked if no other statically defined handler with the given name exists.

Dynamic Handlers provide flexibility to handle cases where the names of Workflows, Activities, Signals, or Queries aren't known at run time.

:::caution

Dynamic Handlers should be used judiciously as a fallback mechanism rather than the primary approach.
Overusing them can lead to maintainability and debugging issues down the line.

Instead, Workflows, Activities, Signals, and Queries should be defined statically whenever possible, with clear names that indicate their purpose.
Use static definitions as the primary way of structuring your Workflows.

Reserve Dynamic Handlers for cases where the handler names are not known at compile time and need to be looked up dynamically at runtime.
They are meant to handle edge cases and act as a catch-all, not as the main way of invoking logic.

:::

---

## Patching

This page discusses [Patching](#patching).

## What is Patching? {#patching}

A Patch defines a logical branch in a Workflow for a specific change, similar to a feature flag.
It applies a code change to new Workflow Executions while avoiding disruptive changes to in-progress ones.
When you want to make substantive code changes that may affect existing Workflow executions, create a patch. Note that there's no need to patch [Pinned Workflows](/worker-versioning).

### Detailed Description of the `patched()` Function

This applies to the `patched()` function in the Python, .NET, and Ruby SDKs.

#### Behavior When Not Replaying

If the execution is not replaying, when it encounters a call to `patched()`, it first checks the event history.

- If the patch ID is not in the event history, the execution adds a marker to the event history, upserts a search attribute, and returns `true`. This happens in the first block of the patch ID.
- If the patch ID is in the event history, the execution doesn't modify the history, and returns `true`.
  This happens in a patch ID's subsequent blocks, because the event history was updated in the first block.

There is a caveat to this behavior, which we will cover below.

#### Behavior When Replaying With Marker Before-Or-At Current Location

If the execution is replaying and has a call to `patched()`, and if the event history has a marker from a call to `patched()` in the same place (which means it will match the original event history), then it writes a marker to the replay event history and returns `true`.

This is similar to the behavior of the non-replay case, and also happens in a given patch ID's first block.

If the code has a call to `patched()`, and the event history has a marker with that Patch ID earlier in the history, it will return `true` and will not modify the replay event history.

This is also similar to the behavior of the non-replay case, and also happens in a given patch ID's subsequent blocks.

#### Behavior When Replaying With Marker After Current Location

If the Event History's Marker Event is after the current execution point, that means the new patch is too early.
The execution will encounter the new patch before the original.
The execution will attempt to write the marker to the replay event history, but it will throw a non-deterministic exception because the replay and original event histories don't match.

#### Behavior When Replaying With No Marker For that Patch ID

During a Replay, if there is no marker for a given patch ID, the execution will return `false` and will not add a marker to the event history. In addition, all future calls to `patched()` with that ID will return `false` -- even after it is done replaying and is running new code.

The [preceding section](#behavior-when-not-replaying) states that if the execution is not replaying, the `patched()` function will always return `true`.
If the marker doesn't exist, it will be added, and if the marker already exists, it won't be re-added.

However, this behavior doesn't occur if there was already a call to `patched()` with that ID in the replay code, but not in the event history.
In this situation, the function won't return `true`.

#### A Summary of the Two Potentially Unexpected Behaviors

Recapping the potentially unexpected behaviors that may occur during a Replay:

If the execution hits a call to `patched()`, but that patch ID isn't _at or before that point_ in the event history, you may not realize that the event history _after_ the current execution location matters.
This behavior occurs because:

- If that patch ID exists later, you get a non-determinism error
- If the patch doesn't exist later, you don't get a non-determinism error, and the call returns `false`

If the execution hits a call to `patched()` with an ID that doesn't exist in the history, then not only will it return `false` in that occurence, but it will also return `false` if the execution surpasses the Replay threshold and is running new code.

#### Implications of the Behaviors

If you deploy new code while Workflows are executing, any Workflows that were in the middle of executing will Replay up to the point they were at when the Worker was shut down.
When they do this Replay, they will not follow the `patched()` branches in the code.
For the rest of the execution after they have replayed to the point before the deployment and worker restart, they will either:

- Use new code if there was no call to `patched()` in the replay code
- If there was a call to `patched()` in the replay code, they will
  run the non-patched code during and after replay

This might sound odd, but it's actually exactly what's needed because that means that if the future patched code depends on earlier patched code, then it won't use the new code -- it will use the old code instead.

But if there's new code in the future, and there was no code earlier in the body that required the new patch, then it can switch over to the new code, which it will do.

Note that this behavior means that the Workflow _does not always run the newest code_.
It only does that if not replaying or if replay is surpassed and there hasn't been a call to `patched()` (with that ID) throughout the replay.

#### Recommendations

Based on this behavior and the implications, when patching in new code, always put the newest code at the top of an if-patched-block.

```python
if patched('v3'):
    # This is the newest version of the code.
    # put this at the top, so when it is running
    # a fresh execution and not replaying,
    # this patched statement will return true
    # and it will run the new code.
    pass
elif patched('v2'):
    pass
else:
    pass
```

The following sample shows how `patched()` will behave in a conditional block that's arranged differently.
In this case, the code's conditional block doesn't have the newest code at the top.
Because `patched()` will return `True` when not Replaying (except with the preceding caveats), this snippet will run the `v2` branch instead of `v3` in new executions.

```python
if patched('v2'):
    # This is bad because when doing a new execution (i.e. not replaying),
    # patched statements evaluate to True (and put a marker
    # in the event history), which means that new executions
    # will use v2, and miss v3 below
    pass
elif patched('v3'):
    pass
else:
  pass
```

---

## Schedule

This page discusses [Schedule](#schedule).

## What is a Schedule? {#schedule}

A Schedule contains instructions for starting a [Workflow Execution](/workflow-execution) at specific times.
Schedules provide a more flexible and user-friendly approach than [Temporal Cron Jobs](/cron-job).

- [How to enable Schedules](#limitations)
- [How to operate Schedules using the Temporal CLI](/cli/schedule)

A Schedule has an identity and is independent of a Workflow Execution.
This differs from a Temporal Cron Job, which relies on a cron schedule as a property of the Workflow Execution.

:::info

For triggering a Workflow Execution at a specific one-time future point rather than on a recurring schedule, the [Start Delay](/workflow-execution/timers-delays#delay-workflow-execution) option should be used instead of a Schedule.

:::

### Action

The Action of a Schedule is where the Workflow Execution properties are established, such as Workflow Type, Task Queue, parameters, and timeouts.

Workflow Executions started by a Schedule have the following additional properties:

- The Action's timestamp is appended to the Workflow Id.
- The `TemporalScheduledStartTime` [Search Attribute](/search-attribute) is added to the Workflow Execution.
  The value is the Action's timestamp.
- The `TemporalScheduledById` Search Attribute is added to the Workflow Execution.
  The value is the Schedule Id.

### Spec

The Schedule Spec defines when the Action should be taken.
Unless many Schedules have Actions scheduled at the same time, Actions should generally start within 1 second of the specified time.
There are two kinds of Schedule Spec:

- A simple interval, like "every 30 minutes" (aligned to start at the Unix epoch, and optionally including a phase offset).
- A calendar-based expression, similar to the "cron expressions" supported by lots of software, including the older Temporal Cron feature.

These two kinds have multiple representations, depending on the interface or SDK you're using, but they all support the same features.

In the Temporal CLI, for example, an interval is specified as a string like `45m` to mean every 45 minutes, or `6h/5h` to mean every 6 hours but at the start of the fifth hour within each period.

In the Temporal CLI, a calendar expression can be specified as either a traditional cron string with five (or six or seven) positional fields, or as JSON with named fields:

```json
{
  "year": "2022",
  "month": "Jan,Apr,Jul,Oct",
  "dayOfMonth": "1,15",
  "hour": "11-14"
}
```

The following calendar JSON fields are available:

- `year`
- `month`
- `dayOfMonth`
- `dayOfWeek`
- `hour`
- `minute`
- `second`
- `comment`

Each field can contain a comma-separated list of ranges (or the `*` wildcard), and each range can include a slash followed by a skip value.
The `hour`, `minute`, and `second` fields default to `0` while the others default to `*`, so you can describe many useful specs with only a few fields.

For `month`, names of months may be used instead of integers (case-insensitive, abbreviations permitted).
For `dayOfWeek`, day-of-week names may be used.

The `comment` field is optional and can be used to include a free-form description of the intent of the calendar spec, useful for complicated specs.

No matter which form you supply, calendar and interval specs are converted to canonical representations.
What you see when you "describe" or "list" a Schedule might not look exactly like what you entered, but it has the same meaning.

Other Spec features:

**Multiple intervals/calendar expressions:** A Spec can have combinations of multiple intervals and/or calendar expressions to define a specific Schedule.

**Time bounds:** Provide an absolute start or end time (or both) with a Spec to ensure that no actions are taken before the start time or after the end time.

**Exclusions:** A Spec can contain exclusions in the form of zero or more calendar expressions.
This can be used to express scheduling like "each Monday at noon except for holidays".
You'll have to provide your own set of exclusions and include it in each schedule; there are no pre-defined sets.
(This feature isn't currently exposed in the Temporal CLI or the Temporal Web UI.)

**Jitter:** If given, a random offset between zero and the maximum jitter is added to each Action time (but bounded by the time until the next scheduled Action).

**Time zones:** By default, calendar-based expressions are interpreted in UTC.
Temporal recommends using UTC to avoid various surprising properties of time zones.
If you don't want to use UTC, you can provide the name of a time zone.
The time zone definition is loaded on the Temporal Server Worker Service from either disk or the fallback embedded in the binary.

For more operational control, embed the contents of the time zone database file in the Schedule Spec itself.
(Note: this isn't currently exposed in the Temporal CLI or the web UI.)

### Pause

A Schedule can be Paused.
When a Schedule is Paused, the Spec has no effect.
However, you can still force manual actions by using the [temporal schedule trigger](/cli/schedule#trigger) command.

To assist communication among developers and operators, a “notes” field can be updated on pause or resume to store an explanation for the current state.

### Backfill

A Schedule can be Backfilled.
When a Schedule is Backfilled, all the Actions that would have been taken over a specified time period are taken now (in parallel if the `AllowAll` [Overlap Policy](#overlap-policy) is used; sequentially if `BufferAll` is used).
You might use this to fill in runs from a time period when the Schedule was paused due to an external condition that's now resolved, or a period before the Schedule was created.

### Limit number of Actions

A Schedule can be limited to a certain number of scheduled Actions (that is, not trigger immediately).
After that it will act as if it were paused.

### Policies

A Schedule supports a set of Policies that enable customizing behavior.

#### Overlap Policy

The Overlap Policy controls what happens when it is time to start a Workflow Execution but a previously started Workflow Execution is still running.
The following options are available:

- `Skip`: **Default**.
  Nothing happens; the Workflow Execution is not started.
- `BufferOne`: Starts the Workflow Execution as soon as the current one completes.
  The buffer is limited to one.
  If another Workflow Execution is supposed to start, but one is already in the buffer, only the one in the buffer eventually starts.
- `BufferAll`: Allows an unlimited number of Workflows to buffer.
  They are started sequentially.
- `CancelOther`: Cancels the running Workflow Execution, and then starts the new one after the old one completes cancellation.
- `TerminateOther`: Terminates the running Workflow Execution and starts the new one immediately.
- `AllowAll` Starts any number of concurrent Workflow Executions.
  With this policy (and only this policy), more than one Workflow Execution, started by the Schedule, can run simultaneously.

#### Catchup Window

The Temporal Service might be down or unavailable at the time when a Schedule should take an Action.
When it comes back up, the Catchup Window controls which missed Actions should be taken at that point.
The default is one year, meaning Actions will be taken unless over one year late.
If your Actions are more time-sensitive, you can set the Catchup Window to a smaller value (minimum ten seconds), accepting that an outage longer than the window could lead to missed Actions.
(But you can always [Backfill](#backfill).)

#### Pause-on-failure

If this policy is set, a Workflow Execution started by a Schedule that ends with a failure or timeout (but not Cancellation or Termination) causes the Schedule to automatically pause.

Note that with the `AllowAll` Overlap Policy, this pause might not apply to the next Workflow Execution, because the next Workflow Execution might have started before the failed one finished.
It applies only to Workflow Executions that were scheduled to start after the failed one finished.

### Last completion result

A Workflow started by a Schedule can obtain the completion result from the most recent successful run.
(How you do this depends on the SDK you're using.)

For overlap policies that don't allow overlap, “the most recent successful run” is straightforward to define.
For the `AllowAll` policy, it refers to the run that completed most recently, at the time that the run in question is started.
Consider the following overlapping runs:

```
time -------------------------------------------->
 A     |----------------------|
 B               |-------|
 C                          |---------------|
 D                                |--------------T
```

If D asks for the last completion result at time T, it gets the result of A.
Not B, even though B started more recently, because A completed later.
And not C, even though C completed after A, because the result for D is captured when D is started, not when it's queried.

Failures and timeouts do not affect the last completion result.

:::note

When a Schedule triggers a Workflow that completes successfully and yields a result, the result from the initial Schedule execution can be accessed by the subsequent scheduled execution through `LastCompletionResult`.

Be aware that if, during the subsequent run, the Workflow employs the [Continue-As-New](/workflow-execution/continue-as-new) feature, `LastCompletionResult` won't be accessible for this new Workflow iteration.

It is important to note that the [status](/workflow-execution#workflow-execution-status) of the subsequent run is marked as `Continued-As-New` and not as `Completed`.

:::

:::caution

A scheduled Workflow Execution may complete with a result up to the maximum blob size (2 MiB by default).
However, due to internal limitations, results that are within 1 KiB of this limit cannot be passed to the next execution.
So, for example, a Workflow Execution that returns a result of size 2,096,640 bytes (which is above 2MiB - 1KiB limit)
will be allowed to compete successfully, but that value will not be available as a last completion result.
This limitation may be lifted in the future.

:::

### Last failure

A Workflow started by a Schedule can obtain the details of the failure of the most recent run that ended at the time when the Workflow in question was started. Unlike last completion result, a _successful_ run _does_ reset the last failure.

### Limitations

Internally, a Schedule is implemented as a Workflow.
If you're using Advanced Visibility (Elasticsearch), these Workflow Executions are hidden from normal views.
If you're using Standard Visibility, they are visible, though there's no need to interact with them directly.

---

## Temporal Workflow Definition

This pages covers the following:

- [What is a Workflow Definition?](/workflow-definition)
- [Determinism and constraints](#deterministic-constraints)
- [Handling code changes and non-deterministic behavior](#non-deterministic-change)
- [Intrinsic non-determinism logic](#intrinsic-nondeterministic-logic)
- [Versioning Workflow code and Patching](#workflow-versioning)
- [Handling unreliable Worker Processes](#unreliable-worker-processes)
- [What is a Workflow Type?](#workflow-type)

A Temporal Workflow defines the overall flow of the application.
Conceptually, a Workflow is a sequence of steps written in a general-purpose programming language.
With Temporal, those steps are defined by writing code, known as a Workflow Definition, and are carried out by running that code, which results in a Workflow Execution.

In day-to-day conversations, the term _Workflow_ might refer to [Workflow Type](#workflow-type), a [Workflow Definition](/workflow-definition), or a [Workflow Execution](/workflow-execution).
Temporal documentation aims to be explicit and differentiate between them.

## What is a Workflow Definition? {#workflow-definition}

A Workflow Definition is the code that defines the Workflow.
It is written with a programming language and corresponding Temporal SDK.
Depending on the programming language, it's typically implemented as a function or an object method and encompasses the end-to-end series of steps of a Temporal application.

Below are different ways to develop a basic Workflow Definition.

<Tabs groupId="basic-workflow-definition" queryString>
<TabItem value="go" label="Go">

**[Workflow Definition in Go](/develop/go/core-application#develop-workflows)**

```go
func YourBasicWorkflow(ctx workflow.Context) error {
    // ...
    return nil
}
```

</TabItem>
<TabItem value="java" label="Java">

**[Workflow Definition in Java (Interface)](/develop/java/core-application#develop-workflows)**

```java
// Workflow interface
@WorkflowInterface
public interface YourBasicWorkflow {

    @WorkflowMethod
    String workflowMethod(Arguments args);
}
```

**[Workflow Definition in Java (Implementation)](/develop/java/core-application#develop-workflows)**

```java
// Workflow implementation
public class YourBasicWorkflowImpl implements YourBasicWorkflow {
    // ...
}
```

</TabItem>
<TabItem value="php" label="PHP">

**[Workflow Definition in PHP (Interface)](/develop/php/core-application#develop-workflows)**

```php
#[WorkflowInterface]
interface YourBasicWorkflow {
    #[WorkflowMethod]
    public function workflowMethod(Arguments args);
}
```

**[Workflow Definition in PHP (Implementation)](/develop/php/core-application#develop-workflows)**

```php
class YourBasicWorkflowImpl implements YourBasicWorkflow {
    // ...
}
```

</TabItem>
<TabItem value="python" label="Python">

**[Workflow Definition in Python](/develop/python/core-application#develop-workflows)**

```Python
@workflow.defn
class YourWorkflow:
    @workflow.run
    async def YourBasicWorkflow(self, input: str) -> str:
        # ...
```

</TabItem>
<TabItem value="typescript" label="Typescript">

**[Workflow Definition in Typescript](/develop/typescript/core-application#develop-workflows)**

```Typescript
type BasicWorkflowArgs = {
  param: string;
};

export async function WorkflowExample(
  args: BasicWorkflowArgs,
): Promise<{ result: string }> {
  // ...
}
```

</TabItem>
<TabItem value="dotnet" label=".NET">

**[Workflow Definition in C# and .NET](/develop/dotnet/core-application#develop-workflow)**

```csharp
[Workflow]
public class YourBasicWorkflow {

    [WorkflowRun]
    public async Task<string> workflowExample(string param) {
        // ...
    }
}
```

</TabItem>

</Tabs>

A Workflow Definition may be also referred to as a Workflow Function.
In Temporal's documentation, a Workflow Definition refers to the source for the instance of a Workflow Execution, while a Workflow Function refers to the source for the instance of a Workflow Function Execution.

A Workflow Execution effectively executes once to completion, while a Workflow Function Execution occurs many times during the life of a Workflow Execution.

We strongly recommend that you write a Workflow Definition in a language that has a corresponding Temporal SDK.

### Deterministic constraints {#deterministic-constraints}

A critical aspect of developing Workflow Definitions is ensuring that they are deterministic.
Generally speaking, this means you must take care to ensure that any time your Workflow code is executed it makes the same Workflow API calls in the same sequence, given the same input.
Some changes to those API calls are safe to make.

For example, you can change:

- The input parameters, return values, and execution timeouts of Child Workflows and Activities
  - However, it is not safe to change the types or IDs of Child Workflows or Activities
- The input parameters used to Signal an external Workflow
- The duration of Timers (although changing them to 0 is not safe in all SDKs)
- Add or remove calls to Workflow APIs that don't produce [Commands](/workflow-execution#command) (For example - `workflow.GetInfo` in the Go SDK or its equivalent in other SDKs)

The following Workflow API calls all can produce Commands, and thus must not be reordered, added, or removed without proper [Versioning techniques](#workflow-versioning):

- Starting or cancelling a Timer
- Scheduling or cancelling Activity Executions (including local Activities)
- Starting or cancelling Child Workflow executions
- Signalling or cancelling signals to external Workflow Executions
- Scheduling or cancelling Nexus operations
- Ending the Workflow Execution in any way (completing, failing, cancelling, or continuing-as-new)
- `Patched` or `GetVersion` calls for Versioning (although they may be added or removed according to the [patching](#workflow-patching) rules)
- Upserting Workflow Search Attributes
- Upserting Workflow Memos
- Running a `SideEffect` or `MutableSideEffect`

For a complete reference, see the [Command reference](/references/commands).

More formally, the use of certain Workflow APIs in the function is what generates Commands.
Commands tell the Temporal Service which Events to create and add to the Workflow Execution's [Event History](/workflow-execution/event#event-history).
When the Workflow's code [replays](/workflow-execution#replay), the Commands that are emitted are compared with the existing Event History.
If a corresponding Event already exists within the Event History that matches that command, then the Execution progresses.
See [Event History](/encyclopedia/event-history/) for a detailed walkthrough of the process.

For example, using an SDK's "Execute Activity" API generates the [ScheduleActivityTask](/references/commands#scheduleactivitytask) Command.
When this API is called upon re-execution, that Command is compared with the Event that is in the same location within the sequence.
The Event in the sequence must be an [ActivityTaskScheduled](/references/events#activitytaskscheduled) Event, where the Activity name is the same as what is in the Command.

If a generated Command doesn't match what it needs to in the existing Event History, then the Workflow Execution returns a _non-deterministic_ error.

The following are the two reasons why a Command might be generated out of sequence or the wrong Command might be generated altogether:

1. Code changes are made to a Workflow Definition that is in use by a running Workflow Execution.
2. There is intrinsic non-deterministic logic (such as inline random branching).

### Code changes can cause non-deterministic behavior {#non-deterministic-change}

The Workflow Definition can change in very limited ways once there is a Workflow Execution depending on it.
To alleviate non-deterministic issues that arise from code changes, we recommend using [Workflow Versioning](#workflow-versioning).

For example, let's say we have a Workflow Definition that defines the following sequence:

1. Start and wait on a Timer/sleep.
2. Spawn and wait on an Activity Execution.
3. Complete.

We start a Worker and spawn a Workflow Execution that uses that Workflow Definition.
The Worker would emit the [StartTimer](/references/commands#starttimer) Command and the Workflow Execution would become suspended.

Before the Timer is up, we change the Workflow Definition to the following sequence:

1. Spawn and wait on an Activity Execution.
2. Start and wait on a Timer/sleep.
3. Complete.

When the Timer fires, the next Workflow Task will cause the Workflow Function to re-execute.
The first Command the Worker sees would be ScheduleActivityTask Command, which wouldn't match up to the expected [TimerStarted](/references/events#timerstarted) Event.

The Workflow Execution would fail and return a nondeterminism error.

The following are examples of minor changes that would not result in non-determinism errors when re-executing a History which already contain the Events:

- Changing the duration of a Timer, with the following exceptions:
  - In Java, Python, and Go, changing a Timer's duration from or to 0 is a non-deterministic behavior.
  - In .NET, changing a Timer's duration from or to -1 (which means "infinite") is a non-deterministic behavior.
- Changing the arguments to:
  - The Activity Options in a call to spawn an Activity Execution (local or nonlocal).
  - The Child Workflow Options in a call to spawn a Child Workflow Execution.
  - Call to Signal an External Workflow Execution.
- Adding a Signal Handler for a Signal Type that has not been sent to this Workflow Execution.

### Intrinsic non-deterministic logic {#intrinsic-nondeterministic-logic}

Intrinsic non-determinism is when a Workflow Function Execution might emit a different sequence of Commands on re-execution, regardless of whether all the input parameters are the same.

For example, a Workflow Definition can not have inline logic that branches (emits a different Command sequence) based off a local time setting or a random number.
In the representative pseudocode below, the `local_clock()` function returns the local time, rather than Temporal-defined time:

```text
fn your_workflow() {
  if local_clock().is_before("12pm") {
    await workflow.sleep(duration_until("12pm"))
  } else {
    await your_afternoon_activity()
  }
}
```

Each Temporal SDK offers APIs that enable Workflow Definitions to have logic that gets and uses time, random numbers, and data from unreliable resources.
When those APIs are used, the results are stored as part of the Event History, which means that a re-executed Workflow Function will issue the same sequence of Commands, even if there is branching involved.

In other words, all operations that do not purely mutate the Workflow Execution's state should occur through a Temporal SDK API.

### Versioning Workflows {#workflow-versioning}

The Temporal Platform requires that Workflow code (Workflow Definitions) be deterministic in nature.
This requirement means that developers should consider how they plan to handle changes to Workflow code over time.

A versioning strategy is even more important if your Workflow Executions live long enough to run on multiple versions of your Worker. Temporal Platform provides Workflow Versioning APIs.

Temporal offers two Versioning strategies:

- [Versioning with patching](#workflow-patching): make sure your code changes are compatible across versions of your Workflow.
- [Worker Versioning](#worker-versioning): keep Workers tied to specific code revisions, so that old Workers can run old code paths and new Workers can run new code paths. (Note: If you were using this method experimentally prior to 2025, refer to the [Worker Versioning Legacy](/encyclopedia/worker-versioning-legacy) docs, but note that these are planned for deprecation.)

You can use either strategy, or a combination.

#### Versioning with Patching {#workflow-patching}

When keeping Workflows compatible, you should learn how to patch and ideally how to test your running Workflows will be safe to run on a new code version.

To patch:

- [How to patch Workflow code in Go](/develop/go/versioning#patching)
- [How to patch Workflow code in Java](/develop/java/versioning#patching)
- [How to patch Workflow code in Python](/develop/python/versioning#patching)
- [How to patch Workflow code in PHP](/develop/php/versioning#php-sdk-patching-api)
- [How to patch Workflow code in TypeScript](/develop/typescript/versioning#patching)
- [How to patch Workflow code in .NET](/develop/dotnet/versioning#patching)

To test, see [Safe Deployments](/develop/safe-deployments.mdx).

#### Worker Versioning {#worker-versioning}

To learn more about Worker Versioning, see our [Worker Versioning](production-deployment/worker-deployments/worker-versioning) page.

### Handling unreliable Worker Processes {#unreliable-worker-processes}

You do not handle Worker Process failure or restarts in a Workflow Definition.

Workflow Function Executions are completely oblivious to the Worker Process in terms of failures or downtime.
The Temporal Platform ensures that the state of a Workflow Execution is recovered and progress resumes if there is an outage of either Worker Processes or the Temporal Service itself.
The only reason a Workflow Execution might fail is due to the code throwing an error or exception, not because of underlying infrastructure outages.

### What is a Workflow Type? {#workflow-type}

A Workflow Type is a name that maps to a Workflow Definition.

- A single Workflow Type can be instantiated as multiple Workflow Executions.
- A Workflow Type is scoped by a Task Queue.
  It is acceptable to have the same Workflow Type name map to different Workflow Definitions if they are using completely different Workers.

<CaptionedImage
    src="/diagrams/workflow-type-cardinality.svg"
    title="Workflow Type cardinality with Workflow Definitions and Workflow Executions" />

---

## Continue-As-New

This page discusses [Continue-As-New](#continue-as-new) and how to decide [when to use it](#when).

## What is Continue-As-New? {#continue-as-new}

Continue-As-New allows you to checkpoint your Workflow's state and start a fresh Workflow.

There are two main reasons you might want to start a new Workflow:

- A Workflow Execution with a long, or large [Event History](/workflow-execution/event#event-history), such as one calling many Activities, may bog down and have performance issues.
  It could even generate more Events than allowed by the [Event History limits](/workflow-execution/event#event-history-limits).
- A Workflow Execution can hit [Workflow Versioning](/workflow-definition#workflow-versioning) problems if it started running on an older version of your code and then begins executing on a newer version.

Your goal is to create a new Workflow with a fresh history that picks up where your last one left off.
First, pass your latest relevant state into Continue-As-New.
This hands it to a new Execution in the [Execution Chain](/workflow-execution#workflow-execution-chain).
This state is passed in as arguments to your Workflow.
The parameters are typically optional and left unset by the original caller of the Workflow.

The new Workflow Execution has the same Workflow Id, but a different Run Id, and starts its own Event History.

You can repeat Continue-As-New as often as needed, which means that your Workflow can run forever.
Workflows that do this are often called Entity Workflows because they represent durable objects, not just processes.

- [How to Continue-As-New using the Go SDK](/develop/go/continue-as-new#how)
- [How to Continue-As-New using the Java SDK](/develop/java/continue-as-new)
- [How to Continue-As-New using the PHP SDK](/develop/php/continue-as-new)
- [How to Continue-As-New using the Python SDK](/develop/python/continue-as-new#how)
- [How to Continue-As-New using the TypeScript SDK](/develop/typescript/continue-as-new)
- [How to Continue-As-New using the .NET SDK](/develop/dotnet/continue-as-new)

## When in your Workflow is it right to Continue-As-New? {#when}

Temporal will tell your Workflow when it's approaching performance or scalability problems.
Find out if it's time by checking Continue-As-New Suggested in your Workflow at spots in your implementation where you are ready to checkpoint your state.

To prevent long-running Workflows from running on stale versions of code, you may also want to Continue-as-New periodically, depending on how often you deploy. This makes sure you're running only a couple of versions, which avoids some backwards compatibility problems.

- [Determine when to Continue-As-New using the Go SDK](/develop/go/continue-as-new#when)
- [Determine when to Continue-As-New using the Java SDK](/develop/java/continue-as-new)
- [Determine when to Continue-As-New using the PHP SDK](/develop/php/continue-as-new)
- [Determine when to Continue-As-New using the Python SDK](/develop/python/continue-as-new#when)
- [Determine when to Continue-As-New using the TypeScript SDK](/develop/typescript/continue-as-new)
- [Determine when to Continue-As-New using the .NET SDK](/develop/dotnet/continue-as-new)

---

## Events and Event History

This page discusses the following:

- [Events](#event)
- [Activity Events](#activity-events)
- [Event History](#event-history)
- [Event Loop](#event-loop)
- [Time Constraints](#time-constraints)
- [Reset](#reset)
- [Side Effect](#side-effect)

The Temporal Service tracks the progress of each Workflow Execution by appending information about Events, such as when the Workflow Execution began or ended, to the Event History associated with that execution.
This information not only enables developers to know what took place, but is also essential for providing Durable Execution, since it enables the Workflow Execution to recover from a crash and continue making progress.
In order to maintain high performance, the Temporal Service places limits on both the number and size of items in the Event History for each Workflow Execution.

## What is an Event? {#event}

Events are created by the Temporal Service in response to external occurrences and Commands generated by a Workflow Execution.
Each Event corresponds to an `enum` that is defined in the [Server API](https://github.com/temporalio/api/blob/master/temporal/api/enums/v1/event_type.proto).

All Events are recorded in the [Event History](#event-history).

A list of all possible Events that could appear in a Workflow Execution Event History is provided in the [Event reference](/references/events).

### Activity Events {#activity-events}

Seven Activity-related Events are added to Event History at various points in an Activity Execution:

- After a [Workflow Task Execution](/tasks#activity-task-execution) reaches a line of code that starts/executes an Activity, the Worker sends the Activity Type and arguments to the Temporal Service, and the Temporal Service adds an [ActivityTaskScheduled](/references/events#activitytaskscheduled) Event to Event History.
- When `ActivityTaskScheduled` is added to History, the Temporal Service adds a corresponding Activity Task to the Task Queue.
- A Worker polling that Task Queue picks up the Activity Task and runs the Activity function or method.
- If the Activity function returns, the Worker reports completion to the Temporal Service, and the Temporal Service adds [ActivityTaskStarted](/references/events#activitytaskstarted) and [ActivityTaskCompleted](/references/events#activitytaskcompleted) to Event History.
- If the Activity function throws a [non-retryable Failure](/references/failures#non-retryable), the Temporal Service adds [ActivityTaskStarted](/references/events#activitytaskstarted) and [ActivityTaskFailed](/references/events#activitytaskfailed) to Event History.
- If the Activity function throws an error or retryable Failure, the Temporal Service schedules an Activity Task retry to be added to the Task Queue (unless you’ve reached the Maximum Attempts value of the [Retry Policy](/encyclopedia/retry-policies), in which case the Temporal Service adds [ActivityTaskStarted](/references/events#activitytaskstarted) and [ActivityTaskFailed](/references/events#activitytaskfailed) to Event History).
- If the Activity’s [Start-to-Close Timeout](/encyclopedia/detecting-activity-failures#start-to-close-timeout) passes before the Activity function returns or throws, the Temporal Service schedules a retry.
- If the Activity’s [Schedule-to-Close Timeout](/encyclopedia/detecting-activity-failures#schedule-to-close-timeout) passes before Activity Execution is complete, or if [Schedule-to-Start Timeout](/encyclopedia/detecting-activity-failures#schedule-to-start-timeout) passes before a Worker gets the Activity Task, the Temporal Service writes [ActivityTaskTimedOut](/references/events#activitytasktimedout) to Event History.
- If the Activity is [canceled](/activity-execution#cancellation), the Temporal Service writes [ActivityTaskCancelRequested](/references/events#activitytaskcancelrequested) to Event History, and if the Activity accepts cancellation, the Temporal Service writes [ActivityTaskCanceled](/references/events#activitytaskcanceled).

:::note

While the Activity is running and retrying, [ActivityTaskScheduled](/references/events#activitytaskscheduled) is the only Activity-related Event in History: [ActivityTaskStarted](/references/events#activitytaskstarted) is written along with a terminal Event like [ActivityTaskCompleted](/references/events#activitytaskcompleted) or [ActivityTaskFailed](/references/events#activitytaskfailed).

:::

### What is an Event History? {#event-history}

An append-only log of [Events](#event) for your application.

- Event History is durably persisted by the Temporal service, enabling seamless recovery of your application state from crashes or failures.
- It also serves as an audit log for debugging.

### Event History limits {#event-history-limits}

The Temporal Service stores the complete Event History for the entire lifecycle of a Workflow Execution.

The Temporal Service logs a [warning after 10,240 Events](/workflow-execution/limits) and periodically logs additional warnings as new Events are added.

The Workflow Execution is terminated when the Event History:

- exceeds 51,200 Events.
- contains more than 2000 Updates.
- contains more than 10000 Signals.

To avoid hitting these limits, you can use the [Continue-As-New](/workflow-execution/continue-as-new) feature to close the current Workflow Execution and create a new one.

### Event loop {#event-loop}

A Workflow Execution is made up of a sequence of [Events](#event) called an [Event History](#event-history).
Events are created by the Temporal Service in response to either Commands or actions requested by a Temporal Client (such as a request to spawn a Workflow Execution).

<CaptionedImage
    src="/diagrams/workflow-execution-swim-lane-01.svg"
    title="Workflow Execution" />

## Time constraints {#time-constraints}

**Is there a limit to how long Workflows can run?**

No, there is no time constraint on how long a Workflow Execution can run.

However, if your Workflow will perform many actions, or will receive many messages, it can run into [Event History limits](#event-history-limits).

It can also hit [Workflow Versioning](/workflow-definition#workflow-versioning) and other backwards incompatibility problems.

For these reasons, it can be a good idea to [Continue-As-New](/workflow-execution/continue-as-new) periodically.

## What is a Reset? {#reset}

A Reset terminates a [Workflow Execution](/workflow-execution) and creates a new Workflow Execution with the same [Workflow Type](/workflow-definition#workflow-type) and [Workflow ID](/workflow-execution/workflowid-runid).
The [Event History](/workflow-execution/event#event-history) is copied from the original execution up to and including the reset point.
The new execution continues from the reset point.
Signals in the original history can be optionally copied to the new history, whether they appear after the reset point or not.

## What is a Side Effect? {#side-effect}

:::note

Side Effects are included in the Go, Java, and PHP SDKs.
They are not included in other SDKs.
[Local Activities](/local-activity) fit the same use case and are slightly less resource intensive.

:::

A Side Effect is a way to execute a short, non-deterministic code snippet, such as generating a UUID, that executes the provided function once and records its result into the Workflow Execution Event History.

A Side Effect does not re-execute upon replay, but instead returns the recorded result.

Do not ever have a Side Effect that could fail, because failure could result in the Side Effect function executing more than once.
If there is any chance that the code provided to the Side Effect could fail, use an Activity.

---

## Workflow Execution Limits

This page discusses [Workflow Execution limits](#workflow-execution-limits), [Workflow Execution Callback limits](#workflow-execution-callback-limits), and [Nexus Operation limits](#workflow-execution-nexus-operation-limits).

## Limits {#workflow-execution-limits}

There is no limit to the number of concurrent Workflow Executions, albeit you must abide by the Workflow Execution's Event History limit.

:::caution

As a precautionary measure, the Workflow Execution's Event History is limited to [51,200 Events](https://github.com/temporalio/temporal/blob/e3496b1c51bfaaae8142b78e4032cc791de8a76f/service/history/configs/config.go#L382) or [50 MB](https://github.com/temporalio/temporal/blob/e3496b1c51bfaaae8142b78e4032cc791de8a76f/service/history/configs/config.go#L380) and will warn you after 10,240 Events or 10 MB.

:::

There is also a limit to the number of certain types of incomplete operations.

Each in-progress Activity generates a metadata entry in the Workflow Execution's mutable state.
Too many entries in a single Workflow Execution's mutable state causes unstable persistence.
To protect the system, Temporal enforces a maximum number of incomplete Activities, Child Workflows, Signals, or Cancellation requests per Workflow Execution (by default, 2,000 for each type of operation).
Once the limit is reached for a type of operation, if the Workflow Execution attempts to start another operation of that type (by producing a `ScheduleActivityTask`, `StartChildWorkflowExecution`, `SignalExternalWorkflowExecution`, or `RequestCancelExternalWorkflowExecution` Command), it will be unable to (the Workflow Task Execution will fail and get retried).

These limits are set with the following [dynamic configuration keys](https://github.com/temporalio/temporal/blob/main/service/history/configs/config.go):

- `NumPendingActivitiesLimit`
- `NumPendingChildExecutionsLimit`
- `NumPendingSignalsLimit`
- `NumPendingCancelRequestsLimit`

## Workflow Execution Callback limits {#workflow-execution-callback-limits}

There is a limit to the total number of Workflow Callbacks that may be attached to a single Workflow Execution (by default, 32 Workflow Callbacks).
Attaching [multiple Nexus callers to a handler Workflow](/nexus/operations#attaching-multiple-nexus-callers) may exceed these limits.

These limits can be set with the following [dynamic configuration keys](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go#L924):

- MaxCallbacksPerWorkflow

## Workflow Execution Nexus Operation Limits {#workflow-execution-nexus-operation-limits}

There is a limit to the maximum number of Nexus Operations in a Workflow before Continue-As-New is required.
Each in-progress Nexus Operation generates a metadata entry in the Workflow Execution's mutable state.
Too many entries in a single Workflow Execution's mutable state causes unstable persistence.
To protect the system, Temporal enforces a maximum number of incomplete Nexus Operation requests per Workflow Execution (by default, 30 Nexus Operations).
Once the limit is reached for a type of operation, if the Workflow Execution attempts to start another Nexus operation (by producing a ScheduleNexusOperation), it will be unable to do so (the Workflow Task Execution will fail and get retried).

These limits are set with the following [dynamic configuration keys](https://github.com/temporalio/temporal/blob/de7c8879e103be666a7b067cc1b247f0ac63c25c/components/nexusoperations/config.go#L38):

- MaxConcurrentOperations

---

## Timers and Start Delays

This page discusses [Timer](#timer) and [Start Delay](#delay-workflow-execution).

## What is a Timer? {#timer}

Temporal SDKs offer Timer APIs so that Workflow Executions are deterministic in their handling of time values.

Timers in Temporal are persisted, meaning that even if your Worker or Temporal Service is down when the time period completes, as soon as your Worker and Temporal Service become available, the call that is awaiting the Timer in your Workflow code will resolve, causing execution to proceed.
Timers are reliable and efficient.
Workers consume no additional resources while waiting for a Timer to fire, so a single Worker can await millions of Timers concurrently.

- [How to set Timers in Go](/develop/go/timers)
- [How to set Timers in Java](/develop/java/timers)
- [How to set Timers in PHP](/develop/php/timers)
- [How to set Timers in Python](/develop/python/timers)
- [How to set Timers in TypeScript](/develop/typescript/timers)
- [How to set Timers in .NET](/develop/dotnet/durable-timers)

The duration of a Timer is fixed, and your Workflow might specify a value as short as one second or as long as several years.
Although it's possible to specify an extremely precise duration, such as 36 milliseconds or 15.072 minutes, your Workflows should not rely on sub-second accuracy for Timers.
We recommend that you consider the duration as a minimum time, one which will be rounded up slightly due to the latency involved with scheduling and firing the Timer.
For example, setting a Timer for 11.97 seconds is guaranteed to delay execution for at least that long, but will likely be closer to 12 seconds in practice.

## What is a Start Delay? {#delay-workflow-execution}

:::tip COMPATIBILITY

Start Delay Workflow Execution is incompatible with both [Schedules](/schedule) and [Cron Jobs](/cron-job).

:::

Start Delay determines the amount of time to wait before initiating a Workflow Execution.
This is useful if you have a Workflow you want to schedule out in the future, but only want it to execute once: in comparison to reoccurring Workflows using Schedules.

If the Workflow receives a Signal-With-Start during the delay, it dispatches a Workflow Task and the remaining delay is bypassed.
If the Workflow receives a Signal during the delay that is not a Signal-With-Start, the Signal does not interrupt the delay, and the Workflow continues to be delayed until the delay expires or a Signal-With-Start is received.

You can delay the dispatch of the initial Workflow Execution by setting this option in the Workflow Options field of your chosen SDK.
This delay only applies to the initial Workflow Execution and does not affect subsequent executions, such as when the Workflow Continues-as-New.

---

## Temporal Workflow Execution Overview

This page provides an overview of Workflow Execution:

- [What is a Workflow Execution?](#workflow-execution)
- [Replay](#replay)
- [Commands and awaitables](#commands-awaitables)
- [What is a Command?](#command)
- [Checking Workflow Execution Status](#workflow-execution-status)
- [Workflow Execution Chain](#workflow-execution-chain)
- [Memo](#memo)
- [State Transition](#state-transition)

## What is a Workflow Execution? {#workflow-execution}

While the Workflow Definition is the code that defines the Workflow, the Workflow Execution is created by executing that code.
A Temporal Workflow Execution is a durable, reliable, and scalable function execution.
It is the main unit of execution of a [Temporal Application](/temporal#temporal-application).

- [How to start a Workflow Execution using temporal](/cli/workflow#start)
- [How to start a Workflow Execution using the Go SDK](/develop/go/temporal-client#start-workflow-execution)
- [How to start a Workflow Execution using the Java SDK](/develop/java/temporal-client#start-workflow-execution)
- [How to start a Workflow Execution using the PHP SDK](/develop/php/temporal-client#start-workflow-execution)
- [How to start a Workflow Execution using the Python SDK](/develop/python/temporal-client#start-workflow-execution)
- [How to start a Workflow Execution using the TypeScript SDK](/develop/typescript/temporal-client#start-workflow-execution)
- [How to start a Workflow Execution using the .NET SDK](/develop/dotnet/temporal-client#start-workflow)

Each Temporal Workflow Execution has exclusive access to its local state.
It executes concurrently to all other Workflow Executions, and communicates with other Workflow Executions through [Signals](/sending-messages#sending-signals) and the environment through [Activities](/activities).
While a single Workflow Execution has limits on size and throughput, a Temporal Application can consist of millions to billions of Workflow Executions.

**Durability**

Durability is the absence of an imposed time limit.

A Workflow Execution is durable because it executes a Temporal Workflow Definition (also called a Temporal Workflow Function), your application code, effectively once and to completion—whether your code executes for seconds or years.

**Reliability**

Reliability is responsiveness in the presence of failure.

A Workflow Execution is reliable, because it is fully recoverable after a failure.
The Temporal Platform ensures the state of the Workflow Execution persists in the face of failures and outages and resumes execution from the latest state.

**Scalability**

Scalability is responsiveness in the presence of load.

A single Workflow Execution is limited in size and throughput but is scalable because it can [Continue-As-New](/workflow-execution/continue-as-new) in response to load.
A Temporal Application is scalable because the Temporal Platform is capable of supporting millions to billions of Workflow Executions executing concurrently, which is realized by the design and nature of the [Temporal Service](/temporal-service) and [Worker Processes](/workers#worker-process).

### Replays {#replay}

A Replay is the method by which a Workflow Execution resumes making progress. During a Replay the Commands that are generated are checked against an existing Event History. Replays are necessary and often happen to give the effect that Workflow Executions are resumable, reliable, and durable.

For more information, see [Deterministic constraints](/workflow-definition#deterministic-constraints).

If a failure occurs, the Workflow Execution picks up where the last recorded event occurred in the Event History.

- [How to use Replay APIs using the Go SDK](/develop/go/testing-suite#replay)
- [How to use Replay APIs using the Java SDK](/develop/java/testing-suite#replay)
- [How to use Replay APIs using the Python SDK](/develop/python/testing-suite#replay)
- [How to use Replay APIs using the TypeScript SDK](/develop/typescript/testing-suite#replay)
- [How to use Replay APIs using the .NET SDK](/develop/dotnet/testing-suite#replay)

### Commands and awaitables {#commands-awaitables}

A Workflow Execution does two things:

1. Issue [Commands](#command).
2. Wait on an Awaitables (often called Futures).

<CaptionedImage
    src="/diagrams/workflow-execution-progession-simple.svg"
    title="Command generation and waiting" />

Commands are issued and Awaitables are provided by the use of Workflow APIs in the [Workflow Definition](/workflow-definition).

Commands are generated whenever the Workflow Function is executed.
The Worker Process supervises the Command generation and makes sure that it maps to the current Event History.
(For more information, see [Deterministic constraints](/workflow-definition#deterministic-constraints).)
The Worker Process batches the Commands and then suspends progress to send the Commands to the Temporal Service whenever the Workflow Function reaches a place where it can no longer progress without a result from an Awaitable.

A Workflow Execution may only ever block progress on an Awaitable that is provided through a Temporal SDK API.
Awaitables are provided when using APIs for the following:

- Awaiting: Progress can block using explicit "Await" APIs.
- Requesting cancellation of another Workflow Execution: Progress can block on confirmation that the other Workflow Execution is cancelled.
- Sending a [Signal](/sending-messages#sending-signals): Progress can block on confirmation that the Signal sent.
- Spawning a [Child Workflow Execution](/child-workflows): Progress can block on confirmation that the Child Workflow Execution started, and on the result of the Child Workflow Execution.
- Spawning an [Activity Execution](/activity-execution): Progress can block on the result of the Activity Execution.
- Starting a Timer: Progress can block until the Timer fires.

### What is a Command? {#command}

A Command is a requested action issued by a [Worker](/workers#worker) to the [Temporal Service](/temporal-service) after a [Workflow Task Execution](/tasks#workflow-task-execution) completes.

The action that the Temporal Service takes is recorded in the [Workflow Execution's](#workflow-execution) [Event History](/workflow-execution/event#event-history) as an [Event](/workflow-execution/event).
The Workflow Execution can await on some of the Events that come as a result from some of the Commands.

Commands are generated by the use of Workflow APIs in your code. During a Workflow Task Execution there may be several Commands that are generated.
The Commands are batched and sent to the Temporal Service as part of the Workflow Task Execution completion request, after the Workflow Task has progressed as far as it can with the Workflow function.
There will always be [WorkflowTaskStarted](/references/events#workflowtaskstarted) and [WorkflowTaskCompleted](/references/events#workflowtaskcompleted) Events in the Event History when there is a Workflow Task Execution completion request.

<CaptionedImage
    src="/diagrams/commands.svg"
    title="Commands are generated by the use of Workflow APIs in your code" />

Commands are described in the [Command reference](/references/commands) and are defined in the [Temporal gRPC API](https://github.com/temporalio/api/blob/master/temporal/api/command/v1/message.proto).

### Status {#workflow-execution-status}

A Workflow Execution can be either _Open_ or _Closed_.

<CaptionedImage
    src="/diagrams/workflow-execution-statuses.svg"
    title="Workflow Execution statuses" />

#### Open

An _Open_ status means that the Workflow Execution is able to make progress.

- Running: The only Open status for a Workflow Execution.
  When the Workflow Execution is Running, it is either actively progressing or is waiting on something.

#### Closed

A _Closed_ status means that the Workflow Execution cannot make further progress because of one of the following reasons:

- Cancelled: The Workflow Execution successfully handled a cancellation request.
- Completed: The Workflow Execution has completed successfully.
- Continued-As-New: The Workflow Execution [Continued-As-New](/workflow-execution/continue-as-new).
- Failed: The Workflow Execution returned an error and failed.
- Terminated: The Workflow Execution was terminated.
- Timed Out: The Workflow Execution reached a timeout limit.

### Workflow Execution Chain {#workflow-execution-chain}

A Workflow Execution Chain is a sequence of Workflow Executions that share the same Workflow Id.
Each link in the Chain is often called a Workflow Run.
Each Workflow Run in the sequence is connected by one of the following:

- [Continue-As-New](/workflow-execution/continue-as-new)
- [Retries](/encyclopedia/retry-policies)
- [Temporal Cron Job](/cron-job)

A Workflow Execution is uniquely identified by its [Namespace](/namespaces), [Workflow Id](/workflow-execution/workflowid-runid#workflow-id), and [Run Id](/workflow-execution/workflowid-runid#run-id).

The [Workflow Execution Timeout](/encyclopedia/detecting-workflow-failures#workflow-execution-timeout) applies to a Workflow Execution Chain.
The [Workflow Run Timeout](/encyclopedia/detecting-workflow-failures#workflow-run-timeout) applies to a single Workflow Execution (Workflow Run).

## What is a Memo? {#memo}

A Memo is a non-indexed set of Workflow Execution metadata that developers supply at start time or in Workflow code and that is returned when you describe or list Workflow Executions.

The primary purpose of using a Memo is to enhance the organization and management of Workflow Executions.
Add your own metadata, such as notes or descriptions, to a Workflow Execution, which lets you annotate and categorize Workflow Executions based on developer-defined criteria.
This feature is particularly useful when dealing with numerous Workflow Executions because it facilitates the addition of context, reminders, or any other relevant information that aids in understanding or tracking the Workflow Execution.

:::note Use Memos judiciously

Memos shouldn't store data that's critical to the execution of a Workflow, for some of the following reasons:

- Unlike Workflow inputs, Memos lack type safety
- Memos are subject to eventual consistency and may not be immediately available
- Excessive reliance on Memos hides mutable state from the Workflow Execution History

:::

## What is a State Transition? {#state-transition}

A State Transition is a unit of progress made by a [Workflow Execution](#workflow-execution).
Each State Transition is recorded in a persistence store.

Some operations, such as [Activity Heartbeats](/encyclopedia/detecting-activity-failures#activity-heartbeat), require only one or two State Transitions each. With an Activity Heartbeat, there are two: the Activity Heartbeat and a Timer.

Most operations require multiple State Transitions.

For example, a simple Workflow with two sequential [Activity Tasks](/tasks#activity-task) (and no retries) produces 11 State Transitions: two for Workflow start, four for each Activity, and one for Workflow completion.

:::tip NEXT STEPS
For more information on Workflow Execution, please refer to the following subpages:

- [Event](/workflow-execution/event)
- [Workflow Id and Run Id](/workflow-execution/workflowid-runid)
- [Limits](/workflow-execution/limits)
- [Continue-as-New](/workflow-execution/continue-as-new)
- [Timers and Start Delay](/workflow-execution/timers-delays)
  :::

---

## Workflow Id and Run Id

This page discusses the following:

- [Run Id](#run-id)
- [Operations leading to non-determinism](#run-id-non-determinism)
- [Workflow Id](#workflow-id)
- [Workflow Id Reuse Policy](#workflow-id-reuse-policy)
- [Workflow Id Conflict Policy](#workflow-id-conflict-policy)

Each Workflow Execution is associated with a user-defined [Workflow ID](#workflow-id), a value which typically carries some business meaning (such as an order number or customer number).
Temporal guarantees that there can be at most one Workflow Execution with a given ID running at any point in time, a constraint that helps to protect against unexpected duplication.
In some cases, such as when running the same Workflow at recurring intervals using the Schedules features, there can be multiple "runs" of a single Workflow Execution over a period of time.
In this case, all runs will have the same Workflow ID.
However, each run will have a unique system-generated [Run ID](#run-id).

## What is a Run Id? {#run-id}

A Run Id is a globally unique, platform-level identifier for a [Workflow Execution](/workflow-execution).

The current Run Id is mutable and can change during a [Workflow Retry](/encyclopedia/retry-policies). You shouldn't rely on storing the current Run Id, or using it for any logical choices, because a Workflow Retry changes the Run Id and can lead to non-determinism issues.

Temporal guarantees that only one Workflow Execution with a given [Workflow Id](#workflow-id) can be in an Open state at any given time.
But when a Workflow Execution reaches a Closed state, it is possible to have another Workflow Execution in an Open state with the same Workflow Id.
For example, a Temporal Cron Job is a chain of Workflow Executions that all have the same Workflow Id.
Each Workflow Execution within the chain is considered a _Run_.

A Run Id uniquely identifies a Workflow Execution even if it shares a Workflow Id with other Workflow Executions.

### Which operations lead to non-determinism issues?{#run-id-non-determinism}

An operation like `ContinueAsNew`, `Retry`, `Cron`, and `Reset` creates a [Workflow Execution Chain](/workflow-execution#workflow-execution-chain) as identified by the [`first_execution_run_id`](https://github.com/temporalio/api/blob/master/temporal/api/history/v1/message.proto).

Each operation creates a new Workflow Execution inside a chain run and saves its information as `first_execution_run_id`.
Thus, the Run Id is updated during each operation on a Workflow Execution.

- The `first_execution_run_id` is the Run Id of the first Workflow Execution in a Chain run.
- The `original_execution_run_id` is the Run Id when the `WorkflowExecutionStarted` Event occurs.

A Workflow `Reset` changes the first execution Run Id, but preserves the original execution Run Id.
For example, when a new Workflow Execution in the chain starts, it stores its Run Id in `original_execution_run_id`.
A reset doesn't change that field, but the current Run Id is updated.

:::caution

Because of this behavior, you shouldn't rely on the current Run Id in your code to make logical choices.

:::

**Learn more**

For more information, see the following link.

- [`message.proto`](https://github.com/temporalio/api/blob/master/temporal/api/history/v1/message.proto#L75-L82)

## What is a Workflow Id? {#workflow-id}

A Workflow Id is a customizable, application-level identifier for a [Workflow Execution](/workflow-execution) that is unique to an Open Workflow Execution within a [Namespace](/namespaces).

- [How to set a Workflow Id](/develop/go/temporal-client#workflow-id)

A Workflow Id is meant to be a business-process identifier, such as customer identifier or order identifier.

The Temporal Platform guarantees uniqueness of the Workflow Id within a [Namespace](/namespaces) based on the Workflow Id Reuse Policy.

A [Workflow Id Reuse Policy](#workflow-id-reuse-policy) can be used to manage whether a Workflow Id from a Closed Workflow can be re-used.

A [Workflow Id Conflict Policy](#workflow-id-conflict-policy) can be used to decide how to resolve a Workflow Id conflict with a Running Workflow.

A Workflow Execution can be uniquely identified across all Namespaces by its [Namespace](/namespaces), Workflow Id, and [Run Id](#run-id).

### What is a Workflow Id Reuse Policy? {#workflow-id-reuse-policy}

A Workflow Id Reuse Policy determines whether a Workflow Execution is allowed to spawn with a particular Workflow Id, if that Workflow Id has been used with a previous, and now Closed, Workflow Execution.

It is not possible for a new Workflow Execution to spawn with the same Workflow Id as another Open Workflow Execution, regardless of the Workflow Id Reuse Policy.

See [Workflow Id Conflict Policy](#workflow-id-conflict-policy) for resolving a Workflow Id conflict.

The Workflow Id Reuse Policy can have one of the following values:

- **Allow Duplicate:** The Workflow Execution is allowed to exist regardless of the Closed status of a previous Workflow Execution with the same Workflow Id.
  **This is the default policy, if one is not specified.**
  Use this when it is OK to have a Workflow Execution with the same Workflow Id as a previous, but now Closed, Workflow Execution.
- **Allow Duplicate Failed Only:** The Workflow Execution is allowed to exist only if a previous Workflow Execution with the same Workflow Id does not have a Completed status.
  Use this policy when there is a need to re-execute a Failed, Timed Out, Terminated, or Cancelled Workflow Execution and guarantee that the Completed Workflow Execution will not be re-executed.
- **Reject Duplicate:** The Workflow Execution cannot exist if a previous Workflow Execution has the same Workflow Id, regardless of the Closed status.
  Use this when there can only be one Workflow Execution per Workflow Id within a Namespace for the given retention period.
- **Terminate if Running:** Specifies that if a Workflow Execution with the same Workflow Id is already running, it should be terminated and a new Workflow Execution with the same Workflow Id should be started. This policy allows for only one Workflow Execution with a specific Workflow Id to be running at any given time.

The first three values (Allow Duplicate, Allow Duplicate Failed Only, and Reject Duplicate) of the Workflow Id Reuse Policy apply to Closed Workflow Executions that are retained within the Namespace.
For example, given a default Retention Period, the Temporal Service can only check the Workflow Id of the spawning Workflow Execution based on the Workflow Id Reuse Policy against the Closed Workflow Executions for the last _30 days_.

If you need to start a Workflow for a particular implementation only if it hasn't started yet, ensure that your Retention Period is long enough to check against.
If this becomes unwieldy, consider using [Workflow message passing](/encyclopedia/workflow-message-passing) instead of trying to start Workflows atomically.

The fourth value of the Workflow Id Reuse Policy, Terminate if Running, only applies to a Workflow Execution that is currently open within the Namespace.
For Terminate if Running, the Retention Period is not a consideration for this policy.

If there is an attempt to spawn a Workflow Execution with a Workflow Id Reuse Policy that won't allow it, the Server will prevent the Workflow Execution from spawning.

### What is a Workflow Id Conflict Policy? {#workflow-id-conflict-policy}

A Workflow Id Conflict Policy determines how to resolve a conflict when spawning a new Workflow Execution with a particular Workflow Id used by an existing Open Workflow Execution.
See [Workflow Id Reuse Policy](#workflow-id-reuse-policy) for managing the reuse of a Workflow Id of a Closed Workflow.

By default, this results in a `Workflow execution already started` error.

:::note

The default [StartWorkflowOptions](https://pkg.go.dev/go.temporal.io/sdk/internal#StartWorkflowOptions) behavior in the Go SDK is to not return an error when a new Workflow Execution is attempted with the same Workflow Id as an Open Workflow Execution.
Instead, it returns a WorkflowRun instance representing the current or last run of the Open Workflow Execution.

To return the `Workflow execution already started` error, set `WorkflowExecutionErrorWhenAlreadyStarted` to `true`.

:::

The Workflow Id Conflict Policy can have one of the following values:

- **Fail:** Prevents the Workflow Execution from spawning and returns a `Workflow execution already started` error.
  **This is the default policy, if one isn't specified.**
- **Use Existing:** Prevents the Workflow Execution from spawning and returns a successful response with the Open Workflow Execution's Run Id.
- **Terminate Existing:** Terminates the Open Workflow Execution then spawns the new Workflow Execution with the same Workflow Id.

---

## Temporal Workflow

This guide provides a comprehensive overview of Temporal Workflows and covers the following:

- [Workflow Definition](/workflow-definition)
- [Workflow Execution](/workflow-execution)
- [Schedules](/schedule)
- [Dynamic Handler](/dynamic-handler)
- [Cron Job](/cron-job)

## Intro to Workflows

Conceptually, a workflow defines a sequence of steps.
With Temporal, those steps are defined by writing code, known as a Workflow Definition, and are carried out by running that code, which results in a Workflow Execution.

In day-to-day conversations, the term Workflow might refer to Workflow Type, a Workflow Definition, or a Workflow Execution.

1. A **Workflow Definition** is the code that defines your Workflow.
2. The **Workflow Type** is the name that maps to a Workflow Definition.
   It's an identifier that makes it possible to distinguish one type of Workflow (such as order processing) from another (such as customer onboarding).
3. A **Workflow Execution** is a running Workflow, which is created by combining a Workflow Definition with a request to execute it.
   You can execute a Workflow Definition any number of times, potentially providing different input each time (i.e., a Workflow Definition for order processing might process order #123 in one execution and order #567 in another execution).
   It is the actual instance of the Workflow Definition running in the Temporal Platform.

You'll develop those Workflows by writing code in a general-purpose programming language such as Go, Java, TypeScript, or Python.
The code you write is the same code that will be executed at runtime, so you can use your favorite tools and libraries to develop Temporal Workflows.

Temporal Workflows are resilient.
They can run—and keeping running—for years, even if the underlying infrastructure fails.
If the application itself crashes, Temporal will automatically recreate its pre-failure state so it can continue right where it left off.

Each Workflow Execution progresses through a series of **Commands** and **Events**, which are recorded in an **Event History**.

Workflows must follow deterministic constraints to ensure consistent replay behavior.

---

## Handling Signals, Queries, & Updates

When Signals, Updates, and Queries arrive at your Workflow, the handlers for these messages will operate on the current state of your Workflow and can use the fields you have set.
In this section, we’ll give you an overview of how messages work with Temporal and cover how to write correct and robust handlers by covering topics like atomicity, guaranteeing completion before the Workflow exits, exceptions, and idempotency.

## Handling Messages {#handling-messages}

### Message handler concurrency {#message-handler-concurrency}

If your Workflow receives messages, you may need to consider how those messages interact with one another or with the main Workflow method.
Behind the scenes, Temporal is running a loop that looks like this:

<CaptionedImage
    src="/img/info/messages-workflow-loop.png"
    title="Diagram that shows the execution ordering of Workflows" />

Every time the Workflow wakes up--generally, it wakes up when it needs to--it will process messages in the order they were received, followed by making progress in the Workflow’s main method.

This execution is on a single thread–while this means you don’t have to worry about parallelism, you do need to worry about concurrency if you have written Signal and Update handlers that can block. These can run interleaved with the main Workflow and with one another, resulting in potential race conditions. These methods should be made reentrant.

#### Initializing the Workflow first {#workflow-initializers}

Initialize your Workflow's state before handling messages.
This prevents your handler from reading uninitialized instance variables.

To see why, refer to the [diagram](#message-handler-concurrency).
It shows that your Workflow processes messages before the first run of your Workflow's main method.

The message handler runs first in several scenarios, such as:

- When using [Signal-with-Start](/sending-messages#signal-with-start).
- When your Worker experiences delays, such as when the Task Queue it polls gets backlogged.
- When messages arrive immediately after a Workflow continues as new but before it resumes.

For all languages except Go and TypeScript, use your constructor to set up state.
Annotate your constructor as a Workflow Initializer and take the same arguments as your Workflow's main method.

Note that you can't make blocking calls from your constructor.
If you need to block, make your Signal or Update handler [wait](#waiting) for an initialization flag.

In Go and TypeScript, register any message handlers only after completing initialization.

### Message handler patterns {#message-handler-patterns}

Here are several common patterns for write operations, Signal and Update handlers. They don't apply to pure read operations, i.e. Queries or [Update Validators](/handling-messages#update-validators):

- Returning immediately from a handler
- Waiting for the Workflow to be ready to process them
- Kicking off activities and other asynchronous tasks
- Injecting work into the main Workflow
- Finishing handlers before the Workflow completes
- Ensuring your messages are processed exactly once

#### Synchronous handlers

Synchronous handlers don’t kick off any long-running operations or otherwise block. They're guaranteed to run atomically.

#### Waiting {#waiting}

A Signal or Update handler can block waiting for the Workflow to reach a certain state using a Wait Condition. See the links below to find out how to use this with your SDK.

#### Running asynchronous tasks

Sometimes, you need your message handler to wait for long-running operations such as executing an Activity. When this happens, the handler will yield control back to [the loop](#message-handler-concurrency). This means that your handlers can have race conditions if you’re not careful.
You can guard your handlers with concurrency primitives like mutexes or semaphores, but you should use versions of these primitives provided for Workflows in most languages. See the links below for examples of how to use them in your SDK.

#### Inject work into the main Workflow {#injecting-work-into-main-workflow}

Sometimes you want to process work provided by messages in the main Workflow. Perhaps you’d like to accumulate several messages before acting on any of them. For example, message handlers might put work into a queue, which can then be picked up and processed in an event loop that you yourself write.
This option is considered advanced but offers powerful flexibility. And if you serialize the handling of your messages inside your main Workflow, you can avoid using concurrency primitives like mutexes and semaphores. See the links above for how to do this in your SDK.

#### Finishing handlers before the Workflow completes {#finishing-message-handlers}

You should generally finish running all handlers before the Workflow run completes or continues as new. For some Workflows, this means you should explicitly check to make sure that all the handlers have completed before finishing. You can await a condition called All Handlers Finished at the end of your Workflow.

If you don’t need to ensure that your handlers complete, you may specify your handler’s Handler Unfinished Policy as Abandon to turn off the warnings. However, note that clients waiting for Updates will get Not Found errors if they're waiting for Updates that never complete before the Workflow run completes.

See the links below for how to ensure handlers are finished in your SDK.

#### Ensuring your messages are processed exactly once {#exactly-once-message-processing}

Many developers want their message handlers to run exactly once--to be idempotent--in cases where the same Signal or Update is delivered twice or sent by two different call sites. Temporal deduplicates messages for you on the server, but there is one important case when you need to think about this yourself when authoring a Workflow, and one when sending Signals and Updates.

When your workflow Continues-As-New, you should handle deduplication yourself in your message handler. This is because Temporal's built-in deduplication doesn't work across [Continue-As-New](/workflow-execution/continue-as-new) boundaries, meaning you would risk processing messages twice for such Workflows if you don't check for duplicate messages yourself.

To deduplicate in your message handler, you can use an idempotency key.

Clients can provide an idempotency key. This can be important because Temporal's SDKs provide a randomized key by default, which means Temporal only deduplicates retries from the same call. For Updates, if you craft an Update ID, Temporal will deduplicate any calls that use that key. This is useful when you have two different callsites that may send the same Update, or when your client itself may get retried. For Signals, you can provide a key as part of your Signal arguments.

Inside your message handler, you can check your idempotency key--the Update ID or the one you provided to the Signal--to check whether the Workflow has already handled the update.

See the links below for examples of solving this in your SDK.

#### Authoring message handler patterns

See examples of the above patterns.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/dotnet/message-passing" text="Author message handler patterns in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/go/message-passing#message-handler-patterns" text="Author message handler patterns in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing" text="Author message handler patterns in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing" text="Author message handler patterns in PHP" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#message-handler-patterns" text="Author message handler patterns in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#message-handler-patterns" text="Author message handler patterns in TypeScript" archetype="feature-guide" />
</RelatedReadContainer>

### Update Validators {#update-validators}

When you define an Update handler, you may optionally define an Update Validator: a read operation that's responsible for accepting or rejecting the Update. You can use Validators to verify arguments or make sure the Workflow is ready to accept your Updates.

- If it accepts, the Update will become part of your Workflow’s history and the client will be notified that the operation has been Accepted. The Update handler will then run until it returns a value.
- If it rejects, the client will be informed that it was Rejected, and the Workflow will have no indication that it was ever requested, similar to a Query handler.

:::note

Like Queries, Validators are not allowed to block.

:::

Once the Update handler is finished and has returned a value, the operation is considered Completed.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#updates" text="Validate updates in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#updates" text="Validate updates in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#updates" text="Validate updates in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#updates" text="Validate updates in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#updates" text="Validate updates in TypeScript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-updates" text="Validate updates in PHP" archetype="feature-guide" />
</RelatedReadContainer>

### Exceptions in message handlers {#exceptions}

When throwing an exception in a message handler, you should decide whether to make it an [Application Failure](/references/failures#application-failure). The implications are different between Signals and Updates.

:::caution
The following content applies in every SDK except the Go SDK. See below.
:::

#### Exceptions in Signals

In Signal handlers, throw [Application Failures](/references/failures#application-failure) only for unrecoverable errors, because the entire Workflow will fail.
Similarly, allowing a failing Activity or Child Workflow to exhaust its retries, so that it throws an [Activity Failure](https://docs.temporal.io/references/failures#activity-failure) or [Child Workflow Failure](https://docs.temporal.io/references/failures#child-workflow-failure) will cause the entire Workflow to fail.
Note that for Activities, this will only happen if you change the default Activity [Retry Policy](https://docs.temporal.io/encyclopedia/retry-policies), since by default they retry forever.
If you throw any other exception, by default, it will cause a [Workflow Task Failure](/references/failures#workflow-task-failures). This means the Workflow will get stuck and will retry the handler periodically until the exception is fixed, for example by a code change.

#### Exceptions in Updates

Doing any of the following will fail the Update and cause the client to receive the error:

- Reject the Update by throwing any exception from your [Validator](https://docs.temporal.io/handling-messages#update-validators).
- Allow a failing Activity or Child Workflow to exhaust its retries, so that it throws an [Activity Failure](https://docs.temporal.io/references/failures#activity-failure) or [Child Workflow Failure](https://docs.temporal.io/references/failures#child-workflow-failure). Note that for Activities, this will only happen if you change the default Activity [Retry Policy](https://docs.temporal.io/encyclopedia/retry-policies), since by default they retry forever.
- Throw an [Application Failure](/references/failures#application-failure) from your Update handler.

Unlike with Signals, the Workflow will keep going in these cases.

If you throw any other exception, by default, it will cause a [Workflow Task Failure](/references/failures#workflow-task-failures). This means the Workflow will get stuck and will retry the handler periodically until the exception is fixed, for example by a code change or infrastructure coming back online. Note that this will cause a delay for clients waiting for an Update result.

#### Errors and panics in message handlers in the Go SDK

In Go, returning an error behaves like an [Application Failure](/references/failures#application-failure) in the other SDKs. Panics behave like non-Application Failure exceptions in other languages, in that they cause a [Workflow Task Failure](/references/failures#workflow-task-failures).

### Writing Signal Handlers {#writing-signal-handlers}

Use these links to see a simple Signal handler.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#signals" text="Handle Signals in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#signals" text="Handle Signals in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#signals" text="Handle Signals in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#signals" text="Handle Signals in TypeScript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#signals" text="Handle Signals in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-signal" text="Handle Signals in PHP" archetype="feature-guide" />
</RelatedReadContainer>

### Writing Update Handlers {#writing-update-handlers}

Use these links to see a simple update handler.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#updates" text="Handle Updates in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#updates" text="Handle Updates in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#updates" text="Handle Updates in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#updates" text="Handle Updates in TypeScript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#updates" text="Handle Updates in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-updates" text="Handle Updates in PHP" archetype="feature-guide" />
</RelatedReadContainer>

### Writing Query Handlers {#writing-query-handlers}

Author queries using these per-language guides.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#queries" text="Handle Queries in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#queries" text="Handle Queries in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#queries" text="Handle Queries in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#queries" text="Handle Queries in TypeScript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#queries" text="Handle Queries in .NET" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#handle-query" text="Handle Queries in PHP" archetype="feature-guide" />
</RelatedReadContainer>

---

## Sending Signals, Queries, & Updates

This section will help you write clients that send messages to Workflows which includes:

- [Sending Signals](#sending-signals)
- [Sending Updates](#sending-updates)
- [Sending Queries](#sending-queries)

### Sending Signals {#sending-signals}

You can send Signals from any Temporal Client, the Temporal CLI, or you can Signal one Workflow to another.

You can also Signal-With-Start to lazily initialize a Workflow while sending a Signal.

#### Send a Signal from a Temporal Client or the CLI

<RelatedReadContainer>
    <RelatedReadItem path="/cli/workflow#signal" text="Send a Signal using the Temporal CLI" archetype="feature-guide" />
    <RelatedReadItem path="/develop/go/message-passing#send-signal-from-client" text="Send Signals with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-signal-from-client" text="Send Signals with the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-signal-from-client" text="Send Signals with the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-signal-from-client" text="Send Signals with the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-signal-from-client" text="Send Signals with the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-signal-from-client" text="Send Signals with the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

#### Send a Signal from one Workflow to another

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-signal-from-workflow" text="Send Signals from Workflows with the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

#### Signal-With-Start {#signal-with-start}

Signal-With-Start is a great tool for lazily initializing Workflows. When you send this operation, if there is a running Workflow Execution with the given Workflow Id, it will be Signaled. Otherwise, a new Workflow Execution starts and is immediately sent the Signal.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#signal-with-start" text="Signal-With-Start using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#signal-with-start" text="Signal-With-Start using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#signal-with-start" text="Signal-With-Start using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#signal-with-start" text="Signal-With-Start using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#signal-with-start" text="Signal-With-Start using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#signal-with-start" text="Signal-With-Start using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

### Sending Updates {#sending-updates}

:::note

To use the Workflow Update feature in versions prior to v1.25.0, it must be manually enabled.

Set the [frontend.enableUpdateWorkflowExecution](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go) and [frontend.enableUpdateWorkflowExecutionAsyncAccepted](https://github.com/temporalio/temporal/blob/main/common/dynamicconfig/constants.go) dynamic config values to `true`.

For example, with the Temporal CLI, run these commands:

```command
temporal server start-dev --dynamic-config-value frontend.enableUpdateWorkflowExecution=true
temporal server start-dev --dynamic-config-value frontend.enableUpdateWorkflowExecutionAsyncAccepted=true
```

:::

Updates can be sent from a Temporal Client or the Temporal CLI to a Workflow Execution. This call is synchronous and will call into the corresponding Update handler. If you’d rather make an asynchronous request, you should use Signals.

In most languages (except Go), you may call `executeUpdate` to complete an Update and get its result.

Alternatively, to start an Update, you may call `startUpdate` and pass in the Workflow Update Stage as an argument. You have two choices on what to await:

- Accepted - wait until the Worker is contacted, which ensures that the Update is persisted. See [Update Validators](/handling-messages#update-validators) for more information.
- Completed - wait until the handler finishes and returns a result. (This is equivalent to `executeUpdate`.)

The start call will give you a handle you can use to track the Update, determine whether it was Accepted, and ultimately get its result or an error.

If you want to send an Update to another Workflow such as a Child Workflow from within a Workflow, you should do so within an Activity and use the Temporal Client as normal.

There are limits on the total number of Updates that may occur during a Workflow Execution run, and also on the number of concurrent in-progress Updates that a Workflow Execution may have.
Use [Update Validators](/handling-messages#update-validators) and [Update IDs](/handling-messages#exactly-once-message-processing) to stay within the system limits in both [Cloud](/cloud/limits#per-workflow-execution-update-limits) and [Self-Hosted](/self-hosted-guide/defaults).

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#send-update-from-client" text="Send Updates in Go" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-update-from-client" text="Send Updates in Java" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-update-from-client" text="Send Updates in PHP" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-update-from-client" text="Send Updates in Python" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-update-from-client" text="Send Updates in TypeScript" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-update-from-client" text="Send Updates in .NET" archetype="feature-guide" />
</RelatedReadContainer>

#### Update-With-Start {#update-with-start}

:::tip

For open source server users, Temporal Server version [Temporal Server version 1.28](https://github.com/temporalio/temporal/releases/tag/v1.28.0) is recommended.

:::

Update-with-Start sends an Update request, starting a Workflow if necessary.
A [`WorkflowIDConflictPolicy`](https://docs.temporal.io/workflow-execution/workflowid-runid#workflow-id-conflict-policy) must be specified.
Workflow ID and Update ID can be used as idempotency keys as follows:

- If the Workflow exists and you provided an Update ID, and the Update exists in the latest Workflow Run, then Update-With-Start attaches to the existing Update (regardless of `WorkflowIDConflictPolicy`)
  - If the Workflow is closed, it attaches only if the Update has completed.
- Otherwise it uses [`WorkflowIDConflictPolicy`](https://docs.temporal.io/workflow-execution/workflowid-runid#workflow-id-conflict-policy) and [`WorkflowIDReusePolicy`](https://docs.temporal.io/workflow-execution/workflowid-runid#workflow-id-reuse-policy) as usual to determine whether to start a Workflow, and then starts a new Update immediately.

Update-With-Start is great for latency-sensitive use cases:

- **Lazy Initialization** -
  Instead of making separate Start Workflow and Update Workflow calls, Update-With-Start allows you to send them together in a single roundtrip.
  For example, a shopping cart can be modeled using Update-With-Start.
  Updates let you add and remove items from the cart.
  Update-With-Start lets the customer start shopping, whether the cart already exists or they've just started shopping.
  It ensures the cart, modeled by a Workflow Execution, exists before applying any Update that changes the state of items within the cart.
  Set your `WorkflowIDConflictPolicy` to `USE_EXISTING` for this pattern.
- **Early Return** -
  Using Update-With-Start you can begin a new Workflow Execution and synchronously receive a response, while the Workflow Execution continues to run to completion.
  For example, you might model a payment process using Update-With-Start.
  This allows you to send the payment validation results back to the client synchronously, while the transaction Workflow continues in the background.
  Set your `WorkflowIDConflictPolicy` to `FAIL` and use a unique Update ID for this pattern if you want to assert it does not reuse an existing Workflow.

:::caution

Unlike Signal-with-Start - Update-With-Start is _not_ atomic.
If the Update can't be delivered, for example, because there's no running Worker available, a new Workflow Execution will still start.
The SDKs will retry the Update-With-Start request, but there is no guarantee that the Update will succeed.

:::

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/message-passing#update-with-start" text="Update-With-Start with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#update-with-start" text="Update-With-Start with the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#update-with-start" text="Update-With-Start with the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#update-with-start" text="Update-With-Start with the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#update-with-start" text="Update-With-Start with the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#update-with-start" text="Update-With-Start with the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

### Sending Queries {#sending-queries}

Queries can be sent from a Temporal Client or the Temporal CLI to a Workflow Execution--even if this Workflow has Completed. This call is synchronous and will call into the corresponding Query handler.
You can also send a built-in "Stack Trace Query" for debugging.

<RelatedReadContainer>
    <RelatedReadItem path="/cli/workflow#query" text="Send a Query using the Temporal CLI" archetype="feature-guide" />
    <RelatedReadItem path="/develop/go/message-passing#send-query" text="Send a Query with the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/message-passing#send-query" text="Send a Query with the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/message-passing#send-query" text="Send a Query with the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/message-passing#send-query" text="Send a Query with the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/message-passing#send-query" text="Send a Query with the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/message-passing#send-query" text="Send a Query with the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

#### Stack Trace Query {#stack-trace-query}

In many SDKs, the Temporal Client exposes a predefined `__stack_trace` Query that returns the call stack of all the threads owned by that Workflow Execution.
This is a great way to troubleshoot a Workflow Execution in production.
For example, if a Workflow Execution has been stuck at a state for longer than an expected period of time, you can send a `__stack_trace` Query to return the current call stack.
The `__stack_trace` Query name does not require special handling in your Workflow code.

:::note

Stack Trace Queries are available only for running Workflow Executions.

:::

---

## Temporal Workflow message passing - Signals, Queries, & Updates

Workflows can be thought of as stateful web services that can receive messages.
The Workflow can have powerful message handlers akin to endpoints that react to the incoming messages in combination with the current state of the Workflow.
Temporal supports three types of messages: Signals, Queries, and Updates:

- Queries are read requests. They can read the current state of the Workflow but cannot block in doing so.
- Signals are asynchronous write requests. They cause changes in the running Workflow, but you cannot await any response or error.
- Updates are synchronous, tracked write requests. The sender of the Update can wait for a response on completion or an error on failure.

## How to choose between Signals, Updates, and Queries as a Workflow author? {#choosing-messages}

This section will help you write Workflows that receive messages.

### For write requests

Unlike Signals, Updates must be synchronous. That is, they must wait for the Worker running the Workflow to acknowledge the request.

Use Signals instead of Updates when:

- The Workflow's clients want to quickly move on after sending an asynchronous message.
- The clients are willing to "fire and forget": they don't want a result or exception from the message.
- The clients don't want to rely on the Worker being available.

Use Updates instead of Signals when:

- The Workflow's clients want to track the completion of the message.
- The clients need a result or an exception from your message without having to query subsequently.
- You’d like to “validate” the Update before accepting it into the Workflow and its history.
- The clients want a low-latency end-to-end operation and are willing to wait for it to finish or be validated.

### For read requests

You normally want to do a Query, because:

- Queries are efficient–they never add entries to the [Workflow Event History](/workflow-execution/event#event-history), whereas an Update would (if accepted).
- Queries can operate on completed Workflows.

However, because Queries cannot block, sometimes Updates are best.
When your goal is to do a read once the Workflow achieves a certain desired state, you have two options:

- You could poll periodically with Queries until the Workflow is ready.
- You could write your read operation as an Update, which will give you better efficiency and latency, though it will write an entry to the [Workflow Event History](/workflow-execution/event#event-history).

### For read/write requests

Use an Update for synchronous read/write requests. If your request must be asynchronous, consider sending a Signal followed by polling with a Query.

---

## Cloud automation - Temporal feature

Temporal Cloud Automation changes the way how you manage and scale your cloud infrastructure.
Its features enable you to automate critical tasks like user and namespace management, mTLS certificate rotation, and access control, ensuring security and operational efficiency.
Cloud Automation offers secure authentication across all interfaces, reducing errors and enhancing security.

**Key Features:**

- [Secure API Keys](https://docs.temporal.io/cloud/api-keys): Manage resources securely with Temporal Cloud API Keys.
- [Temporal Cloud CLI (tcld)](https://docs.temporal.io/cloud/tcld): Automate operations directly from the command line.
- [Terraform Provider for Cloud](https://docs.temporal.io/production-deployment/cloud/terraform-provider#prerequisites): Scale effortlessly with infrastructure-as-code.

<RelatedReadContainer>
  <RelatedReadItem path="https://docs.temporal.io/cloud/api-keys" text="API Keys documentation" archetype="cloud-guide" />
  <RelatedReadItem path="https://docs.temporal.io/ops?_gl=1*1yf937l*_gcl_au*MTg1MTAxMTEwNC4xNzEzOTcxMjYw*_ga*MTgwODU1MzQyNi4xNzA3NzA4ODIz*_ga_R90Q9SJD3D*MTcyMTI0MTAyNy41MjIuMS4xNzIxMjQ5NTYxLjAuMC4w" text="Cloud Ops API documentation" archetype="cloud-guide" />
  <RelatedReadItem path="/cloud/tcld" text="Temporal Cloud CLI" archetype="cloud-guide" />
  <RelatedReadItem path="/production-deployment/cloud/terraform-provider" text="Terraform Provider for Cloud" archetype="cloud-guide" />
</RelatedReadContainer>

From centralizing cloud operations and automating certificate rotation to streamlining user management and onboarding new teams, Temporal's Cloud Automation features covers a wide range of use cases that enhance efficiency and security across your organization.

---

## Temporal's production deployment features

Transform your Temporal applications into production-ready systems by deploying your application code, Workflows, Activities, and Workers for operational use.
When your application is ready to start serving production traffic, we offer two Temporal Service options:

- **[Choose Temporal Cloud for your Temporal Service](/cloud)**
  Let us handle the Temporal Service operations so you can focus on your applications.
- **[Self-host a Temporal Service](/self-hosted-guide)**
  Deploy your own production level Temporal Service to orchestrate your durable applications.

| Feature                            | Temporal Cloud                                                            | Self-hosted                                      |
| ---------------------------------- | ------------------------------------------------------------------------- | ------------------------------------------------ |
| **Multi-tenant**                   | ✅ Up to 100 Namespaces                                                   | ✅ Unlimited Namespaces                          |
| **High availability and failover** | ✅ [Namespaces with High Availability features](/cloud/high-availability) | ✅ Global Namespaces & Multi-Cluster Replication |
| **Application state persistence**  | ✅ 30-90 day Retention                                                    | ✅ Unlimited                                     |
| **Long term state retention**      | ✅ Workflow History Export                                                | ✅ Archival                                      |
| **Community support**              | ✅ Slack, Forum                                                           | ✅ Slack, Forum                                  |
| **Paid support**                   | ✅ Prioritized responses                                                  | ✖️                                                |

---

## Core application - Temporal feature

**Workflows**, **Activities**, and **Workers** form the core parts of a Temporal Application.

**Workflows**: A Workflow defines the overall flow of the application.
You write it in your programming language of choice using the Temporal SDK.
Conceptually, a Workflow specifies a sequence of steps and orchestrates the execution of Activities.

**Activities**: An Activity is a method or function that encapsulates business logic prone to failure (e.g., calling a service that may go down).
The system can automatically retry these Activities upon some failures.
Activities perform a single, well-defined action, such as calling another service, transcoding a media file, or sending an email message.

**Workers**: A Worker executes your Workflow and Activity code.

**Follow one of our tutorials to [Get started](https://learn.temporal.io/getting_started/) learning how to develop Workflows and Activities and run them in Worker Processes.**

Or jump straight to a Temporal SDK feature guide:

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/core-application" text="Go SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/core-application" text="Java SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/core-application" text="PHP SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/core-application" text="Python SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/core-application#connect-to-a-dev-cluster" text="TypeScript SDK Core application feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/core-application" text=".NET SDK Core application feature guide" archetype="feature-guide" />
</RelatedReadContainer>

For a deep dive into Temporal Workflows, Activities, and Workers, visit the following Temporal Encyclopedia pages or enroll in one of [our courses](https://learn.temporal.io/courses/).

- [Temporal Workflows](/workflows)
- [Temporal Activities](/activities)
- [Temporal Workers](/workers)

---

## Data encryption - Temporal feature

Data Converters in Temporal are SDK components that handle the serialization and encoding of data transmitted and received by a Temporal Client.
Workflow input and output need to be serialized and deserialized so they can be sent as JSON to the Temporal Service.

Temporal provides its own default Data Converter logic, which is not apparent to a user if payloads contain plain text or JSON data.
For enhanced security, you can implement your own encryption standards using a Codec Server.
Temporal's data encryption capabilities ensures the security and confidentiality of your Workflows and provides protection without compromising performance.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/converters-and-encryption" text="Data Encryption using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/converters-and-encryption" text="Data Encryption using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/converters-and-encryption" text="Data Encryption using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/converters-and-encryption" text="Data Encryption using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/converters-and-encryption" text="Data Encryption using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

---

## Debugging - Temporal feature

Temporal offers powerful and efficient debugging capabilities for both development and production. These capabilities help developers inspect and troubleshoot Workflows and Activities with precision, ensuring that Workflows perform as expected.

By leveraging detailed event histories and intuitive tooling, you can trace the execution path of Workflows, identify issues, and understand the state of your application at any given point in time.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/debugging" text="Debugging using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/debugging" text="Debugging using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/debugging" text="Debugging using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/debugging" text="Debugging using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/debugging" text="Debugging using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/debugging" text="Debugging using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

---

## Failure detection - Temporal feature

In Temporal, timeouts detect application failures.
The system can then automatically mitigate these failures through retries.
Both major application function primitives, **Workflows** and **Activities**, have dedicated **timeout configurations** and can be configured with a **Retry Policy**.

**Follow one of our tutorials to [Get started](https://learn.temporal.io/getting_started/) exploring timeouts and Retry Policies.**

Or jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/failure-detection#workflow-timeouts" text="Set Workflow timeouts and Retry Policies using the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the Go SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the Java SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the PHP SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the Python SDK" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/failure-detection#activity-timeouts" text="Set Activity timeouts and Retry Policies using the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

For a deep dive into timeouts and Retry Policies visit the following Temporal Encyclopedia pages or enroll in one of [our courses](https://learn.temporal.io/courses/).

<RelatedReadContainer>
    <RelatedReadItem path="/encyclopedia/detecting-workflow-failures" text="Detecting Workflow failures" archetype="encyclopedia" />
    <RelatedReadItem path="/encyclopedia/detecting-activity-failures" text="Detecting Activity failures" archetype="encyclopedia" />
    <RelatedReadItem path="/encyclopedia/retry-policies" text="Retry Policies" archetype="encyclopedia" />
</RelatedReadContainer>

---

## High availability - Temporal Cloud and Self Hosted production feature

Temporal offers high availability as a feature for both Temporal Cloud and self-hosted deployments. Multi-region Namespace ensures your applications remain operational even in the face of regional outages or service disruptions.

[Multi-region Namespaces for Temporal Cloud](/evaluate/development-production-features/multi-region-namespace): Temporal Cloud's Multi-region Namespaces offer automated failover, synchronized data replication, and high availability for workloads requiring disaster-tolerant deployment and 99.99% uptime.

<RelatedReadContainer>
    <RelatedReadItem path="/cloud/high-availability" text=" Namespaces with High Availability features for Temporal Cloud" archetype="encyclopedia" />
    <RelatedReadItem path="/global-namespace" text="Global Namespace for self-hosted deployments" archetype="encyclopedia" />
    <RelatedReadItem path="/cloud/pricing" text="Multi-region Pricing" archetype="encyclopedia" />
    <RelatedReadItem path="/cloud/high-availability/private-link" text="PrivateLink routing for Multi-region replication" archetype="encyclopedia" />
</RelatedReadContainer>

---

## Temporal development and production features

Through a Temporal SDK, Temporal provides a wide range of features that enable developers to build applications that serve a wide range of use cases.

- **[Core application primitives](/evaluate/development-production-features/core-application)**: Develop and run your application with Workflows, Activities, and Workers.
- **[Testing suite](/evaluate/development-production-features/testing-suite)**: Each Temporal SDK comes with a testing suite that enables developers to test their applications as they would any other.
- **[Scheduled Workflows](/evaluate/development-production-features/schedules)**: Start a business process at a specific time or on a given time interval.
- **[Interrupt a Workflow](/evaluate/development-production-features/interrupt-workflow)**: Cancel or terminate a business process (Workflow) that is already in progress and compensate for any steps already taken.
- **Runtime safeguards**: Prevent avoidable errors and issues from executing during runtime.
- **[Failure detection and mitigation](/evaluate/development-production-features/failure-detection)**: Detect failures with timeouts and configure automatic retries to mitigate them.
- **[Temporal Nexus](/evaluate/nexus)**: Connect Temporal Applications across (and within) isolated Namespaces for improved modularity, security, debugging, and fault isolation. Nexus supports cross-team, cross-domain, and multi-region use cases.
- **[Workflow message passing](/evaluate/development-production-features/workflow-message-passing)**: Build responsive applications that react to events at runtime and enable data retrieval from ongoing Workflows.
- **Versioning**: Support multiple versions of your business logic for long-running business processes.
- **[Observability](/evaluate/development-production-features/observability)**: List business process, view their state, and set up dashboards with metrics.
- **[Debugging](/evaluate/development-production-features/debugging)**: Surface errors and step through code to find issues.
- **[Data encryption](/evaluate/development-production-features/data-encryption)**: Transform data and protect the privacy of the users of your application.
- **[Throughput composability](/evaluate/development-production-features/throughput-composability)**: Breakup business processes by data streams, team ownership, or other organization factors.
- **[Cloud Automation](/evaluate/development-production-features/cloud-automation)**: Simplify cloud management and boost security with Temporal's Cloud Automation.
- **[Low Latency](/evaluate/development-production-features/low-latency)**: Making your applications faster, more performant, and more efficient.
- **[Multi-tenancy](/evaluate/development-production-features/multi-tenancy)**: Enhances efficiency and cost-effectiveness.

For detailed information on Temporal feature release stages and criteria, see this [Product Release Stages Guide](/evaluate/development-production-features/release-stages).

---

## Interrupt a Workflow - Cancellation and Termination

Discover how Temporal enables you to gracefully handle Workflow interruptions through cancellations and terminations.
Understand how to stop a Workflow cleanly with cancellation, allowing for proper cleanup and state management.

For situations where a Workflow is stuck, termination provides an immediate solution, ensuring your applications remain robust and responsive.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/cancellation" text="Handling Cancellation and Termination using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/cancellation" text="Handling Cancellation and Termination using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/cancellation" text="Handling Cancellation and Termination using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/cancellation" text="Handling Cancellation and Termination using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/cancellation" text="Handling Cancellation and Termination using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

---

## Low latency - Temporal feature

Temporal Cloud provides features that significantly reduce latency compared to self-hosted instances, making your applications faster, more performant, and more efficient.
In the world of modern applications, low latency is crucial for ensuring minimal delay in Workflow Executions.
This low-latency architecture ensures rapid Workflow Execution and responsiveness, critical for time-sensitive applications and high-performance systems.

Temporal Cloud's custom persistence layer incorporates three key components that contribute to low latency:

- **Better Sharding:** Distributes load across multiple databases, preventing bottlenecks.
  Enables independent resizing, improving scalability and handling high-traffic events without delay.
- **Write-Ahead Log (WAL):** Aggregates updates before writing to the database, reducing write latency.
  Stores writes in an append-only format, reducing latency and database size by batching updates before writing to the database.
- **Tiered Storage of Workflow Event History:** Offloads completed Workflow Event Histories, improving database efficiency.

Temporal Cloud provides lower latency, making it suitable for latency-sensitive, large-scale, or business-critical applications.

<RelatedReadContainer>
  <RelatedReadItem path="https://temporal.io/blog/exploring-temporal-cloud-automation-features" text="Exploring Temporal Cloud Automation Features" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/high-availability-and-disaster-recovery-with-temporal-cloud" text="High Availability and Disaster Recovery with Temporal Cloud" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/higher-throughput-and-lower-latency-temporal-clouds-custom-persistence-layer" text="Higher throughput and lower latency: Temporal Cloud’s custom persistence layer" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/how-to-migrate-your-self-hosted-service-to-temporal-cloud" text="How to Migrate Your Self-Hosted Service to Temporal Cloud" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/scaling-temporal-the-basics" text="Scaling your self-hosted instance" archetype="blog-post" />
  <RelatedReadItem path="https://temporal.io/blog/benchmarking-latency-temporal-cloud-vs-self-hosted-temporal" text="Benchmarking Latency: Temporal Cloud vs. Self-Hosted Temporal" archetype="blog-post" />
  <RelatedReadItem path="https://docs.temporal.io/cloud/service-availability#latency" text="Temporal Cloud’s Latency SLO" archetype="cloud-guide" />
  <RelatedReadItem path="https://www.youtube.com/watch?v=SQv9ot-jB6o&list=PLl9kRkvFJrlREHL7fiEKBWTp5QuFeYS2r&index=5" text="Replay Conference Talk: Custom Persistence Layer" archetype="replay-talk" />
</RelatedReadContainer>

---

## Multi-cloud Replication - Temporal Cloud production feature

Temporal Cloud offers disaster-tolerant deployment for workloads with stringent availability requirements.
With the multi-cloud feature enabled, Temporal Cloud automates [failover](/glossary#failover) and synchronizes data between Namespaces hosted on different cloud providers (either AWS or GCP).
This page introduces Temporal Cloud patterns that support your workload's availability requirements.

## Multi-cloud Replication

Multi-cloud Replication provides failover capabilities to mitigate service outages due to cloud provider failures.
It reduces risk and minimize operational disruption.
This feature seamlessly shif​​ts Workflow execution between cloud providers to maintain service availability.

Your Clients use a single logical Namespace with a single endpoint that operates on two separate cloud providers: one active and one standby.
As Workflows progress in the active provider, history events asynchronously replicate to the standby provider.
Data replication ensures both providers are in sync so the standby is ready to take over when needed.

Should an incident or outage occur in the active provider, Temporal Cloud initiates a "failover" to the standby provider.
During a failover, the roles of the active and standby providers reverse.
The standby takes over as the primary provider.

### Advantages of Multi-cloud Replication {#multi-region-advantages}

**Why choose Multi-cloud Replication (MCR)?**

- **Reduce Risk**:
  Protects your operations from unexpected cloud provider outages.
  Automated disaster recovery features ensure that workloads remain available and continue execution.
- **Minimize Operational Disruption**:
  Seamless failovers shift Workflow Executions to a secondary provider during outages.
  Maintains service availability without needing manual synchronization between Namespaces.
  Real-time alerts during failover events keep you informed.
- **No manual deployment or configuration needed:**
  Temporal Cloud simplifies deployment with push-button operation.
  This eliminates the need for manual deployment or configuration.
- **Fault tolerance**.
  Your open Workflows continue their progress in the standby region.
  This minimizes interruption and data loss during cloud provider failures.
- **No code changes**.
  Your Workers and Workflow starter code don't need updates to take advantage of multi-cloud setup or to respond to failover conditions.
  This allows for a smooth transition and continued operation.

### Service Level Objectives (SLO) and guarantees {#cloud-region-SLO}

**What reliability promises does this feature offer?**

- Temporal provides a 99.99% Contractual SLA that provides redress in the event of downtime ([SLA](https://docs.temporal.io/cloud/sla)).
- [RTO](https://csrc.nist.gov/glossary/term/recovery_time_objective): 20 minutes or less.
- [RPO](https://csrc.nist.gov/glossary/term/recovery_point_objective): Near zero.

### Target workloads {#target-workloads}

**Who benefits from this feature?**

Multi-cloud Namespaces are a great solution for Workloads where a regional cloud outage would cause:

- Revenue loss
- Poor customer experience
- Problems stemming from policy/legal requirements that demand high availability

Some examples: financial services, e-commerce, gaming, global SaaS platforms, bookings & reservations, delivery & shipping, order management.

### Explore {#explore-multi-cloud}

**Read more about our multi-cloud features**

- [Multi-cloud Namespaces](/cloud/high-availability/enable) offer High Availability service for Temporal Cloud customers who need the highest level of availability at all times.
- [Multi-cloud Pricing](/cloud/pricing) scales to use.
- Multi-cloud replication supports [PrivateLink routing](/cloud/high-availability/private-link).

### Explore {#explore-temporal-namespaces}

**Read more about Namespaces**

- [Temporal Cloud Namespaces](/cloud/namespaces) offer outstanding reliable service for Temporal Cloud customers.

---

## Multi-region Replication - Temporal Cloud production feature

Temporal Cloud offers disaster-tolerant deployment for workloads with stringent availability requirements.
With the multi-region feature enabled, Temporal Cloud automates [failover](/glossary#failover) and synchronizes data between Namespace regions.
This page introduces Temporal Cloud patterns that support your workload's availability requirements.

## Multi-region Replication

Multi-region Replication provides failover capabilities to mitigate service outages due to regional failures.
It reduces risk and minimize operational disruption.
This feature seamlessly shif​​ts Workflow execution between regions to maintain service availability.

Your Clients use a single logical Namespace with a single endpoint that operates in two physical regions: one active and one standby.
As Workflows progress in the active region, history events asynchronously replicate to the standby region.
Data replication ensures both regions are in sync so the standby is ready to take over when needed.

Should an incident or outage occur in the active region, Temporal Cloud initiates a "failover" to the standby region.
During a failover, the roles of the active and standby regions reverse.
The standby takes over as the primary region.

### Advantages of Multi-region Replication {#multi-region-advantages}

**Why choose a Multi-region Replication (MRR)?**

- **Reduce Risk**:
  MRR protects your operations from unexpected regional outages.
  Its automated disaster recovery features ensure that workloads remain available and continue execution.
- **Minimize Operational Disruption**:
  Seamless failovers shift Workflow Executions to a secondary region during outages.
  MRR maintains service availability without needing manual synchronization between Namespaces.
  Real-time alerts during failover events keep you informed.
- **No manual deployment or configuration needed:**
  Temporal Cloud simplifies deployment with push-button operation.
  This eliminates the need for manual deployment or configuration.
- **Fault tolerance**.
  Your open Workflows continue their progress in the standby region.
  This minimizes interruption and data loss during regional failures.
- **No code changes**.
  Your Workers and Workflow starter code don't need updates to take advantage of multi-region setup or to respond to failover conditions.
  This allows for a smooth transition and continued operation.

### Service Level Objectives (SLO) and guarantees {#multi-region-SLO}

**What reliability promises does this feature offer?**

- Temporal provides a 99.99% Contractual SLA that provides redress in the event of downtime ([SLA](https://docs.temporal.io/cloud/sla)).
- [RTO](https://csrc.nist.gov/glossary/term/recovery_time_objective): 20 minutes or less.
- [RPO](https://csrc.nist.gov/glossary/term/recovery_point_objective): Near zero.

### Target workloads {#target-workloads}

**Who benefits from this feature?**

Multi-region Replication is a great solution for Workloads where a regional cloud outage would cause:

- Revenue loss
- Poor customer experience
- Problems stemming from policy/legal requirements that demand high availability

Some examples: financial services, e-commerce, gaming, global SaaS platforms, bookings & reservations, delivery & shipping, order management.

### Explore {#explore-multi-region}

**Read more about our multi-region features**

- [Multi-region Replication](/cloud/high-availability/enable) offers High Availability service for Temporal Cloud customers who need the highest level of availability at all times.
- [Multi-region Pricing](/cloud/pricing) scales with use.
- Multi-region Replication supports [PrivateLink routing](/cloud/high-availability/private-link).

## Single-region Namespaces

A typical Temporal Cloud Namespace is deployed into one [AWS region](https://docs.temporal.io/cloud/service-availability), or GCP region.
Temporal Cloud provides [99.99% availability](https://docs.temporal.io/cloud/sla) and a contractual [service level agreement](https://docs.temporal.io/cloud/sla) (SLA) of 99.9% guarantee against service errors.
It provides a great all-around solution that's suitable for most organizations.

### Advantages of single-region Namespaces {#single-region-advantages}

**Why choose single-region Namespaces?**

- This option offers sufficient availability for most use cases and workloads.
- Temporal Cloud provides 99.99% availability and a contractual service level agreement of 99.9% guarantee against service errors.
  Read more on our [SLA page](https://docs.temporal.io/cloud/sla).

Some downsides of single-region Namespaces compared to Multi-region Replication:

- Stalled work during failures: Open Workflow Executions pause until the region/Namespace recovers.
- Blocked work initiation: No new Workflow Executions will start until the region/Namespace recovers.

### Explore {#explore-temporal-namespaces}

**Read more about Namespaces**

- [Temporal Cloud Namespaces](/cloud/namespaces) offer outstanding reliable service for Temporal Cloud customers.

---

## Multi-tenancy - Temporal feature

A Namespace is a unit of isolation within the Temporal Platform -- but even a single Namespace is still multi-tenant.
Multi-tenancy ensures extra capacity is available for all customers during traffic spikes.

However, multi-tenancy can also presents the challenge of "noisy neighbors", where high-traffic tenants consume excess resources, causing slower performance for other tenants.
This is a common problem for database scaling.

Temporal's write-heavy workload, where changes in execution state are constantly written to the persistence layer, demands a database that supports reliably high throughput with low latency for multiple customers, concurrently and fairly.

With Temporal Cloud, customers pay for consumption instead of entire sets of hardware, providing a cost-effective solution.
Temporal Cloud's architecture scales to handle multiple tenants efficiently.

<RelatedReadContainer>
  <RelatedReadItem path="https://docs.temporal.io/cloud/security#namespace-isolation" text="Namespace Isolation" archetype="cloud-guide" />
  <RelatedReadItem path="https://docs.temporal.io/cloud/pricing" text="Cost-effective Consumption" archetype="cloud-guide" />
</RelatedReadContainer>

---

## Observability - Temporal feature

Temporal's observability feature helps you track the state of your Workflows in real-time, providing tools for detailed metrics, tracing, comprehensive logging, and visibility into your application state.

Monitor performance, trace Activity and Workflow Executions, debug, and filter Workflow Executions to gain deeper insights into your Workflows.

**Key Components of Temporal's Observability and Visibility**

- **Metrics**: Detailed performance metrics to track the health and efficiency of your Temporal Service and Workflows.
- **Tracing**: End-to-end tracing of Workflow and Activity Executions to understand the flow and timing of operations.
- **Logging**: Comprehensive logging capabilities for debugging and auditing purposes.
- **Search Attributes**: Custom attributes that can be used to enhance searchability and provide additional context to Workflow Executions.
- **Web UI**: A user-friendly interface for visualizing and interacting with your Workflows and Temporal Service state.

**Benefits of Temporal's Observability and Visibility Features**

- **Real-time Monitoring**: Track the state and progress of your Workflows as they execute.
- **Performance Optimization**: Identify bottlenecks and optimize your Workflow and Activity implementations.
- **Effective Debugging**: Quickly locate and diagnose issues in your Temporal applications.
- **Compliance and Auditing**: Maintain detailed records of all Workflow executions for compliance and auditing purposes.
- **Operational Insights**: Gain a deep understanding of your application's behavior and usage patterns.
- **Scalability Management**: Monitor and manage the scalability of your Temporal Service effectively.

Jump straight into the Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/observability" text="Observability using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/observability" text="Observability using the .NET SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/observability" text="Observability using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/observability" text="Observability using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/observability" text="Observability using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/observability" text="Observability using the TypeScript SDK" archetype="feature-guide" />
</RelatedReadContainer>

---

## Temporal product release stages guide

:::tip CHANGELOG
To stay up-to-date with the latest feature changes, visit the [changelog](https://temporal.io/change-log).
:::

This Product Release Stages Guide provides an understanding of how Temporal features are released. It describes and lists the criteria for each release stage, so that you can make informed decisions about the adoption of each new feature.

Product Release Guide Expectations:

|                                 | Pre-release                                                        | Public Preview                                                                              | General Availability                             |
| ------------------------------- | ------------------------------------------------------------------ | ------------------------------------------------------------------------------------------- | ------------------------------------------------ |
| **Features access**             | Self-hosted Temporal users: Everyone; Temporal Cloud: Invite only. | Everyone. Temporal Cloud may limit the number of users being onboarded to ensure stability. | Everyone.                                        |
| **Feature completeness**        | Limited functionality.                                             | Core functionality is complete.                                                             | Mature and feature complete.                     |
| **API stability**               | Experimental; API is subject to change.                            | API breaking changes are kept to a minimum.                                                 | API is stable.                                   |
| **Feature region Availability** | Limited regions.                                                   | Most regions.                                                                               | All [regions](/cloud/regions).                   |
| **Feature support**             | Community and engineering team.                                    | [Formal support](/cloud/support#support-ticket).                                            | [Formal support](/cloud/support#support-ticket). |
| **Feature recommended usage**   | Experimental.                                                      | Production use cases.                                                                       | Production usage.                                |
| **Feature Cloud pricing**       | No additional cost.                                                | Pricing changes are kept to a minimum.                                                      | Pricing is stable.                               |
| **Feature Interoperability**    | Limited.                                                           | Features are compatible with each other, unless otherwise stated.                           | Features are compatible with each other.         |

## Pre-release {#pre-release}

**Access:** Most Pre-release features are released in the open source Temporal software and are publicly available.
However, some features which are explicit to hosting Temporal Services, such as [API Keys](/cloud/api-keys), may be specific to Temporal Cloud.

In Temporal Cloud, Pre-release features are invite-only: Temporal will work directly with a group of existing Temporal Cloud customers to be part of testing of each Pre-release feature.
These customers are invited to provide feedback to the Temporal team.

**Classification:** New features in Pre-release may not be fully mature and may have bugs.
Users acknowledge and agree that Pre-release features are provided on an “as-is” basis, and that they are provided without any indemnification, support, warranties, or representation of any kind.

**Feedback:** Feedback is highly encouraged and important for guiding Temporal feature development.
We encourage you to share your experience so that you can influence the future direction of Temporal.

**Availability:** Temporal may modify features before they become Generally Available, or may even decide to remove them.
This means there is no guarantee that a new feature will become Generally Available.
A Pre-release feature can be deprecated at any time.

Pre-release features may be disabled by default, and can be enabled via configuration.
Temporal Cloud customers can contact the Temporal account team or [Temporal Support Team](/cloud/support#support-ticket) to gain Pre-release access.

## Public Preview {#public-preview}

**Access:** New features in Public preview are available to everyone.

**Classification:** Features in public preview may undergo further development and testing before they are made Generally Available.
These features are being refined and are recommended for production usage.

**Feedback:** Temporal users are invited to share feedback via the [Community Slack](http://t.mp/slack), by reaching out directly to the Temporal team at product@temporal.io, or by creating issues in the relevant [GitHub repository](https://github.com/temporalio).
Temporal also encourages Temporal Cloud users to submit feedback via [support ticket](/cloud/support#support-ticket).
This feedback will assist in guiding the improvements for General Availability.

**Availability:** New Features in Public Preview may evolve.
The APIs may undergo changes; however, Temporal's goal is to maintain backward compatibility.

## General Availability {#general-availability}

**Access:** Features in General Availability are available to everyone.

**Classification:** The feature is now fully developed, tested, and available for use without further anticipated changes.

**Feedback:** Temporal users are invited to share feedback via the [Community Slack](http://t.mp/slack), by reaching out directly to the Temporal team at product@temporal.io, or by creating issues in the relevant [GitHub repository](https://github.com/temporalio).

**Availability:** Features in General Availability are released with stable APIs and recommended for production use with a committed SLA.

:::info Exceptions

There may be exceptions for different features, but this is the typical expectation.
Any variation will be documented.

:::

---

## Schedules - Temporal feature

Temporal Schedules is a feature that allows you to "schedule" Temporal Workflows at specified times or intervals, adjusting for peak use.

It offers a flexible way to automate and manage your Temporal Workflows, ensuring your business processes run smoothly and efficiently especially when handling time-sensitive tasks.

1. **Automate Repetitive Tasks:**
   Schedules automate repetitive tasks, reducing manual intervention and ensuring timely execution of business processes.
2. **Enhanced Workflow Control and Observability:**
   Gain complete control over your automation processes. With Schedules, you can create, backfill, delete, describe, list, pause, trigger, and update Workflow Executions.
3. **Flexible Timing:**
   Schedule Workflow Executions to run at regular intervals or specific future times, ensuring they execute precisely when needed.
4. **Reliable and Scalable:**
   Designed for reliability and scalability, Temporal Schedules handle the complexities of distributed systems while ensuring your Workflows run as intended, even during failures.
5. **Eliminate External Dependencies:**
   Schedules remove the need to integrate external scheduling systems.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/schedules" text="Schedules using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/schedules" text="Schedules using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/schedules" text="Schedules using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/schedules" text="Schedules using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/schedules" text="Schedules using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/schedules" text="Schedules using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

---

## Temporal Nexus - Temporal feature

:::tip SUPPORT, STABILITY, and DEPENDENCY INFO

Temporal Nexus is now [Generally Available](/evaluate/development-production-features/release-stages#general-availability) for [Temporal Cloud](/cloud/nexus) and [self-hosted deployments](/production-deployment/self-hosted-guide/nexus).

:::

## Connect Temporal Applications

Nexus allows you to connect Temporal Applications across (and within) isolated Namespaces.
This provides all the benefits of Durable Execution across team and application boundaries with improved modularity, security, debugging, and fault isolation.
Nexus supports cross-team, cross-domain, cross-namespace, multi-region, and multi-cloud use cases.

## Why use Nexus?

Unlike other forms of inter-service communication, Nexus combines a familiar programming model with the resiliency of the Temporal Platform and its queue-based Worker architecture.

### Benefits

- **Integrated Temporal experience** \- with improved security, observability, and reliability.
- **Microservice contracts** \- suitable for sharing across teams or domains.
- **Abstract and share underlying Temporal primitives** \- like Workflows, Signals, or Updates.
- **At-least-once execution guarantees** \- with support for exactly-once execution using Workflow policy.
- **Improved security and blast-radius isolation** \- with separate Namespaces for each team or domain.
- **Modular design** \- for streamlined multi-team development.
- **Custom handlers** \- that execute arbitrary code.
- **No error-prone boilerplate code** \- with Temporal SDK support to build and use Nexus Services.
- **Same queue-based Worker architecture** \- so no bespoke service deployments are needed.

### Use cases

- **Cross-team, cross-domain, and cross-namespace** \-
  Nexus is purpose-built to connect Temporal Applications within and across Namespaces.
  It addresses the limitations of Child Workflows, Activity Wrappers, and bespoke APIs that target a remote Namespace; such as leaking implementation details, second-class observability, overly-permissive security, and error-prone boilerplate code.
  Nexus has a streamlined Temporal developer experience, reliable execution, and integrated observability.

- **Share a subset of a Temporal Application** \-
  Abstract and share a subset of an Application as a Nexus Service.
  Nexus Operations can span any length of execution, be synchronous or asynchronous, and be implemented with Temporal primitives, like Workflows, Signals, or Updates.
  Expose Services on a Nexus Endpoint for others to use and secure them with access control policies.
  Nexus Endpoints decouple callers from handlers, so teams can operate more autonomously.

- **Modular design for growth** \-
  Temporal Nexus enables a modular application design that can evolve as you grow.
  Start with Nexus Services in a monolithic Namespace and move Services to separate Namespaces with small configuration changes.

- **Smaller failure domains** \- When teams operate in the same monolithic Namespace, everything is available to everyone, and mis-behaving Workers can trigger rate limits that affect all teams operating in that monolithic Namespace.
  Nexus enables each team to have their own Namespace for improved security, troubleshooting, and fault isolation.

- **Multi-region** \-
  Nexus requests in Temporal Cloud are routed across a global mTLS-secured Envoy mesh within and across AWS and GCP.
  Built-in Nexus Machinery provides reliable at-least-once execution and Workflow policy can deduplicate requests for exactly-once execution, even across multi-region boundaries.

### Key features

- **Familiar developer experience** \-
  Temporal SDKs provide an integrated way to build and use Nexus Services.
  - Use Nexus Services from a caller Workflow.
  - Run Nexus Service handlers in a Worker, often the same Worker as underlying Temporal primitives.
  - Implement long-running asynchronous Nexus Operations as Workflows.
  - Handle low-latency synchronous Nexus Operations with Temporal primitives or arbitrary code.
  - Execute Operations with at-least-once semantics by default, and exactly-once semantics using Workflow ID reuse policies.

- **Nexus Endpoints with a queue-based Worker architecture** \- Nexus Endpoints are a reverse proxy for Nexus Services.
  - Connect callers and handlers through Nexus Endpoints, for looser coupling.
  - Manage Endpoints in the Nexus Registry using the UI, CLI, or Cloud Ops API.
  - Use a Nexus Endpoint by name, which routes requests to an upstream target Namespace and Task Queue.
  - Handle Nexus requests in a Nexus Worker by polling an Endpoint's target Task Queue, with automatic load balancing.
  - Streamline operations by running Nexus Services in existing queue-based Workers.

- **Built-in Nexus Machinery** \-
  Execution guarantees are provided with built-in Nexus Machinery.
  - Execute Nexus Operations with reliable state-machine-based invocation and completion callbacks.
  - Guarantee atomic handoff from Workflow Event History to Nexus Operation state machines.
  - Ensure reliable execution with automatic retries, rate limiting, concurrency limiting, and circuit breaking.

- **Integrated observability** \-
  Execution debugging and observability is integrated into the Temporal Platform.
  - View Nexus Operation lifecycle and error info in Workflow Event History.
  - Debug across Namespaces with bi-directional linking.
  - Generate metrics, traces, and logs.

- **Improved blast radius isolation** \-
  Separate Namespaces isolate underlying Workers and sensitive Workflow state.
  - Limit direct access to a Namespace, while exposing Nexus Endpoints for others to use.
  - Isolate misbehaving Workers that affect rate limits for all Workers in a Namespace.
  - Avoid leaking Workflow implementation details to external callers.

- **Enhanced security and connectivity** \-
  Temporal Cloud provides integrated Nexus access controls and multi-region routing.
  - Connect Applications across Namespaces in an Account with Temporal's private mTLS-secured Envoy mesh.
  - Multi-region connectivity within and across AWS and GCP.
  - Restrict which callers can use a Nexus Endpoint, with built-in Endpoint access controls.
  - Stream audit logs including Nexus Registry actions to create, update, or delete Endpoints.

## Learn more

To connect with the Nexus community, join the [#nexus](https://temporalio.slack.com/archives/C07LQN0JK9B) channel in [Temporal Slack](https://t.mp/slack).

<RelatedReadContainer>
  <RelatedReadItem path="https://temporal.io/blog/temporal-nexus-now-available" text="Nexus is now generally available - blog post" archetype="blog" />
  <RelatedReadItem path="https://youtu.be/qqc2vsv1mrU?feature=shared&t=2082" text="Nexus keynote & demo - Replay video" archetype="replay-talk" />
  <RelatedReadItem path="https://www.youtube.com/watch?v=izR9dQ_eIe4" text="Nexus deep dive - Replay video" archetype="replay-talk" />
  <RelatedReadItem path="/nexus" text="Nexus concepts and getting started" archetype="encyclopedia" />
  <RelatedReadItem path="/develop/go/nexus" text="Go SDK - Nexus quick start and code sample" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/nexus" text="Java SDK - Nexus quick start and code sample" archetype="feature-guide" />
  <RelatedReadItem path="/cloud/nexus" text="Production deployment in Temporal Cloud" archetype="feature-guide" />
  <RelatedReadItem path="/production-deployment/self-hosted-guide/nexus" text="Self-hosted deployment" archetype="feature-guide" />
</RelatedReadContainer>

---

## Temporal Testing Suite - Temporal feature

In the context of Temporal, you can create these types of automated tests:

1. End-to-end: Running a Temporal Server and Worker with all its Workflows and Activities; starting and interacting with Workflows from a Client.
2. Integration: Anything between end-to-end and unit testing.
   Running Activities with mocked Context and other SDK imports (and usually network requests).
   Running Workers with mock Activities, and using a Client to start Workflows.
   Running Workflows with mocked SDK imports.
3. Unit: Running a piece of Workflow or Activity code and mocking any code it calls.

Jump straight to a Temporal SDK feature guide.

<RelatedReadContainer>
    <RelatedReadItem path="/develop/go/testing-suite" text="Testing using the Go SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/java/testing-suite" text="Testing using the Java SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/php/testing-suite" text="Testing using the PHP SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/python/testing-suite" text="Testing using the Python SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/typescript/testing-suite" text="Testing using the TypeScript SDK" archetype="feature-guide" />
    <RelatedReadItem path="/develop/dotnet/testing-suite" text="Testing using the .NET SDK" archetype="feature-guide" />
</RelatedReadContainer>

---

## Child Workflows - Temporal feature

In Temporal, **Child Workflows** enable applications to achieve another level of composability when it comes to throughput.

The following example scenarios are a few reasons to use this feature:

- To create a separate service that can be invoked from multiple other services or applications.
- To partition a step into smaller chunks.
- To manage a dedicated resource and guarantee uniqueness.
- To execute logic periodically without overwhelming the parent business process.

See the SDK feature guides for implementation details:

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/child-workflows" text="Go SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/child-workflows" text="Java SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/php/child-workflows" text="PHP SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/child-workflows" text="Python SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/child-workflows" text="TypeScript SDK Child Workflow feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/child-workflows" text=".NET SDK Child Workflow feature guide" archetype="feature-guide" />
</RelatedReadContainer>

For a deep dive into Child Workflows see the [Child Workflows Encyclopedia page](/child-workflows).

---

## Workflow message passing - Temporal feature

Need to interact with your Workflow from outside of it? Think about use cases like these:

- Your shipment-tracking Workflow needs to know when the item leaves the warehouse and is loaded into their truck. **Signal** your Workflow when the truck driver scans the barcode.
- Folks in your company want to track the progress of their data migration Workflows. **Query** your running batch Workflow to get the data for the progress bar.
- Your eCommerce shopping cart Workflow needs to know when a new item is added. **Update** it to add the item and receive back the current items to render.

Temporal provides Signals, Queries, and Updates to allow rich interactivity with your running Workflows.

**Signals**: Signal to send messages asynchronously to a running Workflow, changing its state or controlling its flow in real-time.

**Queries**: Query to check the progress of your Workflow or debug the internal state in real-time.

**Updates**: Update to send synchronous requests to your Workflow and track it in real-time.

To learn more about using these powerful primitives, see our encyclopedia Entry:

<RelatedReadContainer>
  <RelatedReadItem path="/encyclopedia/workflow-message-passing" text="Workflow message passing (Signals, Queries, & Updates)" archetype="encyclopedia" />
</RelatedReadContainer>

For a deeper dive into Workflow message passing, enroll in one of [our courses](https://learn.temporal.io/courses/interacting_with_workflows).

If you want to jump to straight to implementation details, see the SDK feature guides.

<RelatedReadContainer>
  <RelatedReadItem path="/develop/go/message-passing" text="Go SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/java/message-passing" text="Java SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/python/message-passing" text="Python SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/typescript/message-passing" text="TypeScript SDK Workflow message passing feature guide" archetype="feature-guide" />
  <RelatedReadItem path="/develop/dotnet/message-passing" text=".NET SDK Workflow message passing feature guide" archetype="feature-guide" />
</RelatedReadContainer>

---

## Temporal Use Cases and Design Patterns

This page provides an overview of how leading organizations leverage Temporal to solve real-world problems, general use cases, and architectural design patterns.

## Use Cases of Temporal in Production

Here are some examples where Temporal is most impactful and running in production at large organizations today. For more examples, see our [Temporal Use Cases](https://temporal.io/in-use) page.

### Transactions

Actions or activities involving two or more parties or things that reciprocally affect or influence each other. For example:

- [Payment processing at Stripe](https://temporal.io/resources/on-demand/stripe)
- [Money movement at Coinbase](https://temporal.io/in-use/coinbase)
- [Content management at Box](https://temporal.io/resources/case-studies/box)

### Business processes

A sequence of tasks that find their end in the delivery of a service or product to a client. For example:

- [Bookings at Turo](https://temporal.io/replay/videos/temporal-adoption-and-integration-at-turo)
- [Orders/logistics at Maersk](https://temporal.io/replay/videos/building-a-time-machine-for-the-logistics-industry)
- [Marketing Campaigns at AirBnb](https://medium.com/airbnb-engineering/journey-platform-a-low-code-tool-for-creating-interactive-user-workflows-9954f51fa3f8)
- [Human-in-the-loop at Checkr](https://temporal.io/in-use/checkr)

### Entity lifecycle

Complex long-running processes that accumulate state over time. For example:

- [Mortgage underwriting applications at ANZ](https://temporal.io/in-use/anz-story)
- [Menu versioning at Yum! Brands](https://temporal.io/replay-2023/videos/synchronizing-concurrent-workflows)

### Operations

An automated method for getting a repeatable, mundane task accomplished. For example:

- [Infrastructure services at DataDog](https://www.youtube.com/watch?v=Hz7ZZzafBoE)
- [Custom CI/CD at Netflix](https://temporal.io/replay-2023/videos/actor-workflows-reliably-orchestrating-thousands-of-flink-clusters-at)

### AI / ML and Data Engineering

AI and ML developers face challenges in system orchestration, such as managing complex data pipelines and job coordination across GPU resources.
Temporal's code-first approach helps build reliable services faster, making it popular among AI companies. For example:

- [Orchestrating video processing at Descript](https://temporal.io/blog/ai-ml-and-data-engineering-workflows-with-temporal#descript)
- [Automating data pipelines at Neosync](https://temporal.io/blog/ai-ml-and-data-engineering-workflows-with-temporal#neosync)

## General Use Cases

### Human in the Loop

"Human in the Loop" systems require human interaction for certain steps, such as customer onboarding, forms, or invoice approval.
These are event driven system with humans generating events, and may be challenging to implement due to timing or unreliable connections between the human to the rest of the system.
They can use schedules and timers to prompt for user input.

**Example**: [Background checks example using the Go SDK](https://learn.temporal.io/examples/go/background-checks/).

**Code Sample**: [Candidate acceptance example prompting for a response](https://learn.temporal.io/examples/go/background-checks/candidate-acceptance)

### Polyglot Systems

Modern development teams often work with different programming languages based on their expertise and project requirements. Temporal supports this through built-in multi-language capabilities, allowing teams to continue using their preferred languages while working together.

The example below showcases how Workflow Executions, written in different languages, can send messages to each other. Go, Java, PHP, and TypeScript SDKs are represented in this sample. It also shows how to properly propagate errors, including how to do so across Workflows written in different languages.

**Example**: [Polyglot example](https://github.com/temporalio/temporal-polyglot).

### Long Running Tasks

This use case is particularly relevant for scenarios like shopping cart Workflows in an eCommerce app, where you can handling long-running tasks efficiently without managing state in a separate database.
It processes one message at a time, ensuring each message is processed only once.

This approach addresses issues that can arise with long message processing times, which in other systems might cause consumer failover (typically with a default 5-minute message poll timeout) and potentially result in duplicate message processing by multiple consumers.
Temporal's ability to handle extended task durations makes it well-suited for such scenarios.
The [heartbeat](/encyclopedia/detecting-activity-failures#activity-heartbeat) feature allows you to know that an activity is still working, providing insight into the progress of long-running processes.

**Example**: [eCommerce example](https://learn.temporal.io/tutorials/go/build-an-ecommerce-app/).

**Code Sample**: [Temporal eCommerce](https://github.com/temporalio/temporal-ecommerce)

## Design Patterns

### Saga

The Saga pattern is a design pattern used to manage and handle failures in complex Workflows by breaking down a transaction into a series of smaller, manageable sub-transactions.
If a step in the Workflow fails, the Saga pattern compensates for this failure by executing specific actions to undo the previous steps.
This ensures that even in the event of a failure, the system can revert to a consistent state.

**Examples:**

- [Build a trip booking application in Python](https://learn.temporal.io/tutorials/python/trip-booking-app/).
- [Saga Pattern with Temporal Whitepaper](https://pages.temporal.io/download-saga-pattern-made-easy)
- [To choreograph or orchestrate your saga, that is the question](https://temporal.io/blog/to-choreograph-or-orchestrate-your-saga-that-is-the-question)
- [Saga Webinar](https://pages.temporal.io/on-demand-webinar-what-is-a-saga.html)

### State Machine

A state machine is a software design pattern used to modify a system’s behavior in response to changes in its state.
While state machines are widely used in software development, applying them to complex business processes can be a difficult undertaking.
Temporal simplifies the complexity of state machines by providing a structured approach to workflow development, avoiding the intricate state management code required for state machines.

**Example**: [State Machine Simplified Whitepaper](https://pages.temporal.io/download-state-machines-simplified.html)

:::tip

If you're interested in code to help get you started, check out our [Temporal Example Applications](https://learn.temporal.io/examples/), [Getting Starting Tutorials](https://learn.temporal.io/getting_started/), or [Project-based Tutorials](https://learn.temporal.io/tutorials/).

:::
